{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-gram addr2vec\n",
    "\n",
    "In this notebook, I'll convert addresses to vectors through TensorFlow and understand the ability to correct for mistyping.\n",
    "\n",
    "\n",
    "## Word embeddings\n",
    "\n",
    "When you're dealing with words in text, you end up with tens of thousands of classes to predict, one for each word. Trying to one-hot encode these words is massively inefficient, you'll have one element set to 1 and the other 50,000 set to 0. The matrix multiplication going into the first hidden layer will have almost all of the resulting values be zero. This a huge waste of computation. \n",
    "\n",
    "![one-hot encodings](assets/one_hot_encoding.png)\n",
    "\n",
    "To solve this problem and greatly increase the efficiency of our networks, we use what are called embeddings. Embeddings are just a fully connected layer like you've seen before. We call this layer the embedding layer and the weights are embedding weights. We skip the multiplication into the embedding layer by instead directly grabbing the hidden layer values from the weight matrix. We can do this because the multiplication of a one-hot encoded vector with a matrix returns the row of the matrix corresponding the index of the \"on\" input unit.\n",
    "\n",
    "![lookup](assets/lookup_matrix.png)\n",
    "\n",
    "Instead of doing the matrix multiplication, we use the weight matrix as a lookup table. We encode the words as integers, for example \"heart\" is encoded as 958, \"mind\" as 18094. Then to get hidden layer values for \"heart\", you just take the 958th row of the embedding matrix. This process is called an **embedding lookup** and the number of hidden units is the **embedding dimension**.\n",
    "\n",
    "<img src='assets/tokenize_lookup.png' width=500>\n",
    " \n",
    "There is nothing magical going on here. The embedding lookup table is just a weight matrix. The embedding layer is just a hidden layer. The lookup is just a shortcut for the matrix multiplication. The lookup table is trained just like any weight matrix as well.\n",
    "\n",
    "Embeddings aren't only used for words of course. You can use them for any model where you have a massive number of classes. A particular type of model called **Word2Vec** uses the embedding layer to find vector representations of words that contain semantic meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the [openaddress US North East dataset](https://s3.amazonaws.com/data.openaddresses.io/openaddr-collected-us_northeast.zip), and extract onto 'openaddr' directory if not found. read the csv files and load address dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data: LON                 -69.7958\n",
      "LAT                  44.6535\n",
      "NUMBER                  1033\n",
      "STREET             E Pond Rd\n",
      "UNIT                     NaN\n",
      "CITY                     NaN\n",
      "DISTRICT            Somerset\n",
      "REGION                    ME\n",
      "POSTCODE                4978\n",
      "ID                       NaN\n",
      "HASH        8bbbfb5152ee2563\n",
      "Name: 2, dtype: object\n",
      "Example data: LON                   -80.0287\n",
      "LAT                    40.7328\n",
      "NUMBER                    1260\n",
      "STREET      MARS-EVANS CITY RD\n",
      "UNIT                       NaN\n",
      "CITY                 ADAMS TWP\n",
      "DISTRICT                   NaN\n",
      "REGION                     NaN\n",
      "POSTCODE                   NaN\n",
      "ID                         NaN\n",
      "HASH          1b447375afa847e4\n",
      "Name: 2, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3,4,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "dataset_folder_path = 'openaddr'\n",
    "dataset_filename = 'openaddr-collected-us_northeast.zip'\n",
    "dataset_name = 'Openaddress Dataset'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/data.openaddresses.io/openaddr-collected-us_northeast.zip',\n",
    "            dataset_filename,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\n",
    "\n",
    "\n",
    "id_to_address = {}\n",
    "address_to_id = {}\n",
    "i = 0\n",
    "for state in os.listdir('./openaddr/us'):\n",
    "    \n",
    "    for filename in glob.glob('./openaddr/us/{}/*.csv'.format(state)):\n",
    "        csv = pd.read_csv(filename)\n",
    "        if i == 0:\n",
    "            print(\"Example data: {}\".format(csv.iloc[2]))\n",
    "\n",
    "        stack = np.stack((csv['CITY'],), axis=-1)\n",
    "        for j in stack:\n",
    "            addr = \" \".join([str(k).lower()\n",
    "                             for k in j if not isinstance(k, type(np.nan))])\n",
    "            if addr not in address_to_id and addr != '' and addr != ' ':\n",
    "                id_to_address[i] = addr\n",
    "                address_to_id[addr] = i\n",
    "                i += 1\n",
    "\n",
    "del csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The addresses have all been converted to lower case and only city names are being used and tested for correction cases. vocabulary is the letters from which the city is made up of. We vectorise by counting the number of letters and normalizing to the total number between zero and one. Visualisations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adams twp', 'cranberry twp', 'middlesex twp', 'mars boro', 'allegheny twp', 'bruin boro', 'brady twp', 'slippery rock twp', 'buffalo twp', 'winfield twp', 'butler city', 'butler twp', 'penn twp', 'callery boro', 'center twp', 'clay twp', 'cherry twp', 'cherry valley boro', 'chicora boro', 'clearfield twp', 'donegal twp', 'summit twp', 'clinton twp', 'connoq boro', 'forward twp', 'connoq twp', 'lancaster twp', 'seven fields boro', 'fairview twp', 'east butler boro']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in address_to_id.keys()][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addresses: 4155\n",
      "Total unique letters: 45\n"
     ]
    }
   ],
   "source": [
    "print(\"Total addresses: {}\".format(len(address_to_id)))\n",
    "\n",
    "vocab_to_id = {}\n",
    "int_to_vocab = {}\n",
    "idx = 0\n",
    "for address in address_to_id.keys():\n",
    "    for j in range(len(address)):\n",
    "        if address[j] not in vocab_to_id:\n",
    "            vocab_to_id[address[j]] = idx\n",
    "            int_to_vocab[idx] = address[j]\n",
    "            idx += 1\n",
    "\n",
    "vocab_size = len(vocab_to_id)\n",
    "print(\"Total unique letters: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example feature vector and label:\n",
      "[1.001e+00 1.000e-03 1.001e+00 1.001e+00 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.001e+00 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "labels_to_id = {}\n",
    "count = 0\n",
    "\n",
    "for address, idx in address_to_id.items():\n",
    "    X = np.zeros(vocab_size)\n",
    "    Y = np.zeros(len(address_to_id))\n",
    "    for j in range(len(address)):\n",
    "        X[vocab_to_id[address[j]]] += 1 \n",
    "    \n",
    "    # normalize input sizes \n",
    "    X = ((X - X.min()) / (X.max() - X.min())) + 0.001\n",
    "    \n",
    "    features.append(X)\n",
    "    \n",
    "    labels_to_id[idx] = count\n",
    "    Y[idx] = 1\n",
    "    labels.append(Y)\n",
    "    count += 1\n",
    "    \n",
    "print(\"Example feature vector and label:\")\n",
    "print(features[500])\n",
    "print(labels[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 41, 32)\n",
      "(?, 37, 64)\n",
      "(?, 33, 128)\n",
      "(?, 33)\n",
      "(?, 500)\n",
      "(?, 4155)\n"
     ]
    }
   ],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 500\n",
    "alpha = 0.1\n",
    "\n",
    "# Input and target placeholders\n",
    "inp_shape = vocab_size\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32 ,(None, inp_shape))\n",
    "targets_ = tf.placeholder(tf.float32 ,(None, len(address_to_id)))\n",
    "\n",
    "# Input layer is 45\n",
    "x1 = tf.expand_dims(inputs_, axis=-1)\n",
    "x1 = tf.layers.conv1d(x1, filters=32, kernel_size=5, strides=1, padding='valid')\n",
    "x1 = tf.nn.dropout(x1, 0.5)\n",
    "relu1 = tf.maximum(alpha * x1, x1)\n",
    "print(relu1.shape)\n",
    "# 41x32\n",
    "\n",
    "x2 = tf.layers.conv1d(relu1, filters=64, kernel_size=5, strides=1, padding='valid')\n",
    "x2 = tf.nn.dropout(x2, 0.5)\n",
    "relu2 = tf.maximum(alpha * x2, x2)\n",
    "print(relu2.shape)\n",
    "# 37x64\n",
    "\n",
    "x3 = tf.layers.conv1d(relu2, filters=128, kernel_size=5, strides=1, padding='valid')\n",
    "x3 = tf.nn.dropout(x3, 0.5)\n",
    "relu3 = tf.maximum(alpha * x3, x3)\n",
    "print(relu3.shape)\n",
    "# 33x128\n",
    "\n",
    "# global average pooling layer\n",
    "first_h_dim = tf.reduce_mean(relu3, axis=2)\n",
    "print(first_h_dim.shape)\n",
    "\n",
    "# dense layer\n",
    "encoded = tf.layers.dense(first_h_dim, encoding_dim)\n",
    "relu4 = tf.maximum(alpha * encoded, encoded)\n",
    "print(relu4.shape)\n",
    "\n",
    "# Output layer logits\n",
    "logits = tf.layers.dense(relu4, len(address_to_id), activation=None)\n",
    "print(logits.shape)\n",
    "# Sigmoid output from logits\n",
    "#decoded = tf.nn.sigmoid(logits, name='outputs')\n",
    "\n",
    "# loss = tf.log(tf.reduce_sum(tf.abs(targets_ - logits)) + 1)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=targets_, logits=logits)\n",
    "# Mean of the loss\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500... Training loss: 8.3324\n",
      "Epoch: 1/500... Training loss: 8.3323\n",
      "Epoch: 1/500... Training loss: 8.3321\n",
      "Epoch: 1/500... Training loss: 8.3325\n",
      "Epoch: 1/500... Training loss: 8.3323\n",
      "Epoch: 1/500... Training loss: 8.3330\n",
      "Epoch: 1/500... Training loss: 8.3328\n",
      "Epoch: 1/500... Training loss: 8.3330\n",
      "Epoch: 1/500... Training loss: 8.3335\n",
      "Epoch: 1/500... Training loss: 8.3336\n",
      "Epoch: 1/500... Training loss: 8.3339\n",
      "Epoch: 1/500... Training loss: 8.3342\n",
      "Epoch: 1/500... Training loss: 8.3343\n",
      "Epoch: 1/500... Training loss: 8.3346\n",
      "Epoch: 1/500... Training loss: 8.3348\n",
      "Epoch: 1/500... Training loss: 8.3349\n",
      "Epoch: 1/500... Training loss: 8.3351\n",
      "Epoch: 1/500... Training loss: 8.3353\n",
      "Epoch: 1/500... Training loss: 8.3353\n",
      "Epoch: 1/500... Training loss: 8.3357\n",
      "Epoch: 1/500... Training loss: 8.3357\n",
      "Epoch: 1/500... Training loss: 8.3361\n",
      "Epoch: 1/500... Training loss: 8.3363\n",
      "Epoch: 1/500... Training loss: 8.3366\n",
      "Epoch: 1/500... Training loss: 8.3368\n",
      "Epoch: 1/500... Training loss: 8.3371\n",
      "Epoch: 1/500... Training loss: 8.3375\n",
      "Epoch: 1/500... Training loss: 8.3378\n",
      "Epoch: 1/500... Training loss: 8.3386\n",
      "Epoch: 1/500... Training loss: 8.3388\n",
      "Epoch: 1/500... Training loss: 8.3394\n",
      "Epoch: 2/500... Training loss: 8.3312\n",
      "Epoch: 2/500... Training loss: 8.3311\n",
      "Epoch: 2/500... Training loss: 8.3320\n",
      "Epoch: 2/500... Training loss: 8.3316\n",
      "Epoch: 2/500... Training loss: 8.3319\n",
      "Epoch: 2/500... Training loss: 8.3319\n",
      "Epoch: 2/500... Training loss: 8.3319\n",
      "Epoch: 2/500... Training loss: 8.3322\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3322\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3325\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3325\n",
      "Epoch: 2/500... Training loss: 8.3327\n",
      "Epoch: 2/500... Training loss: 8.3331\n",
      "Epoch: 2/500... Training loss: 8.3335\n",
      "Epoch: 2/500... Training loss: 8.3340\n",
      "Epoch: 2/500... Training loss: 8.3345\n",
      "Epoch: 2/500... Training loss: 8.3351\n",
      "Epoch: 2/500... Training loss: 8.3356\n",
      "Epoch: 2/500... Training loss: 8.3362\n",
      "Epoch: 2/500... Training loss: 8.3367\n",
      "Epoch: 2/500... Training loss: 8.3373\n",
      "Epoch: 2/500... Training loss: 8.3378\n",
      "Epoch: 2/500... Training loss: 8.3383\n",
      "Epoch: 2/500... Training loss: 8.3388\n",
      "Epoch: 2/500... Training loss: 8.3392\n",
      "Epoch: 2/500... Training loss: 8.3397\n",
      "Epoch: 3/500... Training loss: 8.3237\n",
      "Epoch: 3/500... Training loss: 8.3246\n",
      "Epoch: 3/500... Training loss: 8.3252\n",
      "Epoch: 3/500... Training loss: 8.3257\n",
      "Epoch: 3/500... Training loss: 8.3262\n",
      "Epoch: 3/500... Training loss: 8.3267\n",
      "Epoch: 3/500... Training loss: 8.3272\n",
      "Epoch: 3/500... Training loss: 8.3276\n",
      "Epoch: 3/500... Training loss: 8.3281\n",
      "Epoch: 3/500... Training loss: 8.3285\n",
      "Epoch: 3/500... Training loss: 8.3289\n",
      "Epoch: 3/500... Training loss: 8.3293\n",
      "Epoch: 3/500... Training loss: 8.3297\n",
      "Epoch: 3/500... Training loss: 8.3301\n",
      "Epoch: 3/500... Training loss: 8.3305\n",
      "Epoch: 3/500... Training loss: 8.3310\n",
      "Epoch: 3/500... Training loss: 8.3314\n",
      "Epoch: 3/500... Training loss: 8.3320\n",
      "Epoch: 3/500... Training loss: 8.3326\n",
      "Epoch: 3/500... Training loss: 8.3332\n",
      "Epoch: 3/500... Training loss: 8.3338\n",
      "Epoch: 3/500... Training loss: 8.3344\n",
      "Epoch: 3/500... Training loss: 8.3350\n",
      "Epoch: 3/500... Training loss: 8.3357\n",
      "Epoch: 3/500... Training loss: 8.3362\n",
      "Epoch: 3/500... Training loss: 8.3367\n",
      "Epoch: 3/500... Training loss: 8.3372\n",
      "Epoch: 3/500... Training loss: 8.3377\n",
      "Epoch: 3/500... Training loss: 8.3382\n",
      "Epoch: 3/500... Training loss: 8.3386\n",
      "Epoch: 3/500... Training loss: 8.3391\n",
      "Epoch: 4/500... Training loss: 8.3231\n",
      "Epoch: 4/500... Training loss: 8.3239\n",
      "Epoch: 4/500... Training loss: 8.3245\n",
      "Epoch: 4/500... Training loss: 8.3250\n",
      "Epoch: 4/500... Training loss: 8.3256\n",
      "Epoch: 4/500... Training loss: 8.3260\n",
      "Epoch: 4/500... Training loss: 8.3265\n",
      "Epoch: 4/500... Training loss: 8.3270\n",
      "Epoch: 4/500... Training loss: 8.3274\n",
      "Epoch: 4/500... Training loss: 8.3278\n",
      "Epoch: 4/500... Training loss: 8.3283\n",
      "Epoch: 4/500... Training loss: 8.3286\n",
      "Epoch: 4/500... Training loss: 8.3290\n",
      "Epoch: 4/500... Training loss: 8.3294\n",
      "Epoch: 4/500... Training loss: 8.3299\n",
      "Epoch: 4/500... Training loss: 8.3304\n",
      "Epoch: 4/500... Training loss: 8.3308\n",
      "Epoch: 4/500... Training loss: 8.3314\n",
      "Epoch: 4/500... Training loss: 8.3319\n",
      "Epoch: 4/500... Training loss: 8.3325\n",
      "Epoch: 4/500... Training loss: 8.3331\n",
      "Epoch: 4/500... Training loss: 8.3337\n",
      "Epoch: 4/500... Training loss: 8.3343\n",
      "Epoch: 4/500... Training loss: 8.3349\n",
      "Epoch: 4/500... Training loss: 8.3354\n",
      "Epoch: 4/500... Training loss: 8.3360\n",
      "Epoch: 4/500... Training loss: 8.3365\n",
      "Epoch: 4/500... Training loss: 8.3370\n",
      "Epoch: 4/500... Training loss: 8.3374\n",
      "Epoch: 4/500... Training loss: 8.3379\n",
      "Epoch: 4/500... Training loss: 8.3383\n",
      "Epoch: 5/500... Training loss: 8.3224\n",
      "Epoch: 5/500... Training loss: 8.3232\n",
      "Epoch: 5/500... Training loss: 8.3238\n",
      "Epoch: 5/500... Training loss: 8.3243\n",
      "Epoch: 5/500... Training loss: 8.3249\n",
      "Epoch: 5/500... Training loss: 8.3253\n",
      "Epoch: 5/500... Training loss: 8.3258\n",
      "Epoch: 5/500... Training loss: 8.3263\n",
      "Epoch: 5/500... Training loss: 8.3267\n",
      "Epoch: 5/500... Training loss: 8.3271\n",
      "Epoch: 5/500... Training loss: 8.3276\n",
      "Epoch: 5/500... Training loss: 8.3280\n",
      "Epoch: 5/500... Training loss: 8.3284\n",
      "Epoch: 5/500... Training loss: 8.3288\n",
      "Epoch: 5/500... Training loss: 8.3292\n",
      "Epoch: 5/500... Training loss: 8.3297\n",
      "Epoch: 5/500... Training loss: 8.3301\n",
      "Epoch: 5/500... Training loss: 8.3307\n",
      "Epoch: 5/500... Training loss: 8.3313\n",
      "Epoch: 5/500... Training loss: 8.3318\n",
      "Epoch: 5/500... Training loss: 8.3324\n",
      "Epoch: 5/500... Training loss: 8.3330\n",
      "Epoch: 5/500... Training loss: 8.3336\n",
      "Epoch: 5/500... Training loss: 8.3342\n",
      "Epoch: 5/500... Training loss: 8.3348\n",
      "Epoch: 5/500... Training loss: 8.3353\n",
      "Epoch: 5/500... Training loss: 8.3358\n",
      "Epoch: 5/500... Training loss: 8.3363\n",
      "Epoch: 5/500... Training loss: 8.3367\n",
      "Epoch: 5/500... Training loss: 8.3371\n",
      "Epoch: 5/500... Training loss: 8.3376\n",
      "Epoch: 6/500... Training loss: 8.3216\n",
      "Epoch: 6/500... Training loss: 8.3224\n",
      "Epoch: 6/500... Training loss: 8.3230\n",
      "Epoch: 6/500... Training loss: 8.3236\n",
      "Epoch: 6/500... Training loss: 8.3242\n",
      "Epoch: 6/500... Training loss: 8.3246\n",
      "Epoch: 6/500... Training loss: 8.3251\n",
      "Epoch: 6/500... Training loss: 8.3256\n",
      "Epoch: 6/500... Training loss: 8.3260\n",
      "Epoch: 6/500... Training loss: 8.3264\n",
      "Epoch: 6/500... Training loss: 8.3269\n",
      "Epoch: 6/500... Training loss: 8.3273\n",
      "Epoch: 6/500... Training loss: 8.3277\n",
      "Epoch: 6/500... Training loss: 8.3281\n",
      "Epoch: 6/500... Training loss: 8.3285\n",
      "Epoch: 6/500... Training loss: 8.3290\n",
      "Epoch: 6/500... Training loss: 8.3294\n",
      "Epoch: 6/500... Training loss: 8.3299\n",
      "Epoch: 6/500... Training loss: 8.3305\n",
      "Epoch: 6/500... Training loss: 8.3310\n",
      "Epoch: 6/500... Training loss: 8.3318\n",
      "Epoch: 6/500... Training loss: 8.3322\n",
      "Epoch: 6/500... Training loss: 8.3328\n",
      "Epoch: 6/500... Training loss: 8.3335\n",
      "Epoch: 6/500... Training loss: 8.3341\n",
      "Epoch: 6/500... Training loss: 8.3346\n",
      "Epoch: 6/500... Training loss: 8.3351\n",
      "Epoch: 6/500... Training loss: 8.3356\n",
      "Epoch: 6/500... Training loss: 8.3360\n",
      "Epoch: 6/500... Training loss: 8.3364\n",
      "Epoch: 6/500... Training loss: 8.3368\n",
      "Epoch: 7/500... Training loss: 8.3207\n",
      "Epoch: 7/500... Training loss: 8.3216\n",
      "Epoch: 7/500... Training loss: 8.3223\n",
      "Epoch: 7/500... Training loss: 8.3229\n",
      "Epoch: 7/500... Training loss: 8.3235\n",
      "Epoch: 7/500... Training loss: 8.3240\n",
      "Epoch: 7/500... Training loss: 8.3244\n",
      "Epoch: 7/500... Training loss: 8.3249\n",
      "Epoch: 7/500... Training loss: 8.3253\n",
      "Epoch: 7/500... Training loss: 8.3256\n",
      "Epoch: 7/500... Training loss: 8.3260\n",
      "Epoch: 7/500... Training loss: 8.3264\n",
      "Epoch: 7/500... Training loss: 8.3266\n",
      "Epoch: 7/500... Training loss: 8.3272\n",
      "Epoch: 7/500... Training loss: 8.3274\n",
      "Epoch: 7/500... Training loss: 8.3279\n",
      "Epoch: 7/500... Training loss: 8.3280\n",
      "Epoch: 7/500... Training loss: 8.3281\n",
      "Epoch: 7/500... Training loss: 8.3288\n",
      "Epoch: 7/500... Training loss: 8.3288\n",
      "Epoch: 7/500... Training loss: 8.3294\n",
      "Epoch: 7/500... Training loss: 8.3287\n",
      "Epoch: 7/500... Training loss: 8.3298\n",
      "Epoch: 7/500... Training loss: 8.3301\n",
      "Epoch: 7/500... Training loss: 8.3313\n",
      "Epoch: 7/500... Training loss: 8.3319\n",
      "Epoch: 7/500... Training loss: 8.3341\n",
      "Epoch: 7/500... Training loss: 8.3385\n",
      "Epoch: 7/500... Training loss: 8.3402\n",
      "Epoch: 7/500... Training loss: 8.3439\n",
      "Epoch: 7/500... Training loss: 8.3464\n",
      "Epoch: 8/500... Training loss: 8.3045\n",
      "Epoch: 8/500... Training loss: 8.3091\n",
      "Epoch: 8/500... Training loss: 8.3106\n",
      "Epoch: 8/500... Training loss: 8.3157\n",
      "Epoch: 8/500... Training loss: 8.3154\n",
      "Epoch: 8/500... Training loss: 8.3175\n",
      "Epoch: 8/500... Training loss: 8.3175\n",
      "Epoch: 8/500... Training loss: 8.3206\n",
      "Epoch: 8/500... Training loss: 8.3210\n",
      "Epoch: 8/500... Training loss: 8.3219\n",
      "Epoch: 8/500... Training loss: 8.3284\n",
      "Epoch: 8/500... Training loss: 8.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/500... Training loss: 8.3302\n",
      "Epoch: 8/500... Training loss: 8.3417\n",
      "Epoch: 8/500... Training loss: 8.3414\n",
      "Epoch: 8/500... Training loss: 8.3312\n",
      "Epoch: 8/500... Training loss: 8.3270\n",
      "Epoch: 8/500... Training loss: 8.3163\n",
      "Epoch: 8/500... Training loss: 8.3168\n",
      "Epoch: 8/500... Training loss: 8.3115\n",
      "Epoch: 8/500... Training loss: 8.3099\n",
      "Epoch: 8/500... Training loss: 8.3037\n",
      "Epoch: 8/500... Training loss: 8.3072\n",
      "Epoch: 8/500... Training loss: 8.2985\n",
      "Epoch: 8/500... Training loss: 8.2944\n",
      "Epoch: 8/500... Training loss: 8.2838\n",
      "Epoch: 8/500... Training loss: 8.2695\n",
      "Epoch: 8/500... Training loss: 8.2526\n",
      "Epoch: 8/500... Training loss: 8.2583\n",
      "Epoch: 8/500... Training loss: 8.2900\n",
      "Epoch: 8/500... Training loss: 8.3243\n",
      "Epoch: 9/500... Training loss: 8.0112\n",
      "Epoch: 9/500... Training loss: 8.0109\n",
      "Epoch: 9/500... Training loss: 7.9837\n",
      "Epoch: 9/500... Training loss: 8.0848\n",
      "Epoch: 9/500... Training loss: 8.0119\n",
      "Epoch: 9/500... Training loss: 8.0277\n",
      "Epoch: 9/500... Training loss: 7.9538\n",
      "Epoch: 9/500... Training loss: 7.9518\n",
      "Epoch: 9/500... Training loss: 7.9027\n",
      "Epoch: 9/500... Training loss: 7.8092\n",
      "Epoch: 9/500... Training loss: 7.8248\n",
      "Epoch: 9/500... Training loss: 7.8578\n",
      "Epoch: 9/500... Training loss: 7.8853\n",
      "Epoch: 9/500... Training loss: 8.2471\n",
      "Epoch: 9/500... Training loss: 8.3188\n",
      "Epoch: 9/500... Training loss: 8.3650\n",
      "Epoch: 9/500... Training loss: 8.4071\n",
      "Epoch: 9/500... Training loss: 8.2773\n",
      "Epoch: 9/500... Training loss: 8.3430\n",
      "Epoch: 9/500... Training loss: 8.3123\n",
      "Epoch: 9/500... Training loss: 8.2060\n",
      "Epoch: 9/500... Training loss: 8.0701\n",
      "Epoch: 9/500... Training loss: 8.1011\n",
      "Epoch: 9/500... Training loss: 8.0329\n",
      "Epoch: 9/500... Training loss: 8.0083\n",
      "Epoch: 9/500... Training loss: 7.9632\n",
      "Epoch: 9/500... Training loss: 7.9642\n",
      "Epoch: 9/500... Training loss: 7.9069\n",
      "Epoch: 9/500... Training loss: 7.9599\n",
      "Epoch: 9/500... Training loss: 7.9867\n",
      "Epoch: 9/500... Training loss: 8.0207\n",
      "Epoch: 10/500... Training loss: 7.6020\n",
      "Epoch: 10/500... Training loss: 7.6198\n",
      "Epoch: 10/500... Training loss: 7.6845\n",
      "Epoch: 10/500... Training loss: 7.7975\n",
      "Epoch: 10/500... Training loss: 7.7189\n",
      "Epoch: 10/500... Training loss: 7.6730\n",
      "Epoch: 10/500... Training loss: 7.6161\n",
      "Epoch: 10/500... Training loss: 7.5081\n",
      "Epoch: 10/500... Training loss: 7.3860\n",
      "Epoch: 10/500... Training loss: 7.0377\n",
      "Epoch: 10/500... Training loss: 6.9278\n",
      "Epoch: 10/500... Training loss: 6.7387\n",
      "Epoch: 10/500... Training loss: 6.5236\n",
      "Epoch: 10/500... Training loss: 6.7739\n",
      "Epoch: 10/500... Training loss: 6.5444\n",
      "Epoch: 10/500... Training loss: 6.6341\n",
      "Epoch: 10/500... Training loss: 6.6970\n",
      "Epoch: 10/500... Training loss: 6.5759\n",
      "Epoch: 10/500... Training loss: 7.0295\n",
      "Epoch: 10/500... Training loss: 7.3181\n",
      "Epoch: 10/500... Training loss: 7.3887\n",
      "Epoch: 10/500... Training loss: 7.3672\n",
      "Epoch: 10/500... Training loss: 7.6654\n",
      "Epoch: 10/500... Training loss: 7.6163\n",
      "Epoch: 10/500... Training loss: 7.5152\n",
      "Epoch: 10/500... Training loss: 7.4176\n",
      "Epoch: 10/500... Training loss: 7.3399\n",
      "Epoch: 10/500... Training loss: 7.2069\n",
      "Epoch: 10/500... Training loss: 7.0789\n",
      "Epoch: 10/500... Training loss: 7.0397\n",
      "Epoch: 10/500... Training loss: 7.0576\n",
      "Epoch: 11/500... Training loss: 6.6028\n",
      "Epoch: 11/500... Training loss: 6.5732\n",
      "Epoch: 11/500... Training loss: 6.7117\n",
      "Epoch: 11/500... Training loss: 6.9354\n",
      "Epoch: 11/500... Training loss: 6.8682\n",
      "Epoch: 11/500... Training loss: 6.8995\n",
      "Epoch: 11/500... Training loss: 6.9624\n",
      "Epoch: 11/500... Training loss: 6.8813\n",
      "Epoch: 11/500... Training loss: 6.9568\n",
      "Epoch: 11/500... Training loss: 6.7063\n",
      "Epoch: 11/500... Training loss: 6.8612\n",
      "Epoch: 11/500... Training loss: 6.7590\n",
      "Epoch: 11/500... Training loss: 6.5059\n",
      "Epoch: 11/500... Training loss: 6.7084\n",
      "Epoch: 11/500... Training loss: 6.6077\n",
      "Epoch: 11/500... Training loss: 6.5442\n",
      "Epoch: 11/500... Training loss: 6.4062\n",
      "Epoch: 11/500... Training loss: 5.9365\n",
      "Epoch: 11/500... Training loss: 6.0951\n",
      "Epoch: 11/500... Training loss: 6.0934\n",
      "Epoch: 11/500... Training loss: 5.7705\n",
      "Epoch: 11/500... Training loss: 5.5854\n",
      "Epoch: 11/500... Training loss: 5.7665\n",
      "Epoch: 11/500... Training loss: 5.7101\n",
      "Epoch: 11/500... Training loss: 5.5874\n",
      "Epoch: 11/500... Training loss: 5.4081\n",
      "Epoch: 11/500... Training loss: 5.4527\n",
      "Epoch: 11/500... Training loss: 5.4598\n",
      "Epoch: 11/500... Training loss: 5.4955\n",
      "Epoch: 11/500... Training loss: 5.5976\n",
      "Epoch: 11/500... Training loss: 5.5002\n",
      "Epoch: 12/500... Training loss: 5.0894\n",
      "Epoch: 12/500... Training loss: 5.1303\n",
      "Epoch: 12/500... Training loss: 5.3926\n",
      "Epoch: 12/500... Training loss: 5.8361\n",
      "Epoch: 12/500... Training loss: 5.5979\n",
      "Epoch: 12/500... Training loss: 5.8511\n",
      "Epoch: 12/500... Training loss: 5.6633\n",
      "Epoch: 12/500... Training loss: 5.6053\n",
      "Epoch: 12/500... Training loss: 5.6799\n",
      "Epoch: 12/500... Training loss: 5.5386\n",
      "Epoch: 12/500... Training loss: 5.5927\n",
      "Epoch: 12/500... Training loss: 5.4762\n",
      "Epoch: 12/500... Training loss: 5.1219\n",
      "Epoch: 12/500... Training loss: 5.1557\n",
      "Epoch: 12/500... Training loss: 5.4659\n",
      "Epoch: 12/500... Training loss: 5.2739\n",
      "Epoch: 12/500... Training loss: 5.3497\n",
      "Epoch: 12/500... Training loss: 5.0669\n",
      "Epoch: 12/500... Training loss: 5.4097\n",
      "Epoch: 12/500... Training loss: 5.3102\n",
      "Epoch: 12/500... Training loss: 5.4344\n",
      "Epoch: 12/500... Training loss: 5.3987\n",
      "Epoch: 12/500... Training loss: 5.1899\n",
      "Epoch: 12/500... Training loss: 5.1858\n",
      "Epoch: 12/500... Training loss: 5.1482\n",
      "Epoch: 12/500... Training loss: 4.9254\n",
      "Epoch: 12/500... Training loss: 4.8732\n",
      "Epoch: 12/500... Training loss: 5.0651\n",
      "Epoch: 12/500... Training loss: 4.7896\n",
      "Epoch: 12/500... Training loss: 4.8733\n",
      "Epoch: 12/500... Training loss: 4.4379\n",
      "Epoch: 13/500... Training loss: 4.8061\n",
      "Epoch: 13/500... Training loss: 4.6655\n",
      "Epoch: 13/500... Training loss: 4.6391\n",
      "Epoch: 13/500... Training loss: 4.8276\n",
      "Epoch: 13/500... Training loss: 4.6808\n",
      "Epoch: 13/500... Training loss: 4.9960\n",
      "Epoch: 13/500... Training loss: 4.8472\n",
      "Epoch: 13/500... Training loss: 4.9546\n",
      "Epoch: 13/500... Training loss: 4.9791\n",
      "Epoch: 13/500... Training loss: 4.8188\n",
      "Epoch: 13/500... Training loss: 4.9185\n",
      "Epoch: 13/500... Training loss: 4.8480\n",
      "Epoch: 13/500... Training loss: 4.5700\n",
      "Epoch: 13/500... Training loss: 4.7394\n",
      "Epoch: 13/500... Training loss: 4.7242\n",
      "Epoch: 13/500... Training loss: 4.4457\n",
      "Epoch: 13/500... Training loss: 4.3915\n",
      "Epoch: 13/500... Training loss: 4.1391\n",
      "Epoch: 13/500... Training loss: 4.2921\n",
      "Epoch: 13/500... Training loss: 3.8381\n",
      "Epoch: 13/500... Training loss: 4.0422\n",
      "Epoch: 13/500... Training loss: 3.9064\n",
      "Epoch: 13/500... Training loss: 3.8518\n",
      "Epoch: 13/500... Training loss: 3.8497\n",
      "Epoch: 13/500... Training loss: 3.8315\n",
      "Epoch: 13/500... Training loss: 3.6790\n",
      "Epoch: 13/500... Training loss: 3.7764\n",
      "Epoch: 13/500... Training loss: 3.8628\n",
      "Epoch: 13/500... Training loss: 3.8464\n",
      "Epoch: 13/500... Training loss: 3.7416\n",
      "Epoch: 13/500... Training loss: 3.4740\n",
      "Epoch: 14/500... Training loss: 3.7278\n",
      "Epoch: 14/500... Training loss: 3.4969\n",
      "Epoch: 14/500... Training loss: 3.7773\n",
      "Epoch: 14/500... Training loss: 3.9879\n",
      "Epoch: 14/500... Training loss: 3.7709\n",
      "Epoch: 14/500... Training loss: 4.0361\n",
      "Epoch: 14/500... Training loss: 3.8188\n",
      "Epoch: 14/500... Training loss: 3.9407\n",
      "Epoch: 14/500... Training loss: 3.9277\n",
      "Epoch: 14/500... Training loss: 4.0172\n",
      "Epoch: 14/500... Training loss: 4.0577\n",
      "Epoch: 14/500... Training loss: 3.8290\n",
      "Epoch: 14/500... Training loss: 3.5632\n",
      "Epoch: 14/500... Training loss: 3.7245\n",
      "Epoch: 14/500... Training loss: 3.8935\n",
      "Epoch: 14/500... Training loss: 3.5203\n",
      "Epoch: 14/500... Training loss: 3.6297\n",
      "Epoch: 14/500... Training loss: 3.6556\n",
      "Epoch: 14/500... Training loss: 3.9648\n",
      "Epoch: 14/500... Training loss: 3.4494\n",
      "Epoch: 14/500... Training loss: 3.6790\n",
      "Epoch: 14/500... Training loss: 3.8379\n",
      "Epoch: 14/500... Training loss: 3.4141\n",
      "Epoch: 14/500... Training loss: 3.4116\n",
      "Epoch: 14/500... Training loss: 3.4476\n",
      "Epoch: 14/500... Training loss: 3.2215\n",
      "Epoch: 14/500... Training loss: 3.2059\n",
      "Epoch: 14/500... Training loss: 3.3379\n",
      "Epoch: 14/500... Training loss: 3.1231\n",
      "Epoch: 14/500... Training loss: 3.3328\n",
      "Epoch: 14/500... Training loss: 3.0088\n",
      "Epoch: 15/500... Training loss: 3.4526\n",
      "Epoch: 15/500... Training loss: 3.3687\n",
      "Epoch: 15/500... Training loss: 3.6450\n",
      "Epoch: 15/500... Training loss: 3.4575\n",
      "Epoch: 15/500... Training loss: 3.4824\n",
      "Epoch: 15/500... Training loss: 3.6682\n",
      "Epoch: 15/500... Training loss: 3.6210\n",
      "Epoch: 15/500... Training loss: 3.7653\n",
      "Epoch: 15/500... Training loss: 3.6599\n",
      "Epoch: 15/500... Training loss: 3.8356\n",
      "Epoch: 15/500... Training loss: 3.7511\n",
      "Epoch: 15/500... Training loss: 3.6970\n",
      "Epoch: 15/500... Training loss: 3.4117\n",
      "Epoch: 15/500... Training loss: 3.5803\n",
      "Epoch: 15/500... Training loss: 3.4195\n",
      "Epoch: 15/500... Training loss: 3.0115\n",
      "Epoch: 15/500... Training loss: 3.1780\n",
      "Epoch: 15/500... Training loss: 2.8712\n",
      "Epoch: 15/500... Training loss: 3.0392\n",
      "Epoch: 15/500... Training loss: 2.6738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/500... Training loss: 3.0373\n",
      "Epoch: 15/500... Training loss: 2.9587\n",
      "Epoch: 15/500... Training loss: 2.7458\n",
      "Epoch: 15/500... Training loss: 2.8832\n",
      "Epoch: 15/500... Training loss: 2.8755\n",
      "Epoch: 15/500... Training loss: 2.7218\n",
      "Epoch: 15/500... Training loss: 2.8112\n",
      "Epoch: 15/500... Training loss: 2.8775\n",
      "Epoch: 15/500... Training loss: 2.7382\n",
      "Epoch: 15/500... Training loss: 2.6657\n",
      "Epoch: 15/500... Training loss: 2.2605\n",
      "Epoch: 16/500... Training loss: 2.5744\n",
      "Epoch: 16/500... Training loss: 2.5878\n",
      "Epoch: 16/500... Training loss: 2.6117\n",
      "Epoch: 16/500... Training loss: 2.8054\n",
      "Epoch: 16/500... Training loss: 2.6120\n",
      "Epoch: 16/500... Training loss: 2.7058\n",
      "Epoch: 16/500... Training loss: 2.7597\n",
      "Epoch: 16/500... Training loss: 2.8462\n",
      "Epoch: 16/500... Training loss: 2.9349\n",
      "Epoch: 16/500... Training loss: 3.3038\n",
      "Epoch: 16/500... Training loss: 3.3097\n",
      "Epoch: 16/500... Training loss: 3.2784\n",
      "Epoch: 16/500... Training loss: 2.9350\n",
      "Epoch: 16/500... Training loss: 2.9065\n",
      "Epoch: 16/500... Training loss: 3.2755\n",
      "Epoch: 16/500... Training loss: 2.6427\n",
      "Epoch: 16/500... Training loss: 2.6432\n",
      "Epoch: 16/500... Training loss: 2.5678\n",
      "Epoch: 16/500... Training loss: 2.7281\n",
      "Epoch: 16/500... Training loss: 2.3742\n",
      "Epoch: 16/500... Training loss: 2.4213\n",
      "Epoch: 16/500... Training loss: 2.5794\n",
      "Epoch: 16/500... Training loss: 2.4938\n",
      "Epoch: 16/500... Training loss: 2.4641\n",
      "Epoch: 16/500... Training loss: 2.8038\n",
      "Epoch: 16/500... Training loss: 2.5841\n",
      "Epoch: 16/500... Training loss: 2.6940\n",
      "Epoch: 16/500... Training loss: 2.7301\n",
      "Epoch: 16/500... Training loss: 2.6221\n",
      "Epoch: 16/500... Training loss: 2.9565\n",
      "Epoch: 16/500... Training loss: 2.2233\n",
      "Epoch: 17/500... Training loss: 2.5741\n",
      "Epoch: 17/500... Training loss: 2.4876\n",
      "Epoch: 17/500... Training loss: 2.4471\n",
      "Epoch: 17/500... Training loss: 2.5822\n",
      "Epoch: 17/500... Training loss: 2.1951\n",
      "Epoch: 17/500... Training loss: 2.5275\n",
      "Epoch: 17/500... Training loss: 2.2566\n",
      "Epoch: 17/500... Training loss: 2.5957\n",
      "Epoch: 17/500... Training loss: 2.5547\n",
      "Epoch: 17/500... Training loss: 2.8341\n",
      "Epoch: 17/500... Training loss: 3.1987\n",
      "Epoch: 17/500... Training loss: 3.2665\n",
      "Epoch: 17/500... Training loss: 3.0026\n",
      "Epoch: 17/500... Training loss: 2.9551\n",
      "Epoch: 17/500... Training loss: 3.3262\n",
      "Epoch: 17/500... Training loss: 2.6836\n",
      "Epoch: 17/500... Training loss: 2.7716\n",
      "Epoch: 17/500... Training loss: 2.5195\n",
      "Epoch: 17/500... Training loss: 2.6560\n",
      "Epoch: 17/500... Training loss: 2.2520\n",
      "Epoch: 17/500... Training loss: 2.3356\n",
      "Epoch: 17/500... Training loss: 2.1127\n",
      "Epoch: 17/500... Training loss: 1.8706\n",
      "Epoch: 17/500... Training loss: 2.0617\n",
      "Epoch: 17/500... Training loss: 2.1481\n",
      "Epoch: 17/500... Training loss: 2.0908\n",
      "Epoch: 17/500... Training loss: 2.1968\n",
      "Epoch: 17/500... Training loss: 2.2963\n",
      "Epoch: 17/500... Training loss: 2.3628\n",
      "Epoch: 17/500... Training loss: 2.6834\n",
      "Epoch: 17/500... Training loss: 2.3062\n",
      "Epoch: 18/500... Training loss: 2.4353\n",
      "Epoch: 18/500... Training loss: 2.6103\n",
      "Epoch: 18/500... Training loss: 2.3478\n",
      "Epoch: 18/500... Training loss: 2.6828\n",
      "Epoch: 18/500... Training loss: 2.2518\n",
      "Epoch: 18/500... Training loss: 2.4275\n",
      "Epoch: 18/500... Training loss: 2.1879\n",
      "Epoch: 18/500... Training loss: 2.1469\n",
      "Epoch: 18/500... Training loss: 1.8932\n",
      "Epoch: 18/500... Training loss: 2.2493\n",
      "Epoch: 18/500... Training loss: 2.1703\n",
      "Epoch: 18/500... Training loss: 2.5218\n",
      "Epoch: 18/500... Training loss: 2.1805\n",
      "Epoch: 18/500... Training loss: 2.2725\n",
      "Epoch: 18/500... Training loss: 2.7922\n",
      "Epoch: 18/500... Training loss: 2.3106\n",
      "Epoch: 18/500... Training loss: 2.5438\n",
      "Epoch: 18/500... Training loss: 2.6762\n",
      "Epoch: 18/500... Training loss: 2.5569\n",
      "Epoch: 18/500... Training loss: 2.3306\n",
      "Epoch: 18/500... Training loss: 2.4753\n",
      "Epoch: 18/500... Training loss: 2.4671\n",
      "Epoch: 18/500... Training loss: 1.8947\n",
      "Epoch: 18/500... Training loss: 1.8477\n",
      "Epoch: 18/500... Training loss: 1.9175\n",
      "Epoch: 18/500... Training loss: 2.0294\n",
      "Epoch: 18/500... Training loss: 1.7557\n",
      "Epoch: 18/500... Training loss: 1.8826\n",
      "Epoch: 18/500... Training loss: 1.6786\n",
      "Epoch: 18/500... Training loss: 2.1253\n",
      "Epoch: 18/500... Training loss: 1.7648\n",
      "Epoch: 19/500... Training loss: 1.9735\n",
      "Epoch: 19/500... Training loss: 2.1691\n",
      "Epoch: 19/500... Training loss: 2.2329\n",
      "Epoch: 19/500... Training loss: 2.6780\n",
      "Epoch: 19/500... Training loss: 2.5796\n",
      "Epoch: 19/500... Training loss: 2.7058\n",
      "Epoch: 19/500... Training loss: 2.3011\n",
      "Epoch: 19/500... Training loss: 2.2460\n",
      "Epoch: 19/500... Training loss: 2.1733\n",
      "Epoch: 19/500... Training loss: 1.9789\n",
      "Epoch: 19/500... Training loss: 2.1982\n",
      "Epoch: 19/500... Training loss: 2.1643\n",
      "Epoch: 19/500... Training loss: 1.8536\n",
      "Epoch: 19/500... Training loss: 1.7164\n",
      "Epoch: 19/500... Training loss: 2.1673\n",
      "Epoch: 19/500... Training loss: 1.6612\n",
      "Epoch: 19/500... Training loss: 1.9104\n",
      "Epoch: 19/500... Training loss: 1.9071\n",
      "Epoch: 19/500... Training loss: 2.0153\n",
      "Epoch: 19/500... Training loss: 1.8833\n",
      "Epoch: 19/500... Training loss: 2.1456\n",
      "Epoch: 19/500... Training loss: 2.2214\n",
      "Epoch: 19/500... Training loss: 1.7725\n",
      "Epoch: 19/500... Training loss: 1.8922\n",
      "Epoch: 19/500... Training loss: 1.8510\n",
      "Epoch: 19/500... Training loss: 1.7787\n",
      "Epoch: 19/500... Training loss: 1.8977\n",
      "Epoch: 19/500... Training loss: 2.0048\n",
      "Epoch: 19/500... Training loss: 1.8336\n",
      "Epoch: 19/500... Training loss: 1.5880\n",
      "Epoch: 19/500... Training loss: 1.4680\n",
      "Epoch: 20/500... Training loss: 1.9391\n",
      "Epoch: 20/500... Training loss: 1.9115\n",
      "Epoch: 20/500... Training loss: 1.6668\n",
      "Epoch: 20/500... Training loss: 2.1735\n",
      "Epoch: 20/500... Training loss: 1.8563\n",
      "Epoch: 20/500... Training loss: 2.0925\n",
      "Epoch: 20/500... Training loss: 2.0435\n",
      "Epoch: 20/500... Training loss: 1.9773\n",
      "Epoch: 20/500... Training loss: 2.0077\n",
      "Epoch: 20/500... Training loss: 1.9548\n",
      "Epoch: 20/500... Training loss: 1.8823\n",
      "Epoch: 20/500... Training loss: 2.2176\n",
      "Epoch: 20/500... Training loss: 1.8522\n",
      "Epoch: 20/500... Training loss: 1.6777\n",
      "Epoch: 20/500... Training loss: 1.8985\n",
      "Epoch: 20/500... Training loss: 1.3804\n",
      "Epoch: 20/500... Training loss: 1.5487\n",
      "Epoch: 20/500... Training loss: 1.7239\n",
      "Epoch: 20/500... Training loss: 1.5923\n",
      "Epoch: 20/500... Training loss: 1.3190\n",
      "Epoch: 20/500... Training loss: 1.6613\n",
      "Epoch: 20/500... Training loss: 1.8001\n",
      "Epoch: 20/500... Training loss: 1.5151\n",
      "Epoch: 20/500... Training loss: 1.5657\n",
      "Epoch: 20/500... Training loss: 1.6877\n",
      "Epoch: 20/500... Training loss: 1.5215\n",
      "Epoch: 20/500... Training loss: 1.7514\n",
      "Epoch: 20/500... Training loss: 1.7970\n",
      "Epoch: 20/500... Training loss: 1.4939\n",
      "Epoch: 20/500... Training loss: 1.6311\n",
      "Epoch: 20/500... Training loss: 1.3210\n",
      "Epoch: 21/500... Training loss: 1.6386\n",
      "Epoch: 21/500... Training loss: 1.4341\n",
      "Epoch: 21/500... Training loss: 1.7577\n",
      "Epoch: 21/500... Training loss: 1.9558\n",
      "Epoch: 21/500... Training loss: 1.6831\n",
      "Epoch: 21/500... Training loss: 1.8447\n",
      "Epoch: 21/500... Training loss: 1.6106\n",
      "Epoch: 21/500... Training loss: 1.7841\n",
      "Epoch: 21/500... Training loss: 1.5392\n",
      "Epoch: 21/500... Training loss: 1.5241\n",
      "Epoch: 21/500... Training loss: 1.9550\n",
      "Epoch: 21/500... Training loss: 1.8749\n",
      "Epoch: 21/500... Training loss: 1.6134\n",
      "Epoch: 21/500... Training loss: 1.5086\n",
      "Epoch: 21/500... Training loss: 1.7918\n",
      "Epoch: 21/500... Training loss: 1.2715\n",
      "Epoch: 21/500... Training loss: 1.5444\n",
      "Epoch: 21/500... Training loss: 1.3589\n",
      "Epoch: 21/500... Training loss: 1.4976\n",
      "Epoch: 21/500... Training loss: 1.2032\n",
      "Epoch: 21/500... Training loss: 1.5008\n",
      "Epoch: 21/500... Training loss: 1.5309\n",
      "Epoch: 21/500... Training loss: 1.1515\n",
      "Epoch: 21/500... Training loss: 1.3514\n",
      "Epoch: 21/500... Training loss: 1.4432\n",
      "Epoch: 21/500... Training loss: 1.3259\n",
      "Epoch: 21/500... Training loss: 1.3460\n",
      "Epoch: 21/500... Training loss: 1.4427\n",
      "Epoch: 21/500... Training loss: 1.2912\n",
      "Epoch: 21/500... Training loss: 1.3918\n",
      "Epoch: 21/500... Training loss: 1.0350\n",
      "Epoch: 22/500... Training loss: 1.5056\n",
      "Epoch: 22/500... Training loss: 1.2165\n",
      "Epoch: 22/500... Training loss: 1.2812\n",
      "Epoch: 22/500... Training loss: 1.5838\n",
      "Epoch: 22/500... Training loss: 1.2299\n",
      "Epoch: 22/500... Training loss: 1.3890\n",
      "Epoch: 22/500... Training loss: 1.4431\n",
      "Epoch: 22/500... Training loss: 1.4893\n",
      "Epoch: 22/500... Training loss: 1.2772\n",
      "Epoch: 22/500... Training loss: 1.3991\n",
      "Epoch: 22/500... Training loss: 1.7755\n",
      "Epoch: 22/500... Training loss: 1.5665\n",
      "Epoch: 22/500... Training loss: 1.4374\n",
      "Epoch: 22/500... Training loss: 1.3479\n",
      "Epoch: 22/500... Training loss: 1.6364\n",
      "Epoch: 22/500... Training loss: 1.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/500... Training loss: 1.2024\n",
      "Epoch: 22/500... Training loss: 1.4375\n",
      "Epoch: 22/500... Training loss: 1.3030\n",
      "Epoch: 22/500... Training loss: 1.1199\n",
      "Epoch: 22/500... Training loss: 1.3036\n",
      "Epoch: 22/500... Training loss: 1.3671\n",
      "Epoch: 22/500... Training loss: 1.1483\n",
      "Epoch: 22/500... Training loss: 1.0192\n",
      "Epoch: 22/500... Training loss: 1.0967\n",
      "Epoch: 22/500... Training loss: 1.2195\n",
      "Epoch: 22/500... Training loss: 1.3186\n",
      "Epoch: 22/500... Training loss: 1.2749\n",
      "Epoch: 22/500... Training loss: 1.2862\n",
      "Epoch: 22/500... Training loss: 1.2299\n",
      "Epoch: 22/500... Training loss: 1.0439\n",
      "Epoch: 23/500... Training loss: 1.5149\n",
      "Epoch: 23/500... Training loss: 1.4759\n",
      "Epoch: 23/500... Training loss: 1.2381\n",
      "Epoch: 23/500... Training loss: 1.4693\n",
      "Epoch: 23/500... Training loss: 1.1674\n",
      "Epoch: 23/500... Training loss: 1.4562\n",
      "Epoch: 23/500... Training loss: 1.2491\n",
      "Epoch: 23/500... Training loss: 1.3467\n",
      "Epoch: 23/500... Training loss: 1.2343\n",
      "Epoch: 23/500... Training loss: 1.2617\n",
      "Epoch: 23/500... Training loss: 1.8440\n",
      "Epoch: 23/500... Training loss: 1.6278\n",
      "Epoch: 23/500... Training loss: 1.1459\n",
      "Epoch: 23/500... Training loss: 1.1977\n",
      "Epoch: 23/500... Training loss: 1.4151\n",
      "Epoch: 23/500... Training loss: 1.0027\n",
      "Epoch: 23/500... Training loss: 1.1037\n",
      "Epoch: 23/500... Training loss: 1.3070\n",
      "Epoch: 23/500... Training loss: 1.2591\n",
      "Epoch: 23/500... Training loss: 0.8975\n",
      "Epoch: 23/500... Training loss: 1.2466\n",
      "Epoch: 23/500... Training loss: 1.2833\n",
      "Epoch: 23/500... Training loss: 0.9287\n",
      "Epoch: 23/500... Training loss: 1.1528\n",
      "Epoch: 23/500... Training loss: 0.9823\n",
      "Epoch: 23/500... Training loss: 0.9963\n",
      "Epoch: 23/500... Training loss: 1.2763\n",
      "Epoch: 23/500... Training loss: 1.1803\n",
      "Epoch: 23/500... Training loss: 0.9851\n",
      "Epoch: 23/500... Training loss: 1.0830\n",
      "Epoch: 23/500... Training loss: 0.9523\n",
      "Epoch: 24/500... Training loss: 1.2625\n",
      "Epoch: 24/500... Training loss: 1.2001\n",
      "Epoch: 24/500... Training loss: 1.2030\n",
      "Epoch: 24/500... Training loss: 1.4555\n",
      "Epoch: 24/500... Training loss: 1.3352\n",
      "Epoch: 24/500... Training loss: 1.1822\n",
      "Epoch: 24/500... Training loss: 1.1794\n",
      "Epoch: 24/500... Training loss: 1.2412\n",
      "Epoch: 24/500... Training loss: 1.1937\n",
      "Epoch: 24/500... Training loss: 1.2649\n",
      "Epoch: 24/500... Training loss: 1.4339\n",
      "Epoch: 24/500... Training loss: 1.5355\n",
      "Epoch: 24/500... Training loss: 1.3337\n",
      "Epoch: 24/500... Training loss: 1.1870\n",
      "Epoch: 24/500... Training loss: 1.4093\n",
      "Epoch: 24/500... Training loss: 0.9551\n",
      "Epoch: 24/500... Training loss: 1.0361\n",
      "Epoch: 24/500... Training loss: 1.1997\n",
      "Epoch: 24/500... Training loss: 1.1422\n",
      "Epoch: 24/500... Training loss: 0.9377\n",
      "Epoch: 24/500... Training loss: 1.2162\n",
      "Epoch: 24/500... Training loss: 1.1268\n",
      "Epoch: 24/500... Training loss: 0.9920\n",
      "Epoch: 24/500... Training loss: 0.9882\n",
      "Epoch: 24/500... Training loss: 1.1175\n",
      "Epoch: 24/500... Training loss: 1.0706\n",
      "Epoch: 24/500... Training loss: 1.0524\n",
      "Epoch: 24/500... Training loss: 1.1600\n",
      "Epoch: 24/500... Training loss: 1.0097\n",
      "Epoch: 24/500... Training loss: 1.1337\n",
      "Epoch: 24/500... Training loss: 0.7793\n",
      "Epoch: 25/500... Training loss: 1.2576\n",
      "Epoch: 25/500... Training loss: 1.4244\n",
      "Epoch: 25/500... Training loss: 1.3780\n",
      "Epoch: 25/500... Training loss: 1.2058\n",
      "Epoch: 25/500... Training loss: 1.0824\n",
      "Epoch: 25/500... Training loss: 1.2006\n",
      "Epoch: 25/500... Training loss: 0.9864\n",
      "Epoch: 25/500... Training loss: 1.1736\n",
      "Epoch: 25/500... Training loss: 1.1119\n",
      "Epoch: 25/500... Training loss: 1.1063\n",
      "Epoch: 25/500... Training loss: 1.4836\n",
      "Epoch: 25/500... Training loss: 1.3152\n",
      "Epoch: 25/500... Training loss: 0.9809\n",
      "Epoch: 25/500... Training loss: 0.8561\n",
      "Epoch: 25/500... Training loss: 1.2959\n",
      "Epoch: 25/500... Training loss: 0.7721\n",
      "Epoch: 25/500... Training loss: 0.9108\n",
      "Epoch: 25/500... Training loss: 0.9628\n",
      "Epoch: 25/500... Training loss: 1.2052\n",
      "Epoch: 25/500... Training loss: 0.8899\n",
      "Epoch: 25/500... Training loss: 1.1239\n",
      "Epoch: 25/500... Training loss: 1.1129\n",
      "Epoch: 25/500... Training loss: 1.0053\n",
      "Epoch: 25/500... Training loss: 0.8129\n",
      "Epoch: 25/500... Training loss: 0.8341\n",
      "Epoch: 25/500... Training loss: 0.9159\n",
      "Epoch: 25/500... Training loss: 0.9787\n",
      "Epoch: 25/500... Training loss: 1.0516\n",
      "Epoch: 25/500... Training loss: 0.9713\n",
      "Epoch: 25/500... Training loss: 1.0270\n",
      "Epoch: 25/500... Training loss: 0.8987\n",
      "Epoch: 26/500... Training loss: 1.2937\n",
      "Epoch: 26/500... Training loss: 0.9742\n",
      "Epoch: 26/500... Training loss: 0.9925\n",
      "Epoch: 26/500... Training loss: 1.2628\n",
      "Epoch: 26/500... Training loss: 0.9889\n",
      "Epoch: 26/500... Training loss: 1.0276\n",
      "Epoch: 26/500... Training loss: 1.0449\n",
      "Epoch: 26/500... Training loss: 0.9794\n",
      "Epoch: 26/500... Training loss: 1.2020\n",
      "Epoch: 26/500... Training loss: 1.1582\n",
      "Epoch: 26/500... Training loss: 1.3899\n",
      "Epoch: 26/500... Training loss: 1.0554\n",
      "Epoch: 26/500... Training loss: 1.0096\n",
      "Epoch: 26/500... Training loss: 0.9533\n",
      "Epoch: 26/500... Training loss: 0.9830\n",
      "Epoch: 26/500... Training loss: 0.8073\n",
      "Epoch: 26/500... Training loss: 0.9095\n",
      "Epoch: 26/500... Training loss: 1.1170\n",
      "Epoch: 26/500... Training loss: 1.0759\n",
      "Epoch: 26/500... Training loss: 0.8733\n",
      "Epoch: 26/500... Training loss: 1.0630\n",
      "Epoch: 26/500... Training loss: 0.9663\n",
      "Epoch: 26/500... Training loss: 0.9745\n",
      "Epoch: 26/500... Training loss: 0.8531\n",
      "Epoch: 26/500... Training loss: 0.8277\n",
      "Epoch: 26/500... Training loss: 1.0277\n",
      "Epoch: 26/500... Training loss: 0.8500\n",
      "Epoch: 26/500... Training loss: 1.0386\n",
      "Epoch: 26/500... Training loss: 0.8052\n",
      "Epoch: 26/500... Training loss: 0.9280\n",
      "Epoch: 26/500... Training loss: 0.7546\n",
      "Epoch: 27/500... Training loss: 0.9984\n",
      "Epoch: 27/500... Training loss: 1.0206\n",
      "Epoch: 27/500... Training loss: 0.9962\n",
      "Epoch: 27/500... Training loss: 1.1438\n",
      "Epoch: 27/500... Training loss: 1.0166\n",
      "Epoch: 27/500... Training loss: 0.9472\n",
      "Epoch: 27/500... Training loss: 0.9848\n",
      "Epoch: 27/500... Training loss: 1.0105\n",
      "Epoch: 27/500... Training loss: 1.0240\n",
      "Epoch: 27/500... Training loss: 0.8359\n",
      "Epoch: 27/500... Training loss: 1.2135\n",
      "Epoch: 27/500... Training loss: 1.1868\n",
      "Epoch: 27/500... Training loss: 0.9311\n",
      "Epoch: 27/500... Training loss: 0.8456\n",
      "Epoch: 27/500... Training loss: 1.0639\n",
      "Epoch: 27/500... Training loss: 0.6833\n",
      "Epoch: 27/500... Training loss: 0.7474\n",
      "Epoch: 27/500... Training loss: 1.0126\n",
      "Epoch: 27/500... Training loss: 0.9042\n",
      "Epoch: 27/500... Training loss: 0.9559\n",
      "Epoch: 27/500... Training loss: 1.0608\n",
      "Epoch: 27/500... Training loss: 1.0133\n",
      "Epoch: 27/500... Training loss: 0.9495\n",
      "Epoch: 27/500... Training loss: 0.8518\n",
      "Epoch: 27/500... Training loss: 0.8937\n",
      "Epoch: 27/500... Training loss: 0.7538\n",
      "Epoch: 27/500... Training loss: 0.9949\n",
      "Epoch: 27/500... Training loss: 0.9237\n",
      "Epoch: 27/500... Training loss: 0.8214\n",
      "Epoch: 27/500... Training loss: 0.9634\n",
      "Epoch: 27/500... Training loss: 0.8650\n",
      "Epoch: 28/500... Training loss: 1.0142\n",
      "Epoch: 28/500... Training loss: 1.1493\n",
      "Epoch: 28/500... Training loss: 0.9916\n",
      "Epoch: 28/500... Training loss: 1.0447\n",
      "Epoch: 28/500... Training loss: 1.0300\n",
      "Epoch: 28/500... Training loss: 0.9192\n",
      "Epoch: 28/500... Training loss: 0.9889\n",
      "Epoch: 28/500... Training loss: 0.9738\n",
      "Epoch: 28/500... Training loss: 0.8896\n",
      "Epoch: 28/500... Training loss: 1.0391\n",
      "Epoch: 28/500... Training loss: 1.1117\n",
      "Epoch: 28/500... Training loss: 1.2556\n",
      "Epoch: 28/500... Training loss: 1.1087\n",
      "Epoch: 28/500... Training loss: 0.7742\n",
      "Epoch: 28/500... Training loss: 0.8174\n",
      "Epoch: 28/500... Training loss: 0.6966\n",
      "Epoch: 28/500... Training loss: 0.7181\n",
      "Epoch: 28/500... Training loss: 0.9347\n",
      "Epoch: 28/500... Training loss: 0.8978\n",
      "Epoch: 28/500... Training loss: 0.7343\n",
      "Epoch: 28/500... Training loss: 0.9170\n",
      "Epoch: 28/500... Training loss: 1.0279\n",
      "Epoch: 28/500... Training loss: 0.7393\n",
      "Epoch: 28/500... Training loss: 0.8934\n",
      "Epoch: 28/500... Training loss: 0.7711\n",
      "Epoch: 28/500... Training loss: 0.8957\n",
      "Epoch: 28/500... Training loss: 0.7501\n",
      "Epoch: 28/500... Training loss: 0.7498\n",
      "Epoch: 28/500... Training loss: 0.6558\n",
      "Epoch: 28/500... Training loss: 0.6753\n",
      "Epoch: 28/500... Training loss: 0.6601\n",
      "Epoch: 29/500... Training loss: 1.0469\n",
      "Epoch: 29/500... Training loss: 0.8907\n",
      "Epoch: 29/500... Training loss: 1.1061\n",
      "Epoch: 29/500... Training loss: 1.0383\n",
      "Epoch: 29/500... Training loss: 0.9534\n",
      "Epoch: 29/500... Training loss: 0.8814\n",
      "Epoch: 29/500... Training loss: 0.9020\n",
      "Epoch: 29/500... Training loss: 0.8474\n",
      "Epoch: 29/500... Training loss: 0.6942\n",
      "Epoch: 29/500... Training loss: 0.8609\n",
      "Epoch: 29/500... Training loss: 1.0932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/500... Training loss: 0.9495\n",
      "Epoch: 29/500... Training loss: 1.0062\n",
      "Epoch: 29/500... Training loss: 0.7001\n",
      "Epoch: 29/500... Training loss: 0.9434\n",
      "Epoch: 29/500... Training loss: 0.6461\n",
      "Epoch: 29/500... Training loss: 0.7038\n",
      "Epoch: 29/500... Training loss: 0.7024\n",
      "Epoch: 29/500... Training loss: 0.9373\n",
      "Epoch: 29/500... Training loss: 0.8745\n",
      "Epoch: 29/500... Training loss: 0.7296\n",
      "Epoch: 29/500... Training loss: 0.9070\n",
      "Epoch: 29/500... Training loss: 0.7675\n",
      "Epoch: 29/500... Training loss: 0.7696\n",
      "Epoch: 29/500... Training loss: 0.8171\n",
      "Epoch: 29/500... Training loss: 0.6231\n",
      "Epoch: 29/500... Training loss: 0.6974\n",
      "Epoch: 29/500... Training loss: 0.9709\n",
      "Epoch: 29/500... Training loss: 0.6769\n",
      "Epoch: 29/500... Training loss: 0.7637\n",
      "Epoch: 29/500... Training loss: 0.6099\n",
      "Epoch: 30/500... Training loss: 0.9511\n",
      "Epoch: 30/500... Training loss: 0.8425\n",
      "Epoch: 30/500... Training loss: 0.7748\n",
      "Epoch: 30/500... Training loss: 0.9658\n",
      "Epoch: 30/500... Training loss: 0.8241\n",
      "Epoch: 30/500... Training loss: 0.7228\n",
      "Epoch: 30/500... Training loss: 0.7978\n",
      "Epoch: 30/500... Training loss: 0.7840\n",
      "Epoch: 30/500... Training loss: 0.9216\n",
      "Epoch: 30/500... Training loss: 0.8829\n",
      "Epoch: 30/500... Training loss: 1.0293\n",
      "Epoch: 30/500... Training loss: 0.8980\n",
      "Epoch: 30/500... Training loss: 0.8536\n",
      "Epoch: 30/500... Training loss: 0.6724\n",
      "Epoch: 30/500... Training loss: 0.7880\n",
      "Epoch: 30/500... Training loss: 0.6227\n",
      "Epoch: 30/500... Training loss: 0.7768\n",
      "Epoch: 30/500... Training loss: 0.8386\n",
      "Epoch: 30/500... Training loss: 0.7714\n",
      "Epoch: 30/500... Training loss: 0.5982\n",
      "Epoch: 30/500... Training loss: 1.0615\n",
      "Epoch: 30/500... Training loss: 0.8338\n",
      "Epoch: 30/500... Training loss: 0.6764\n",
      "Epoch: 30/500... Training loss: 0.8213\n",
      "Epoch: 30/500... Training loss: 0.7879\n",
      "Epoch: 30/500... Training loss: 0.7620\n",
      "Epoch: 30/500... Training loss: 0.6997\n",
      "Epoch: 30/500... Training loss: 0.6646\n",
      "Epoch: 30/500... Training loss: 0.8112\n",
      "Epoch: 30/500... Training loss: 0.7124\n",
      "Epoch: 30/500... Training loss: 0.5622\n",
      "Epoch: 31/500... Training loss: 0.9736\n",
      "Epoch: 31/500... Training loss: 0.7743\n",
      "Epoch: 31/500... Training loss: 0.7707\n",
      "Epoch: 31/500... Training loss: 0.9981\n",
      "Epoch: 31/500... Training loss: 0.7375\n",
      "Epoch: 31/500... Training loss: 0.8071\n",
      "Epoch: 31/500... Training loss: 0.8191\n",
      "Epoch: 31/500... Training loss: 0.7851\n",
      "Epoch: 31/500... Training loss: 0.7947\n",
      "Epoch: 31/500... Training loss: 1.0116\n",
      "Epoch: 31/500... Training loss: 0.9699\n",
      "Epoch: 31/500... Training loss: 0.8687\n",
      "Epoch: 31/500... Training loss: 0.8791\n",
      "Epoch: 31/500... Training loss: 0.7903\n",
      "Epoch: 31/500... Training loss: 0.7832\n",
      "Epoch: 31/500... Training loss: 0.4891\n",
      "Epoch: 31/500... Training loss: 0.8045\n",
      "Epoch: 31/500... Training loss: 0.7141\n",
      "Epoch: 31/500... Training loss: 0.8930\n",
      "Epoch: 31/500... Training loss: 0.6215\n",
      "Epoch: 31/500... Training loss: 0.7292\n",
      "Epoch: 31/500... Training loss: 0.8562\n",
      "Epoch: 31/500... Training loss: 0.6077\n",
      "Epoch: 31/500... Training loss: 0.6869\n",
      "Epoch: 31/500... Training loss: 0.7515\n",
      "Epoch: 31/500... Training loss: 0.8222\n",
      "Epoch: 31/500... Training loss: 0.7713\n",
      "Epoch: 31/500... Training loss: 0.6062\n",
      "Epoch: 31/500... Training loss: 0.6399\n",
      "Epoch: 31/500... Training loss: 0.7268\n",
      "Epoch: 31/500... Training loss: 0.5454\n",
      "Epoch: 32/500... Training loss: 0.8758\n",
      "Epoch: 32/500... Training loss: 0.8263\n",
      "Epoch: 32/500... Training loss: 0.7622\n",
      "Epoch: 32/500... Training loss: 1.0289\n",
      "Epoch: 32/500... Training loss: 0.7320\n",
      "Epoch: 32/500... Training loss: 0.8869\n",
      "Epoch: 32/500... Training loss: 0.8241\n",
      "Epoch: 32/500... Training loss: 0.8238\n",
      "Epoch: 32/500... Training loss: 0.8189\n",
      "Epoch: 32/500... Training loss: 0.8252\n",
      "Epoch: 32/500... Training loss: 1.1390\n",
      "Epoch: 32/500... Training loss: 0.9398\n",
      "Epoch: 32/500... Training loss: 0.8718\n",
      "Epoch: 32/500... Training loss: 0.7363\n",
      "Epoch: 32/500... Training loss: 0.6736\n",
      "Epoch: 32/500... Training loss: 0.6666\n",
      "Epoch: 32/500... Training loss: 0.6619\n",
      "Epoch: 32/500... Training loss: 0.7579\n",
      "Epoch: 32/500... Training loss: 0.8145\n",
      "Epoch: 32/500... Training loss: 0.4714\n",
      "Epoch: 32/500... Training loss: 0.8087\n",
      "Epoch: 32/500... Training loss: 0.8735\n",
      "Epoch: 32/500... Training loss: 0.6873\n",
      "Epoch: 32/500... Training loss: 0.8023\n",
      "Epoch: 32/500... Training loss: 0.5973\n",
      "Epoch: 32/500... Training loss: 0.6347\n",
      "Epoch: 32/500... Training loss: 0.5916\n",
      "Epoch: 32/500... Training loss: 0.6706\n",
      "Epoch: 32/500... Training loss: 0.6896\n",
      "Epoch: 32/500... Training loss: 0.6277\n",
      "Epoch: 32/500... Training loss: 0.6010\n",
      "Epoch: 33/500... Training loss: 0.7685\n",
      "Epoch: 33/500... Training loss: 0.7060\n",
      "Epoch: 33/500... Training loss: 1.0537\n",
      "Epoch: 33/500... Training loss: 0.7575\n",
      "Epoch: 33/500... Training loss: 0.6012\n",
      "Epoch: 33/500... Training loss: 0.8147\n",
      "Epoch: 33/500... Training loss: 0.7919\n",
      "Epoch: 33/500... Training loss: 0.9897\n",
      "Epoch: 33/500... Training loss: 0.7673\n",
      "Epoch: 33/500... Training loss: 0.8813\n",
      "Epoch: 33/500... Training loss: 0.9265\n",
      "Epoch: 33/500... Training loss: 1.1395\n",
      "Epoch: 33/500... Training loss: 0.9243\n",
      "Epoch: 33/500... Training loss: 0.6096\n",
      "Epoch: 33/500... Training loss: 0.8011\n",
      "Epoch: 33/500... Training loss: 0.5814\n",
      "Epoch: 33/500... Training loss: 0.7737\n",
      "Epoch: 33/500... Training loss: 0.6117\n",
      "Epoch: 33/500... Training loss: 0.8748\n",
      "Epoch: 33/500... Training loss: 0.5660\n",
      "Epoch: 33/500... Training loss: 0.6858\n",
      "Epoch: 33/500... Training loss: 0.7259\n",
      "Epoch: 33/500... Training loss: 0.5909\n",
      "Epoch: 33/500... Training loss: 0.6163\n",
      "Epoch: 33/500... Training loss: 0.6636\n",
      "Epoch: 33/500... Training loss: 0.5918\n",
      "Epoch: 33/500... Training loss: 0.6805\n",
      "Epoch: 33/500... Training loss: 0.6328\n",
      "Epoch: 33/500... Training loss: 0.5556\n",
      "Epoch: 33/500... Training loss: 0.5766\n",
      "Epoch: 33/500... Training loss: 0.6620\n",
      "Epoch: 34/500... Training loss: 0.9101\n",
      "Epoch: 34/500... Training loss: 0.7664\n",
      "Epoch: 34/500... Training loss: 0.6326\n",
      "Epoch: 34/500... Training loss: 0.8959\n",
      "Epoch: 34/500... Training loss: 0.6878\n",
      "Epoch: 34/500... Training loss: 0.6444\n",
      "Epoch: 34/500... Training loss: 0.6463\n",
      "Epoch: 34/500... Training loss: 0.6587\n",
      "Epoch: 34/500... Training loss: 0.6838\n",
      "Epoch: 34/500... Training loss: 0.6142\n",
      "Epoch: 34/500... Training loss: 0.9466\n",
      "Epoch: 34/500... Training loss: 0.9854\n",
      "Epoch: 34/500... Training loss: 0.7628\n",
      "Epoch: 34/500... Training loss: 0.6136\n",
      "Epoch: 34/500... Training loss: 0.6051\n",
      "Epoch: 34/500... Training loss: 0.3797\n",
      "Epoch: 34/500... Training loss: 0.6755\n",
      "Epoch: 34/500... Training loss: 0.6841\n",
      "Epoch: 34/500... Training loss: 0.5677\n",
      "Epoch: 34/500... Training loss: 0.4546\n",
      "Epoch: 34/500... Training loss: 0.6531\n",
      "Epoch: 34/500... Training loss: 0.7834\n",
      "Epoch: 34/500... Training loss: 0.6844\n",
      "Epoch: 34/500... Training loss: 0.6520\n",
      "Epoch: 34/500... Training loss: 0.4650\n",
      "Epoch: 34/500... Training loss: 0.6011\n",
      "Epoch: 34/500... Training loss: 0.5136\n",
      "Epoch: 34/500... Training loss: 0.5624\n",
      "Epoch: 34/500... Training loss: 0.6343\n",
      "Epoch: 34/500... Training loss: 0.5842\n",
      "Epoch: 34/500... Training loss: 0.7233\n",
      "Epoch: 35/500... Training loss: 0.7547\n",
      "Epoch: 35/500... Training loss: 0.6938\n",
      "Epoch: 35/500... Training loss: 0.5789\n",
      "Epoch: 35/500... Training loss: 0.9128\n",
      "Epoch: 35/500... Training loss: 0.6892\n",
      "Epoch: 35/500... Training loss: 0.6788\n",
      "Epoch: 35/500... Training loss: 0.6140\n",
      "Epoch: 35/500... Training loss: 0.7557\n",
      "Epoch: 35/500... Training loss: 0.6893\n",
      "Epoch: 35/500... Training loss: 0.7233\n",
      "Epoch: 35/500... Training loss: 0.7657\n",
      "Epoch: 35/500... Training loss: 0.7745\n",
      "Epoch: 35/500... Training loss: 0.8541\n",
      "Epoch: 35/500... Training loss: 0.6277\n",
      "Epoch: 35/500... Training loss: 0.5058\n",
      "Epoch: 35/500... Training loss: 0.5510\n",
      "Epoch: 35/500... Training loss: 0.6759\n",
      "Epoch: 35/500... Training loss: 0.5524\n",
      "Epoch: 35/500... Training loss: 0.8165\n",
      "Epoch: 35/500... Training loss: 0.6397\n",
      "Epoch: 35/500... Training loss: 0.7406\n",
      "Epoch: 35/500... Training loss: 0.5488\n",
      "Epoch: 35/500... Training loss: 0.5949\n",
      "Epoch: 35/500... Training loss: 0.6691\n",
      "Epoch: 35/500... Training loss: 0.6587\n",
      "Epoch: 35/500... Training loss: 0.4974\n",
      "Epoch: 35/500... Training loss: 0.5542\n",
      "Epoch: 35/500... Training loss: 0.6012\n",
      "Epoch: 35/500... Training loss: 0.4647\n",
      "Epoch: 35/500... Training loss: 0.5692\n",
      "Epoch: 35/500... Training loss: 0.5238\n",
      "Epoch: 36/500... Training loss: 0.6536\n",
      "Epoch: 36/500... Training loss: 0.6677\n",
      "Epoch: 36/500... Training loss: 0.6380\n",
      "Epoch: 36/500... Training loss: 0.7230\n",
      "Epoch: 36/500... Training loss: 0.5146\n",
      "Epoch: 36/500... Training loss: 0.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/500... Training loss: 0.6626\n",
      "Epoch: 36/500... Training loss: 0.5718\n",
      "Epoch: 36/500... Training loss: 0.6110\n",
      "Epoch: 36/500... Training loss: 0.6142\n",
      "Epoch: 36/500... Training loss: 1.0069\n",
      "Epoch: 36/500... Training loss: 0.9038\n",
      "Epoch: 36/500... Training loss: 0.6636\n",
      "Epoch: 36/500... Training loss: 0.4801\n",
      "Epoch: 36/500... Training loss: 0.5437\n",
      "Epoch: 36/500... Training loss: 0.4591\n",
      "Epoch: 36/500... Training loss: 0.4910\n",
      "Epoch: 36/500... Training loss: 0.7460\n",
      "Epoch: 36/500... Training loss: 0.8008\n",
      "Epoch: 36/500... Training loss: 0.4271\n",
      "Epoch: 36/500... Training loss: 0.5425\n",
      "Epoch: 36/500... Training loss: 0.7541\n",
      "Epoch: 36/500... Training loss: 0.5796\n",
      "Epoch: 36/500... Training loss: 0.5664\n",
      "Epoch: 36/500... Training loss: 0.6514\n",
      "Epoch: 36/500... Training loss: 0.7511\n",
      "Epoch: 36/500... Training loss: 0.5462\n",
      "Epoch: 36/500... Training loss: 0.4510\n",
      "Epoch: 36/500... Training loss: 0.6456\n",
      "Epoch: 36/500... Training loss: 0.5424\n",
      "Epoch: 36/500... Training loss: 0.5344\n",
      "Epoch: 37/500... Training loss: 0.6897\n",
      "Epoch: 37/500... Training loss: 0.7501\n",
      "Epoch: 37/500... Training loss: 0.6398\n",
      "Epoch: 37/500... Training loss: 0.9080\n",
      "Epoch: 37/500... Training loss: 0.7228\n",
      "Epoch: 37/500... Training loss: 0.6116\n",
      "Epoch: 37/500... Training loss: 0.6384\n",
      "Epoch: 37/500... Training loss: 0.6584\n",
      "Epoch: 37/500... Training loss: 0.6353\n",
      "Epoch: 37/500... Training loss: 0.6330\n",
      "Epoch: 37/500... Training loss: 0.8585\n",
      "Epoch: 37/500... Training loss: 0.6554\n",
      "Epoch: 37/500... Training loss: 0.6323\n",
      "Epoch: 37/500... Training loss: 0.6506\n",
      "Epoch: 37/500... Training loss: 0.7015\n",
      "Epoch: 37/500... Training loss: 0.4916\n",
      "Epoch: 37/500... Training loss: 0.6175\n",
      "Epoch: 37/500... Training loss: 0.6820\n",
      "Epoch: 37/500... Training loss: 0.6317\n",
      "Epoch: 37/500... Training loss: 0.4105\n",
      "Epoch: 37/500... Training loss: 0.6484\n",
      "Epoch: 37/500... Training loss: 0.6069\n",
      "Epoch: 37/500... Training loss: 0.4824\n",
      "Epoch: 37/500... Training loss: 0.5555\n",
      "Epoch: 37/500... Training loss: 0.6937\n",
      "Epoch: 37/500... Training loss: 0.4748\n",
      "Epoch: 37/500... Training loss: 0.5235\n",
      "Epoch: 37/500... Training loss: 0.4163\n",
      "Epoch: 37/500... Training loss: 0.4580\n",
      "Epoch: 37/500... Training loss: 0.5267\n",
      "Epoch: 37/500... Training loss: 0.4833\n",
      "Epoch: 38/500... Training loss: 0.5493\n",
      "Epoch: 38/500... Training loss: 0.6509\n",
      "Epoch: 38/500... Training loss: 0.6759\n",
      "Epoch: 38/500... Training loss: 0.8437\n",
      "Epoch: 38/500... Training loss: 0.5470\n",
      "Epoch: 38/500... Training loss: 0.6082\n",
      "Epoch: 38/500... Training loss: 0.7130\n",
      "Epoch: 38/500... Training loss: 0.6454\n",
      "Epoch: 38/500... Training loss: 0.5949\n",
      "Epoch: 38/500... Training loss: 0.5961\n",
      "Epoch: 38/500... Training loss: 0.9646\n",
      "Epoch: 38/500... Training loss: 0.6953\n",
      "Epoch: 38/500... Training loss: 0.6303\n",
      "Epoch: 38/500... Training loss: 0.6144\n",
      "Epoch: 38/500... Training loss: 0.4378\n",
      "Epoch: 38/500... Training loss: 0.4501\n",
      "Epoch: 38/500... Training loss: 0.4838\n",
      "Epoch: 38/500... Training loss: 0.5092\n",
      "Epoch: 38/500... Training loss: 0.5762\n",
      "Epoch: 38/500... Training loss: 0.4007\n",
      "Epoch: 38/500... Training loss: 0.4672\n",
      "Epoch: 38/500... Training loss: 0.6212\n",
      "Epoch: 38/500... Training loss: 0.6267\n",
      "Epoch: 38/500... Training loss: 0.6280\n",
      "Epoch: 38/500... Training loss: 0.5805\n",
      "Epoch: 38/500... Training loss: 0.7306\n",
      "Epoch: 38/500... Training loss: 0.5991\n",
      "Epoch: 38/500... Training loss: 0.4669\n",
      "Epoch: 38/500... Training loss: 0.3885\n",
      "Epoch: 38/500... Training loss: 0.4719\n",
      "Epoch: 38/500... Training loss: 0.3807\n",
      "Epoch: 39/500... Training loss: 0.7540\n",
      "Epoch: 39/500... Training loss: 0.5907\n",
      "Epoch: 39/500... Training loss: 0.6798\n",
      "Epoch: 39/500... Training loss: 0.7246\n",
      "Epoch: 39/500... Training loss: 0.6196\n",
      "Epoch: 39/500... Training loss: 0.6280\n",
      "Epoch: 39/500... Training loss: 0.5587\n",
      "Epoch: 39/500... Training loss: 0.5603\n",
      "Epoch: 39/500... Training loss: 0.5202\n",
      "Epoch: 39/500... Training loss: 0.6622\n",
      "Epoch: 39/500... Training loss: 0.9126\n",
      "Epoch: 39/500... Training loss: 0.6986\n",
      "Epoch: 39/500... Training loss: 0.5385\n",
      "Epoch: 39/500... Training loss: 0.4741\n",
      "Epoch: 39/500... Training loss: 0.6309\n",
      "Epoch: 39/500... Training loss: 0.5366\n",
      "Epoch: 39/500... Training loss: 0.4601\n",
      "Epoch: 39/500... Training loss: 0.6326\n",
      "Epoch: 39/500... Training loss: 0.5318\n",
      "Epoch: 39/500... Training loss: 0.5541\n",
      "Epoch: 39/500... Training loss: 0.5380\n",
      "Epoch: 39/500... Training loss: 0.6248\n",
      "Epoch: 39/500... Training loss: 0.4848\n",
      "Epoch: 39/500... Training loss: 0.6086\n",
      "Epoch: 39/500... Training loss: 0.4953\n",
      "Epoch: 39/500... Training loss: 0.5807\n",
      "Epoch: 39/500... Training loss: 0.5265\n",
      "Epoch: 39/500... Training loss: 0.5611\n",
      "Epoch: 39/500... Training loss: 0.4622\n",
      "Epoch: 39/500... Training loss: 0.5889\n",
      "Epoch: 39/500... Training loss: 0.4338\n",
      "Epoch: 40/500... Training loss: 0.4808\n",
      "Epoch: 40/500... Training loss: 0.5586\n",
      "Epoch: 40/500... Training loss: 0.7537\n",
      "Epoch: 40/500... Training loss: 0.7049\n",
      "Epoch: 40/500... Training loss: 0.5725\n",
      "Epoch: 40/500... Training loss: 0.5294\n",
      "Epoch: 40/500... Training loss: 0.5628\n",
      "Epoch: 40/500... Training loss: 0.6085\n",
      "Epoch: 40/500... Training loss: 0.6137\n",
      "Epoch: 40/500... Training loss: 0.5107\n",
      "Epoch: 40/500... Training loss: 0.6736\n",
      "Epoch: 40/500... Training loss: 0.7839\n",
      "Epoch: 40/500... Training loss: 0.4950\n",
      "Epoch: 40/500... Training loss: 0.4622\n",
      "Epoch: 40/500... Training loss: 0.4904\n",
      "Epoch: 40/500... Training loss: 0.4011\n",
      "Epoch: 40/500... Training loss: 0.5934\n",
      "Epoch: 40/500... Training loss: 0.4892\n",
      "Epoch: 40/500... Training loss: 0.7117\n",
      "Epoch: 40/500... Training loss: 0.4416\n",
      "Epoch: 40/500... Training loss: 0.6094\n",
      "Epoch: 40/500... Training loss: 0.7126\n",
      "Epoch: 40/500... Training loss: 0.5959\n",
      "Epoch: 40/500... Training loss: 0.4929\n",
      "Epoch: 40/500... Training loss: 0.4753\n",
      "Epoch: 40/500... Training loss: 0.6088\n",
      "Epoch: 40/500... Training loss: 0.4826\n",
      "Epoch: 40/500... Training loss: 0.4883\n",
      "Epoch: 40/500... Training loss: 0.4401\n",
      "Epoch: 40/500... Training loss: 0.5642\n",
      "Epoch: 40/500... Training loss: 0.3414\n",
      "Epoch: 41/500... Training loss: 0.4947\n",
      "Epoch: 41/500... Training loss: 0.4444\n",
      "Epoch: 41/500... Training loss: 0.5486\n",
      "Epoch: 41/500... Training loss: 0.5684\n",
      "Epoch: 41/500... Training loss: 0.6200\n",
      "Epoch: 41/500... Training loss: 0.4932\n",
      "Epoch: 41/500... Training loss: 0.6559\n",
      "Epoch: 41/500... Training loss: 0.5394\n",
      "Epoch: 41/500... Training loss: 0.5590\n",
      "Epoch: 41/500... Training loss: 0.6219\n",
      "Epoch: 41/500... Training loss: 0.5581\n",
      "Epoch: 41/500... Training loss: 0.7827\n",
      "Epoch: 41/500... Training loss: 0.5899\n",
      "Epoch: 41/500... Training loss: 0.4487\n",
      "Epoch: 41/500... Training loss: 0.5372\n",
      "Epoch: 41/500... Training loss: 0.4474\n",
      "Epoch: 41/500... Training loss: 0.3508\n",
      "Epoch: 41/500... Training loss: 0.5725\n",
      "Epoch: 41/500... Training loss: 0.6419\n",
      "Epoch: 41/500... Training loss: 0.4138\n",
      "Epoch: 41/500... Training loss: 0.5270\n",
      "Epoch: 41/500... Training loss: 0.6220\n",
      "Epoch: 41/500... Training loss: 0.5144\n",
      "Epoch: 41/500... Training loss: 0.6421\n",
      "Epoch: 41/500... Training loss: 0.5087\n",
      "Epoch: 41/500... Training loss: 0.4390\n",
      "Epoch: 41/500... Training loss: 0.4313\n",
      "Epoch: 41/500... Training loss: 0.4694\n",
      "Epoch: 41/500... Training loss: 0.5594\n",
      "Epoch: 41/500... Training loss: 0.4548\n",
      "Epoch: 41/500... Training loss: 0.4243\n",
      "Epoch: 42/500... Training loss: 0.4980\n",
      "Epoch: 42/500... Training loss: 0.6507\n",
      "Epoch: 42/500... Training loss: 0.6796\n",
      "Epoch: 42/500... Training loss: 0.6034\n",
      "Epoch: 42/500... Training loss: 0.6260\n",
      "Epoch: 42/500... Training loss: 0.5250\n",
      "Epoch: 42/500... Training loss: 0.5604\n",
      "Epoch: 42/500... Training loss: 0.6236\n",
      "Epoch: 42/500... Training loss: 0.4895\n",
      "Epoch: 42/500... Training loss: 0.6254\n",
      "Epoch: 42/500... Training loss: 0.7240\n",
      "Epoch: 42/500... Training loss: 0.6187\n",
      "Epoch: 42/500... Training loss: 0.6416\n",
      "Epoch: 42/500... Training loss: 0.4389\n",
      "Epoch: 42/500... Training loss: 0.3643\n",
      "Epoch: 42/500... Training loss: 0.4062\n",
      "Epoch: 42/500... Training loss: 0.4919\n",
      "Epoch: 42/500... Training loss: 0.5987\n",
      "Epoch: 42/500... Training loss: 0.8159\n",
      "Epoch: 42/500... Training loss: 0.4829\n",
      "Epoch: 42/500... Training loss: 0.4951\n",
      "Epoch: 42/500... Training loss: 0.6349\n",
      "Epoch: 42/500... Training loss: 0.5540\n",
      "Epoch: 42/500... Training loss: 0.5012\n",
      "Epoch: 42/500... Training loss: 0.5564\n",
      "Epoch: 42/500... Training loss: 0.6814\n",
      "Epoch: 42/500... Training loss: 0.8343\n",
      "Epoch: 42/500... Training loss: 0.3894\n",
      "Epoch: 42/500... Training loss: 0.5521\n",
      "Epoch: 42/500... Training loss: 0.5160\n",
      "Epoch: 42/500... Training loss: 0.5874\n",
      "Epoch: 43/500... Training loss: 0.4790\n",
      "Epoch: 43/500... Training loss: 0.5075\n",
      "Epoch: 43/500... Training loss: 0.5149\n",
      "Epoch: 43/500... Training loss: 0.6579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/500... Training loss: 0.5912\n",
      "Epoch: 43/500... Training loss: 0.5096\n",
      "Epoch: 43/500... Training loss: 0.5285\n",
      "Epoch: 43/500... Training loss: 0.6100\n",
      "Epoch: 43/500... Training loss: 0.4450\n",
      "Epoch: 43/500... Training loss: 0.6632\n",
      "Epoch: 43/500... Training loss: 0.6996\n",
      "Epoch: 43/500... Training loss: 0.7434\n",
      "Epoch: 43/500... Training loss: 0.6325\n",
      "Epoch: 43/500... Training loss: 0.4558\n",
      "Epoch: 43/500... Training loss: 0.5876\n",
      "Epoch: 43/500... Training loss: 0.5739\n",
      "Epoch: 43/500... Training loss: 0.5107\n",
      "Epoch: 43/500... Training loss: 0.5347\n",
      "Epoch: 43/500... Training loss: 0.4642\n",
      "Epoch: 43/500... Training loss: 0.4644\n",
      "Epoch: 43/500... Training loss: 0.4352\n",
      "Epoch: 43/500... Training loss: 0.5133\n",
      "Epoch: 43/500... Training loss: 0.5030\n",
      "Epoch: 43/500... Training loss: 0.4486\n",
      "Epoch: 43/500... Training loss: 0.3542\n",
      "Epoch: 43/500... Training loss: 0.5256\n",
      "Epoch: 43/500... Training loss: 0.2703\n",
      "Epoch: 43/500... Training loss: 0.4590\n",
      "Epoch: 43/500... Training loss: 0.4541\n",
      "Epoch: 43/500... Training loss: 0.4560\n",
      "Epoch: 43/500... Training loss: 0.4359\n",
      "Epoch: 44/500... Training loss: 0.6052\n",
      "Epoch: 44/500... Training loss: 0.5945\n",
      "Epoch: 44/500... Training loss: 0.4377\n",
      "Epoch: 44/500... Training loss: 0.5571\n",
      "Epoch: 44/500... Training loss: 0.5856\n",
      "Epoch: 44/500... Training loss: 0.5451\n",
      "Epoch: 44/500... Training loss: 0.6036\n",
      "Epoch: 44/500... Training loss: 0.7114\n",
      "Epoch: 44/500... Training loss: 0.4723\n",
      "Epoch: 44/500... Training loss: 0.5523\n",
      "Epoch: 44/500... Training loss: 0.6133\n",
      "Epoch: 44/500... Training loss: 0.5818\n",
      "Epoch: 44/500... Training loss: 0.7642\n",
      "Epoch: 44/500... Training loss: 0.4102\n",
      "Epoch: 44/500... Training loss: 0.5009\n",
      "Epoch: 44/500... Training loss: 0.3466\n",
      "Epoch: 44/500... Training loss: 0.4140\n",
      "Epoch: 44/500... Training loss: 0.5049\n",
      "Epoch: 44/500... Training loss: 0.6535\n",
      "Epoch: 44/500... Training loss: 0.3887\n",
      "Epoch: 44/500... Training loss: 0.5612\n",
      "Epoch: 44/500... Training loss: 0.5558\n",
      "Epoch: 44/500... Training loss: 0.5223\n",
      "Epoch: 44/500... Training loss: 0.5163\n",
      "Epoch: 44/500... Training loss: 0.4486\n",
      "Epoch: 44/500... Training loss: 0.5023\n",
      "Epoch: 44/500... Training loss: 0.6393\n",
      "Epoch: 44/500... Training loss: 0.3329\n",
      "Epoch: 44/500... Training loss: 0.4023\n",
      "Epoch: 44/500... Training loss: 0.4031\n",
      "Epoch: 44/500... Training loss: 0.4583\n",
      "Epoch: 45/500... Training loss: 0.4819\n",
      "Epoch: 45/500... Training loss: 0.5236\n",
      "Epoch: 45/500... Training loss: 0.5443\n",
      "Epoch: 45/500... Training loss: 0.6754\n",
      "Epoch: 45/500... Training loss: 0.5095\n",
      "Epoch: 45/500... Training loss: 0.4910\n",
      "Epoch: 45/500... Training loss: 0.4586\n",
      "Epoch: 45/500... Training loss: 0.5425\n",
      "Epoch: 45/500... Training loss: 0.5528\n",
      "Epoch: 45/500... Training loss: 0.4193\n",
      "Epoch: 45/500... Training loss: 0.4632\n",
      "Epoch: 45/500... Training loss: 0.8003\n",
      "Epoch: 45/500... Training loss: 0.4772\n",
      "Epoch: 45/500... Training loss: 0.4762\n",
      "Epoch: 45/500... Training loss: 0.5224\n",
      "Epoch: 45/500... Training loss: 0.3024\n",
      "Epoch: 45/500... Training loss: 0.4655\n",
      "Epoch: 45/500... Training loss: 0.4906\n",
      "Epoch: 45/500... Training loss: 0.6750\n",
      "Epoch: 45/500... Training loss: 0.3624\n",
      "Epoch: 45/500... Training loss: 0.5496\n",
      "Epoch: 45/500... Training loss: 0.5735\n",
      "Epoch: 45/500... Training loss: 0.4463\n",
      "Epoch: 45/500... Training loss: 0.4343\n",
      "Epoch: 45/500... Training loss: 0.3183\n",
      "Epoch: 45/500... Training loss: 0.5125\n",
      "Epoch: 45/500... Training loss: 0.4628\n",
      "Epoch: 45/500... Training loss: 0.4759\n",
      "Epoch: 45/500... Training loss: 0.3703\n",
      "Epoch: 45/500... Training loss: 0.4222\n",
      "Epoch: 45/500... Training loss: 0.2378\n",
      "Epoch: 46/500... Training loss: 0.6381\n",
      "Epoch: 46/500... Training loss: 0.4368\n",
      "Epoch: 46/500... Training loss: 0.6541\n",
      "Epoch: 46/500... Training loss: 0.5872\n",
      "Epoch: 46/500... Training loss: 0.4911\n",
      "Epoch: 46/500... Training loss: 0.4581\n",
      "Epoch: 46/500... Training loss: 0.6192\n",
      "Epoch: 46/500... Training loss: 0.5423\n",
      "Epoch: 46/500... Training loss: 0.4342\n",
      "Epoch: 46/500... Training loss: 0.5874\n",
      "Epoch: 46/500... Training loss: 0.6403\n",
      "Epoch: 46/500... Training loss: 0.7290\n",
      "Epoch: 46/500... Training loss: 0.5446\n",
      "Epoch: 46/500... Training loss: 0.3745\n",
      "Epoch: 46/500... Training loss: 0.2844\n",
      "Epoch: 46/500... Training loss: 0.3949\n",
      "Epoch: 46/500... Training loss: 0.3671\n",
      "Epoch: 46/500... Training loss: 0.4718\n",
      "Epoch: 46/500... Training loss: 0.6609\n",
      "Epoch: 46/500... Training loss: 0.3371\n",
      "Epoch: 46/500... Training loss: 0.5098\n",
      "Epoch: 46/500... Training loss: 0.6277\n",
      "Epoch: 46/500... Training loss: 0.4165\n",
      "Epoch: 46/500... Training loss: 0.4282\n",
      "Epoch: 46/500... Training loss: 0.4259\n",
      "Epoch: 46/500... Training loss: 0.3914\n",
      "Epoch: 46/500... Training loss: 0.4434\n",
      "Epoch: 46/500... Training loss: 0.4937\n",
      "Epoch: 46/500... Training loss: 0.3445\n",
      "Epoch: 46/500... Training loss: 0.3441\n",
      "Epoch: 46/500... Training loss: 0.4672\n",
      "Epoch: 47/500... Training loss: 0.4188\n",
      "Epoch: 47/500... Training loss: 0.3616\n",
      "Epoch: 47/500... Training loss: 0.4475\n",
      "Epoch: 47/500... Training loss: 0.6140\n",
      "Epoch: 47/500... Training loss: 0.4753\n",
      "Epoch: 47/500... Training loss: 0.4516\n",
      "Epoch: 47/500... Training loss: 0.6311\n",
      "Epoch: 47/500... Training loss: 0.5107\n",
      "Epoch: 47/500... Training loss: 0.6145\n",
      "Epoch: 47/500... Training loss: 0.4852\n",
      "Epoch: 47/500... Training loss: 0.5485\n",
      "Epoch: 47/500... Training loss: 0.6002\n",
      "Epoch: 47/500... Training loss: 0.7009\n",
      "Epoch: 47/500... Training loss: 0.3879\n",
      "Epoch: 47/500... Training loss: 0.4061\n",
      "Epoch: 47/500... Training loss: 0.3048\n",
      "Epoch: 47/500... Training loss: 0.4756\n",
      "Epoch: 47/500... Training loss: 0.5447\n",
      "Epoch: 47/500... Training loss: 0.5218\n",
      "Epoch: 47/500... Training loss: 0.4646\n",
      "Epoch: 47/500... Training loss: 0.5123\n",
      "Epoch: 47/500... Training loss: 0.4376\n",
      "Epoch: 47/500... Training loss: 0.4571\n",
      "Epoch: 47/500... Training loss: 0.3468\n",
      "Epoch: 47/500... Training loss: 0.4629\n",
      "Epoch: 47/500... Training loss: 0.5313\n",
      "Epoch: 47/500... Training loss: 0.3661\n",
      "Epoch: 47/500... Training loss: 0.3655\n",
      "Epoch: 47/500... Training loss: 0.3924\n",
      "Epoch: 47/500... Training loss: 0.3547\n",
      "Epoch: 47/500... Training loss: 0.4000\n",
      "Epoch: 48/500... Training loss: 0.5868\n",
      "Epoch: 48/500... Training loss: 0.5047\n",
      "Epoch: 48/500... Training loss: 0.4318\n",
      "Epoch: 48/500... Training loss: 0.5581\n",
      "Epoch: 48/500... Training loss: 0.4957\n",
      "Epoch: 48/500... Training loss: 0.5205\n",
      "Epoch: 48/500... Training loss: 0.4335\n",
      "Epoch: 48/500... Training loss: 0.4596\n",
      "Epoch: 48/500... Training loss: 0.5159\n",
      "Epoch: 48/500... Training loss: 0.4635\n",
      "Epoch: 48/500... Training loss: 0.6477\n",
      "Epoch: 48/500... Training loss: 0.7751\n",
      "Epoch: 48/500... Training loss: 0.5756\n",
      "Epoch: 48/500... Training loss: 0.4293\n",
      "Epoch: 48/500... Training loss: 0.2788\n",
      "Epoch: 48/500... Training loss: 0.3854\n",
      "Epoch: 48/500... Training loss: 0.3252\n",
      "Epoch: 48/500... Training loss: 0.4235\n",
      "Epoch: 48/500... Training loss: 0.5515\n",
      "Epoch: 48/500... Training loss: 0.6143\n",
      "Epoch: 48/500... Training loss: 0.4073\n",
      "Epoch: 48/500... Training loss: 0.4598\n",
      "Epoch: 48/500... Training loss: 0.4473\n",
      "Epoch: 48/500... Training loss: 0.4833\n",
      "Epoch: 48/500... Training loss: 0.4050\n",
      "Epoch: 48/500... Training loss: 0.3574\n",
      "Epoch: 48/500... Training loss: 0.3704\n",
      "Epoch: 48/500... Training loss: 0.4041\n",
      "Epoch: 48/500... Training loss: 0.2945\n",
      "Epoch: 48/500... Training loss: 0.5139\n",
      "Epoch: 48/500... Training loss: 0.3203\n",
      "Epoch: 49/500... Training loss: 0.4695\n",
      "Epoch: 49/500... Training loss: 0.3906\n",
      "Epoch: 49/500... Training loss: 0.3208\n",
      "Epoch: 49/500... Training loss: 0.5801\n",
      "Epoch: 49/500... Training loss: 0.4160\n",
      "Epoch: 49/500... Training loss: 0.4229\n",
      "Epoch: 49/500... Training loss: 0.5100\n",
      "Epoch: 49/500... Training loss: 0.4277\n",
      "Epoch: 49/500... Training loss: 0.3541\n",
      "Epoch: 49/500... Training loss: 0.5196\n",
      "Epoch: 49/500... Training loss: 0.5703\n",
      "Epoch: 49/500... Training loss: 0.6990\n",
      "Epoch: 49/500... Training loss: 0.5961\n",
      "Epoch: 49/500... Training loss: 0.2820\n",
      "Epoch: 49/500... Training loss: 0.5062\n",
      "Epoch: 49/500... Training loss: 0.3493\n",
      "Epoch: 49/500... Training loss: 0.2678\n",
      "Epoch: 49/500... Training loss: 0.3899\n",
      "Epoch: 49/500... Training loss: 0.4487\n",
      "Epoch: 49/500... Training loss: 0.2330\n",
      "Epoch: 49/500... Training loss: 0.3948\n",
      "Epoch: 49/500... Training loss: 0.5182\n",
      "Epoch: 49/500... Training loss: 0.3735\n",
      "Epoch: 49/500... Training loss: 0.3491\n",
      "Epoch: 49/500... Training loss: 0.4397\n",
      "Epoch: 49/500... Training loss: 0.4655\n",
      "Epoch: 49/500... Training loss: 0.2917\n",
      "Epoch: 49/500... Training loss: 0.5287\n",
      "Epoch: 49/500... Training loss: 0.3770\n",
      "Epoch: 49/500... Training loss: 0.3635\n",
      "Epoch: 49/500... Training loss: 0.5388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/500... Training loss: 0.5943\n",
      "Epoch: 50/500... Training loss: 0.3016\n",
      "Epoch: 50/500... Training loss: 0.3651\n",
      "Epoch: 50/500... Training loss: 0.4451\n",
      "Epoch: 50/500... Training loss: 0.5538\n",
      "Epoch: 50/500... Training loss: 0.5316\n",
      "Epoch: 50/500... Training loss: 0.4425\n",
      "Epoch: 50/500... Training loss: 0.4642\n",
      "Epoch: 50/500... Training loss: 0.3687\n",
      "Epoch: 50/500... Training loss: 0.5294\n",
      "Epoch: 50/500... Training loss: 0.4978\n",
      "Epoch: 50/500... Training loss: 0.5843\n",
      "Epoch: 50/500... Training loss: 0.5781\n",
      "Epoch: 50/500... Training loss: 0.3869\n",
      "Epoch: 50/500... Training loss: 0.3351\n",
      "Epoch: 50/500... Training loss: 0.3160\n",
      "Epoch: 50/500... Training loss: 0.4862\n",
      "Epoch: 50/500... Training loss: 0.4539\n",
      "Epoch: 50/500... Training loss: 0.5479\n",
      "Epoch: 50/500... Training loss: 0.4214\n",
      "Epoch: 50/500... Training loss: 0.3586\n",
      "Epoch: 50/500... Training loss: 0.3868\n",
      "Epoch: 50/500... Training loss: 0.5450\n",
      "Epoch: 50/500... Training loss: 0.4794\n",
      "Epoch: 50/500... Training loss: 0.3036\n",
      "Epoch: 50/500... Training loss: 0.4148\n",
      "Epoch: 50/500... Training loss: 0.5135\n",
      "Epoch: 50/500... Training loss: 0.2497\n",
      "Epoch: 50/500... Training loss: 0.3711\n",
      "Epoch: 50/500... Training loss: 0.4248\n",
      "Epoch: 50/500... Training loss: 0.3050\n",
      "Epoch: 51/500... Training loss: 0.4607\n",
      "Epoch: 51/500... Training loss: 0.3431\n",
      "Epoch: 51/500... Training loss: 0.5112\n",
      "Epoch: 51/500... Training loss: 0.4800\n",
      "Epoch: 51/500... Training loss: 0.4455\n",
      "Epoch: 51/500... Training loss: 0.4668\n",
      "Epoch: 51/500... Training loss: 0.4613\n",
      "Epoch: 51/500... Training loss: 0.4912\n",
      "Epoch: 51/500... Training loss: 0.4455\n",
      "Epoch: 51/500... Training loss: 0.3050\n",
      "Epoch: 51/500... Training loss: 0.5061\n",
      "Epoch: 51/500... Training loss: 0.4880\n",
      "Epoch: 51/500... Training loss: 0.4480\n",
      "Epoch: 51/500... Training loss: 0.2890\n",
      "Epoch: 51/500... Training loss: 0.4147\n",
      "Epoch: 51/500... Training loss: 0.4045\n",
      "Epoch: 51/500... Training loss: 0.3587\n",
      "Epoch: 51/500... Training loss: 0.5385\n",
      "Epoch: 51/500... Training loss: 0.6202\n",
      "Epoch: 51/500... Training loss: 0.3451\n",
      "Epoch: 51/500... Training loss: 0.3931\n",
      "Epoch: 51/500... Training loss: 0.6793\n",
      "Epoch: 51/500... Training loss: 0.4740\n",
      "Epoch: 51/500... Training loss: 0.3964\n",
      "Epoch: 51/500... Training loss: 0.4495\n",
      "Epoch: 51/500... Training loss: 0.4418\n",
      "Epoch: 51/500... Training loss: 0.3375\n",
      "Epoch: 51/500... Training loss: 0.2568\n",
      "Epoch: 51/500... Training loss: 0.3568\n",
      "Epoch: 51/500... Training loss: 0.3218\n",
      "Epoch: 51/500... Training loss: 0.3943\n",
      "Epoch: 52/500... Training loss: 0.4642\n",
      "Epoch: 52/500... Training loss: 0.3726\n",
      "Epoch: 52/500... Training loss: 0.4043\n",
      "Epoch: 52/500... Training loss: 0.5107\n",
      "Epoch: 52/500... Training loss: 0.4213\n",
      "Epoch: 52/500... Training loss: 0.4204\n",
      "Epoch: 52/500... Training loss: 0.3992\n",
      "Epoch: 52/500... Training loss: 0.4248\n",
      "Epoch: 52/500... Training loss: 0.3581\n",
      "Epoch: 52/500... Training loss: 0.3946\n",
      "Epoch: 52/500... Training loss: 0.6271\n",
      "Epoch: 52/500... Training loss: 0.4254\n",
      "Epoch: 52/500... Training loss: 0.5634\n",
      "Epoch: 52/500... Training loss: 0.3293\n",
      "Epoch: 52/500... Training loss: 0.3927\n",
      "Epoch: 52/500... Training loss: 0.3648\n",
      "Epoch: 52/500... Training loss: 0.3626\n",
      "Epoch: 52/500... Training loss: 0.3458\n",
      "Epoch: 52/500... Training loss: 0.5058\n",
      "Epoch: 52/500... Training loss: 0.2954\n",
      "Epoch: 52/500... Training loss: 0.4647\n",
      "Epoch: 52/500... Training loss: 0.4076\n",
      "Epoch: 52/500... Training loss: 0.3605\n",
      "Epoch: 52/500... Training loss: 0.4137\n",
      "Epoch: 52/500... Training loss: 0.2960\n",
      "Epoch: 52/500... Training loss: 0.3359\n",
      "Epoch: 52/500... Training loss: 0.3508\n",
      "Epoch: 52/500... Training loss: 0.4020\n",
      "Epoch: 52/500... Training loss: 0.2752\n",
      "Epoch: 52/500... Training loss: 0.4661\n",
      "Epoch: 52/500... Training loss: 0.2380\n",
      "Epoch: 53/500... Training loss: 0.3593\n",
      "Epoch: 53/500... Training loss: 0.3972\n",
      "Epoch: 53/500... Training loss: 0.3087\n",
      "Epoch: 53/500... Training loss: 0.4747\n",
      "Epoch: 53/500... Training loss: 0.5192\n",
      "Epoch: 53/500... Training loss: 0.3701\n",
      "Epoch: 53/500... Training loss: 0.4389\n",
      "Epoch: 53/500... Training loss: 0.4804\n",
      "Epoch: 53/500... Training loss: 0.4777\n",
      "Epoch: 53/500... Training loss: 0.3834\n",
      "Epoch: 53/500... Training loss: 0.5467\n",
      "Epoch: 53/500... Training loss: 0.6040\n",
      "Epoch: 53/500... Training loss: 0.5257\n",
      "Epoch: 53/500... Training loss: 0.3556\n",
      "Epoch: 53/500... Training loss: 0.2948\n",
      "Epoch: 53/500... Training loss: 0.3133\n",
      "Epoch: 53/500... Training loss: 0.3473\n",
      "Epoch: 53/500... Training loss: 0.4247\n",
      "Epoch: 53/500... Training loss: 0.4721\n",
      "Epoch: 53/500... Training loss: 0.3128\n",
      "Epoch: 53/500... Training loss: 0.2437\n",
      "Epoch: 53/500... Training loss: 0.4564\n",
      "Epoch: 53/500... Training loss: 0.4370\n",
      "Epoch: 53/500... Training loss: 0.3439\n",
      "Epoch: 53/500... Training loss: 0.4174\n",
      "Epoch: 53/500... Training loss: 0.4277\n",
      "Epoch: 53/500... Training loss: 0.4705\n",
      "Epoch: 53/500... Training loss: 0.3089\n",
      "Epoch: 53/500... Training loss: 0.3296\n",
      "Epoch: 53/500... Training loss: 0.3213\n",
      "Epoch: 53/500... Training loss: 0.3400\n",
      "Epoch: 54/500... Training loss: 0.3820\n",
      "Epoch: 54/500... Training loss: 0.4504\n",
      "Epoch: 54/500... Training loss: 0.4461\n",
      "Epoch: 54/500... Training loss: 0.4363\n",
      "Epoch: 54/500... Training loss: 0.4730\n",
      "Epoch: 54/500... Training loss: 0.5248\n",
      "Epoch: 54/500... Training loss: 0.3676\n",
      "Epoch: 54/500... Training loss: 0.5256\n",
      "Epoch: 54/500... Training loss: 0.3564\n",
      "Epoch: 54/500... Training loss: 0.4986\n",
      "Epoch: 54/500... Training loss: 0.8054\n",
      "Epoch: 54/500... Training loss: 0.6028\n",
      "Epoch: 54/500... Training loss: 0.5616\n",
      "Epoch: 54/500... Training loss: 0.4237\n",
      "Epoch: 54/500... Training loss: 0.3839\n",
      "Epoch: 54/500... Training loss: 0.2301\n",
      "Epoch: 54/500... Training loss: 0.3655\n",
      "Epoch: 54/500... Training loss: 0.4407\n",
      "Epoch: 54/500... Training loss: 0.4497\n",
      "Epoch: 54/500... Training loss: 0.2768\n",
      "Epoch: 54/500... Training loss: 0.3583\n",
      "Epoch: 54/500... Training loss: 0.4690\n",
      "Epoch: 54/500... Training loss: 0.4806\n",
      "Epoch: 54/500... Training loss: 0.3128\n",
      "Epoch: 54/500... Training loss: 0.3470\n",
      "Epoch: 54/500... Training loss: 0.3687\n",
      "Epoch: 54/500... Training loss: 0.3018\n",
      "Epoch: 54/500... Training loss: 0.3249\n",
      "Epoch: 54/500... Training loss: 0.2397\n",
      "Epoch: 54/500... Training loss: 0.2810\n",
      "Epoch: 54/500... Training loss: 0.3028\n",
      "Epoch: 55/500... Training loss: 0.4161\n",
      "Epoch: 55/500... Training loss: 0.3759\n",
      "Epoch: 55/500... Training loss: 0.4868\n",
      "Epoch: 55/500... Training loss: 0.4729\n",
      "Epoch: 55/500... Training loss: 0.5480\n",
      "Epoch: 55/500... Training loss: 0.3428\n",
      "Epoch: 55/500... Training loss: 0.4505\n",
      "Epoch: 55/500... Training loss: 0.5368\n",
      "Epoch: 55/500... Training loss: 0.4889\n",
      "Epoch: 55/500... Training loss: 0.4025\n",
      "Epoch: 55/500... Training loss: 0.4045\n",
      "Epoch: 55/500... Training loss: 0.5622\n",
      "Epoch: 55/500... Training loss: 0.5405\n",
      "Epoch: 55/500... Training loss: 0.4641\n",
      "Epoch: 55/500... Training loss: 0.3576\n",
      "Epoch: 55/500... Training loss: 0.2413\n",
      "Epoch: 55/500... Training loss: 0.3607\n",
      "Epoch: 55/500... Training loss: 0.4009\n",
      "Epoch: 55/500... Training loss: 0.4050\n",
      "Epoch: 55/500... Training loss: 0.3827\n",
      "Epoch: 55/500... Training loss: 0.3406\n",
      "Epoch: 55/500... Training loss: 0.5747\n",
      "Epoch: 55/500... Training loss: 0.3889\n",
      "Epoch: 55/500... Training loss: 0.3937\n",
      "Epoch: 55/500... Training loss: 0.4123\n",
      "Epoch: 55/500... Training loss: 0.3475\n",
      "Epoch: 55/500... Training loss: 0.3690\n",
      "Epoch: 55/500... Training loss: 0.3163\n",
      "Epoch: 55/500... Training loss: 0.2934\n",
      "Epoch: 55/500... Training loss: 0.4026\n",
      "Epoch: 55/500... Training loss: 0.4065\n",
      "Epoch: 56/500... Training loss: 0.2586\n",
      "Epoch: 56/500... Training loss: 0.3981\n",
      "Epoch: 56/500... Training loss: 0.5045\n",
      "Epoch: 56/500... Training loss: 0.5774\n",
      "Epoch: 56/500... Training loss: 0.4087\n",
      "Epoch: 56/500... Training loss: 0.4368\n",
      "Epoch: 56/500... Training loss: 0.4024\n",
      "Epoch: 56/500... Training loss: 0.4369\n",
      "Epoch: 56/500... Training loss: 0.3517\n",
      "Epoch: 56/500... Training loss: 0.4067\n",
      "Epoch: 56/500... Training loss: 0.5710\n",
      "Epoch: 56/500... Training loss: 0.6363\n",
      "Epoch: 56/500... Training loss: 0.9077\n",
      "Epoch: 56/500... Training loss: 0.4620\n",
      "Epoch: 56/500... Training loss: 0.3220\n",
      "Epoch: 56/500... Training loss: 0.2699\n",
      "Epoch: 56/500... Training loss: 0.3692\n",
      "Epoch: 56/500... Training loss: 0.3906\n",
      "Epoch: 56/500... Training loss: 0.4092\n",
      "Epoch: 56/500... Training loss: 0.3534\n",
      "Epoch: 56/500... Training loss: 0.4433\n",
      "Epoch: 56/500... Training loss: 0.5751\n",
      "Epoch: 56/500... Training loss: 0.4615\n",
      "Epoch: 56/500... Training loss: 0.2901\n",
      "Epoch: 56/500... Training loss: 0.2087\n",
      "Epoch: 56/500... Training loss: 0.3726\n",
      "Epoch: 56/500... Training loss: 0.3802\n",
      "Epoch: 56/500... Training loss: 0.3486\n",
      "Epoch: 56/500... Training loss: 0.2736\n",
      "Epoch: 56/500... Training loss: 0.3193\n",
      "Epoch: 56/500... Training loss: 0.3209\n",
      "Epoch: 57/500... Training loss: 0.3276\n",
      "Epoch: 57/500... Training loss: 0.4127\n",
      "Epoch: 57/500... Training loss: 0.4026\n",
      "Epoch: 57/500... Training loss: 0.5072\n",
      "Epoch: 57/500... Training loss: 0.3942\n",
      "Epoch: 57/500... Training loss: 0.3717\n",
      "Epoch: 57/500... Training loss: 0.3433\n",
      "Epoch: 57/500... Training loss: 0.4740\n",
      "Epoch: 57/500... Training loss: 0.2899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/500... Training loss: 0.4868\n",
      "Epoch: 57/500... Training loss: 0.4899\n",
      "Epoch: 57/500... Training loss: 0.4004\n",
      "Epoch: 57/500... Training loss: 0.5129\n",
      "Epoch: 57/500... Training loss: 0.2855\n",
      "Epoch: 57/500... Training loss: 0.4049\n",
      "Epoch: 57/500... Training loss: 0.3761\n",
      "Epoch: 57/500... Training loss: 0.3545\n",
      "Epoch: 57/500... Training loss: 0.3963\n",
      "Epoch: 57/500... Training loss: 0.5142\n",
      "Epoch: 57/500... Training loss: 0.2321\n",
      "Epoch: 57/500... Training loss: 0.4270\n",
      "Epoch: 57/500... Training loss: 0.3497\n",
      "Epoch: 57/500... Training loss: 0.4093\n",
      "Epoch: 57/500... Training loss: 0.3793\n",
      "Epoch: 57/500... Training loss: 0.2710\n",
      "Epoch: 57/500... Training loss: 0.2861\n",
      "Epoch: 57/500... Training loss: 0.2826\n",
      "Epoch: 57/500... Training loss: 0.2913\n",
      "Epoch: 57/500... Training loss: 0.2619\n",
      "Epoch: 57/500... Training loss: 0.2982\n",
      "Epoch: 57/500... Training loss: 0.2379\n",
      "Epoch: 58/500... Training loss: 0.3508\n",
      "Epoch: 58/500... Training loss: 0.4568\n",
      "Epoch: 58/500... Training loss: 0.4706\n",
      "Epoch: 58/500... Training loss: 0.4257\n",
      "Epoch: 58/500... Training loss: 0.4279\n",
      "Epoch: 58/500... Training loss: 0.3738\n",
      "Epoch: 58/500... Training loss: 0.4848\n",
      "Epoch: 58/500... Training loss: 0.3282\n",
      "Epoch: 58/500... Training loss: 0.4535\n",
      "Epoch: 58/500... Training loss: 0.4750\n",
      "Epoch: 58/500... Training loss: 0.5761\n",
      "Epoch: 58/500... Training loss: 0.5465\n",
      "Epoch: 58/500... Training loss: 0.4767\n",
      "Epoch: 58/500... Training loss: 0.2655\n",
      "Epoch: 58/500... Training loss: 0.3937\n",
      "Epoch: 58/500... Training loss: 0.2624\n",
      "Epoch: 58/500... Training loss: 0.3300\n",
      "Epoch: 58/500... Training loss: 0.4424\n",
      "Epoch: 58/500... Training loss: 0.4143\n",
      "Epoch: 58/500... Training loss: 0.2330\n",
      "Epoch: 58/500... Training loss: 0.3413\n",
      "Epoch: 58/500... Training loss: 0.5416\n",
      "Epoch: 58/500... Training loss: 0.3594\n",
      "Epoch: 58/500... Training loss: 0.3572\n",
      "Epoch: 58/500... Training loss: 0.2899\n",
      "Epoch: 58/500... Training loss: 0.4649\n",
      "Epoch: 58/500... Training loss: 0.4206\n",
      "Epoch: 58/500... Training loss: 0.3096\n",
      "Epoch: 58/500... Training loss: 0.2389\n",
      "Epoch: 58/500... Training loss: 0.2561\n",
      "Epoch: 58/500... Training loss: 0.2524\n",
      "Epoch: 59/500... Training loss: 0.4367\n",
      "Epoch: 59/500... Training loss: 0.5476\n",
      "Epoch: 59/500... Training loss: 0.3204\n",
      "Epoch: 59/500... Training loss: 0.3814\n",
      "Epoch: 59/500... Training loss: 0.3960\n",
      "Epoch: 59/500... Training loss: 0.3303\n",
      "Epoch: 59/500... Training loss: 0.2796\n",
      "Epoch: 59/500... Training loss: 0.4745\n",
      "Epoch: 59/500... Training loss: 0.3631\n",
      "Epoch: 59/500... Training loss: 0.5138\n",
      "Epoch: 59/500... Training loss: 0.4668\n",
      "Epoch: 59/500... Training loss: 0.5926\n",
      "Epoch: 59/500... Training loss: 0.4529\n",
      "Epoch: 59/500... Training loss: 0.3373\n",
      "Epoch: 59/500... Training loss: 0.3205\n",
      "Epoch: 59/500... Training loss: 0.2580\n",
      "Epoch: 59/500... Training loss: 0.2895\n",
      "Epoch: 59/500... Training loss: 0.4072\n",
      "Epoch: 59/500... Training loss: 0.4896\n",
      "Epoch: 59/500... Training loss: 0.2778\n",
      "Epoch: 59/500... Training loss: 0.3014\n",
      "Epoch: 59/500... Training loss: 0.3595\n",
      "Epoch: 59/500... Training loss: 0.3374\n",
      "Epoch: 59/500... Training loss: 0.3411\n",
      "Epoch: 59/500... Training loss: 0.3260\n",
      "Epoch: 59/500... Training loss: 0.2494\n",
      "Epoch: 59/500... Training loss: 0.2746\n",
      "Epoch: 59/500... Training loss: 0.3206\n",
      "Epoch: 59/500... Training loss: 0.2209\n",
      "Epoch: 59/500... Training loss: 0.2923\n",
      "Epoch: 59/500... Training loss: 0.3178\n",
      "Epoch: 60/500... Training loss: 0.2485\n",
      "Epoch: 60/500... Training loss: 0.3971\n",
      "Epoch: 60/500... Training loss: 0.4515\n",
      "Epoch: 60/500... Training loss: 0.3869\n",
      "Epoch: 60/500... Training loss: 0.2947\n",
      "Epoch: 60/500... Training loss: 0.3672\n",
      "Epoch: 60/500... Training loss: 0.4572\n",
      "Epoch: 60/500... Training loss: 0.3015\n",
      "Epoch: 60/500... Training loss: 0.3377\n",
      "Epoch: 60/500... Training loss: 0.4002\n",
      "Epoch: 60/500... Training loss: 0.5359\n",
      "Epoch: 60/500... Training loss: 0.5447\n",
      "Epoch: 60/500... Training loss: 0.4874\n",
      "Epoch: 60/500... Training loss: 0.2161\n",
      "Epoch: 60/500... Training loss: 0.3458\n",
      "Epoch: 60/500... Training loss: 0.2833\n",
      "Epoch: 60/500... Training loss: 0.3616\n",
      "Epoch: 60/500... Training loss: 0.3347\n",
      "Epoch: 60/500... Training loss: 0.2655\n",
      "Epoch: 60/500... Training loss: 0.2908\n",
      "Epoch: 60/500... Training loss: 0.2918\n",
      "Epoch: 60/500... Training loss: 0.4008\n",
      "Epoch: 60/500... Training loss: 0.3081\n",
      "Epoch: 60/500... Training loss: 0.2894\n",
      "Epoch: 60/500... Training loss: 0.3571\n",
      "Epoch: 60/500... Training loss: 0.4054\n",
      "Epoch: 60/500... Training loss: 0.3165\n",
      "Epoch: 60/500... Training loss: 0.2406\n",
      "Epoch: 60/500... Training loss: 0.2282\n",
      "Epoch: 60/500... Training loss: 0.2973\n",
      "Epoch: 60/500... Training loss: 0.3205\n",
      "Epoch: 61/500... Training loss: 0.2670\n",
      "Epoch: 61/500... Training loss: 0.5023\n",
      "Epoch: 61/500... Training loss: 0.4002\n",
      "Epoch: 61/500... Training loss: 0.5549\n",
      "Epoch: 61/500... Training loss: 0.3316\n",
      "Epoch: 61/500... Training loss: 0.4042\n",
      "Epoch: 61/500... Training loss: 0.3073\n",
      "Epoch: 61/500... Training loss: 0.4070\n",
      "Epoch: 61/500... Training loss: 0.3140\n",
      "Epoch: 61/500... Training loss: 0.3347\n",
      "Epoch: 61/500... Training loss: 0.5782\n",
      "Epoch: 61/500... Training loss: 0.6783\n",
      "Epoch: 61/500... Training loss: 0.3467\n",
      "Epoch: 61/500... Training loss: 0.3048\n",
      "Epoch: 61/500... Training loss: 0.3262\n",
      "Epoch: 61/500... Training loss: 0.2469\n",
      "Epoch: 61/500... Training loss: 0.3075\n",
      "Epoch: 61/500... Training loss: 0.3400\n",
      "Epoch: 61/500... Training loss: 0.2911\n",
      "Epoch: 61/500... Training loss: 0.3152\n",
      "Epoch: 61/500... Training loss: 0.3265\n",
      "Epoch: 61/500... Training loss: 0.3988\n",
      "Epoch: 61/500... Training loss: 0.3033\n",
      "Epoch: 61/500... Training loss: 0.3657\n",
      "Epoch: 61/500... Training loss: 0.3341\n",
      "Epoch: 61/500... Training loss: 0.2542\n",
      "Epoch: 61/500... Training loss: 0.2552\n",
      "Epoch: 61/500... Training loss: 0.2895\n",
      "Epoch: 61/500... Training loss: 0.2943\n",
      "Epoch: 61/500... Training loss: 0.2246\n",
      "Epoch: 61/500... Training loss: 0.2764\n",
      "Epoch: 62/500... Training loss: 0.2904\n",
      "Epoch: 62/500... Training loss: 0.2511\n",
      "Epoch: 62/500... Training loss: 0.2467\n",
      "Epoch: 62/500... Training loss: 0.3791\n",
      "Epoch: 62/500... Training loss: 0.5053\n",
      "Epoch: 62/500... Training loss: 0.3446\n",
      "Epoch: 62/500... Training loss: 0.5474\n",
      "Epoch: 62/500... Training loss: 0.3000\n",
      "Epoch: 62/500... Training loss: 0.2712\n",
      "Epoch: 62/500... Training loss: 0.3310\n",
      "Epoch: 62/500... Training loss: 0.5159\n",
      "Epoch: 62/500... Training loss: 0.5288\n",
      "Epoch: 62/500... Training loss: 0.4525\n",
      "Epoch: 62/500... Training loss: 0.2786\n",
      "Epoch: 62/500... Training loss: 0.2807\n",
      "Epoch: 62/500... Training loss: 0.2818\n",
      "Epoch: 62/500... Training loss: 0.2463\n",
      "Epoch: 62/500... Training loss: 0.3940\n",
      "Epoch: 62/500... Training loss: 0.3489\n",
      "Epoch: 62/500... Training loss: 0.1872\n",
      "Epoch: 62/500... Training loss: 0.2917\n",
      "Epoch: 62/500... Training loss: 0.4469\n",
      "Epoch: 62/500... Training loss: 0.3276\n",
      "Epoch: 62/500... Training loss: 0.3113\n",
      "Epoch: 62/500... Training loss: 0.2895\n",
      "Epoch: 62/500... Training loss: 0.4262\n",
      "Epoch: 62/500... Training loss: 0.3219\n",
      "Epoch: 62/500... Training loss: 0.4886\n",
      "Epoch: 62/500... Training loss: 0.3287\n",
      "Epoch: 62/500... Training loss: 0.2769\n",
      "Epoch: 62/500... Training loss: 0.1503\n",
      "Epoch: 63/500... Training loss: 0.4787\n",
      "Epoch: 63/500... Training loss: 0.3790\n",
      "Epoch: 63/500... Training loss: 0.2594\n",
      "Epoch: 63/500... Training loss: 0.4034\n",
      "Epoch: 63/500... Training loss: 0.3355\n",
      "Epoch: 63/500... Training loss: 0.3689\n",
      "Epoch: 63/500... Training loss: 0.4123\n",
      "Epoch: 63/500... Training loss: 0.4059\n",
      "Epoch: 63/500... Training loss: 0.3375\n",
      "Epoch: 63/500... Training loss: 0.5876\n",
      "Epoch: 63/500... Training loss: 0.5823\n",
      "Epoch: 63/500... Training loss: 0.5617\n",
      "Epoch: 63/500... Training loss: 0.3063\n",
      "Epoch: 63/500... Training loss: 0.2768\n",
      "Epoch: 63/500... Training loss: 0.2478\n",
      "Epoch: 63/500... Training loss: 0.2315\n",
      "Epoch: 63/500... Training loss: 0.2527\n",
      "Epoch: 63/500... Training loss: 0.3507\n",
      "Epoch: 63/500... Training loss: 0.3375\n",
      "Epoch: 63/500... Training loss: 0.2120\n",
      "Epoch: 63/500... Training loss: 0.4080\n",
      "Epoch: 63/500... Training loss: 0.3623\n",
      "Epoch: 63/500... Training loss: 0.2531\n",
      "Epoch: 63/500... Training loss: 0.3547\n",
      "Epoch: 63/500... Training loss: 0.3765\n",
      "Epoch: 63/500... Training loss: 0.4236\n",
      "Epoch: 63/500... Training loss: 0.2047\n",
      "Epoch: 63/500... Training loss: 0.2033\n",
      "Epoch: 63/500... Training loss: 0.2188\n",
      "Epoch: 63/500... Training loss: 0.2246\n",
      "Epoch: 63/500... Training loss: 0.1490\n",
      "Epoch: 64/500... Training loss: 0.3180\n",
      "Epoch: 64/500... Training loss: 0.3481\n",
      "Epoch: 64/500... Training loss: 0.3442\n",
      "Epoch: 64/500... Training loss: 0.3927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/500... Training loss: 0.4481\n",
      "Epoch: 64/500... Training loss: 0.3722\n",
      "Epoch: 64/500... Training loss: 0.3764\n",
      "Epoch: 64/500... Training loss: 0.2734\n",
      "Epoch: 64/500... Training loss: 0.4541\n",
      "Epoch: 64/500... Training loss: 0.2846\n",
      "Epoch: 64/500... Training loss: 0.6078\n",
      "Epoch: 64/500... Training loss: 0.5215\n",
      "Epoch: 64/500... Training loss: 0.4343\n",
      "Epoch: 64/500... Training loss: 0.2879\n",
      "Epoch: 64/500... Training loss: 0.3891\n",
      "Epoch: 64/500... Training loss: 0.2853\n",
      "Epoch: 64/500... Training loss: 0.2108\n",
      "Epoch: 64/500... Training loss: 0.3098\n",
      "Epoch: 64/500... Training loss: 0.3601\n",
      "Epoch: 64/500... Training loss: 0.2812\n",
      "Epoch: 64/500... Training loss: 0.4769\n",
      "Epoch: 64/500... Training loss: 0.4615\n",
      "Epoch: 64/500... Training loss: 0.3099\n",
      "Epoch: 64/500... Training loss: 0.2508\n",
      "Epoch: 64/500... Training loss: 0.3475\n",
      "Epoch: 64/500... Training loss: 0.4573\n",
      "Epoch: 64/500... Training loss: 0.2344\n",
      "Epoch: 64/500... Training loss: 0.2260\n",
      "Epoch: 64/500... Training loss: 0.2311\n",
      "Epoch: 64/500... Training loss: 0.1952\n",
      "Epoch: 64/500... Training loss: 0.2144\n",
      "Epoch: 65/500... Training loss: 0.3514\n",
      "Epoch: 65/500... Training loss: 0.4505\n",
      "Epoch: 65/500... Training loss: 0.3060\n",
      "Epoch: 65/500... Training loss: 0.4895\n",
      "Epoch: 65/500... Training loss: 0.4289\n",
      "Epoch: 65/500... Training loss: 0.3929\n",
      "Epoch: 65/500... Training loss: 0.4155\n",
      "Epoch: 65/500... Training loss: 0.3840\n",
      "Epoch: 65/500... Training loss: 0.3632\n",
      "Epoch: 65/500... Training loss: 0.3580\n",
      "Epoch: 65/500... Training loss: 0.3893\n",
      "Epoch: 65/500... Training loss: 0.5565\n",
      "Epoch: 65/500... Training loss: 0.3928\n",
      "Epoch: 65/500... Training loss: 0.3582\n",
      "Epoch: 65/500... Training loss: 0.2905\n",
      "Epoch: 65/500... Training loss: 0.2872\n",
      "Epoch: 65/500... Training loss: 0.2292\n",
      "Epoch: 65/500... Training loss: 0.3319\n",
      "Epoch: 65/500... Training loss: 0.2670\n",
      "Epoch: 65/500... Training loss: 0.1587\n",
      "Epoch: 65/500... Training loss: 0.3511\n",
      "Epoch: 65/500... Training loss: 0.3145\n",
      "Epoch: 65/500... Training loss: 0.4390\n",
      "Epoch: 65/500... Training loss: 0.3934\n",
      "Epoch: 65/500... Training loss: 0.2620\n",
      "Epoch: 65/500... Training loss: 0.3009\n",
      "Epoch: 65/500... Training loss: 0.3623\n",
      "Epoch: 65/500... Training loss: 0.2389\n",
      "Epoch: 65/500... Training loss: 0.2079\n",
      "Epoch: 65/500... Training loss: 0.3121\n",
      "Epoch: 65/500... Training loss: 0.1914\n",
      "Epoch: 66/500... Training loss: 0.2739\n",
      "Epoch: 66/500... Training loss: 0.2359\n",
      "Epoch: 66/500... Training loss: 0.4594\n",
      "Epoch: 66/500... Training loss: 0.4464\n",
      "Epoch: 66/500... Training loss: 0.4568\n",
      "Epoch: 66/500... Training loss: 0.4149\n",
      "Epoch: 66/500... Training loss: 0.3590\n",
      "Epoch: 66/500... Training loss: 0.4236\n",
      "Epoch: 66/500... Training loss: 0.2171\n",
      "Epoch: 66/500... Training loss: 0.2860\n",
      "Epoch: 66/500... Training loss: 0.4961\n",
      "Epoch: 66/500... Training loss: 0.5421\n",
      "Epoch: 66/500... Training loss: 0.5116\n",
      "Epoch: 66/500... Training loss: 0.3389\n",
      "Epoch: 66/500... Training loss: 0.3039\n",
      "Epoch: 66/500... Training loss: 0.1884\n",
      "Epoch: 66/500... Training loss: 0.1524\n",
      "Epoch: 66/500... Training loss: 0.3696\n",
      "Epoch: 66/500... Training loss: 0.3574\n",
      "Epoch: 66/500... Training loss: 0.2639\n",
      "Epoch: 66/500... Training loss: 0.2388\n",
      "Epoch: 66/500... Training loss: 0.3344\n",
      "Epoch: 66/500... Training loss: 0.2885\n",
      "Epoch: 66/500... Training loss: 0.2599\n",
      "Epoch: 66/500... Training loss: 0.3663\n",
      "Epoch: 66/500... Training loss: 0.3605\n",
      "Epoch: 66/500... Training loss: 0.2375\n",
      "Epoch: 66/500... Training loss: 0.3826\n",
      "Epoch: 66/500... Training loss: 0.2699\n",
      "Epoch: 66/500... Training loss: 0.2908\n",
      "Epoch: 66/500... Training loss: 0.1899\n",
      "Epoch: 67/500... Training loss: 0.5070\n",
      "Epoch: 67/500... Training loss: 0.2831\n",
      "Epoch: 67/500... Training loss: 0.4049\n",
      "Epoch: 67/500... Training loss: 0.4313\n",
      "Epoch: 67/500... Training loss: 0.3139\n",
      "Epoch: 67/500... Training loss: 0.2313\n",
      "Epoch: 67/500... Training loss: 0.3331\n",
      "Epoch: 67/500... Training loss: 0.3776\n",
      "Epoch: 67/500... Training loss: 0.3213\n",
      "Epoch: 67/500... Training loss: 0.4079\n",
      "Epoch: 67/500... Training loss: 0.4805\n",
      "Epoch: 67/500... Training loss: 0.5423\n",
      "Epoch: 67/500... Training loss: 0.5299\n",
      "Epoch: 67/500... Training loss: 0.1377\n",
      "Epoch: 67/500... Training loss: 0.4242\n",
      "Epoch: 67/500... Training loss: 0.3544\n",
      "Epoch: 67/500... Training loss: 0.3266\n",
      "Epoch: 67/500... Training loss: 0.3207\n",
      "Epoch: 67/500... Training loss: 0.2809\n",
      "Epoch: 67/500... Training loss: 0.2064\n",
      "Epoch: 67/500... Training loss: 0.2766\n",
      "Epoch: 67/500... Training loss: 0.2485\n",
      "Epoch: 67/500... Training loss: 0.3594\n",
      "Epoch: 67/500... Training loss: 0.4251\n",
      "Epoch: 67/500... Training loss: 0.3230\n",
      "Epoch: 67/500... Training loss: 0.2526\n",
      "Epoch: 67/500... Training loss: 0.2168\n",
      "Epoch: 67/500... Training loss: 0.2869\n",
      "Epoch: 67/500... Training loss: 0.3544\n",
      "Epoch: 67/500... Training loss: 0.2593\n",
      "Epoch: 67/500... Training loss: 0.3249\n",
      "Epoch: 68/500... Training loss: 0.5101\n",
      "Epoch: 68/500... Training loss: 0.2539\n",
      "Epoch: 68/500... Training loss: 0.3154\n",
      "Epoch: 68/500... Training loss: 0.3559\n",
      "Epoch: 68/500... Training loss: 0.4264\n",
      "Epoch: 68/500... Training loss: 0.2988\n",
      "Epoch: 68/500... Training loss: 0.3959\n",
      "Epoch: 68/500... Training loss: 0.3250\n",
      "Epoch: 68/500... Training loss: 0.2469\n",
      "Epoch: 68/500... Training loss: 0.3938\n",
      "Epoch: 68/500... Training loss: 0.4744\n",
      "Epoch: 68/500... Training loss: 0.4085\n",
      "Epoch: 68/500... Training loss: 0.5354\n",
      "Epoch: 68/500... Training loss: 0.2676\n",
      "Epoch: 68/500... Training loss: 0.2164\n",
      "Epoch: 68/500... Training loss: 0.1892\n",
      "Epoch: 68/500... Training loss: 0.1972\n",
      "Epoch: 68/500... Training loss: 0.4017\n",
      "Epoch: 68/500... Training loss: 0.3933\n",
      "Epoch: 68/500... Training loss: 0.3419\n",
      "Epoch: 68/500... Training loss: 0.3741\n",
      "Epoch: 68/500... Training loss: 0.3609\n",
      "Epoch: 68/500... Training loss: 0.4730\n",
      "Epoch: 68/500... Training loss: 0.2087\n",
      "Epoch: 68/500... Training loss: 0.3589\n",
      "Epoch: 68/500... Training loss: 0.2763\n",
      "Epoch: 68/500... Training loss: 0.3486\n",
      "Epoch: 68/500... Training loss: 0.3431\n",
      "Epoch: 68/500... Training loss: 0.2238\n",
      "Epoch: 68/500... Training loss: 0.2309\n",
      "Epoch: 68/500... Training loss: 0.2010\n",
      "Epoch: 69/500... Training loss: 0.2850\n",
      "Epoch: 69/500... Training loss: 0.2194\n",
      "Epoch: 69/500... Training loss: 0.3257\n",
      "Epoch: 69/500... Training loss: 0.4214\n",
      "Epoch: 69/500... Training loss: 0.2906\n",
      "Epoch: 69/500... Training loss: 0.2331\n",
      "Epoch: 69/500... Training loss: 0.3739\n",
      "Epoch: 69/500... Training loss: 0.3208\n",
      "Epoch: 69/500... Training loss: 0.2653\n",
      "Epoch: 69/500... Training loss: 0.2989\n",
      "Epoch: 69/500... Training loss: 0.5021\n",
      "Epoch: 69/500... Training loss: 0.5084\n",
      "Epoch: 69/500... Training loss: 0.3467\n",
      "Epoch: 69/500... Training loss: 0.1724\n",
      "Epoch: 69/500... Training loss: 0.2759\n",
      "Epoch: 69/500... Training loss: 0.3015\n",
      "Epoch: 69/500... Training loss: 0.3003\n",
      "Epoch: 69/500... Training loss: 0.2658\n",
      "Epoch: 69/500... Training loss: 0.2676\n",
      "Epoch: 69/500... Training loss: 0.2519\n",
      "Epoch: 69/500... Training loss: 0.3350\n",
      "Epoch: 69/500... Training loss: 0.2426\n",
      "Epoch: 69/500... Training loss: 0.3752\n",
      "Epoch: 69/500... Training loss: 0.3493\n",
      "Epoch: 69/500... Training loss: 0.3003\n",
      "Epoch: 69/500... Training loss: 0.2632\n",
      "Epoch: 69/500... Training loss: 0.2697\n",
      "Epoch: 69/500... Training loss: 0.2885\n",
      "Epoch: 69/500... Training loss: 0.2003\n",
      "Epoch: 69/500... Training loss: 0.2805\n",
      "Epoch: 69/500... Training loss: 0.2712\n",
      "Epoch: 70/500... Training loss: 0.5369\n",
      "Epoch: 70/500... Training loss: 0.3698\n",
      "Epoch: 70/500... Training loss: 0.2832\n",
      "Epoch: 70/500... Training loss: 0.3774\n",
      "Epoch: 70/500... Training loss: 0.3726\n",
      "Epoch: 70/500... Training loss: 0.3233\n",
      "Epoch: 70/500... Training loss: 0.3842\n",
      "Epoch: 70/500... Training loss: 0.3227\n",
      "Epoch: 70/500... Training loss: 0.3134\n",
      "Epoch: 70/500... Training loss: 0.3011\n",
      "Epoch: 70/500... Training loss: 0.4198\n",
      "Epoch: 70/500... Training loss: 0.4732\n",
      "Epoch: 70/500... Training loss: 0.3817\n",
      "Epoch: 70/500... Training loss: 0.2553\n",
      "Epoch: 70/500... Training loss: 0.2596\n",
      "Epoch: 70/500... Training loss: 0.2147\n",
      "Epoch: 70/500... Training loss: 0.3095\n",
      "Epoch: 70/500... Training loss: 0.3599\n",
      "Epoch: 70/500... Training loss: 0.3414\n",
      "Epoch: 70/500... Training loss: 0.2584\n",
      "Epoch: 70/500... Training loss: 0.2130\n",
      "Epoch: 70/500... Training loss: 0.3664\n",
      "Epoch: 70/500... Training loss: 0.3094\n",
      "Epoch: 70/500... Training loss: 0.3738\n",
      "Epoch: 70/500... Training loss: 0.2372\n",
      "Epoch: 70/500... Training loss: 0.2703\n",
      "Epoch: 70/500... Training loss: 0.3569\n",
      "Epoch: 70/500... Training loss: 0.1694\n",
      "Epoch: 70/500... Training loss: 0.2037\n",
      "Epoch: 70/500... Training loss: 0.1546\n",
      "Epoch: 70/500... Training loss: 0.1365\n",
      "Epoch: 71/500... Training loss: 0.5086\n",
      "Epoch: 71/500... Training loss: 0.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/500... Training loss: 0.3505\n",
      "Epoch: 71/500... Training loss: 0.3195\n",
      "Epoch: 71/500... Training loss: 0.3728\n",
      "Epoch: 71/500... Training loss: 0.2781\n",
      "Epoch: 71/500... Training loss: 0.2747\n",
      "Epoch: 71/500... Training loss: 0.3080\n",
      "Epoch: 71/500... Training loss: 0.2450\n",
      "Epoch: 71/500... Training loss: 0.2756\n",
      "Epoch: 71/500... Training loss: 0.3592\n",
      "Epoch: 71/500... Training loss: 0.4644\n",
      "Epoch: 71/500... Training loss: 0.3723\n",
      "Epoch: 71/500... Training loss: 0.2755\n",
      "Epoch: 71/500... Training loss: 0.1951\n",
      "Epoch: 71/500... Training loss: 0.1825\n",
      "Epoch: 71/500... Training loss: 0.2246\n",
      "Epoch: 71/500... Training loss: 0.3618\n",
      "Epoch: 71/500... Training loss: 0.1994\n",
      "Epoch: 71/500... Training loss: 0.2014\n",
      "Epoch: 71/500... Training loss: 0.2164\n",
      "Epoch: 71/500... Training loss: 0.2354\n",
      "Epoch: 71/500... Training loss: 0.3747\n",
      "Epoch: 71/500... Training loss: 0.2275\n",
      "Epoch: 71/500... Training loss: 0.2425\n",
      "Epoch: 71/500... Training loss: 0.3199\n",
      "Epoch: 71/500... Training loss: 0.2665\n",
      "Epoch: 71/500... Training loss: 0.2854\n",
      "Epoch: 71/500... Training loss: 0.2367\n",
      "Epoch: 71/500... Training loss: 0.1842\n",
      "Epoch: 71/500... Training loss: 0.2186\n",
      "Epoch: 72/500... Training loss: 0.4141\n",
      "Epoch: 72/500... Training loss: 0.2326\n",
      "Epoch: 72/500... Training loss: 0.3062\n",
      "Epoch: 72/500... Training loss: 0.3094\n",
      "Epoch: 72/500... Training loss: 0.3634\n",
      "Epoch: 72/500... Training loss: 0.3810\n",
      "Epoch: 72/500... Training loss: 0.2645\n",
      "Epoch: 72/500... Training loss: 0.3641\n",
      "Epoch: 72/500... Training loss: 0.3614\n",
      "Epoch: 72/500... Training loss: 0.2506\n",
      "Epoch: 72/500... Training loss: 0.4334\n",
      "Epoch: 72/500... Training loss: 0.3644\n",
      "Epoch: 72/500... Training loss: 0.4520\n",
      "Epoch: 72/500... Training loss: 0.1862\n",
      "Epoch: 72/500... Training loss: 0.2240\n",
      "Epoch: 72/500... Training loss: 0.1949\n",
      "Epoch: 72/500... Training loss: 0.2220\n",
      "Epoch: 72/500... Training loss: 0.3009\n",
      "Epoch: 72/500... Training loss: 0.5062\n",
      "Epoch: 72/500... Training loss: 0.1604\n",
      "Epoch: 72/500... Training loss: 0.3164\n",
      "Epoch: 72/500... Training loss: 0.3740\n",
      "Epoch: 72/500... Training loss: 0.2659\n",
      "Epoch: 72/500... Training loss: 0.3165\n",
      "Epoch: 72/500... Training loss: 0.2661\n",
      "Epoch: 72/500... Training loss: 0.2736\n",
      "Epoch: 72/500... Training loss: 0.2833\n",
      "Epoch: 72/500... Training loss: 0.2465\n",
      "Epoch: 72/500... Training loss: 0.2449\n",
      "Epoch: 72/500... Training loss: 0.2642\n",
      "Epoch: 72/500... Training loss: 0.1658\n",
      "Epoch: 73/500... Training loss: 0.2680\n",
      "Epoch: 73/500... Training loss: 0.2454\n",
      "Epoch: 73/500... Training loss: 0.2579\n",
      "Epoch: 73/500... Training loss: 0.3389\n",
      "Epoch: 73/500... Training loss: 0.2751\n",
      "Epoch: 73/500... Training loss: 0.3214\n",
      "Epoch: 73/500... Training loss: 0.3300\n",
      "Epoch: 73/500... Training loss: 0.3487\n",
      "Epoch: 73/500... Training loss: 0.2938\n",
      "Epoch: 73/500... Training loss: 0.1804\n",
      "Epoch: 73/500... Training loss: 0.3317\n",
      "Epoch: 73/500... Training loss: 0.3631\n",
      "Epoch: 73/500... Training loss: 0.3893\n",
      "Epoch: 73/500... Training loss: 0.1262\n",
      "Epoch: 73/500... Training loss: 0.1581\n",
      "Epoch: 73/500... Training loss: 0.2600\n",
      "Epoch: 73/500... Training loss: 0.2131\n",
      "Epoch: 73/500... Training loss: 0.2762\n",
      "Epoch: 73/500... Training loss: 0.2101\n",
      "Epoch: 73/500... Training loss: 0.3230\n",
      "Epoch: 73/500... Training loss: 0.2967\n",
      "Epoch: 73/500... Training loss: 0.3003\n",
      "Epoch: 73/500... Training loss: 0.3136\n",
      "Epoch: 73/500... Training loss: 0.2181\n",
      "Epoch: 73/500... Training loss: 0.2029\n",
      "Epoch: 73/500... Training loss: 0.3191\n",
      "Epoch: 73/500... Training loss: 0.2660\n",
      "Epoch: 73/500... Training loss: 0.1617\n",
      "Epoch: 73/500... Training loss: 0.2358\n",
      "Epoch: 73/500... Training loss: 0.1797\n",
      "Epoch: 73/500... Training loss: 0.2821\n",
      "Epoch: 74/500... Training loss: 0.3764\n",
      "Epoch: 74/500... Training loss: 0.2854\n",
      "Epoch: 74/500... Training loss: 0.3495\n",
      "Epoch: 74/500... Training loss: 0.4484\n",
      "Epoch: 74/500... Training loss: 0.3280\n",
      "Epoch: 74/500... Training loss: 0.2748\n",
      "Epoch: 74/500... Training loss: 0.2342\n",
      "Epoch: 74/500... Training loss: 0.5127\n",
      "Epoch: 74/500... Training loss: 0.2639\n",
      "Epoch: 74/500... Training loss: 0.4133\n",
      "Epoch: 74/500... Training loss: 0.3104\n",
      "Epoch: 74/500... Training loss: 0.3466\n",
      "Epoch: 74/500... Training loss: 0.4954\n",
      "Epoch: 74/500... Training loss: 0.2394\n",
      "Epoch: 74/500... Training loss: 0.1802\n",
      "Epoch: 74/500... Training loss: 0.1376\n",
      "Epoch: 74/500... Training loss: 0.2163\n",
      "Epoch: 74/500... Training loss: 0.1484\n",
      "Epoch: 74/500... Training loss: 0.4491\n",
      "Epoch: 74/500... Training loss: 0.2448\n",
      "Epoch: 74/500... Training loss: 0.2446\n",
      "Epoch: 74/500... Training loss: 0.2195\n",
      "Epoch: 74/500... Training loss: 0.2435\n",
      "Epoch: 74/500... Training loss: 0.2676\n",
      "Epoch: 74/500... Training loss: 0.3089\n",
      "Epoch: 74/500... Training loss: 0.1794\n",
      "Epoch: 74/500... Training loss: 0.3080\n",
      "Epoch: 74/500... Training loss: 0.2745\n",
      "Epoch: 74/500... Training loss: 0.2484\n",
      "Epoch: 74/500... Training loss: 0.2547\n",
      "Epoch: 74/500... Training loss: 0.2097\n",
      "Epoch: 75/500... Training loss: 0.2883\n",
      "Epoch: 75/500... Training loss: 0.2207\n",
      "Epoch: 75/500... Training loss: 0.2951\n",
      "Epoch: 75/500... Training loss: 0.2281\n",
      "Epoch: 75/500... Training loss: 0.2850\n",
      "Epoch: 75/500... Training loss: 0.2335\n",
      "Epoch: 75/500... Training loss: 0.2838\n",
      "Epoch: 75/500... Training loss: 0.3409\n",
      "Epoch: 75/500... Training loss: 0.2801\n",
      "Epoch: 75/500... Training loss: 0.2649\n",
      "Epoch: 75/500... Training loss: 0.4405\n",
      "Epoch: 75/500... Training loss: 0.4962\n",
      "Epoch: 75/500... Training loss: 0.3644\n",
      "Epoch: 75/500... Training loss: 0.1754\n",
      "Epoch: 75/500... Training loss: 0.2533\n",
      "Epoch: 75/500... Training loss: 0.2180\n",
      "Epoch: 75/500... Training loss: 0.2091\n",
      "Epoch: 75/500... Training loss: 0.4611\n",
      "Epoch: 75/500... Training loss: 0.2259\n",
      "Epoch: 75/500... Training loss: 0.1681\n",
      "Epoch: 75/500... Training loss: 0.2610\n",
      "Epoch: 75/500... Training loss: 0.2351\n",
      "Epoch: 75/500... Training loss: 0.2712\n",
      "Epoch: 75/500... Training loss: 0.2533\n",
      "Epoch: 75/500... Training loss: 0.2139\n",
      "Epoch: 75/500... Training loss: 0.3119\n",
      "Epoch: 75/500... Training loss: 0.2180\n",
      "Epoch: 75/500... Training loss: 0.2499\n",
      "Epoch: 75/500... Training loss: 0.2081\n",
      "Epoch: 75/500... Training loss: 0.3551\n",
      "Epoch: 75/500... Training loss: 0.2244\n",
      "Epoch: 76/500... Training loss: 0.3692\n",
      "Epoch: 76/500... Training loss: 0.2791\n",
      "Epoch: 76/500... Training loss: 0.2178\n",
      "Epoch: 76/500... Training loss: 0.4303\n",
      "Epoch: 76/500... Training loss: 0.4281\n",
      "Epoch: 76/500... Training loss: 0.3052\n",
      "Epoch: 76/500... Training loss: 0.3705\n",
      "Epoch: 76/500... Training loss: 0.3298\n",
      "Epoch: 76/500... Training loss: 0.3093\n",
      "Epoch: 76/500... Training loss: 0.4307\n",
      "Epoch: 76/500... Training loss: 0.3882\n",
      "Epoch: 76/500... Training loss: 0.5267\n",
      "Epoch: 76/500... Training loss: 0.2949\n",
      "Epoch: 76/500... Training loss: 0.2077\n",
      "Epoch: 76/500... Training loss: 0.2864\n",
      "Epoch: 76/500... Training loss: 0.2623\n",
      "Epoch: 76/500... Training loss: 0.2288\n",
      "Epoch: 76/500... Training loss: 0.2235\n",
      "Epoch: 76/500... Training loss: 0.3998\n",
      "Epoch: 76/500... Training loss: 0.2673\n",
      "Epoch: 76/500... Training loss: 0.2457\n",
      "Epoch: 76/500... Training loss: 0.4364\n",
      "Epoch: 76/500... Training loss: 0.3023\n",
      "Epoch: 76/500... Training loss: 0.2180\n",
      "Epoch: 76/500... Training loss: 0.2236\n",
      "Epoch: 76/500... Training loss: 0.1901\n",
      "Epoch: 76/500... Training loss: 0.1991\n",
      "Epoch: 76/500... Training loss: 0.3593\n",
      "Epoch: 76/500... Training loss: 0.1668\n",
      "Epoch: 76/500... Training loss: 0.1828\n",
      "Epoch: 76/500... Training loss: 0.2294\n",
      "Epoch: 77/500... Training loss: 0.4675\n",
      "Epoch: 77/500... Training loss: 0.2397\n",
      "Epoch: 77/500... Training loss: 0.3337\n",
      "Epoch: 77/500... Training loss: 0.4957\n",
      "Epoch: 77/500... Training loss: 0.3030\n",
      "Epoch: 77/500... Training loss: 0.2629\n",
      "Epoch: 77/500... Training loss: 0.2670\n",
      "Epoch: 77/500... Training loss: 0.2966\n",
      "Epoch: 77/500... Training loss: 0.3485\n",
      "Epoch: 77/500... Training loss: 0.3247\n",
      "Epoch: 77/500... Training loss: 0.3411\n",
      "Epoch: 77/500... Training loss: 0.3881\n",
      "Epoch: 77/500... Training loss: 0.2802\n",
      "Epoch: 77/500... Training loss: 0.3322\n",
      "Epoch: 77/500... Training loss: 0.1787\n",
      "Epoch: 77/500... Training loss: 0.2466\n",
      "Epoch: 77/500... Training loss: 0.1821\n",
      "Epoch: 77/500... Training loss: 0.3219\n",
      "Epoch: 77/500... Training loss: 0.2272\n",
      "Epoch: 77/500... Training loss: 0.2598\n",
      "Epoch: 77/500... Training loss: 0.2783\n",
      "Epoch: 77/500... Training loss: 0.4222\n",
      "Epoch: 77/500... Training loss: 0.3041\n",
      "Epoch: 77/500... Training loss: 0.3692\n",
      "Epoch: 77/500... Training loss: 0.2403\n",
      "Epoch: 77/500... Training loss: 0.2013\n",
      "Epoch: 77/500... Training loss: 0.2616\n",
      "Epoch: 77/500... Training loss: 0.1733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/500... Training loss: 0.1264\n",
      "Epoch: 77/500... Training loss: 0.2412\n",
      "Epoch: 77/500... Training loss: 0.2643\n",
      "Epoch: 78/500... Training loss: 0.3393\n",
      "Epoch: 78/500... Training loss: 0.1841\n",
      "Epoch: 78/500... Training loss: 0.3338\n",
      "Epoch: 78/500... Training loss: 0.2785\n",
      "Epoch: 78/500... Training loss: 0.2534\n",
      "Epoch: 78/500... Training loss: 0.3667\n",
      "Epoch: 78/500... Training loss: 0.2731\n",
      "Epoch: 78/500... Training loss: 0.3419\n",
      "Epoch: 78/500... Training loss: 0.3900\n",
      "Epoch: 78/500... Training loss: 0.3808\n",
      "Epoch: 78/500... Training loss: 0.4086\n",
      "Epoch: 78/500... Training loss: 0.3526\n",
      "Epoch: 78/500... Training loss: 0.3280\n",
      "Epoch: 78/500... Training loss: 0.1345\n",
      "Epoch: 78/500... Training loss: 0.2532\n",
      "Epoch: 78/500... Training loss: 0.1591\n",
      "Epoch: 78/500... Training loss: 0.1785\n",
      "Epoch: 78/500... Training loss: 0.2302\n",
      "Epoch: 78/500... Training loss: 0.3179\n",
      "Epoch: 78/500... Training loss: 0.1352\n",
      "Epoch: 78/500... Training loss: 0.1440\n",
      "Epoch: 78/500... Training loss: 0.3595\n",
      "Epoch: 78/500... Training loss: 0.2837\n",
      "Epoch: 78/500... Training loss: 0.3676\n",
      "Epoch: 78/500... Training loss: 0.2382\n",
      "Epoch: 78/500... Training loss: 0.2188\n",
      "Epoch: 78/500... Training loss: 0.2159\n",
      "Epoch: 78/500... Training loss: 0.2796\n",
      "Epoch: 78/500... Training loss: 0.1555\n",
      "Epoch: 78/500... Training loss: 0.1538\n",
      "Epoch: 78/500... Training loss: 0.3241\n",
      "Epoch: 79/500... Training loss: 0.4168\n",
      "Epoch: 79/500... Training loss: 0.3465\n",
      "Epoch: 79/500... Training loss: 0.4286\n",
      "Epoch: 79/500... Training loss: 0.3267\n",
      "Epoch: 79/500... Training loss: 0.3450\n",
      "Epoch: 79/500... Training loss: 0.3156\n",
      "Epoch: 79/500... Training loss: 0.2979\n",
      "Epoch: 79/500... Training loss: 0.3421\n",
      "Epoch: 79/500... Training loss: 0.2634\n",
      "Epoch: 79/500... Training loss: 0.2355\n",
      "Epoch: 79/500... Training loss: 0.3638\n",
      "Epoch: 79/500... Training loss: 0.3375\n",
      "Epoch: 79/500... Training loss: 0.3619\n",
      "Epoch: 79/500... Training loss: 0.2573\n",
      "Epoch: 79/500... Training loss: 0.1625\n",
      "Epoch: 79/500... Training loss: 0.1525\n",
      "Epoch: 79/500... Training loss: 0.2289\n",
      "Epoch: 79/500... Training loss: 0.2603\n",
      "Epoch: 79/500... Training loss: 0.3210\n",
      "Epoch: 79/500... Training loss: 0.1266\n",
      "Epoch: 79/500... Training loss: 0.1800\n",
      "Epoch: 79/500... Training loss: 0.3437\n",
      "Epoch: 79/500... Training loss: 0.2403\n",
      "Epoch: 79/500... Training loss: 0.2440\n",
      "Epoch: 79/500... Training loss: 0.2276\n",
      "Epoch: 79/500... Training loss: 0.2442\n",
      "Epoch: 79/500... Training loss: 0.1376\n",
      "Epoch: 79/500... Training loss: 0.2499\n",
      "Epoch: 79/500... Training loss: 0.1475\n",
      "Epoch: 79/500... Training loss: 0.1937\n",
      "Epoch: 79/500... Training loss: 0.1464\n",
      "Epoch: 80/500... Training loss: 0.2976\n",
      "Epoch: 80/500... Training loss: 0.2246\n",
      "Epoch: 80/500... Training loss: 0.2049\n",
      "Epoch: 80/500... Training loss: 0.2985\n",
      "Epoch: 80/500... Training loss: 0.2330\n",
      "Epoch: 80/500... Training loss: 0.2413\n",
      "Epoch: 80/500... Training loss: 0.3602\n",
      "Epoch: 80/500... Training loss: 0.2906\n",
      "Epoch: 80/500... Training loss: 0.2751\n",
      "Epoch: 80/500... Training loss: 0.2936\n",
      "Epoch: 80/500... Training loss: 0.2925\n",
      "Epoch: 80/500... Training loss: 0.2807\n",
      "Epoch: 80/500... Training loss: 0.2194\n",
      "Epoch: 80/500... Training loss: 0.1921\n",
      "Epoch: 80/500... Training loss: 0.3064\n",
      "Epoch: 80/500... Training loss: 0.1416\n",
      "Epoch: 80/500... Training loss: 0.3317\n",
      "Epoch: 80/500... Training loss: 0.2065\n",
      "Epoch: 80/500... Training loss: 0.3005\n",
      "Epoch: 80/500... Training loss: 0.2544\n",
      "Epoch: 80/500... Training loss: 0.1255\n",
      "Epoch: 80/500... Training loss: 0.1756\n",
      "Epoch: 80/500... Training loss: 0.1914\n",
      "Epoch: 80/500... Training loss: 0.2646\n",
      "Epoch: 80/500... Training loss: 0.1626\n",
      "Epoch: 80/500... Training loss: 0.2745\n",
      "Epoch: 80/500... Training loss: 0.2863\n",
      "Epoch: 80/500... Training loss: 0.2323\n",
      "Epoch: 80/500... Training loss: 0.1792\n",
      "Epoch: 80/500... Training loss: 0.1470\n",
      "Epoch: 80/500... Training loss: 0.1712\n",
      "Epoch: 81/500... Training loss: 0.3057\n",
      "Epoch: 81/500... Training loss: 0.3039\n",
      "Epoch: 81/500... Training loss: 0.3481\n",
      "Epoch: 81/500... Training loss: 0.2959\n",
      "Epoch: 81/500... Training loss: 0.3444\n",
      "Epoch: 81/500... Training loss: 0.3402\n",
      "Epoch: 81/500... Training loss: 0.2678\n",
      "Epoch: 81/500... Training loss: 0.1894\n",
      "Epoch: 81/500... Training loss: 0.3726\n",
      "Epoch: 81/500... Training loss: 0.2215\n",
      "Epoch: 81/500... Training loss: 0.3529\n",
      "Epoch: 81/500... Training loss: 0.4136\n",
      "Epoch: 81/500... Training loss: 0.3734\n",
      "Epoch: 81/500... Training loss: 0.1834\n",
      "Epoch: 81/500... Training loss: 0.2472\n",
      "Epoch: 81/500... Training loss: 0.1621\n",
      "Epoch: 81/500... Training loss: 0.2420\n",
      "Epoch: 81/500... Training loss: 0.2883\n",
      "Epoch: 81/500... Training loss: 0.2313\n",
      "Epoch: 81/500... Training loss: 0.2373\n",
      "Epoch: 81/500... Training loss: 0.2635\n",
      "Epoch: 81/500... Training loss: 0.3494\n",
      "Epoch: 81/500... Training loss: 0.2982\n",
      "Epoch: 81/500... Training loss: 0.3300\n",
      "Epoch: 81/500... Training loss: 0.2834\n",
      "Epoch: 81/500... Training loss: 0.2060\n",
      "Epoch: 81/500... Training loss: 0.2139\n",
      "Epoch: 81/500... Training loss: 0.1765\n",
      "Epoch: 81/500... Training loss: 0.1822\n",
      "Epoch: 81/500... Training loss: 0.1942\n",
      "Epoch: 81/500... Training loss: 0.1296\n",
      "Epoch: 82/500... Training loss: 0.3573\n",
      "Epoch: 82/500... Training loss: 0.2096\n",
      "Epoch: 82/500... Training loss: 0.4423\n",
      "Epoch: 82/500... Training loss: 0.4555\n",
      "Epoch: 82/500... Training loss: 0.3226\n",
      "Epoch: 82/500... Training loss: 0.2416\n",
      "Epoch: 82/500... Training loss: 0.3224\n",
      "Epoch: 82/500... Training loss: 0.2349\n",
      "Epoch: 82/500... Training loss: 0.2903\n",
      "Epoch: 82/500... Training loss: 0.3550\n",
      "Epoch: 82/500... Training loss: 0.3690\n",
      "Epoch: 82/500... Training loss: 0.3494\n",
      "Epoch: 82/500... Training loss: 0.5086\n",
      "Epoch: 82/500... Training loss: 0.2613\n",
      "Epoch: 82/500... Training loss: 0.2534\n",
      "Epoch: 82/500... Training loss: 0.1548\n",
      "Epoch: 82/500... Training loss: 0.2937\n",
      "Epoch: 82/500... Training loss: 0.3388\n",
      "Epoch: 82/500... Training loss: 0.3216\n",
      "Epoch: 82/500... Training loss: 0.2824\n",
      "Epoch: 82/500... Training loss: 0.1464\n",
      "Epoch: 82/500... Training loss: 0.2589\n",
      "Epoch: 82/500... Training loss: 0.2702\n",
      "Epoch: 82/500... Training loss: 0.2650\n",
      "Epoch: 82/500... Training loss: 0.2404\n",
      "Epoch: 82/500... Training loss: 0.2624\n",
      "Epoch: 82/500... Training loss: 0.2302\n",
      "Epoch: 82/500... Training loss: 0.2209\n",
      "Epoch: 82/500... Training loss: 0.2004\n",
      "Epoch: 82/500... Training loss: 0.1722\n",
      "Epoch: 82/500... Training loss: 0.1846\n",
      "Epoch: 83/500... Training loss: 0.3437\n",
      "Epoch: 83/500... Training loss: 0.4394\n",
      "Epoch: 83/500... Training loss: 0.2594\n",
      "Epoch: 83/500... Training loss: 0.2952\n",
      "Epoch: 83/500... Training loss: 0.2201\n",
      "Epoch: 83/500... Training loss: 0.4568\n",
      "Epoch: 83/500... Training loss: 0.2220\n",
      "Epoch: 83/500... Training loss: 0.3140\n",
      "Epoch: 83/500... Training loss: 0.2187\n",
      "Epoch: 83/500... Training loss: 0.2741\n",
      "Epoch: 83/500... Training loss: 0.4529\n",
      "Epoch: 83/500... Training loss: 0.5237\n",
      "Epoch: 83/500... Training loss: 0.2884\n",
      "Epoch: 83/500... Training loss: 0.2293\n",
      "Epoch: 83/500... Training loss: 0.1801\n",
      "Epoch: 83/500... Training loss: 0.1766\n",
      "Epoch: 83/500... Training loss: 0.2638\n",
      "Epoch: 83/500... Training loss: 0.2755\n",
      "Epoch: 83/500... Training loss: 0.2002\n",
      "Epoch: 83/500... Training loss: 0.2414\n",
      "Epoch: 83/500... Training loss: 0.2860\n",
      "Epoch: 83/500... Training loss: 0.3209\n",
      "Epoch: 83/500... Training loss: 0.3465\n",
      "Epoch: 83/500... Training loss: 0.2894\n",
      "Epoch: 83/500... Training loss: 0.1178\n",
      "Epoch: 83/500... Training loss: 0.1827\n",
      "Epoch: 83/500... Training loss: 0.2942\n",
      "Epoch: 83/500... Training loss: 0.1587\n",
      "Epoch: 83/500... Training loss: 0.1347\n",
      "Epoch: 83/500... Training loss: 0.2110\n",
      "Epoch: 83/500... Training loss: 0.1827\n",
      "Epoch: 84/500... Training loss: 0.2301\n",
      "Epoch: 84/500... Training loss: 0.3012\n",
      "Epoch: 84/500... Training loss: 0.2509\n",
      "Epoch: 84/500... Training loss: 0.3324\n",
      "Epoch: 84/500... Training loss: 0.2587\n",
      "Epoch: 84/500... Training loss: 0.1521\n",
      "Epoch: 84/500... Training loss: 0.3039\n",
      "Epoch: 84/500... Training loss: 0.2709\n",
      "Epoch: 84/500... Training loss: 0.2905\n",
      "Epoch: 84/500... Training loss: 0.3453\n",
      "Epoch: 84/500... Training loss: 0.3764\n",
      "Epoch: 84/500... Training loss: 0.2971\n",
      "Epoch: 84/500... Training loss: 0.3039\n",
      "Epoch: 84/500... Training loss: 0.2475\n",
      "Epoch: 84/500... Training loss: 0.1936\n",
      "Epoch: 84/500... Training loss: 0.1318\n",
      "Epoch: 84/500... Training loss: 0.1657\n",
      "Epoch: 84/500... Training loss: 0.2760\n",
      "Epoch: 84/500... Training loss: 0.2784\n",
      "Epoch: 84/500... Training loss: 0.2225\n",
      "Epoch: 84/500... Training loss: 0.1765\n",
      "Epoch: 84/500... Training loss: 0.2308\n",
      "Epoch: 84/500... Training loss: 0.2450\n",
      "Epoch: 84/500... Training loss: 0.2335\n",
      "Epoch: 84/500... Training loss: 0.3546\n",
      "Epoch: 84/500... Training loss: 0.2348\n",
      "Epoch: 84/500... Training loss: 0.1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/500... Training loss: 0.2466\n",
      "Epoch: 84/500... Training loss: 0.1984\n",
      "Epoch: 84/500... Training loss: 0.2486\n",
      "Epoch: 84/500... Training loss: 0.1081\n",
      "Epoch: 85/500... Training loss: 0.2429\n",
      "Epoch: 85/500... Training loss: 0.2521\n",
      "Epoch: 85/500... Training loss: 0.2257\n",
      "Epoch: 85/500... Training loss: 0.3449\n",
      "Epoch: 85/500... Training loss: 0.2045\n",
      "Epoch: 85/500... Training loss: 0.3645\n",
      "Epoch: 85/500... Training loss: 0.2706\n",
      "Epoch: 85/500... Training loss: 0.3179\n",
      "Epoch: 85/500... Training loss: 0.2752\n",
      "Epoch: 85/500... Training loss: 0.2130\n",
      "Epoch: 85/500... Training loss: 0.3610\n",
      "Epoch: 85/500... Training loss: 0.4701\n",
      "Epoch: 85/500... Training loss: 0.3981\n",
      "Epoch: 85/500... Training loss: 0.2379\n",
      "Epoch: 85/500... Training loss: 0.1812\n",
      "Epoch: 85/500... Training loss: 0.2193\n",
      "Epoch: 85/500... Training loss: 0.1809\n",
      "Epoch: 85/500... Training loss: 0.2667\n",
      "Epoch: 85/500... Training loss: 0.2317\n",
      "Epoch: 85/500... Training loss: 0.1540\n",
      "Epoch: 85/500... Training loss: 0.1781\n",
      "Epoch: 85/500... Training loss: 0.2034\n",
      "Epoch: 85/500... Training loss: 0.2219\n",
      "Epoch: 85/500... Training loss: 0.2107\n",
      "Epoch: 85/500... Training loss: 0.2021\n",
      "Epoch: 85/500... Training loss: 0.2237\n",
      "Epoch: 85/500... Training loss: 0.2575\n",
      "Epoch: 85/500... Training loss: 0.1691\n",
      "Epoch: 85/500... Training loss: 0.2628\n",
      "Epoch: 85/500... Training loss: 0.1925\n",
      "Epoch: 85/500... Training loss: 0.1958\n",
      "Epoch: 86/500... Training loss: 0.2621\n",
      "Epoch: 86/500... Training loss: 0.1573\n",
      "Epoch: 86/500... Training loss: 0.2240\n",
      "Epoch: 86/500... Training loss: 0.3169\n",
      "Epoch: 86/500... Training loss: 0.2951\n",
      "Epoch: 86/500... Training loss: 0.1923\n",
      "Epoch: 86/500... Training loss: 0.2537\n",
      "Epoch: 86/500... Training loss: 0.2234\n",
      "Epoch: 86/500... Training loss: 0.2982\n",
      "Epoch: 86/500... Training loss: 0.3582\n",
      "Epoch: 86/500... Training loss: 0.2938\n",
      "Epoch: 86/500... Training loss: 0.2229\n",
      "Epoch: 86/500... Training loss: 0.1936\n",
      "Epoch: 86/500... Training loss: 0.1482\n",
      "Epoch: 86/500... Training loss: 0.2716\n",
      "Epoch: 86/500... Training loss: 0.1344\n",
      "Epoch: 86/500... Training loss: 0.2307\n",
      "Epoch: 86/500... Training loss: 0.3270\n",
      "Epoch: 86/500... Training loss: 0.2365\n",
      "Epoch: 86/500... Training loss: 0.2866\n",
      "Epoch: 86/500... Training loss: 0.0876\n",
      "Epoch: 86/500... Training loss: 0.1877\n",
      "Epoch: 86/500... Training loss: 0.2954\n",
      "Epoch: 86/500... Training loss: 0.2854\n",
      "Epoch: 86/500... Training loss: 0.2147\n",
      "Epoch: 86/500... Training loss: 0.2584\n",
      "Epoch: 86/500... Training loss: 0.1988\n",
      "Epoch: 86/500... Training loss: 0.2415\n",
      "Epoch: 86/500... Training loss: 0.1117\n",
      "Epoch: 86/500... Training loss: 0.1012\n",
      "Epoch: 86/500... Training loss: 0.1068\n",
      "Epoch: 87/500... Training loss: 0.2896\n",
      "Epoch: 87/500... Training loss: 0.3028\n",
      "Epoch: 87/500... Training loss: 0.1956\n",
      "Epoch: 87/500... Training loss: 0.2747\n",
      "Epoch: 87/500... Training loss: 0.2955\n",
      "Epoch: 87/500... Training loss: 0.3066\n",
      "Epoch: 87/500... Training loss: 0.3480\n",
      "Epoch: 87/500... Training loss: 0.2778\n",
      "Epoch: 87/500... Training loss: 0.2607\n",
      "Epoch: 87/500... Training loss: 0.2726\n",
      "Epoch: 87/500... Training loss: 0.3017\n",
      "Epoch: 87/500... Training loss: 0.3807\n",
      "Epoch: 87/500... Training loss: 0.3160\n",
      "Epoch: 87/500... Training loss: 0.2279\n",
      "Epoch: 87/500... Training loss: 0.2075\n",
      "Epoch: 87/500... Training loss: 0.1983\n",
      "Epoch: 87/500... Training loss: 0.1541\n",
      "Epoch: 87/500... Training loss: 0.2868\n",
      "Epoch: 87/500... Training loss: 0.2027\n",
      "Epoch: 87/500... Training loss: 0.1304\n",
      "Epoch: 87/500... Training loss: 0.1529\n",
      "Epoch: 87/500... Training loss: 0.2624\n",
      "Epoch: 87/500... Training loss: 0.3364\n",
      "Epoch: 87/500... Training loss: 0.2579\n",
      "Epoch: 87/500... Training loss: 0.1818\n",
      "Epoch: 87/500... Training loss: 0.1961\n",
      "Epoch: 87/500... Training loss: 0.2708\n",
      "Epoch: 87/500... Training loss: 0.1630\n",
      "Epoch: 87/500... Training loss: 0.2037\n",
      "Epoch: 87/500... Training loss: 0.2045\n",
      "Epoch: 87/500... Training loss: 0.1772\n",
      "Epoch: 88/500... Training loss: 0.2594\n",
      "Epoch: 88/500... Training loss: 0.2358\n",
      "Epoch: 88/500... Training loss: 0.3482\n",
      "Epoch: 88/500... Training loss: 0.4076\n",
      "Epoch: 88/500... Training loss: 0.3627\n",
      "Epoch: 88/500... Training loss: 0.2055\n",
      "Epoch: 88/500... Training loss: 0.2128\n",
      "Epoch: 88/500... Training loss: 0.2510\n",
      "Epoch: 88/500... Training loss: 0.2408\n",
      "Epoch: 88/500... Training loss: 0.2641\n",
      "Epoch: 88/500... Training loss: 0.3133\n",
      "Epoch: 88/500... Training loss: 0.4083\n",
      "Epoch: 88/500... Training loss: 0.2424\n",
      "Epoch: 88/500... Training loss: 0.1857\n",
      "Epoch: 88/500... Training loss: 0.3130\n",
      "Epoch: 88/500... Training loss: 0.1630\n",
      "Epoch: 88/500... Training loss: 0.2640\n",
      "Epoch: 88/500... Training loss: 0.2731\n",
      "Epoch: 88/500... Training loss: 0.3492\n",
      "Epoch: 88/500... Training loss: 0.1559\n",
      "Epoch: 88/500... Training loss: 0.1855\n",
      "Epoch: 88/500... Training loss: 0.3352\n",
      "Epoch: 88/500... Training loss: 0.3114\n",
      "Epoch: 88/500... Training loss: 0.2665\n",
      "Epoch: 88/500... Training loss: 0.2087\n",
      "Epoch: 88/500... Training loss: 0.1580\n",
      "Epoch: 88/500... Training loss: 0.1177\n",
      "Epoch: 88/500... Training loss: 0.2216\n",
      "Epoch: 88/500... Training loss: 0.2127\n",
      "Epoch: 88/500... Training loss: 0.2134\n",
      "Epoch: 88/500... Training loss: 0.2605\n",
      "Epoch: 89/500... Training loss: 0.3231\n",
      "Epoch: 89/500... Training loss: 0.2129\n",
      "Epoch: 89/500... Training loss: 0.1896\n",
      "Epoch: 89/500... Training loss: 0.3556\n",
      "Epoch: 89/500... Training loss: 0.1858\n",
      "Epoch: 89/500... Training loss: 0.2419\n",
      "Epoch: 89/500... Training loss: 0.3226\n",
      "Epoch: 89/500... Training loss: 0.1945\n",
      "Epoch: 89/500... Training loss: 0.2138\n",
      "Epoch: 89/500... Training loss: 0.1489\n",
      "Epoch: 89/500... Training loss: 0.2960\n",
      "Epoch: 89/500... Training loss: 0.2670\n",
      "Epoch: 89/500... Training loss: 0.4033\n",
      "Epoch: 89/500... Training loss: 0.1785\n",
      "Epoch: 89/500... Training loss: 0.1638\n",
      "Epoch: 89/500... Training loss: 0.1891\n",
      "Epoch: 89/500... Training loss: 0.1877\n",
      "Epoch: 89/500... Training loss: 0.1636\n",
      "Epoch: 89/500... Training loss: 0.2247\n",
      "Epoch: 89/500... Training loss: 0.1726\n",
      "Epoch: 89/500... Training loss: 0.2775\n",
      "Epoch: 89/500... Training loss: 0.3398\n",
      "Epoch: 89/500... Training loss: 0.3429\n",
      "Epoch: 89/500... Training loss: 0.1848\n",
      "Epoch: 89/500... Training loss: 0.1344\n",
      "Epoch: 89/500... Training loss: 0.2406\n",
      "Epoch: 89/500... Training loss: 0.1584\n",
      "Epoch: 89/500... Training loss: 0.1984\n",
      "Epoch: 89/500... Training loss: 0.2548\n",
      "Epoch: 89/500... Training loss: 0.1557\n",
      "Epoch: 89/500... Training loss: 0.2259\n",
      "Epoch: 90/500... Training loss: 0.4720\n",
      "Epoch: 90/500... Training loss: 0.2590\n",
      "Epoch: 90/500... Training loss: 0.2034\n",
      "Epoch: 90/500... Training loss: 0.2393\n",
      "Epoch: 90/500... Training loss: 0.1703\n",
      "Epoch: 90/500... Training loss: 0.2745\n",
      "Epoch: 90/500... Training loss: 0.2248\n",
      "Epoch: 90/500... Training loss: 0.2704\n",
      "Epoch: 90/500... Training loss: 0.1810\n",
      "Epoch: 90/500... Training loss: 0.2156\n",
      "Epoch: 90/500... Training loss: 0.2820\n",
      "Epoch: 90/500... Training loss: 0.3354\n",
      "Epoch: 90/500... Training loss: 0.3920\n",
      "Epoch: 90/500... Training loss: 0.2816\n",
      "Epoch: 90/500... Training loss: 0.2655\n",
      "Epoch: 90/500... Training loss: 0.2025\n",
      "Epoch: 90/500... Training loss: 0.1504\n",
      "Epoch: 90/500... Training loss: 0.3488\n",
      "Epoch: 90/500... Training loss: 0.1912\n",
      "Epoch: 90/500... Training loss: 0.1838\n",
      "Epoch: 90/500... Training loss: 0.1803\n",
      "Epoch: 90/500... Training loss: 0.3039\n",
      "Epoch: 90/500... Training loss: 0.2071\n",
      "Epoch: 90/500... Training loss: 0.2399\n",
      "Epoch: 90/500... Training loss: 0.1208\n",
      "Epoch: 90/500... Training loss: 0.2567\n",
      "Epoch: 90/500... Training loss: 0.1561\n",
      "Epoch: 90/500... Training loss: 0.2449\n",
      "Epoch: 90/500... Training loss: 0.0869\n",
      "Epoch: 90/500... Training loss: 0.1776\n",
      "Epoch: 90/500... Training loss: 0.1649\n",
      "Epoch: 91/500... Training loss: 0.2321\n",
      "Epoch: 91/500... Training loss: 0.2167\n",
      "Epoch: 91/500... Training loss: 0.3456\n",
      "Epoch: 91/500... Training loss: 0.2979\n",
      "Epoch: 91/500... Training loss: 0.3568\n",
      "Epoch: 91/500... Training loss: 0.3753\n",
      "Epoch: 91/500... Training loss: 0.2623\n",
      "Epoch: 91/500... Training loss: 0.1477\n",
      "Epoch: 91/500... Training loss: 0.2365\n",
      "Epoch: 91/500... Training loss: 0.2046\n",
      "Epoch: 91/500... Training loss: 0.3144\n",
      "Epoch: 91/500... Training loss: 0.3621\n",
      "Epoch: 91/500... Training loss: 0.3086\n",
      "Epoch: 91/500... Training loss: 0.1945\n",
      "Epoch: 91/500... Training loss: 0.1770\n",
      "Epoch: 91/500... Training loss: 0.2784\n",
      "Epoch: 91/500... Training loss: 0.2394\n",
      "Epoch: 91/500... Training loss: 0.2388\n",
      "Epoch: 91/500... Training loss: 0.3104\n",
      "Epoch: 91/500... Training loss: 0.2583\n",
      "Epoch: 91/500... Training loss: 0.2243\n",
      "Epoch: 91/500... Training loss: 0.2413\n",
      "Epoch: 91/500... Training loss: 0.3175\n",
      "Epoch: 91/500... Training loss: 0.2275\n",
      "Epoch: 91/500... Training loss: 0.1823\n",
      "Epoch: 91/500... Training loss: 0.2181\n",
      "Epoch: 91/500... Training loss: 0.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/500... Training loss: 0.1980\n",
      "Epoch: 91/500... Training loss: 0.2012\n",
      "Epoch: 91/500... Training loss: 0.1256\n",
      "Epoch: 91/500... Training loss: 0.1927\n",
      "Epoch: 92/500... Training loss: 0.1358\n",
      "Epoch: 92/500... Training loss: 0.2262\n",
      "Epoch: 92/500... Training loss: 0.2670\n",
      "Epoch: 92/500... Training loss: 0.2901\n",
      "Epoch: 92/500... Training loss: 0.3324\n",
      "Epoch: 92/500... Training loss: 0.2492\n",
      "Epoch: 92/500... Training loss: 0.2464\n",
      "Epoch: 92/500... Training loss: 0.1839\n",
      "Epoch: 92/500... Training loss: 0.2045\n",
      "Epoch: 92/500... Training loss: 0.2187\n",
      "Epoch: 92/500... Training loss: 0.4060\n",
      "Epoch: 92/500... Training loss: 0.3350\n",
      "Epoch: 92/500... Training loss: 0.3317\n",
      "Epoch: 92/500... Training loss: 0.1866\n",
      "Epoch: 92/500... Training loss: 0.2178\n",
      "Epoch: 92/500... Training loss: 0.2025\n",
      "Epoch: 92/500... Training loss: 0.1935\n",
      "Epoch: 92/500... Training loss: 0.2648\n",
      "Epoch: 92/500... Training loss: 0.2688\n",
      "Epoch: 92/500... Training loss: 0.3612\n",
      "Epoch: 92/500... Training loss: 0.2606\n",
      "Epoch: 92/500... Training loss: 0.2472\n",
      "Epoch: 92/500... Training loss: 0.1651\n",
      "Epoch: 92/500... Training loss: 0.2519\n",
      "Epoch: 92/500... Training loss: 0.2626\n",
      "Epoch: 92/500... Training loss: 0.1937\n",
      "Epoch: 92/500... Training loss: 0.3304\n",
      "Epoch: 92/500... Training loss: 0.2122\n",
      "Epoch: 92/500... Training loss: 0.1519\n",
      "Epoch: 92/500... Training loss: 0.1571\n",
      "Epoch: 92/500... Training loss: 0.2278\n",
      "Epoch: 93/500... Training loss: 0.3117\n",
      "Epoch: 93/500... Training loss: 0.2744\n",
      "Epoch: 93/500... Training loss: 0.3101\n",
      "Epoch: 93/500... Training loss: 0.2539\n",
      "Epoch: 93/500... Training loss: 0.3280\n",
      "Epoch: 93/500... Training loss: 0.2151\n",
      "Epoch: 93/500... Training loss: 0.2440\n",
      "Epoch: 93/500... Training loss: 0.1906\n",
      "Epoch: 93/500... Training loss: 0.1877\n",
      "Epoch: 93/500... Training loss: 0.1245\n",
      "Epoch: 93/500... Training loss: 0.2115\n",
      "Epoch: 93/500... Training loss: 0.5127\n",
      "Epoch: 93/500... Training loss: 0.3880\n",
      "Epoch: 93/500... Training loss: 0.2283\n",
      "Epoch: 93/500... Training loss: 0.1677\n",
      "Epoch: 93/500... Training loss: 0.2552\n",
      "Epoch: 93/500... Training loss: 0.1595\n",
      "Epoch: 93/500... Training loss: 0.2679\n",
      "Epoch: 93/500... Training loss: 0.2559\n",
      "Epoch: 93/500... Training loss: 0.1753\n",
      "Epoch: 93/500... Training loss: 0.1837\n",
      "Epoch: 93/500... Training loss: 0.2669\n",
      "Epoch: 93/500... Training loss: 0.2024\n",
      "Epoch: 93/500... Training loss: 0.2715\n",
      "Epoch: 93/500... Training loss: 0.2440\n",
      "Epoch: 93/500... Training loss: 0.2238\n",
      "Epoch: 93/500... Training loss: 0.1813\n",
      "Epoch: 93/500... Training loss: 0.1622\n",
      "Epoch: 93/500... Training loss: 0.1738\n",
      "Epoch: 93/500... Training loss: 0.1530\n",
      "Epoch: 93/500... Training loss: 0.1881\n",
      "Epoch: 94/500... Training loss: 0.3023\n",
      "Epoch: 94/500... Training loss: 0.1614\n",
      "Epoch: 94/500... Training loss: 0.2459\n",
      "Epoch: 94/500... Training loss: 0.2600\n",
      "Epoch: 94/500... Training loss: 0.3560\n",
      "Epoch: 94/500... Training loss: 0.2039\n",
      "Epoch: 94/500... Training loss: 0.2661\n",
      "Epoch: 94/500... Training loss: 0.2936\n",
      "Epoch: 94/500... Training loss: 0.1854\n",
      "Epoch: 94/500... Training loss: 0.1625\n",
      "Epoch: 94/500... Training loss: 0.2972\n",
      "Epoch: 94/500... Training loss: 0.2856\n",
      "Epoch: 94/500... Training loss: 0.2999\n",
      "Epoch: 94/500... Training loss: 0.2139\n",
      "Epoch: 94/500... Training loss: 0.1224\n",
      "Epoch: 94/500... Training loss: 0.1604\n",
      "Epoch: 94/500... Training loss: 0.1937\n",
      "Epoch: 94/500... Training loss: 0.1761\n",
      "Epoch: 94/500... Training loss: 0.3148\n",
      "Epoch: 94/500... Training loss: 0.2462\n",
      "Epoch: 94/500... Training loss: 0.1986\n",
      "Epoch: 94/500... Training loss: 0.1393\n",
      "Epoch: 94/500... Training loss: 0.2838\n",
      "Epoch: 94/500... Training loss: 0.1351\n",
      "Epoch: 94/500... Training loss: 0.1679\n",
      "Epoch: 94/500... Training loss: 0.1625\n",
      "Epoch: 94/500... Training loss: 0.2957\n",
      "Epoch: 94/500... Training loss: 0.1006\n",
      "Epoch: 94/500... Training loss: 0.1138\n",
      "Epoch: 94/500... Training loss: 0.1558\n",
      "Epoch: 94/500... Training loss: 0.1612\n",
      "Epoch: 95/500... Training loss: 0.2663\n",
      "Epoch: 95/500... Training loss: 0.2828\n",
      "Epoch: 95/500... Training loss: 0.2456\n",
      "Epoch: 95/500... Training loss: 0.2372\n",
      "Epoch: 95/500... Training loss: 0.2659\n",
      "Epoch: 95/500... Training loss: 0.1954\n",
      "Epoch: 95/500... Training loss: 0.1890\n",
      "Epoch: 95/500... Training loss: 0.1885\n",
      "Epoch: 95/500... Training loss: 0.1479\n",
      "Epoch: 95/500... Training loss: 0.2699\n",
      "Epoch: 95/500... Training loss: 0.2643\n",
      "Epoch: 95/500... Training loss: 0.3876\n",
      "Epoch: 95/500... Training loss: 0.2119\n",
      "Epoch: 95/500... Training loss: 0.1534\n",
      "Epoch: 95/500... Training loss: 0.1871\n",
      "Epoch: 95/500... Training loss: 0.2446\n",
      "Epoch: 95/500... Training loss: 0.1309\n",
      "Epoch: 95/500... Training loss: 0.1370\n",
      "Epoch: 95/500... Training loss: 0.3587\n",
      "Epoch: 95/500... Training loss: 0.1684\n",
      "Epoch: 95/500... Training loss: 0.2179\n",
      "Epoch: 95/500... Training loss: 0.2160\n",
      "Epoch: 95/500... Training loss: 0.2191\n",
      "Epoch: 95/500... Training loss: 0.3578\n",
      "Epoch: 95/500... Training loss: 0.1329\n",
      "Epoch: 95/500... Training loss: 0.2069\n",
      "Epoch: 95/500... Training loss: 0.1300\n",
      "Epoch: 95/500... Training loss: 0.1996\n",
      "Epoch: 95/500... Training loss: 0.1165\n",
      "Epoch: 95/500... Training loss: 0.1947\n",
      "Epoch: 95/500... Training loss: 0.1263\n",
      "Epoch: 96/500... Training loss: 0.1625\n",
      "Epoch: 96/500... Training loss: 0.2053\n",
      "Epoch: 96/500... Training loss: 0.2826\n",
      "Epoch: 96/500... Training loss: 0.2598\n",
      "Epoch: 96/500... Training loss: 0.3584\n",
      "Epoch: 96/500... Training loss: 0.2289\n",
      "Epoch: 96/500... Training loss: 0.2199\n",
      "Epoch: 96/500... Training loss: 0.1472\n",
      "Epoch: 96/500... Training loss: 0.2632\n",
      "Epoch: 96/500... Training loss: 0.2366\n",
      "Epoch: 96/500... Training loss: 0.3073\n",
      "Epoch: 96/500... Training loss: 0.3873\n",
      "Epoch: 96/500... Training loss: 0.2943\n",
      "Epoch: 96/500... Training loss: 0.2097\n",
      "Epoch: 96/500... Training loss: 0.1020\n",
      "Epoch: 96/500... Training loss: 0.1131\n",
      "Epoch: 96/500... Training loss: 0.1503\n",
      "Epoch: 96/500... Training loss: 0.2639\n",
      "Epoch: 96/500... Training loss: 0.3015\n",
      "Epoch: 96/500... Training loss: 0.1357\n",
      "Epoch: 96/500... Training loss: 0.2551\n",
      "Epoch: 96/500... Training loss: 0.1751\n",
      "Epoch: 96/500... Training loss: 0.1627\n",
      "Epoch: 96/500... Training loss: 0.2024\n",
      "Epoch: 96/500... Training loss: 0.2690\n",
      "Epoch: 96/500... Training loss: 0.1733\n",
      "Epoch: 96/500... Training loss: 0.2374\n",
      "Epoch: 96/500... Training loss: 0.2442\n",
      "Epoch: 96/500... Training loss: 0.1410\n",
      "Epoch: 96/500... Training loss: 0.1138\n",
      "Epoch: 96/500... Training loss: 0.1277\n",
      "Epoch: 97/500... Training loss: 0.1722\n",
      "Epoch: 97/500... Training loss: 0.2212\n",
      "Epoch: 97/500... Training loss: 0.2428\n",
      "Epoch: 97/500... Training loss: 0.3025\n",
      "Epoch: 97/500... Training loss: 0.2063\n",
      "Epoch: 97/500... Training loss: 0.2202\n",
      "Epoch: 97/500... Training loss: 0.2320\n",
      "Epoch: 97/500... Training loss: 0.2750\n",
      "Epoch: 97/500... Training loss: 0.1868\n",
      "Epoch: 97/500... Training loss: 0.1717\n",
      "Epoch: 97/500... Training loss: 0.3549\n",
      "Epoch: 97/500... Training loss: 0.3352\n",
      "Epoch: 97/500... Training loss: 0.2913\n",
      "Epoch: 97/500... Training loss: 0.1696\n",
      "Epoch: 97/500... Training loss: 0.1286\n",
      "Epoch: 97/500... Training loss: 0.1715\n",
      "Epoch: 97/500... Training loss: 0.2426\n",
      "Epoch: 97/500... Training loss: 0.1773\n",
      "Epoch: 97/500... Training loss: 0.1812\n",
      "Epoch: 97/500... Training loss: 0.2043\n",
      "Epoch: 97/500... Training loss: 0.1402\n",
      "Epoch: 97/500... Training loss: 0.2482\n",
      "Epoch: 97/500... Training loss: 0.2180\n",
      "Epoch: 97/500... Training loss: 0.2184\n",
      "Epoch: 97/500... Training loss: 0.1854\n",
      "Epoch: 97/500... Training loss: 0.1376\n",
      "Epoch: 97/500... Training loss: 0.2428\n",
      "Epoch: 97/500... Training loss: 0.2520\n",
      "Epoch: 97/500... Training loss: 0.2140\n",
      "Epoch: 97/500... Training loss: 0.1773\n",
      "Epoch: 97/500... Training loss: 0.1060\n",
      "Epoch: 98/500... Training loss: 0.2113\n",
      "Epoch: 98/500... Training loss: 0.1358\n",
      "Epoch: 98/500... Training loss: 0.1716\n",
      "Epoch: 98/500... Training loss: 0.3211\n",
      "Epoch: 98/500... Training loss: 0.2537\n",
      "Epoch: 98/500... Training loss: 0.1796\n",
      "Epoch: 98/500... Training loss: 0.2885\n",
      "Epoch: 98/500... Training loss: 0.1483\n",
      "Epoch: 98/500... Training loss: 0.1839\n",
      "Epoch: 98/500... Training loss: 0.2667\n",
      "Epoch: 98/500... Training loss: 0.3031\n",
      "Epoch: 98/500... Training loss: 0.4366\n",
      "Epoch: 98/500... Training loss: 0.3684\n",
      "Epoch: 98/500... Training loss: 0.2029\n",
      "Epoch: 98/500... Training loss: 0.2282\n",
      "Epoch: 98/500... Training loss: 0.0871\n",
      "Epoch: 98/500... Training loss: 0.1357\n",
      "Epoch: 98/500... Training loss: 0.2508\n",
      "Epoch: 98/500... Training loss: 0.2390\n",
      "Epoch: 98/500... Training loss: 0.1926\n",
      "Epoch: 98/500... Training loss: 0.1102\n",
      "Epoch: 98/500... Training loss: 0.3845\n",
      "Epoch: 98/500... Training loss: 0.2071\n",
      "Epoch: 98/500... Training loss: 0.3524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/500... Training loss: 0.2851\n",
      "Epoch: 98/500... Training loss: 0.0906\n",
      "Epoch: 98/500... Training loss: 0.1217\n",
      "Epoch: 98/500... Training loss: 0.1496\n",
      "Epoch: 98/500... Training loss: 0.1893\n",
      "Epoch: 98/500... Training loss: 0.1249\n",
      "Epoch: 98/500... Training loss: 0.1735\n",
      "Epoch: 99/500... Training loss: 0.1851\n",
      "Epoch: 99/500... Training loss: 0.2711\n",
      "Epoch: 99/500... Training loss: 0.2466\n",
      "Epoch: 99/500... Training loss: 0.2277\n",
      "Epoch: 99/500... Training loss: 0.3351\n",
      "Epoch: 99/500... Training loss: 0.3133\n",
      "Epoch: 99/500... Training loss: 0.1322\n",
      "Epoch: 99/500... Training loss: 0.2274\n",
      "Epoch: 99/500... Training loss: 0.1566\n",
      "Epoch: 99/500... Training loss: 0.2721\n",
      "Epoch: 99/500... Training loss: 0.2552\n",
      "Epoch: 99/500... Training loss: 0.2772\n",
      "Epoch: 99/500... Training loss: 0.3018\n",
      "Epoch: 99/500... Training loss: 0.2185\n",
      "Epoch: 99/500... Training loss: 0.1451\n",
      "Epoch: 99/500... Training loss: 0.1667\n",
      "Epoch: 99/500... Training loss: 0.2655\n",
      "Epoch: 99/500... Training loss: 0.1891\n",
      "Epoch: 99/500... Training loss: 0.2994\n",
      "Epoch: 99/500... Training loss: 0.0888\n",
      "Epoch: 99/500... Training loss: 0.1271\n",
      "Epoch: 99/500... Training loss: 0.2417\n",
      "Epoch: 99/500... Training loss: 0.2920\n",
      "Epoch: 99/500... Training loss: 0.2116\n",
      "Epoch: 99/500... Training loss: 0.1347\n",
      "Epoch: 99/500... Training loss: 0.1558\n",
      "Epoch: 99/500... Training loss: 0.2112\n",
      "Epoch: 99/500... Training loss: 0.1800\n",
      "Epoch: 99/500... Training loss: 0.1712\n",
      "Epoch: 99/500... Training loss: 0.1554\n",
      "Epoch: 99/500... Training loss: 0.0946\n",
      "Epoch: 100/500... Training loss: 0.3090\n",
      "Epoch: 100/500... Training loss: 0.1572\n",
      "Epoch: 100/500... Training loss: 0.2880\n",
      "Epoch: 100/500... Training loss: 0.2432\n",
      "Epoch: 100/500... Training loss: 0.2259\n",
      "Epoch: 100/500... Training loss: 0.2275\n",
      "Epoch: 100/500... Training loss: 0.1824\n",
      "Epoch: 100/500... Training loss: 0.1843\n",
      "Epoch: 100/500... Training loss: 0.1770\n",
      "Epoch: 100/500... Training loss: 0.1581\n",
      "Epoch: 100/500... Training loss: 0.3348\n",
      "Epoch: 100/500... Training loss: 0.3106\n",
      "Epoch: 100/500... Training loss: 0.2302\n",
      "Epoch: 100/500... Training loss: 0.1447\n",
      "Epoch: 100/500... Training loss: 0.1604\n",
      "Epoch: 100/500... Training loss: 0.1519\n",
      "Epoch: 100/500... Training loss: 0.1510\n",
      "Epoch: 100/500... Training loss: 0.1519\n",
      "Epoch: 100/500... Training loss: 0.2176\n",
      "Epoch: 100/500... Training loss: 0.2200\n",
      "Epoch: 100/500... Training loss: 0.2655\n",
      "Epoch: 100/500... Training loss: 0.2280\n",
      "Epoch: 100/500... Training loss: 0.2773\n",
      "Epoch: 100/500... Training loss: 0.2139\n",
      "Epoch: 100/500... Training loss: 0.1752\n",
      "Epoch: 100/500... Training loss: 0.1469\n",
      "Epoch: 100/500... Training loss: 0.1600\n",
      "Epoch: 100/500... Training loss: 0.1544\n",
      "Epoch: 100/500... Training loss: 0.1632\n",
      "Epoch: 100/500... Training loss: 0.1740\n",
      "Epoch: 100/500... Training loss: 0.1559\n",
      "Epoch: 101/500... Training loss: 0.2544\n",
      "Epoch: 101/500... Training loss: 0.1829\n",
      "Epoch: 101/500... Training loss: 0.1601\n",
      "Epoch: 101/500... Training loss: 0.2724\n",
      "Epoch: 101/500... Training loss: 0.3730\n",
      "Epoch: 101/500... Training loss: 0.2853\n",
      "Epoch: 101/500... Training loss: 0.2220\n",
      "Epoch: 101/500... Training loss: 0.2423\n",
      "Epoch: 101/500... Training loss: 0.1620\n",
      "Epoch: 101/500... Training loss: 0.2446\n",
      "Epoch: 101/500... Training loss: 0.5507\n",
      "Epoch: 101/500... Training loss: 0.2582\n",
      "Epoch: 101/500... Training loss: 0.2284\n",
      "Epoch: 101/500... Training loss: 0.1638\n",
      "Epoch: 101/500... Training loss: 0.2041\n",
      "Epoch: 101/500... Training loss: 0.1587\n",
      "Epoch: 101/500... Training loss: 0.1895\n",
      "Epoch: 101/500... Training loss: 0.1990\n",
      "Epoch: 101/500... Training loss: 0.2035\n",
      "Epoch: 101/500... Training loss: 0.1137\n",
      "Epoch: 101/500... Training loss: 0.1361\n",
      "Epoch: 101/500... Training loss: 0.2114\n",
      "Epoch: 101/500... Training loss: 0.1998\n",
      "Epoch: 101/500... Training loss: 0.1876\n",
      "Epoch: 101/500... Training loss: 0.1249\n",
      "Epoch: 101/500... Training loss: 0.2857\n",
      "Epoch: 101/500... Training loss: 0.1324\n",
      "Epoch: 101/500... Training loss: 0.1793\n",
      "Epoch: 101/500... Training loss: 0.0796\n",
      "Epoch: 101/500... Training loss: 0.1522\n",
      "Epoch: 101/500... Training loss: 0.1283\n",
      "Epoch: 102/500... Training loss: 0.1912\n",
      "Epoch: 102/500... Training loss: 0.3396\n",
      "Epoch: 102/500... Training loss: 0.2548\n",
      "Epoch: 102/500... Training loss: 0.3629\n",
      "Epoch: 102/500... Training loss: 0.2164\n",
      "Epoch: 102/500... Training loss: 0.2183\n",
      "Epoch: 102/500... Training loss: 0.3298\n",
      "Epoch: 102/500... Training loss: 0.1936\n",
      "Epoch: 102/500... Training loss: 0.1900\n",
      "Epoch: 102/500... Training loss: 0.1643\n",
      "Epoch: 102/500... Training loss: 0.4582\n",
      "Epoch: 102/500... Training loss: 0.3749\n",
      "Epoch: 102/500... Training loss: 0.2630\n",
      "Epoch: 102/500... Training loss: 0.2044\n",
      "Epoch: 102/500... Training loss: 0.1482\n",
      "Epoch: 102/500... Training loss: 0.1920\n",
      "Epoch: 102/500... Training loss: 0.3011\n",
      "Epoch: 102/500... Training loss: 0.2360\n",
      "Epoch: 102/500... Training loss: 0.1999\n",
      "Epoch: 102/500... Training loss: 0.1320\n",
      "Epoch: 102/500... Training loss: 0.1510\n",
      "Epoch: 102/500... Training loss: 0.1745\n",
      "Epoch: 102/500... Training loss: 0.3031\n",
      "Epoch: 102/500... Training loss: 0.1811\n",
      "Epoch: 102/500... Training loss: 0.1761\n",
      "Epoch: 102/500... Training loss: 0.3003\n",
      "Epoch: 102/500... Training loss: 0.2587\n",
      "Epoch: 102/500... Training loss: 0.1536\n",
      "Epoch: 102/500... Training loss: 0.1180\n",
      "Epoch: 102/500... Training loss: 0.2332\n",
      "Epoch: 102/500... Training loss: 0.1035\n",
      "Epoch: 103/500... Training loss: 0.1810\n",
      "Epoch: 103/500... Training loss: 0.1821\n",
      "Epoch: 103/500... Training loss: 0.2320\n",
      "Epoch: 103/500... Training loss: 0.3498\n",
      "Epoch: 103/500... Training loss: 0.2595\n",
      "Epoch: 103/500... Training loss: 0.1821\n",
      "Epoch: 103/500... Training loss: 0.1757\n",
      "Epoch: 103/500... Training loss: 0.2985\n",
      "Epoch: 103/500... Training loss: 0.1573\n",
      "Epoch: 103/500... Training loss: 0.1780\n",
      "Epoch: 103/500... Training loss: 0.3639\n",
      "Epoch: 103/500... Training loss: 0.2914\n",
      "Epoch: 103/500... Training loss: 0.3434\n",
      "Epoch: 103/500... Training loss: 0.1135\n",
      "Epoch: 103/500... Training loss: 0.2892\n",
      "Epoch: 103/500... Training loss: 0.1112\n",
      "Epoch: 103/500... Training loss: 0.1325\n",
      "Epoch: 103/500... Training loss: 0.3014\n",
      "Epoch: 103/500... Training loss: 0.1507\n",
      "Epoch: 103/500... Training loss: 0.0841\n",
      "Epoch: 103/500... Training loss: 0.2642\n",
      "Epoch: 103/500... Training loss: 0.1355\n",
      "Epoch: 103/500... Training loss: 0.2237\n",
      "Epoch: 103/500... Training loss: 0.1256\n",
      "Epoch: 103/500... Training loss: 0.1092\n",
      "Epoch: 103/500... Training loss: 0.1086\n",
      "Epoch: 103/500... Training loss: 0.1685\n",
      "Epoch: 103/500... Training loss: 0.1612\n",
      "Epoch: 103/500... Training loss: 0.1787\n",
      "Epoch: 103/500... Training loss: 0.1173\n",
      "Epoch: 103/500... Training loss: 0.1466\n",
      "Epoch: 104/500... Training loss: 0.3893\n",
      "Epoch: 104/500... Training loss: 0.2223\n",
      "Epoch: 104/500... Training loss: 0.2025\n",
      "Epoch: 104/500... Training loss: 0.1807\n",
      "Epoch: 104/500... Training loss: 0.2076\n",
      "Epoch: 104/500... Training loss: 0.2214\n",
      "Epoch: 104/500... Training loss: 0.1756\n",
      "Epoch: 104/500... Training loss: 0.2363\n",
      "Epoch: 104/500... Training loss: 0.2199\n",
      "Epoch: 104/500... Training loss: 0.2128\n",
      "Epoch: 104/500... Training loss: 0.2990\n",
      "Epoch: 104/500... Training loss: 0.4067\n",
      "Epoch: 104/500... Training loss: 0.2242\n",
      "Epoch: 104/500... Training loss: 0.1044\n",
      "Epoch: 104/500... Training loss: 0.1703\n",
      "Epoch: 104/500... Training loss: 0.1705\n",
      "Epoch: 104/500... Training loss: 0.2013\n",
      "Epoch: 104/500... Training loss: 0.2260\n",
      "Epoch: 104/500... Training loss: 0.2020\n",
      "Epoch: 104/500... Training loss: 0.1433\n",
      "Epoch: 104/500... Training loss: 0.1267\n",
      "Epoch: 104/500... Training loss: 0.1781\n",
      "Epoch: 104/500... Training loss: 0.2631\n",
      "Epoch: 104/500... Training loss: 0.0970\n",
      "Epoch: 104/500... Training loss: 0.1325\n",
      "Epoch: 104/500... Training loss: 0.2363\n",
      "Epoch: 104/500... Training loss: 0.1776\n",
      "Epoch: 104/500... Training loss: 0.1711\n",
      "Epoch: 104/500... Training loss: 0.1491\n",
      "Epoch: 104/500... Training loss: 0.1376\n",
      "Epoch: 104/500... Training loss: 0.1990\n",
      "Epoch: 105/500... Training loss: 0.1801\n",
      "Epoch: 105/500... Training loss: 0.2661\n",
      "Epoch: 105/500... Training loss: 0.3724\n",
      "Epoch: 105/500... Training loss: 0.1658\n",
      "Epoch: 105/500... Training loss: 0.1870\n",
      "Epoch: 105/500... Training loss: 0.2051\n",
      "Epoch: 105/500... Training loss: 0.2677\n",
      "Epoch: 105/500... Training loss: 0.3055\n",
      "Epoch: 105/500... Training loss: 0.1700\n",
      "Epoch: 105/500... Training loss: 0.2082\n",
      "Epoch: 105/500... Training loss: 0.2970\n",
      "Epoch: 105/500... Training loss: 0.2485\n",
      "Epoch: 105/500... Training loss: 0.3421\n",
      "Epoch: 105/500... Training loss: 0.1857\n",
      "Epoch: 105/500... Training loss: 0.1707\n",
      "Epoch: 105/500... Training loss: 0.1562\n",
      "Epoch: 105/500... Training loss: 0.1243\n",
      "Epoch: 105/500... Training loss: 0.1989\n",
      "Epoch: 105/500... Training loss: 0.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/500... Training loss: 0.2015\n",
      "Epoch: 105/500... Training loss: 0.1773\n",
      "Epoch: 105/500... Training loss: 0.2453\n",
      "Epoch: 105/500... Training loss: 0.4029\n",
      "Epoch: 105/500... Training loss: 0.1381\n",
      "Epoch: 105/500... Training loss: 0.1312\n",
      "Epoch: 105/500... Training loss: 0.1580\n",
      "Epoch: 105/500... Training loss: 0.0887\n",
      "Epoch: 105/500... Training loss: 0.1947\n",
      "Epoch: 105/500... Training loss: 0.0752\n",
      "Epoch: 105/500... Training loss: 0.0999\n",
      "Epoch: 105/500... Training loss: 0.1580\n",
      "Epoch: 106/500... Training loss: 0.1777\n",
      "Epoch: 106/500... Training loss: 0.3895\n",
      "Epoch: 106/500... Training loss: 0.2302\n",
      "Epoch: 106/500... Training loss: 0.1890\n",
      "Epoch: 106/500... Training loss: 0.2851\n",
      "Epoch: 106/500... Training loss: 0.3017\n",
      "Epoch: 106/500... Training loss: 0.2338\n",
      "Epoch: 106/500... Training loss: 0.1152\n",
      "Epoch: 106/500... Training loss: 0.1776\n",
      "Epoch: 106/500... Training loss: 0.1793\n",
      "Epoch: 106/500... Training loss: 0.1089\n",
      "Epoch: 106/500... Training loss: 0.3112\n",
      "Epoch: 106/500... Training loss: 0.2504\n",
      "Epoch: 106/500... Training loss: 0.1310\n",
      "Epoch: 106/500... Training loss: 0.2295\n",
      "Epoch: 106/500... Training loss: 0.1261\n",
      "Epoch: 106/500... Training loss: 0.1761\n",
      "Epoch: 106/500... Training loss: 0.3521\n",
      "Epoch: 106/500... Training loss: 0.2048\n",
      "Epoch: 106/500... Training loss: 0.1270\n",
      "Epoch: 106/500... Training loss: 0.2398\n",
      "Epoch: 106/500... Training loss: 0.1047\n",
      "Epoch: 106/500... Training loss: 0.1558\n",
      "Epoch: 106/500... Training loss: 0.1575\n",
      "Epoch: 106/500... Training loss: 0.2666\n",
      "Epoch: 106/500... Training loss: 0.1882\n",
      "Epoch: 106/500... Training loss: 0.2126\n",
      "Epoch: 106/500... Training loss: 0.1182\n",
      "Epoch: 106/500... Training loss: 0.1185\n",
      "Epoch: 106/500... Training loss: 0.1606\n",
      "Epoch: 106/500... Training loss: 0.2989\n",
      "Epoch: 107/500... Training loss: 0.2782\n",
      "Epoch: 107/500... Training loss: 0.2315\n",
      "Epoch: 107/500... Training loss: 0.2241\n",
      "Epoch: 107/500... Training loss: 0.1646\n",
      "Epoch: 107/500... Training loss: 0.2190\n",
      "Epoch: 107/500... Training loss: 0.2195\n",
      "Epoch: 107/500... Training loss: 0.1705\n",
      "Epoch: 107/500... Training loss: 0.2635\n",
      "Epoch: 107/500... Training loss: 0.1637\n",
      "Epoch: 107/500... Training loss: 0.2825\n",
      "Epoch: 107/500... Training loss: 0.2981\n",
      "Epoch: 107/500... Training loss: 0.3098\n",
      "Epoch: 107/500... Training loss: 0.3050\n",
      "Epoch: 107/500... Training loss: 0.0977\n",
      "Epoch: 107/500... Training loss: 0.2084\n",
      "Epoch: 107/500... Training loss: 0.1706\n",
      "Epoch: 107/500... Training loss: 0.1973\n",
      "Epoch: 107/500... Training loss: 0.2768\n",
      "Epoch: 107/500... Training loss: 0.2909\n",
      "Epoch: 107/500... Training loss: 0.0849\n",
      "Epoch: 107/500... Training loss: 0.1503\n",
      "Epoch: 107/500... Training loss: 0.2309\n",
      "Epoch: 107/500... Training loss: 0.2186\n",
      "Epoch: 107/500... Training loss: 0.1767\n",
      "Epoch: 107/500... Training loss: 0.2496\n",
      "Epoch: 107/500... Training loss: 0.1666\n",
      "Epoch: 107/500... Training loss: 0.4453\n",
      "Epoch: 107/500... Training loss: 0.1128\n",
      "Epoch: 107/500... Training loss: 0.0873\n",
      "Epoch: 107/500... Training loss: 0.1864\n",
      "Epoch: 107/500... Training loss: 0.1308\n",
      "Epoch: 108/500... Training loss: 0.2289\n",
      "Epoch: 108/500... Training loss: 0.2555\n",
      "Epoch: 108/500... Training loss: 0.1905\n",
      "Epoch: 108/500... Training loss: 0.3504\n",
      "Epoch: 108/500... Training loss: 0.2425\n",
      "Epoch: 108/500... Training loss: 0.1943\n",
      "Epoch: 108/500... Training loss: 0.2023\n",
      "Epoch: 108/500... Training loss: 0.1933\n",
      "Epoch: 108/500... Training loss: 0.1530\n",
      "Epoch: 108/500... Training loss: 0.1767\n",
      "Epoch: 108/500... Training loss: 0.2790\n",
      "Epoch: 108/500... Training loss: 0.2775\n",
      "Epoch: 108/500... Training loss: 0.2511\n",
      "Epoch: 108/500... Training loss: 0.1284\n",
      "Epoch: 108/500... Training loss: 0.1196\n",
      "Epoch: 108/500... Training loss: 0.1452\n",
      "Epoch: 108/500... Training loss: 0.1446\n",
      "Epoch: 108/500... Training loss: 0.1162\n",
      "Epoch: 108/500... Training loss: 0.2988\n",
      "Epoch: 108/500... Training loss: 0.1922\n",
      "Epoch: 108/500... Training loss: 0.1882\n",
      "Epoch: 108/500... Training loss: 0.2393\n",
      "Epoch: 108/500... Training loss: 0.1581\n",
      "Epoch: 108/500... Training loss: 0.1356\n",
      "Epoch: 108/500... Training loss: 0.0680\n",
      "Epoch: 108/500... Training loss: 0.2318\n",
      "Epoch: 108/500... Training loss: 0.1616\n",
      "Epoch: 108/500... Training loss: 0.0990\n",
      "Epoch: 108/500... Training loss: 0.1444\n",
      "Epoch: 108/500... Training loss: 0.1143\n",
      "Epoch: 108/500... Training loss: 0.1151\n",
      "Epoch: 109/500... Training loss: 0.2355\n",
      "Epoch: 109/500... Training loss: 0.0930\n",
      "Epoch: 109/500... Training loss: 0.0945\n",
      "Epoch: 109/500... Training loss: 0.2707\n",
      "Epoch: 109/500... Training loss: 0.2022\n",
      "Epoch: 109/500... Training loss: 0.1336\n",
      "Epoch: 109/500... Training loss: 0.2207\n",
      "Epoch: 109/500... Training loss: 0.1243\n",
      "Epoch: 109/500... Training loss: 0.1358\n",
      "Epoch: 109/500... Training loss: 0.2134\n",
      "Epoch: 109/500... Training loss: 0.1833\n",
      "Epoch: 109/500... Training loss: 0.3415\n",
      "Epoch: 109/500... Training loss: 0.2641\n",
      "Epoch: 109/500... Training loss: 0.1564\n",
      "Epoch: 109/500... Training loss: 0.1111\n",
      "Epoch: 109/500... Training loss: 0.1347\n",
      "Epoch: 109/500... Training loss: 0.2990\n",
      "Epoch: 109/500... Training loss: 0.1998\n",
      "Epoch: 109/500... Training loss: 0.1838\n",
      "Epoch: 109/500... Training loss: 0.0686\n",
      "Epoch: 109/500... Training loss: 0.1350\n",
      "Epoch: 109/500... Training loss: 0.1321\n",
      "Epoch: 109/500... Training loss: 0.2372\n",
      "Epoch: 109/500... Training loss: 0.1810\n",
      "Epoch: 109/500... Training loss: 0.1500\n",
      "Epoch: 109/500... Training loss: 0.2147\n",
      "Epoch: 109/500... Training loss: 0.2769\n",
      "Epoch: 109/500... Training loss: 0.1660\n",
      "Epoch: 109/500... Training loss: 0.0853\n",
      "Epoch: 109/500... Training loss: 0.1472\n",
      "Epoch: 109/500... Training loss: 0.2704\n",
      "Epoch: 110/500... Training loss: 0.3173\n",
      "Epoch: 110/500... Training loss: 0.0654\n",
      "Epoch: 110/500... Training loss: 0.3503\n",
      "Epoch: 110/500... Training loss: 0.3175\n",
      "Epoch: 110/500... Training loss: 0.2111\n",
      "Epoch: 110/500... Training loss: 0.2351\n",
      "Epoch: 110/500... Training loss: 0.3154\n",
      "Epoch: 110/500... Training loss: 0.1227\n",
      "Epoch: 110/500... Training loss: 0.1748\n",
      "Epoch: 110/500... Training loss: 0.1326\n",
      "Epoch: 110/500... Training loss: 0.3721\n",
      "Epoch: 110/500... Training loss: 0.2679\n",
      "Epoch: 110/500... Training loss: 0.1858\n",
      "Epoch: 110/500... Training loss: 0.1632\n",
      "Epoch: 110/500... Training loss: 0.0991\n",
      "Epoch: 110/500... Training loss: 0.1581\n",
      "Epoch: 110/500... Training loss: 0.2031\n",
      "Epoch: 110/500... Training loss: 0.2904\n",
      "Epoch: 110/500... Training loss: 0.3223\n",
      "Epoch: 110/500... Training loss: 0.0830\n",
      "Epoch: 110/500... Training loss: 0.2482\n",
      "Epoch: 110/500... Training loss: 0.2383\n",
      "Epoch: 110/500... Training loss: 0.2579\n",
      "Epoch: 110/500... Training loss: 0.1047\n",
      "Epoch: 110/500... Training loss: 0.1575\n",
      "Epoch: 110/500... Training loss: 0.1526\n",
      "Epoch: 110/500... Training loss: 0.1957\n",
      "Epoch: 110/500... Training loss: 0.0927\n",
      "Epoch: 110/500... Training loss: 0.0677\n",
      "Epoch: 110/500... Training loss: 0.1260\n",
      "Epoch: 110/500... Training loss: 0.1632\n",
      "Epoch: 111/500... Training loss: 0.2159\n",
      "Epoch: 111/500... Training loss: 0.0856\n",
      "Epoch: 111/500... Training loss: 0.1660\n",
      "Epoch: 111/500... Training loss: 0.2500\n",
      "Epoch: 111/500... Training loss: 0.2258\n",
      "Epoch: 111/500... Training loss: 0.1596\n",
      "Epoch: 111/500... Training loss: 0.1708\n",
      "Epoch: 111/500... Training loss: 0.1650\n",
      "Epoch: 111/500... Training loss: 0.2067\n",
      "Epoch: 111/500... Training loss: 0.2301\n",
      "Epoch: 111/500... Training loss: 0.1995\n",
      "Epoch: 111/500... Training loss: 0.2983\n",
      "Epoch: 111/500... Training loss: 0.2273\n",
      "Epoch: 111/500... Training loss: 0.1602\n",
      "Epoch: 111/500... Training loss: 0.1786\n",
      "Epoch: 111/500... Training loss: 0.1665\n",
      "Epoch: 111/500... Training loss: 0.2711\n",
      "Epoch: 111/500... Training loss: 0.1736\n",
      "Epoch: 111/500... Training loss: 0.0806\n",
      "Epoch: 111/500... Training loss: 0.0779\n",
      "Epoch: 111/500... Training loss: 0.1573\n",
      "Epoch: 111/500... Training loss: 0.1163\n",
      "Epoch: 111/500... Training loss: 0.2668\n",
      "Epoch: 111/500... Training loss: 0.2271\n",
      "Epoch: 111/500... Training loss: 0.0874\n",
      "Epoch: 111/500... Training loss: 0.1780\n",
      "Epoch: 111/500... Training loss: 0.1535\n",
      "Epoch: 111/500... Training loss: 0.1872\n",
      "Epoch: 111/500... Training loss: 0.0999\n",
      "Epoch: 111/500... Training loss: 0.1066\n",
      "Epoch: 111/500... Training loss: 0.0639\n",
      "Epoch: 112/500... Training loss: 0.1729\n",
      "Epoch: 112/500... Training loss: 0.1328\n",
      "Epoch: 112/500... Training loss: 0.1629\n",
      "Epoch: 112/500... Training loss: 0.3081\n",
      "Epoch: 112/500... Training loss: 0.1527\n",
      "Epoch: 112/500... Training loss: 0.1504\n",
      "Epoch: 112/500... Training loss: 0.1651\n",
      "Epoch: 112/500... Training loss: 0.1678\n",
      "Epoch: 112/500... Training loss: 0.2835\n",
      "Epoch: 112/500... Training loss: 0.1821\n",
      "Epoch: 112/500... Training loss: 0.1786\n",
      "Epoch: 112/500... Training loss: 0.1526\n",
      "Epoch: 112/500... Training loss: 0.2277\n",
      "Epoch: 112/500... Training loss: 0.1680\n",
      "Epoch: 112/500... Training loss: 0.2239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112/500... Training loss: 0.1291\n",
      "Epoch: 112/500... Training loss: 0.1448\n",
      "Epoch: 112/500... Training loss: 0.2686\n",
      "Epoch: 112/500... Training loss: 0.2741\n",
      "Epoch: 112/500... Training loss: 0.1277\n",
      "Epoch: 112/500... Training loss: 0.1530\n",
      "Epoch: 112/500... Training loss: 0.1906\n",
      "Epoch: 112/500... Training loss: 0.2519\n",
      "Epoch: 112/500... Training loss: 0.1016\n",
      "Epoch: 112/500... Training loss: 0.1346\n",
      "Epoch: 112/500... Training loss: 0.1380\n",
      "Epoch: 112/500... Training loss: 0.1240\n",
      "Epoch: 112/500... Training loss: 0.1911\n",
      "Epoch: 112/500... Training loss: 0.0905\n",
      "Epoch: 112/500... Training loss: 0.1181\n",
      "Epoch: 112/500... Training loss: 0.1530\n",
      "Epoch: 113/500... Training loss: 0.1813\n",
      "Epoch: 113/500... Training loss: 0.1909\n",
      "Epoch: 113/500... Training loss: 0.1596\n",
      "Epoch: 113/500... Training loss: 0.2100\n",
      "Epoch: 113/500... Training loss: 0.3223\n",
      "Epoch: 113/500... Training loss: 0.1921\n",
      "Epoch: 113/500... Training loss: 0.1678\n",
      "Epoch: 113/500... Training loss: 0.1510\n",
      "Epoch: 113/500... Training loss: 0.2439\n",
      "Epoch: 113/500... Training loss: 0.1704\n",
      "Epoch: 113/500... Training loss: 0.2213\n",
      "Epoch: 113/500... Training loss: 0.2372\n",
      "Epoch: 113/500... Training loss: 0.2375\n",
      "Epoch: 113/500... Training loss: 0.1531\n",
      "Epoch: 113/500... Training loss: 0.1214\n",
      "Epoch: 113/500... Training loss: 0.1333\n",
      "Epoch: 113/500... Training loss: 0.2064\n",
      "Epoch: 113/500... Training loss: 0.0926\n",
      "Epoch: 113/500... Training loss: 0.1698\n",
      "Epoch: 113/500... Training loss: 0.1012\n",
      "Epoch: 113/500... Training loss: 0.2814\n",
      "Epoch: 113/500... Training loss: 0.2461\n",
      "Epoch: 113/500... Training loss: 0.2136\n",
      "Epoch: 113/500... Training loss: 0.1176\n",
      "Epoch: 113/500... Training loss: 0.1759\n",
      "Epoch: 113/500... Training loss: 0.1691\n",
      "Epoch: 113/500... Training loss: 0.1775\n",
      "Epoch: 113/500... Training loss: 0.1382\n",
      "Epoch: 113/500... Training loss: 0.1742\n",
      "Epoch: 113/500... Training loss: 0.0544\n",
      "Epoch: 113/500... Training loss: 0.0743\n",
      "Epoch: 114/500... Training loss: 0.2478\n",
      "Epoch: 114/500... Training loss: 0.1117\n",
      "Epoch: 114/500... Training loss: 0.1856\n",
      "Epoch: 114/500... Training loss: 0.2411\n",
      "Epoch: 114/500... Training loss: 0.1448\n",
      "Epoch: 114/500... Training loss: 0.1975\n",
      "Epoch: 114/500... Training loss: 0.1376\n",
      "Epoch: 114/500... Training loss: 0.1927\n",
      "Epoch: 114/500... Training loss: 0.1360\n",
      "Epoch: 114/500... Training loss: 0.3526\n",
      "Epoch: 114/500... Training loss: 0.3163\n",
      "Epoch: 114/500... Training loss: 0.3248\n",
      "Epoch: 114/500... Training loss: 0.2809\n",
      "Epoch: 114/500... Training loss: 0.0681\n",
      "Epoch: 114/500... Training loss: 0.1213\n",
      "Epoch: 114/500... Training loss: 0.1260\n",
      "Epoch: 114/500... Training loss: 0.0961\n",
      "Epoch: 114/500... Training loss: 0.1888\n",
      "Epoch: 114/500... Training loss: 0.2210\n",
      "Epoch: 114/500... Training loss: 0.1831\n",
      "Epoch: 114/500... Training loss: 0.1980\n",
      "Epoch: 114/500... Training loss: 0.1374\n",
      "Epoch: 114/500... Training loss: 0.2837\n",
      "Epoch: 114/500... Training loss: 0.2123\n",
      "Epoch: 114/500... Training loss: 0.2242\n",
      "Epoch: 114/500... Training loss: 0.1199\n",
      "Epoch: 114/500... Training loss: 0.0954\n",
      "Epoch: 114/500... Training loss: 0.1413\n",
      "Epoch: 114/500... Training loss: 0.1772\n",
      "Epoch: 114/500... Training loss: 0.1750\n",
      "Epoch: 114/500... Training loss: 0.1291\n",
      "Epoch: 115/500... Training loss: 0.2611\n",
      "Epoch: 115/500... Training loss: 0.2649\n",
      "Epoch: 115/500... Training loss: 0.1621\n",
      "Epoch: 115/500... Training loss: 0.2383\n",
      "Epoch: 115/500... Training loss: 0.2165\n",
      "Epoch: 115/500... Training loss: 0.1826\n",
      "Epoch: 115/500... Training loss: 0.2126\n",
      "Epoch: 115/500... Training loss: 0.1310\n",
      "Epoch: 115/500... Training loss: 0.1136\n",
      "Epoch: 115/500... Training loss: 0.1322\n",
      "Epoch: 115/500... Training loss: 0.3348\n",
      "Epoch: 115/500... Training loss: 0.3880\n",
      "Epoch: 115/500... Training loss: 0.3017\n",
      "Epoch: 115/500... Training loss: 0.0913\n",
      "Epoch: 115/500... Training loss: 0.0712\n",
      "Epoch: 115/500... Training loss: 0.1157\n",
      "Epoch: 115/500... Training loss: 0.1910\n",
      "Epoch: 115/500... Training loss: 0.1902\n",
      "Epoch: 115/500... Training loss: 0.2264\n",
      "Epoch: 115/500... Training loss: 0.1115\n",
      "Epoch: 115/500... Training loss: 0.0949\n",
      "Epoch: 115/500... Training loss: 0.2071\n",
      "Epoch: 115/500... Training loss: 0.1112\n",
      "Epoch: 115/500... Training loss: 0.1459\n",
      "Epoch: 115/500... Training loss: 0.0888\n",
      "Epoch: 115/500... Training loss: 0.1046\n",
      "Epoch: 115/500... Training loss: 0.1643\n",
      "Epoch: 115/500... Training loss: 0.1531\n",
      "Epoch: 115/500... Training loss: 0.0997\n",
      "Epoch: 115/500... Training loss: 0.1640\n",
      "Epoch: 115/500... Training loss: 0.1317\n",
      "Epoch: 116/500... Training loss: 0.2545\n",
      "Epoch: 116/500... Training loss: 0.2267\n",
      "Epoch: 116/500... Training loss: 0.2757\n",
      "Epoch: 116/500... Training loss: 0.2393\n",
      "Epoch: 116/500... Training loss: 0.1523\n",
      "Epoch: 116/500... Training loss: 0.1396\n",
      "Epoch: 116/500... Training loss: 0.1004\n",
      "Epoch: 116/500... Training loss: 0.2016\n",
      "Epoch: 116/500... Training loss: 0.1537\n",
      "Epoch: 116/500... Training loss: 0.3354\n",
      "Epoch: 116/500... Training loss: 0.3052\n",
      "Epoch: 116/500... Training loss: 0.3370\n",
      "Epoch: 116/500... Training loss: 0.1650\n",
      "Epoch: 116/500... Training loss: 0.1469\n",
      "Epoch: 116/500... Training loss: 0.1619\n",
      "Epoch: 116/500... Training loss: 0.1433\n",
      "Epoch: 116/500... Training loss: 0.1195\n",
      "Epoch: 116/500... Training loss: 0.1500\n",
      "Epoch: 116/500... Training loss: 0.2282\n",
      "Epoch: 116/500... Training loss: 0.1011\n",
      "Epoch: 116/500... Training loss: 0.1516\n",
      "Epoch: 116/500... Training loss: 0.1450\n",
      "Epoch: 116/500... Training loss: 0.1897\n",
      "Epoch: 116/500... Training loss: 0.1209\n",
      "Epoch: 116/500... Training loss: 0.1385\n",
      "Epoch: 116/500... Training loss: 0.1263\n",
      "Epoch: 116/500... Training loss: 0.1985\n",
      "Epoch: 116/500... Training loss: 0.1302\n",
      "Epoch: 116/500... Training loss: 0.1368\n",
      "Epoch: 116/500... Training loss: 0.2009\n",
      "Epoch: 116/500... Training loss: 0.1260\n",
      "Epoch: 117/500... Training loss: 0.1881\n",
      "Epoch: 117/500... Training loss: 0.1963\n",
      "Epoch: 117/500... Training loss: 0.2499\n",
      "Epoch: 117/500... Training loss: 0.1839\n",
      "Epoch: 117/500... Training loss: 0.1795\n",
      "Epoch: 117/500... Training loss: 0.2119\n",
      "Epoch: 117/500... Training loss: 0.2165\n",
      "Epoch: 117/500... Training loss: 0.0664\n",
      "Epoch: 117/500... Training loss: 0.1036\n",
      "Epoch: 117/500... Training loss: 0.2151\n",
      "Epoch: 117/500... Training loss: 0.2437\n",
      "Epoch: 117/500... Training loss: 0.2410\n",
      "Epoch: 117/500... Training loss: 0.1754\n",
      "Epoch: 117/500... Training loss: 0.0926\n",
      "Epoch: 117/500... Training loss: 0.0825\n",
      "Epoch: 117/500... Training loss: 0.1839\n",
      "Epoch: 117/500... Training loss: 0.2300\n",
      "Epoch: 117/500... Training loss: 0.1017\n",
      "Epoch: 117/500... Training loss: 0.2270\n",
      "Epoch: 117/500... Training loss: 0.0897\n",
      "Epoch: 117/500... Training loss: 0.0660\n",
      "Epoch: 117/500... Training loss: 0.2086\n",
      "Epoch: 117/500... Training loss: 0.2131\n",
      "Epoch: 117/500... Training loss: 0.1341\n",
      "Epoch: 117/500... Training loss: 0.1369\n",
      "Epoch: 117/500... Training loss: 0.1431\n",
      "Epoch: 117/500... Training loss: 0.1504\n",
      "Epoch: 117/500... Training loss: 0.1727\n",
      "Epoch: 117/500... Training loss: 0.0760\n",
      "Epoch: 117/500... Training loss: 0.1449\n",
      "Epoch: 117/500... Training loss: 0.2332\n",
      "Epoch: 118/500... Training loss: 0.1932\n",
      "Epoch: 118/500... Training loss: 0.2114\n",
      "Epoch: 118/500... Training loss: 0.1451\n",
      "Epoch: 118/500... Training loss: 0.1454\n",
      "Epoch: 118/500... Training loss: 0.2029\n",
      "Epoch: 118/500... Training loss: 0.1116\n",
      "Epoch: 118/500... Training loss: 0.1401\n",
      "Epoch: 118/500... Training loss: 0.1658\n",
      "Epoch: 118/500... Training loss: 0.2431\n",
      "Epoch: 118/500... Training loss: 0.1872\n",
      "Epoch: 118/500... Training loss: 0.2569\n",
      "Epoch: 118/500... Training loss: 0.2840\n",
      "Epoch: 118/500... Training loss: 0.2328\n",
      "Epoch: 118/500... Training loss: 0.1650\n",
      "Epoch: 118/500... Training loss: 0.1117\n",
      "Epoch: 118/500... Training loss: 0.1249\n",
      "Epoch: 118/500... Training loss: 0.0653\n",
      "Epoch: 118/500... Training loss: 0.0894\n",
      "Epoch: 118/500... Training loss: 0.1073\n",
      "Epoch: 118/500... Training loss: 0.0973\n",
      "Epoch: 118/500... Training loss: 0.1385\n",
      "Epoch: 118/500... Training loss: 0.1338\n",
      "Epoch: 118/500... Training loss: 0.1243\n",
      "Epoch: 118/500... Training loss: 0.1402\n",
      "Epoch: 118/500... Training loss: 0.1859\n",
      "Epoch: 118/500... Training loss: 0.1598\n",
      "Epoch: 118/500... Training loss: 0.1402\n",
      "Epoch: 118/500... Training loss: 0.0486\n",
      "Epoch: 118/500... Training loss: 0.0587\n",
      "Epoch: 118/500... Training loss: 0.0820\n",
      "Epoch: 118/500... Training loss: 0.1706\n",
      "Epoch: 119/500... Training loss: 0.2089\n",
      "Epoch: 119/500... Training loss: 0.0975\n",
      "Epoch: 119/500... Training loss: 0.0771\n",
      "Epoch: 119/500... Training loss: 0.1914\n",
      "Epoch: 119/500... Training loss: 0.1373\n",
      "Epoch: 119/500... Training loss: 0.1356\n",
      "Epoch: 119/500... Training loss: 0.2146\n",
      "Epoch: 119/500... Training loss: 0.1290\n",
      "Epoch: 119/500... Training loss: 0.1901\n",
      "Epoch: 119/500... Training loss: 0.0973\n",
      "Epoch: 119/500... Training loss: 0.1546\n",
      "Epoch: 119/500... Training loss: 0.1888\n",
      "Epoch: 119/500... Training loss: 0.3022\n",
      "Epoch: 119/500... Training loss: 0.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/500... Training loss: 0.1574\n",
      "Epoch: 119/500... Training loss: 0.1735\n",
      "Epoch: 119/500... Training loss: 0.1156\n",
      "Epoch: 119/500... Training loss: 0.1621\n",
      "Epoch: 119/500... Training loss: 0.1563\n",
      "Epoch: 119/500... Training loss: 0.1294\n",
      "Epoch: 119/500... Training loss: 0.1859\n",
      "Epoch: 119/500... Training loss: 0.2031\n",
      "Epoch: 119/500... Training loss: 0.1543\n",
      "Epoch: 119/500... Training loss: 0.1763\n",
      "Epoch: 119/500... Training loss: 0.1305\n",
      "Epoch: 119/500... Training loss: 0.0801\n",
      "Epoch: 119/500... Training loss: 0.1353\n",
      "Epoch: 119/500... Training loss: 0.0896\n",
      "Epoch: 119/500... Training loss: 0.1218\n",
      "Epoch: 119/500... Training loss: 0.1980\n",
      "Epoch: 119/500... Training loss: 0.1485\n",
      "Epoch: 120/500... Training loss: 0.2647\n",
      "Epoch: 120/500... Training loss: 0.1229\n",
      "Epoch: 120/500... Training loss: 0.1558\n",
      "Epoch: 120/500... Training loss: 0.0978\n",
      "Epoch: 120/500... Training loss: 0.1775\n",
      "Epoch: 120/500... Training loss: 0.1983\n",
      "Epoch: 120/500... Training loss: 0.2214\n",
      "Epoch: 120/500... Training loss: 0.2349\n",
      "Epoch: 120/500... Training loss: 0.2188\n",
      "Epoch: 120/500... Training loss: 0.1749\n",
      "Epoch: 120/500... Training loss: 0.2378\n",
      "Epoch: 120/500... Training loss: 0.2682\n",
      "Epoch: 120/500... Training loss: 0.1587\n",
      "Epoch: 120/500... Training loss: 0.1576\n",
      "Epoch: 120/500... Training loss: 0.0889\n",
      "Epoch: 120/500... Training loss: 0.0729\n",
      "Epoch: 120/500... Training loss: 0.1095\n",
      "Epoch: 120/500... Training loss: 0.1377\n",
      "Epoch: 120/500... Training loss: 0.1656\n",
      "Epoch: 120/500... Training loss: 0.2100\n",
      "Epoch: 120/500... Training loss: 0.1357\n",
      "Epoch: 120/500... Training loss: 0.1909\n",
      "Epoch: 120/500... Training loss: 0.1999\n",
      "Epoch: 120/500... Training loss: 0.2253\n",
      "Epoch: 120/500... Training loss: 0.1067\n",
      "Epoch: 120/500... Training loss: 0.1839\n",
      "Epoch: 120/500... Training loss: 0.1105\n",
      "Epoch: 120/500... Training loss: 0.1638\n",
      "Epoch: 120/500... Training loss: 0.0470\n",
      "Epoch: 120/500... Training loss: 0.1006\n",
      "Epoch: 120/500... Training loss: 0.0969\n",
      "Epoch: 121/500... Training loss: 0.0713\n",
      "Epoch: 121/500... Training loss: 0.2914\n",
      "Epoch: 121/500... Training loss: 0.1695\n",
      "Epoch: 121/500... Training loss: 0.2417\n",
      "Epoch: 121/500... Training loss: 0.3155\n",
      "Epoch: 121/500... Training loss: 0.0951\n",
      "Epoch: 121/500... Training loss: 0.1976\n",
      "Epoch: 121/500... Training loss: 0.1136\n",
      "Epoch: 121/500... Training loss: 0.3617\n",
      "Epoch: 121/500... Training loss: 0.1285\n",
      "Epoch: 121/500... Training loss: 0.3810\n",
      "Epoch: 121/500... Training loss: 0.2363\n",
      "Epoch: 121/500... Training loss: 0.2535\n",
      "Epoch: 121/500... Training loss: 0.1376\n",
      "Epoch: 121/500... Training loss: 0.1311\n",
      "Epoch: 121/500... Training loss: 0.0851\n",
      "Epoch: 121/500... Training loss: 0.1714\n",
      "Epoch: 121/500... Training loss: 0.0935\n",
      "Epoch: 121/500... Training loss: 0.1823\n",
      "Epoch: 121/500... Training loss: 0.1547\n",
      "Epoch: 121/500... Training loss: 0.1336\n",
      "Epoch: 121/500... Training loss: 0.1917\n",
      "Epoch: 121/500... Training loss: 0.2077\n",
      "Epoch: 121/500... Training loss: 0.1874\n",
      "Epoch: 121/500... Training loss: 0.1257\n",
      "Epoch: 121/500... Training loss: 0.0826\n",
      "Epoch: 121/500... Training loss: 0.1716\n",
      "Epoch: 121/500... Training loss: 0.0839\n",
      "Epoch: 121/500... Training loss: 0.0747\n",
      "Epoch: 121/500... Training loss: 0.1450\n",
      "Epoch: 121/500... Training loss: 0.1599\n",
      "Epoch: 122/500... Training loss: 0.1443\n",
      "Epoch: 122/500... Training loss: 0.2035\n",
      "Epoch: 122/500... Training loss: 0.1807\n",
      "Epoch: 122/500... Training loss: 0.1193\n",
      "Epoch: 122/500... Training loss: 0.1012\n",
      "Epoch: 122/500... Training loss: 0.1993\n",
      "Epoch: 122/500... Training loss: 0.0968\n",
      "Epoch: 122/500... Training loss: 0.1526\n",
      "Epoch: 122/500... Training loss: 0.1262\n",
      "Epoch: 122/500... Training loss: 0.1899\n",
      "Epoch: 122/500... Training loss: 0.3879\n",
      "Epoch: 122/500... Training loss: 0.1902\n",
      "Epoch: 122/500... Training loss: 0.2925\n",
      "Epoch: 122/500... Training loss: 0.1976\n",
      "Epoch: 122/500... Training loss: 0.0794\n",
      "Epoch: 122/500... Training loss: 0.1031\n",
      "Epoch: 122/500... Training loss: 0.1662\n",
      "Epoch: 122/500... Training loss: 0.1957\n",
      "Epoch: 122/500... Training loss: 0.1629\n",
      "Epoch: 122/500... Training loss: 0.0857\n",
      "Epoch: 122/500... Training loss: 0.1800\n",
      "Epoch: 122/500... Training loss: 0.1778\n",
      "Epoch: 122/500... Training loss: 0.1649\n",
      "Epoch: 122/500... Training loss: 0.1806\n",
      "Epoch: 122/500... Training loss: 0.0985\n",
      "Epoch: 122/500... Training loss: 0.1431\n",
      "Epoch: 122/500... Training loss: 0.1417\n",
      "Epoch: 122/500... Training loss: 0.1163\n",
      "Epoch: 122/500... Training loss: 0.0499\n",
      "Epoch: 122/500... Training loss: 0.1331\n",
      "Epoch: 122/500... Training loss: 0.0715\n",
      "Epoch: 123/500... Training loss: 0.1241\n",
      "Epoch: 123/500... Training loss: 0.3863\n",
      "Epoch: 123/500... Training loss: 0.1501\n",
      "Epoch: 123/500... Training loss: 0.2701\n",
      "Epoch: 123/500... Training loss: 0.1990\n",
      "Epoch: 123/500... Training loss: 0.0616\n",
      "Epoch: 123/500... Training loss: 0.1130\n",
      "Epoch: 123/500... Training loss: 0.2363\n",
      "Epoch: 123/500... Training loss: 0.1544\n",
      "Epoch: 123/500... Training loss: 0.1194\n",
      "Epoch: 123/500... Training loss: 0.2141\n",
      "Epoch: 123/500... Training loss: 0.2729\n",
      "Epoch: 123/500... Training loss: 0.2141\n",
      "Epoch: 123/500... Training loss: 0.0774\n",
      "Epoch: 123/500... Training loss: 0.1255\n",
      "Epoch: 123/500... Training loss: 0.1496\n",
      "Epoch: 123/500... Training loss: 0.1035\n",
      "Epoch: 123/500... Training loss: 0.1161\n",
      "Epoch: 123/500... Training loss: 0.1866\n",
      "Epoch: 123/500... Training loss: 0.1348\n",
      "Epoch: 123/500... Training loss: 0.1121\n",
      "Epoch: 123/500... Training loss: 0.2452\n",
      "Epoch: 123/500... Training loss: 0.1869\n",
      "Epoch: 123/500... Training loss: 0.1893\n",
      "Epoch: 123/500... Training loss: 0.0875\n",
      "Epoch: 123/500... Training loss: 0.1233\n",
      "Epoch: 123/500... Training loss: 0.1053\n",
      "Epoch: 123/500... Training loss: 0.2351\n",
      "Epoch: 123/500... Training loss: 0.0976\n",
      "Epoch: 123/500... Training loss: 0.1116\n",
      "Epoch: 123/500... Training loss: 0.0886\n",
      "Epoch: 124/500... Training loss: 0.1668\n",
      "Epoch: 124/500... Training loss: 0.1908\n",
      "Epoch: 124/500... Training loss: 0.1186\n",
      "Epoch: 124/500... Training loss: 0.0896\n",
      "Epoch: 124/500... Training loss: 0.2597\n",
      "Epoch: 124/500... Training loss: 0.1494\n",
      "Epoch: 124/500... Training loss: 0.1379\n",
      "Epoch: 124/500... Training loss: 0.1347\n",
      "Epoch: 124/500... Training loss: 0.1747\n",
      "Epoch: 124/500... Training loss: 0.2118\n",
      "Epoch: 124/500... Training loss: 0.1745\n",
      "Epoch: 124/500... Training loss: 0.2709\n",
      "Epoch: 124/500... Training loss: 0.2573\n",
      "Epoch: 124/500... Training loss: 0.0937\n",
      "Epoch: 124/500... Training loss: 0.1361\n",
      "Epoch: 124/500... Training loss: 0.0799\n",
      "Epoch: 124/500... Training loss: 0.0894\n",
      "Epoch: 124/500... Training loss: 0.0781\n",
      "Epoch: 124/500... Training loss: 0.1169\n",
      "Epoch: 124/500... Training loss: 0.0778\n",
      "Epoch: 124/500... Training loss: 0.0613\n",
      "Epoch: 124/500... Training loss: 0.1322\n",
      "Epoch: 124/500... Training loss: 0.2608\n",
      "Epoch: 124/500... Training loss: 0.1302\n",
      "Epoch: 124/500... Training loss: 0.0910\n",
      "Epoch: 124/500... Training loss: 0.0824\n",
      "Epoch: 124/500... Training loss: 0.0574\n",
      "Epoch: 124/500... Training loss: 0.1352\n",
      "Epoch: 124/500... Training loss: 0.0716\n",
      "Epoch: 124/500... Training loss: 0.0928\n",
      "Epoch: 124/500... Training loss: 0.1825\n",
      "Epoch: 125/500... Training loss: 0.1468\n",
      "Epoch: 125/500... Training loss: 0.1673\n",
      "Epoch: 125/500... Training loss: 0.2041\n",
      "Epoch: 125/500... Training loss: 0.1293\n",
      "Epoch: 125/500... Training loss: 0.1110\n",
      "Epoch: 125/500... Training loss: 0.1451\n",
      "Epoch: 125/500... Training loss: 0.1424\n",
      "Epoch: 125/500... Training loss: 0.1589\n",
      "Epoch: 125/500... Training loss: 0.1311\n",
      "Epoch: 125/500... Training loss: 0.0678\n",
      "Epoch: 125/500... Training loss: 0.1396\n",
      "Epoch: 125/500... Training loss: 0.1963\n",
      "Epoch: 125/500... Training loss: 0.1417\n",
      "Epoch: 125/500... Training loss: 0.0491\n",
      "Epoch: 125/500... Training loss: 0.0803\n",
      "Epoch: 125/500... Training loss: 0.1630\n",
      "Epoch: 125/500... Training loss: 0.0834\n",
      "Epoch: 125/500... Training loss: 0.1290\n",
      "Epoch: 125/500... Training loss: 0.1138\n",
      "Epoch: 125/500... Training loss: 0.1095\n",
      "Epoch: 125/500... Training loss: 0.0834\n",
      "Epoch: 125/500... Training loss: 0.2019\n",
      "Epoch: 125/500... Training loss: 0.1258\n",
      "Epoch: 125/500... Training loss: 0.0832\n",
      "Epoch: 125/500... Training loss: 0.0821\n",
      "Epoch: 125/500... Training loss: 0.1738\n",
      "Epoch: 125/500... Training loss: 0.1073\n",
      "Epoch: 125/500... Training loss: 0.1179\n",
      "Epoch: 125/500... Training loss: 0.0608\n",
      "Epoch: 125/500... Training loss: 0.1020\n",
      "Epoch: 125/500... Training loss: 0.0876\n",
      "Epoch: 126/500... Training loss: 0.1133\n",
      "Epoch: 126/500... Training loss: 0.1677\n",
      "Epoch: 126/500... Training loss: 0.2016\n",
      "Epoch: 126/500... Training loss: 0.2063\n",
      "Epoch: 126/500... Training loss: 0.1028\n",
      "Epoch: 126/500... Training loss: 0.1785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126/500... Training loss: 0.1621\n",
      "Epoch: 126/500... Training loss: 0.1270\n",
      "Epoch: 126/500... Training loss: 0.1313\n",
      "Epoch: 126/500... Training loss: 0.1277\n",
      "Epoch: 126/500... Training loss: 0.1229\n",
      "Epoch: 126/500... Training loss: 0.2090\n",
      "Epoch: 126/500... Training loss: 0.2432\n",
      "Epoch: 126/500... Training loss: 0.1333\n",
      "Epoch: 126/500... Training loss: 0.1839\n",
      "Epoch: 126/500... Training loss: 0.0620\n",
      "Epoch: 126/500... Training loss: 0.1012\n",
      "Epoch: 126/500... Training loss: 0.1627\n",
      "Epoch: 126/500... Training loss: 0.1965\n",
      "Epoch: 126/500... Training loss: 0.0725\n",
      "Epoch: 126/500... Training loss: 0.1827\n",
      "Epoch: 126/500... Training loss: 0.1299\n",
      "Epoch: 126/500... Training loss: 0.1353\n",
      "Epoch: 126/500... Training loss: 0.1108\n",
      "Epoch: 126/500... Training loss: 0.0871\n",
      "Epoch: 126/500... Training loss: 0.2166\n",
      "Epoch: 126/500... Training loss: 0.0980\n",
      "Epoch: 126/500... Training loss: 0.0917\n",
      "Epoch: 126/500... Training loss: 0.0987\n",
      "Epoch: 126/500... Training loss: 0.0998\n",
      "Epoch: 126/500... Training loss: 0.0527\n",
      "Epoch: 127/500... Training loss: 0.2210\n",
      "Epoch: 127/500... Training loss: 0.1227\n",
      "Epoch: 127/500... Training loss: 0.1274\n",
      "Epoch: 127/500... Training loss: 0.2374\n",
      "Epoch: 127/500... Training loss: 0.0944\n",
      "Epoch: 127/500... Training loss: 0.1695\n",
      "Epoch: 127/500... Training loss: 0.1027\n",
      "Epoch: 127/500... Training loss: 0.2532\n",
      "Epoch: 127/500... Training loss: 0.1470\n",
      "Epoch: 127/500... Training loss: 0.1243\n",
      "Epoch: 127/500... Training loss: 0.2048\n",
      "Epoch: 127/500... Training loss: 0.1793\n",
      "Epoch: 127/500... Training loss: 0.0989\n",
      "Epoch: 127/500... Training loss: 0.0612\n",
      "Epoch: 127/500... Training loss: 0.0986\n",
      "Epoch: 127/500... Training loss: 0.0704\n",
      "Epoch: 127/500... Training loss: 0.1071\n",
      "Epoch: 127/500... Training loss: 0.0635\n",
      "Epoch: 127/500... Training loss: 0.1580\n",
      "Epoch: 127/500... Training loss: 0.1618\n",
      "Epoch: 127/500... Training loss: 0.1588\n",
      "Epoch: 127/500... Training loss: 0.1333\n",
      "Epoch: 127/500... Training loss: 0.1811\n",
      "Epoch: 127/500... Training loss: 0.1026\n",
      "Epoch: 127/500... Training loss: 0.1387\n",
      "Epoch: 127/500... Training loss: 0.2269\n",
      "Epoch: 127/500... Training loss: 0.1289\n",
      "Epoch: 127/500... Training loss: 0.0940\n",
      "Epoch: 127/500... Training loss: 0.0628\n",
      "Epoch: 127/500... Training loss: 0.0461\n",
      "Epoch: 127/500... Training loss: 0.0645\n",
      "Epoch: 128/500... Training loss: 0.2191\n",
      "Epoch: 128/500... Training loss: 0.2237\n",
      "Epoch: 128/500... Training loss: 0.1299\n",
      "Epoch: 128/500... Training loss: 0.1446\n",
      "Epoch: 128/500... Training loss: 0.1571\n",
      "Epoch: 128/500... Training loss: 0.2137\n",
      "Epoch: 128/500... Training loss: 0.1659\n",
      "Epoch: 128/500... Training loss: 0.1138\n",
      "Epoch: 128/500... Training loss: 0.1151\n",
      "Epoch: 128/500... Training loss: 0.1062\n",
      "Epoch: 128/500... Training loss: 0.1846\n",
      "Epoch: 128/500... Training loss: 0.2842\n",
      "Epoch: 128/500... Training loss: 0.1045\n",
      "Epoch: 128/500... Training loss: 0.1004\n",
      "Epoch: 128/500... Training loss: 0.0925\n",
      "Epoch: 128/500... Training loss: 0.1145\n",
      "Epoch: 128/500... Training loss: 0.1477\n",
      "Epoch: 128/500... Training loss: 0.1169\n",
      "Epoch: 128/500... Training loss: 0.3105\n",
      "Epoch: 128/500... Training loss: 0.1903\n",
      "Epoch: 128/500... Training loss: 0.1375\n",
      "Epoch: 128/500... Training loss: 0.0939\n",
      "Epoch: 128/500... Training loss: 0.1161\n",
      "Epoch: 128/500... Training loss: 0.0606\n",
      "Epoch: 128/500... Training loss: 0.1196\n",
      "Epoch: 128/500... Training loss: 0.1041\n",
      "Epoch: 128/500... Training loss: 0.0620\n",
      "Epoch: 128/500... Training loss: 0.1092\n",
      "Epoch: 128/500... Training loss: 0.0569\n",
      "Epoch: 128/500... Training loss: 0.0847\n",
      "Epoch: 128/500... Training loss: 0.1201\n",
      "Epoch: 129/500... Training loss: 0.1683\n",
      "Epoch: 129/500... Training loss: 0.0634\n",
      "Epoch: 129/500... Training loss: 0.0836\n",
      "Epoch: 129/500... Training loss: 0.1779\n",
      "Epoch: 129/500... Training loss: 0.1817\n",
      "Epoch: 129/500... Training loss: 0.1642\n",
      "Epoch: 129/500... Training loss: 0.0920\n",
      "Epoch: 129/500... Training loss: 0.1385\n",
      "Epoch: 129/500... Training loss: 0.1172\n",
      "Epoch: 129/500... Training loss: 0.1372\n",
      "Epoch: 129/500... Training loss: 0.3304\n",
      "Epoch: 129/500... Training loss: 0.2542\n",
      "Epoch: 129/500... Training loss: 0.1302\n",
      "Epoch: 129/500... Training loss: 0.1390\n",
      "Epoch: 129/500... Training loss: 0.0947\n",
      "Epoch: 129/500... Training loss: 0.0842\n",
      "Epoch: 129/500... Training loss: 0.1988\n",
      "Epoch: 129/500... Training loss: 0.1488\n",
      "Epoch: 129/500... Training loss: 0.1801\n",
      "Epoch: 129/500... Training loss: 0.1068\n",
      "Epoch: 129/500... Training loss: 0.1123\n",
      "Epoch: 129/500... Training loss: 0.0707\n",
      "Epoch: 129/500... Training loss: 0.1454\n",
      "Epoch: 129/500... Training loss: 0.1104\n",
      "Epoch: 129/500... Training loss: 0.1149\n",
      "Epoch: 129/500... Training loss: 0.0967\n",
      "Epoch: 129/500... Training loss: 0.1621\n",
      "Epoch: 129/500... Training loss: 0.1551\n",
      "Epoch: 129/500... Training loss: 0.0692\n",
      "Epoch: 129/500... Training loss: 0.1304\n",
      "Epoch: 129/500... Training loss: 0.0434\n",
      "Epoch: 130/500... Training loss: 0.1442\n",
      "Epoch: 130/500... Training loss: 0.0670\n",
      "Epoch: 130/500... Training loss: 0.1643\n",
      "Epoch: 130/500... Training loss: 0.1596\n",
      "Epoch: 130/500... Training loss: 0.1583\n",
      "Epoch: 130/500... Training loss: 0.1374\n",
      "Epoch: 130/500... Training loss: 0.1895\n",
      "Epoch: 130/500... Training loss: 0.1351\n",
      "Epoch: 130/500... Training loss: 0.2313\n",
      "Epoch: 130/500... Training loss: 0.1221\n",
      "Epoch: 130/500... Training loss: 0.1544\n",
      "Epoch: 130/500... Training loss: 0.1626\n",
      "Epoch: 130/500... Training loss: 0.0704\n",
      "Epoch: 130/500... Training loss: 0.1695\n",
      "Epoch: 130/500... Training loss: 0.2585\n",
      "Epoch: 130/500... Training loss: 0.0709\n",
      "Epoch: 130/500... Training loss: 0.1141\n",
      "Epoch: 130/500... Training loss: 0.0780\n",
      "Epoch: 130/500... Training loss: 0.1191\n",
      "Epoch: 130/500... Training loss: 0.0609\n",
      "Epoch: 130/500... Training loss: 0.0914\n",
      "Epoch: 130/500... Training loss: 0.0893\n",
      "Epoch: 130/500... Training loss: 0.0677\n",
      "Epoch: 130/500... Training loss: 0.0584\n",
      "Epoch: 130/500... Training loss: 0.1359\n",
      "Epoch: 130/500... Training loss: 0.0920\n",
      "Epoch: 130/500... Training loss: 0.0891\n",
      "Epoch: 130/500... Training loss: 0.0860\n",
      "Epoch: 130/500... Training loss: 0.1393\n",
      "Epoch: 130/500... Training loss: 0.1085\n",
      "Epoch: 130/500... Training loss: 0.1185\n",
      "Epoch: 131/500... Training loss: 0.1355\n",
      "Epoch: 131/500... Training loss: 0.1707\n",
      "Epoch: 131/500... Training loss: 0.1442\n",
      "Epoch: 131/500... Training loss: 0.1224\n",
      "Epoch: 131/500... Training loss: 0.0797\n",
      "Epoch: 131/500... Training loss: 0.1945\n",
      "Epoch: 131/500... Training loss: 0.1231\n",
      "Epoch: 131/500... Training loss: 0.0870\n",
      "Epoch: 131/500... Training loss: 0.1134\n",
      "Epoch: 131/500... Training loss: 0.0574\n",
      "Epoch: 131/500... Training loss: 0.2285\n",
      "Epoch: 131/500... Training loss: 0.1880\n",
      "Epoch: 131/500... Training loss: 0.2587\n",
      "Epoch: 131/500... Training loss: 0.1339\n",
      "Epoch: 131/500... Training loss: 0.1162\n",
      "Epoch: 131/500... Training loss: 0.0767\n",
      "Epoch: 131/500... Training loss: 0.1265\n",
      "Epoch: 131/500... Training loss: 0.2161\n",
      "Epoch: 131/500... Training loss: 0.1556\n",
      "Epoch: 131/500... Training loss: 0.0847\n",
      "Epoch: 131/500... Training loss: 0.0736\n",
      "Epoch: 131/500... Training loss: 0.0992\n",
      "Epoch: 131/500... Training loss: 0.1859\n",
      "Epoch: 131/500... Training loss: 0.0833\n",
      "Epoch: 131/500... Training loss: 0.1427\n",
      "Epoch: 131/500... Training loss: 0.1106\n",
      "Epoch: 131/500... Training loss: 0.1037\n",
      "Epoch: 131/500... Training loss: 0.1582\n",
      "Epoch: 131/500... Training loss: 0.1542\n",
      "Epoch: 131/500... Training loss: 0.1005\n",
      "Epoch: 131/500... Training loss: 0.1412\n",
      "Epoch: 132/500... Training loss: 0.1397\n",
      "Epoch: 132/500... Training loss: 0.1725\n",
      "Epoch: 132/500... Training loss: 0.1313\n",
      "Epoch: 132/500... Training loss: 0.1423\n",
      "Epoch: 132/500... Training loss: 0.1861\n",
      "Epoch: 132/500... Training loss: 0.2178\n",
      "Epoch: 132/500... Training loss: 0.1140\n",
      "Epoch: 132/500... Training loss: 0.1156\n",
      "Epoch: 132/500... Training loss: 0.1007\n",
      "Epoch: 132/500... Training loss: 0.1181\n",
      "Epoch: 132/500... Training loss: 0.2597\n",
      "Epoch: 132/500... Training loss: 0.1721\n",
      "Epoch: 132/500... Training loss: 0.2173\n",
      "Epoch: 132/500... Training loss: 0.0253\n",
      "Epoch: 132/500... Training loss: 0.1352\n",
      "Epoch: 132/500... Training loss: 0.0661\n",
      "Epoch: 132/500... Training loss: 0.0925\n",
      "Epoch: 132/500... Training loss: 0.1331\n",
      "Epoch: 132/500... Training loss: 0.2180\n",
      "Epoch: 132/500... Training loss: 0.0894\n",
      "Epoch: 132/500... Training loss: 0.1012\n",
      "Epoch: 132/500... Training loss: 0.1236\n",
      "Epoch: 132/500... Training loss: 0.0794\n",
      "Epoch: 132/500... Training loss: 0.1037\n",
      "Epoch: 132/500... Training loss: 0.3082\n",
      "Epoch: 132/500... Training loss: 0.0645\n",
      "Epoch: 132/500... Training loss: 0.1227\n",
      "Epoch: 132/500... Training loss: 0.0617\n",
      "Epoch: 132/500... Training loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132/500... Training loss: 0.0737\n",
      "Epoch: 132/500... Training loss: 0.0358\n",
      "Epoch: 133/500... Training loss: 0.1277\n",
      "Epoch: 133/500... Training loss: 0.1980\n",
      "Epoch: 133/500... Training loss: 0.2133\n",
      "Epoch: 133/500... Training loss: 0.1509\n",
      "Epoch: 133/500... Training loss: 0.2098\n",
      "Epoch: 133/500... Training loss: 0.1828\n",
      "Epoch: 133/500... Training loss: 0.1309\n",
      "Epoch: 133/500... Training loss: 0.1153\n",
      "Epoch: 133/500... Training loss: 0.1554\n",
      "Epoch: 133/500... Training loss: 0.2093\n",
      "Epoch: 133/500... Training loss: 0.1581\n",
      "Epoch: 133/500... Training loss: 0.1748\n",
      "Epoch: 133/500... Training loss: 0.1795\n",
      "Epoch: 133/500... Training loss: 0.3214\n",
      "Epoch: 133/500... Training loss: 0.0508\n",
      "Epoch: 133/500... Training loss: 0.0818\n",
      "Epoch: 133/500... Training loss: 0.0585\n",
      "Epoch: 133/500... Training loss: 0.2266\n",
      "Epoch: 133/500... Training loss: 0.1294\n",
      "Epoch: 133/500... Training loss: 0.0492\n",
      "Epoch: 133/500... Training loss: 0.0915\n",
      "Epoch: 133/500... Training loss: 0.1195\n",
      "Epoch: 133/500... Training loss: 0.1580\n",
      "Epoch: 133/500... Training loss: 0.0809\n",
      "Epoch: 133/500... Training loss: 0.0736\n",
      "Epoch: 133/500... Training loss: 0.1886\n",
      "Epoch: 133/500... Training loss: 0.1264\n",
      "Epoch: 133/500... Training loss: 0.1221\n",
      "Epoch: 133/500... Training loss: 0.0509\n",
      "Epoch: 133/500... Training loss: 0.1270\n",
      "Epoch: 133/500... Training loss: 0.0461\n",
      "Epoch: 134/500... Training loss: 0.1336\n",
      "Epoch: 134/500... Training loss: 0.2349\n",
      "Epoch: 134/500... Training loss: 0.3004\n",
      "Epoch: 134/500... Training loss: 0.2409\n",
      "Epoch: 134/500... Training loss: 0.1043\n",
      "Epoch: 134/500... Training loss: 0.0761\n",
      "Epoch: 134/500... Training loss: 0.1386\n",
      "Epoch: 134/500... Training loss: 0.1043\n",
      "Epoch: 134/500... Training loss: 0.0761\n",
      "Epoch: 134/500... Training loss: 0.1736\n",
      "Epoch: 134/500... Training loss: 0.2826\n",
      "Epoch: 134/500... Training loss: 0.2591\n",
      "Epoch: 134/500... Training loss: 0.2711\n",
      "Epoch: 134/500... Training loss: 0.0972\n",
      "Epoch: 134/500... Training loss: 0.0923\n",
      "Epoch: 134/500... Training loss: 0.1226\n",
      "Epoch: 134/500... Training loss: 0.0676\n",
      "Epoch: 134/500... Training loss: 0.1042\n",
      "Epoch: 134/500... Training loss: 0.2302\n",
      "Epoch: 134/500... Training loss: 0.1149\n",
      "Epoch: 134/500... Training loss: 0.0980\n",
      "Epoch: 134/500... Training loss: 0.1208\n",
      "Epoch: 134/500... Training loss: 0.0822\n",
      "Epoch: 134/500... Training loss: 0.1633\n",
      "Epoch: 134/500... Training loss: 0.1612\n",
      "Epoch: 134/500... Training loss: 0.1598\n",
      "Epoch: 134/500... Training loss: 0.1450\n",
      "Epoch: 134/500... Training loss: 0.1432\n",
      "Epoch: 134/500... Training loss: 0.1121\n",
      "Epoch: 134/500... Training loss: 0.1553\n",
      "Epoch: 134/500... Training loss: 0.1242\n",
      "Epoch: 135/500... Training loss: 0.1341\n",
      "Epoch: 135/500... Training loss: 0.1143\n",
      "Epoch: 135/500... Training loss: 0.1639\n",
      "Epoch: 135/500... Training loss: 0.1256\n",
      "Epoch: 135/500... Training loss: 0.0900\n",
      "Epoch: 135/500... Training loss: 0.1471\n",
      "Epoch: 135/500... Training loss: 0.1901\n",
      "Epoch: 135/500... Training loss: 0.1230\n",
      "Epoch: 135/500... Training loss: 0.1352\n",
      "Epoch: 135/500... Training loss: 0.1938\n",
      "Epoch: 135/500... Training loss: 0.2090\n",
      "Epoch: 135/500... Training loss: 0.1196\n",
      "Epoch: 135/500... Training loss: 0.1924\n",
      "Epoch: 135/500... Training loss: 0.0518\n",
      "Epoch: 135/500... Training loss: 0.1150\n",
      "Epoch: 135/500... Training loss: 0.0847\n",
      "Epoch: 135/500... Training loss: 0.0611\n",
      "Epoch: 135/500... Training loss: 0.2661\n",
      "Epoch: 135/500... Training loss: 0.0821\n",
      "Epoch: 135/500... Training loss: 0.0939\n",
      "Epoch: 135/500... Training loss: 0.1836\n",
      "Epoch: 135/500... Training loss: 0.1768\n",
      "Epoch: 135/500... Training loss: 0.1462\n",
      "Epoch: 135/500... Training loss: 0.1545\n",
      "Epoch: 135/500... Training loss: 0.0721\n",
      "Epoch: 135/500... Training loss: 0.1140\n",
      "Epoch: 135/500... Training loss: 0.0964\n",
      "Epoch: 135/500... Training loss: 0.1322\n",
      "Epoch: 135/500... Training loss: 0.0709\n",
      "Epoch: 135/500... Training loss: 0.1731\n",
      "Epoch: 135/500... Training loss: 0.0626\n",
      "Epoch: 136/500... Training loss: 0.2202\n",
      "Epoch: 136/500... Training loss: 0.0526\n",
      "Epoch: 136/500... Training loss: 0.1607\n",
      "Epoch: 136/500... Training loss: 0.2503\n",
      "Epoch: 136/500... Training loss: 0.1061\n",
      "Epoch: 136/500... Training loss: 0.0673\n",
      "Epoch: 136/500... Training loss: 0.1051\n",
      "Epoch: 136/500... Training loss: 0.1163\n",
      "Epoch: 136/500... Training loss: 0.1246\n",
      "Epoch: 136/500... Training loss: 0.1395\n",
      "Epoch: 136/500... Training loss: 0.1099\n",
      "Epoch: 136/500... Training loss: 0.2736\n",
      "Epoch: 136/500... Training loss: 0.2502\n",
      "Epoch: 136/500... Training loss: 0.2408\n",
      "Epoch: 136/500... Training loss: 0.1771\n",
      "Epoch: 136/500... Training loss: 0.1941\n",
      "Epoch: 136/500... Training loss: 0.0396\n",
      "Epoch: 136/500... Training loss: 0.1238\n",
      "Epoch: 136/500... Training loss: 0.1841\n",
      "Epoch: 136/500... Training loss: 0.1028\n",
      "Epoch: 136/500... Training loss: 0.0466\n",
      "Epoch: 136/500... Training loss: 0.1283\n",
      "Epoch: 136/500... Training loss: 0.1287\n",
      "Epoch: 136/500... Training loss: 0.1527\n",
      "Epoch: 136/500... Training loss: 0.0951\n",
      "Epoch: 136/500... Training loss: 0.1119\n",
      "Epoch: 136/500... Training loss: 0.0987\n",
      "Epoch: 136/500... Training loss: 0.2039\n",
      "Epoch: 136/500... Training loss: 0.0836\n",
      "Epoch: 136/500... Training loss: 0.0470\n",
      "Epoch: 136/500... Training loss: 0.1044\n",
      "Epoch: 137/500... Training loss: 0.0845\n",
      "Epoch: 137/500... Training loss: 0.2553\n",
      "Epoch: 137/500... Training loss: 0.0979\n",
      "Epoch: 137/500... Training loss: 0.0932\n",
      "Epoch: 137/500... Training loss: 0.0626\n",
      "Epoch: 137/500... Training loss: 0.1072\n",
      "Epoch: 137/500... Training loss: 0.1450\n",
      "Epoch: 137/500... Training loss: 0.1328\n",
      "Epoch: 137/500... Training loss: 0.0929\n",
      "Epoch: 137/500... Training loss: 0.0957\n",
      "Epoch: 137/500... Training loss: 0.0774\n",
      "Epoch: 137/500... Training loss: 0.1791\n",
      "Epoch: 137/500... Training loss: 0.1450\n",
      "Epoch: 137/500... Training loss: 0.2325\n",
      "Epoch: 137/500... Training loss: 0.1382\n",
      "Epoch: 137/500... Training loss: 0.1171\n",
      "Epoch: 137/500... Training loss: 0.0977\n",
      "Epoch: 137/500... Training loss: 0.1265\n",
      "Epoch: 137/500... Training loss: 0.1298\n",
      "Epoch: 137/500... Training loss: 0.1048\n",
      "Epoch: 137/500... Training loss: 0.1576\n",
      "Epoch: 137/500... Training loss: 0.1870\n",
      "Epoch: 137/500... Training loss: 0.1469\n",
      "Epoch: 137/500... Training loss: 0.0276\n",
      "Epoch: 137/500... Training loss: 0.0900\n",
      "Epoch: 137/500... Training loss: 0.1054\n",
      "Epoch: 137/500... Training loss: 0.0915\n",
      "Epoch: 137/500... Training loss: 0.0651\n",
      "Epoch: 137/500... Training loss: 0.1029\n",
      "Epoch: 137/500... Training loss: 0.1052\n",
      "Epoch: 137/500... Training loss: 0.0679\n",
      "Epoch: 138/500... Training loss: 0.2243\n",
      "Epoch: 138/500... Training loss: 0.1815\n",
      "Epoch: 138/500... Training loss: 0.1100\n",
      "Epoch: 138/500... Training loss: 0.3371\n",
      "Epoch: 138/500... Training loss: 0.1714\n",
      "Epoch: 138/500... Training loss: 0.0690\n",
      "Epoch: 138/500... Training loss: 0.2533\n",
      "Epoch: 138/500... Training loss: 0.0530\n",
      "Epoch: 138/500... Training loss: 0.0904\n",
      "Epoch: 138/500... Training loss: 0.1081\n",
      "Epoch: 138/500... Training loss: 0.2604\n",
      "Epoch: 138/500... Training loss: 0.2285\n",
      "Epoch: 138/500... Training loss: 0.1818\n",
      "Epoch: 138/500... Training loss: 0.1330\n",
      "Epoch: 138/500... Training loss: 0.1565\n",
      "Epoch: 138/500... Training loss: 0.1356\n",
      "Epoch: 138/500... Training loss: 0.0683\n",
      "Epoch: 138/500... Training loss: 0.1381\n",
      "Epoch: 138/500... Training loss: 0.1901\n",
      "Epoch: 138/500... Training loss: 0.1705\n",
      "Epoch: 138/500... Training loss: 0.0358\n",
      "Epoch: 138/500... Training loss: 0.1304\n",
      "Epoch: 138/500... Training loss: 0.1307\n",
      "Epoch: 138/500... Training loss: 0.0550\n",
      "Epoch: 138/500... Training loss: 0.0572\n",
      "Epoch: 138/500... Training loss: 0.1410\n",
      "Epoch: 138/500... Training loss: 0.0771\n",
      "Epoch: 138/500... Training loss: 0.1273\n",
      "Epoch: 138/500... Training loss: 0.0381\n",
      "Epoch: 138/500... Training loss: 0.1196\n",
      "Epoch: 138/500... Training loss: 0.1297\n",
      "Epoch: 139/500... Training loss: 0.1183\n",
      "Epoch: 139/500... Training loss: 0.1542\n",
      "Epoch: 139/500... Training loss: 0.1227\n",
      "Epoch: 139/500... Training loss: 0.1613\n",
      "Epoch: 139/500... Training loss: 0.1671\n",
      "Epoch: 139/500... Training loss: 0.1748\n",
      "Epoch: 139/500... Training loss: 0.1684\n",
      "Epoch: 139/500... Training loss: 0.1600\n",
      "Epoch: 139/500... Training loss: 0.1638\n",
      "Epoch: 139/500... Training loss: 0.0851\n",
      "Epoch: 139/500... Training loss: 0.2034\n",
      "Epoch: 139/500... Training loss: 0.1897\n",
      "Epoch: 139/500... Training loss: 0.1351\n",
      "Epoch: 139/500... Training loss: 0.0943\n",
      "Epoch: 139/500... Training loss: 0.0432\n",
      "Epoch: 139/500... Training loss: 0.0577\n",
      "Epoch: 139/500... Training loss: 0.0751\n",
      "Epoch: 139/500... Training loss: 0.1457\n",
      "Epoch: 139/500... Training loss: 0.0738\n",
      "Epoch: 139/500... Training loss: 0.0706\n",
      "Epoch: 139/500... Training loss: 0.1385\n",
      "Epoch: 139/500... Training loss: 0.1275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139/500... Training loss: 0.1677\n",
      "Epoch: 139/500... Training loss: 0.0950\n",
      "Epoch: 139/500... Training loss: 0.0653\n",
      "Epoch: 139/500... Training loss: 0.0380\n",
      "Epoch: 139/500... Training loss: 0.1807\n",
      "Epoch: 139/500... Training loss: 0.0691\n",
      "Epoch: 139/500... Training loss: 0.1061\n",
      "Epoch: 139/500... Training loss: 0.0504\n",
      "Epoch: 139/500... Training loss: 0.0704\n",
      "Epoch: 140/500... Training loss: 0.0655\n",
      "Epoch: 140/500... Training loss: 0.1158\n",
      "Epoch: 140/500... Training loss: 0.0896\n",
      "Epoch: 140/500... Training loss: 0.1877\n",
      "Epoch: 140/500... Training loss: 0.0523\n",
      "Epoch: 140/500... Training loss: 0.0808\n",
      "Epoch: 140/500... Training loss: 0.0868\n",
      "Epoch: 140/500... Training loss: 0.1002\n",
      "Epoch: 140/500... Training loss: 0.1171\n",
      "Epoch: 140/500... Training loss: 0.1981\n",
      "Epoch: 140/500... Training loss: 0.2124\n",
      "Epoch: 140/500... Training loss: 0.1671\n",
      "Epoch: 140/500... Training loss: 0.2176\n",
      "Epoch: 140/500... Training loss: 0.1160\n",
      "Epoch: 140/500... Training loss: 0.1178\n",
      "Epoch: 140/500... Training loss: 0.0822\n",
      "Epoch: 140/500... Training loss: 0.0950\n",
      "Epoch: 140/500... Training loss: 0.0748\n",
      "Epoch: 140/500... Training loss: 0.1787\n",
      "Epoch: 140/500... Training loss: 0.0705\n",
      "Epoch: 140/500... Training loss: 0.0650\n",
      "Epoch: 140/500... Training loss: 0.1185\n",
      "Epoch: 140/500... Training loss: 0.1273\n",
      "Epoch: 140/500... Training loss: 0.0794\n",
      "Epoch: 140/500... Training loss: 0.0438\n",
      "Epoch: 140/500... Training loss: 0.1166\n",
      "Epoch: 140/500... Training loss: 0.1145\n",
      "Epoch: 140/500... Training loss: 0.0354\n",
      "Epoch: 140/500... Training loss: 0.0414\n",
      "Epoch: 140/500... Training loss: 0.0890\n",
      "Epoch: 140/500... Training loss: 0.0896\n",
      "Epoch: 141/500... Training loss: 0.1132\n",
      "Epoch: 141/500... Training loss: 0.1299\n",
      "Epoch: 141/500... Training loss: 0.1081\n",
      "Epoch: 141/500... Training loss: 0.0824\n",
      "Epoch: 141/500... Training loss: 0.1776\n",
      "Epoch: 141/500... Training loss: 0.0945\n",
      "Epoch: 141/500... Training loss: 0.0942\n",
      "Epoch: 141/500... Training loss: 0.1059\n",
      "Epoch: 141/500... Training loss: 0.0276\n",
      "Epoch: 141/500... Training loss: 0.0714\n",
      "Epoch: 141/500... Training loss: 0.0935\n",
      "Epoch: 141/500... Training loss: 0.2652\n",
      "Epoch: 141/500... Training loss: 0.2046\n",
      "Epoch: 141/500... Training loss: 0.0688\n",
      "Epoch: 141/500... Training loss: 0.1413\n",
      "Epoch: 141/500... Training loss: 0.1000\n",
      "Epoch: 141/500... Training loss: 0.0678\n",
      "Epoch: 141/500... Training loss: 0.0518\n",
      "Epoch: 141/500... Training loss: 0.1161\n",
      "Epoch: 141/500... Training loss: 0.1389\n",
      "Epoch: 141/500... Training loss: 0.0967\n",
      "Epoch: 141/500... Training loss: 0.0843\n",
      "Epoch: 141/500... Training loss: 0.0885\n",
      "Epoch: 141/500... Training loss: 0.0783\n",
      "Epoch: 141/500... Training loss: 0.0688\n",
      "Epoch: 141/500... Training loss: 0.3204\n",
      "Epoch: 141/500... Training loss: 0.1105\n",
      "Epoch: 141/500... Training loss: 0.0588\n",
      "Epoch: 141/500... Training loss: 0.1012\n",
      "Epoch: 141/500... Training loss: 0.1123\n",
      "Epoch: 141/500... Training loss: 0.1499\n",
      "Epoch: 142/500... Training loss: 0.2148\n",
      "Epoch: 142/500... Training loss: 0.1280\n",
      "Epoch: 142/500... Training loss: 0.2098\n",
      "Epoch: 142/500... Training loss: 0.1366\n",
      "Epoch: 142/500... Training loss: 0.0730\n",
      "Epoch: 142/500... Training loss: 0.1091\n",
      "Epoch: 142/500... Training loss: 0.1391\n",
      "Epoch: 142/500... Training loss: 0.1160\n",
      "Epoch: 142/500... Training loss: 0.0582\n",
      "Epoch: 142/500... Training loss: 0.1068\n",
      "Epoch: 142/500... Training loss: 0.1183\n",
      "Epoch: 142/500... Training loss: 0.2228\n",
      "Epoch: 142/500... Training loss: 0.1166\n",
      "Epoch: 142/500... Training loss: 0.0623\n",
      "Epoch: 142/500... Training loss: 0.1279\n",
      "Epoch: 142/500... Training loss: 0.0650\n",
      "Epoch: 142/500... Training loss: 0.1114\n",
      "Epoch: 142/500... Training loss: 0.1581\n",
      "Epoch: 142/500... Training loss: 0.0867\n",
      "Epoch: 142/500... Training loss: 0.1044\n",
      "Epoch: 142/500... Training loss: 0.1095\n",
      "Epoch: 142/500... Training loss: 0.1298\n",
      "Epoch: 142/500... Training loss: 0.1434\n",
      "Epoch: 142/500... Training loss: 0.1473\n",
      "Epoch: 142/500... Training loss: 0.0904\n",
      "Epoch: 142/500... Training loss: 0.0645\n",
      "Epoch: 142/500... Training loss: 0.1491\n",
      "Epoch: 142/500... Training loss: 0.0474\n",
      "Epoch: 142/500... Training loss: 0.0541\n",
      "Epoch: 142/500... Training loss: 0.0811\n",
      "Epoch: 142/500... Training loss: 0.0837\n",
      "Epoch: 143/500... Training loss: 0.1203\n",
      "Epoch: 143/500... Training loss: 0.1566\n",
      "Epoch: 143/500... Training loss: 0.2481\n",
      "Epoch: 143/500... Training loss: 0.1293\n",
      "Epoch: 143/500... Training loss: 0.1521\n",
      "Epoch: 143/500... Training loss: 0.0756\n",
      "Epoch: 143/500... Training loss: 0.0659\n",
      "Epoch: 143/500... Training loss: 0.1366\n",
      "Epoch: 143/500... Training loss: 0.1650\n",
      "Epoch: 143/500... Training loss: 0.0919\n",
      "Epoch: 143/500... Training loss: 0.1912\n",
      "Epoch: 143/500... Training loss: 0.2434\n",
      "Epoch: 143/500... Training loss: 0.1502\n",
      "Epoch: 143/500... Training loss: 0.1485\n",
      "Epoch: 143/500... Training loss: 0.0819\n",
      "Epoch: 143/500... Training loss: 0.0902\n",
      "Epoch: 143/500... Training loss: 0.0460\n",
      "Epoch: 143/500... Training loss: 0.0833\n",
      "Epoch: 143/500... Training loss: 0.2241\n",
      "Epoch: 143/500... Training loss: 0.0381\n",
      "Epoch: 143/500... Training loss: 0.1076\n",
      "Epoch: 143/500... Training loss: 0.0427\n",
      "Epoch: 143/500... Training loss: 0.1009\n",
      "Epoch: 143/500... Training loss: 0.1504\n",
      "Epoch: 143/500... Training loss: 0.1013\n",
      "Epoch: 143/500... Training loss: 0.0537\n",
      "Epoch: 143/500... Training loss: 0.1370\n",
      "Epoch: 143/500... Training loss: 0.1059\n",
      "Epoch: 143/500... Training loss: 0.0835\n",
      "Epoch: 143/500... Training loss: 0.0428\n",
      "Epoch: 143/500... Training loss: 0.0740\n",
      "Epoch: 144/500... Training loss: 0.0273\n",
      "Epoch: 144/500... Training loss: 0.1232\n",
      "Epoch: 144/500... Training loss: 0.1383\n",
      "Epoch: 144/500... Training loss: 0.1095\n",
      "Epoch: 144/500... Training loss: 0.1160\n",
      "Epoch: 144/500... Training loss: 0.0867\n",
      "Epoch: 144/500... Training loss: 0.1222\n",
      "Epoch: 144/500... Training loss: 0.1274\n",
      "Epoch: 144/500... Training loss: 0.1471\n",
      "Epoch: 144/500... Training loss: 0.1044\n",
      "Epoch: 144/500... Training loss: 0.1171\n",
      "Epoch: 144/500... Training loss: 0.1902\n",
      "Epoch: 144/500... Training loss: 0.1044\n",
      "Epoch: 144/500... Training loss: 0.0736\n",
      "Epoch: 144/500... Training loss: 0.1039\n",
      "Epoch: 144/500... Training loss: 0.0454\n",
      "Epoch: 144/500... Training loss: 0.1019\n",
      "Epoch: 144/500... Training loss: 0.0653\n",
      "Epoch: 144/500... Training loss: 0.1705\n",
      "Epoch: 144/500... Training loss: 0.0595\n",
      "Epoch: 144/500... Training loss: 0.0892\n",
      "Epoch: 144/500... Training loss: 0.1687\n",
      "Epoch: 144/500... Training loss: 0.2300\n",
      "Epoch: 144/500... Training loss: 0.0725\n",
      "Epoch: 144/500... Training loss: 0.0343\n",
      "Epoch: 144/500... Training loss: 0.1258\n",
      "Epoch: 144/500... Training loss: 0.0329\n",
      "Epoch: 144/500... Training loss: 0.0531\n",
      "Epoch: 144/500... Training loss: 0.1605\n",
      "Epoch: 144/500... Training loss: 0.2064\n",
      "Epoch: 144/500... Training loss: 0.0827\n",
      "Epoch: 145/500... Training loss: 0.0540\n",
      "Epoch: 145/500... Training loss: 0.0665\n",
      "Epoch: 145/500... Training loss: 0.1990\n",
      "Epoch: 145/500... Training loss: 0.1113\n",
      "Epoch: 145/500... Training loss: 0.1597\n",
      "Epoch: 145/500... Training loss: 0.2416\n",
      "Epoch: 145/500... Training loss: 0.0832\n",
      "Epoch: 145/500... Training loss: 0.0929\n",
      "Epoch: 145/500... Training loss: 0.1213\n",
      "Epoch: 145/500... Training loss: 0.1273\n",
      "Epoch: 145/500... Training loss: 0.1542\n",
      "Epoch: 145/500... Training loss: 0.1325\n",
      "Epoch: 145/500... Training loss: 0.0986\n",
      "Epoch: 145/500... Training loss: 0.0838\n",
      "Epoch: 145/500... Training loss: 0.0914\n",
      "Epoch: 145/500... Training loss: 0.0626\n",
      "Epoch: 145/500... Training loss: 0.1178\n",
      "Epoch: 145/500... Training loss: 0.0408\n",
      "Epoch: 145/500... Training loss: 0.0660\n",
      "Epoch: 145/500... Training loss: 0.0980\n",
      "Epoch: 145/500... Training loss: 0.0789\n",
      "Epoch: 145/500... Training loss: 0.2372\n",
      "Epoch: 145/500... Training loss: 0.1021\n",
      "Epoch: 145/500... Training loss: 0.0694\n",
      "Epoch: 145/500... Training loss: 0.1259\n",
      "Epoch: 145/500... Training loss: 0.1046\n",
      "Epoch: 145/500... Training loss: 0.1709\n",
      "Epoch: 145/500... Training loss: 0.1284\n",
      "Epoch: 145/500... Training loss: 0.1668\n",
      "Epoch: 145/500... Training loss: 0.0478\n",
      "Epoch: 145/500... Training loss: 0.0421\n",
      "Epoch: 146/500... Training loss: 0.1485\n",
      "Epoch: 146/500... Training loss: 0.1946\n",
      "Epoch: 146/500... Training loss: 0.0982\n",
      "Epoch: 146/500... Training loss: 0.0603\n",
      "Epoch: 146/500... Training loss: 0.0944\n",
      "Epoch: 146/500... Training loss: 0.1667\n",
      "Epoch: 146/500... Training loss: 0.0672\n",
      "Epoch: 146/500... Training loss: 0.1042\n",
      "Epoch: 146/500... Training loss: 0.2107\n",
      "Epoch: 146/500... Training loss: 0.0668\n",
      "Epoch: 146/500... Training loss: 0.1442\n",
      "Epoch: 146/500... Training loss: 0.1828\n",
      "Epoch: 146/500... Training loss: 0.2387\n",
      "Epoch: 146/500... Training loss: 0.0615\n",
      "Epoch: 146/500... Training loss: 0.1110\n",
      "Epoch: 146/500... Training loss: 0.1563\n",
      "Epoch: 146/500... Training loss: 0.2580\n",
      "Epoch: 146/500... Training loss: 0.0507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146/500... Training loss: 0.1029\n",
      "Epoch: 146/500... Training loss: 0.0519\n",
      "Epoch: 146/500... Training loss: 0.1012\n",
      "Epoch: 146/500... Training loss: 0.1053\n",
      "Epoch: 146/500... Training loss: 0.2113\n",
      "Epoch: 146/500... Training loss: 0.0660\n",
      "Epoch: 146/500... Training loss: 0.0700\n",
      "Epoch: 146/500... Training loss: 0.1643\n",
      "Epoch: 146/500... Training loss: 0.1266\n",
      "Epoch: 146/500... Training loss: 0.0193\n",
      "Epoch: 146/500... Training loss: 0.1079\n",
      "Epoch: 146/500... Training loss: 0.1008\n",
      "Epoch: 146/500... Training loss: 0.0884\n",
      "Epoch: 147/500... Training loss: 0.0974\n",
      "Epoch: 147/500... Training loss: 0.1808\n",
      "Epoch: 147/500... Training loss: 0.1274\n",
      "Epoch: 147/500... Training loss: 0.0590\n",
      "Epoch: 147/500... Training loss: 0.1029\n",
      "Epoch: 147/500... Training loss: 0.0706\n",
      "Epoch: 147/500... Training loss: 0.0580\n",
      "Epoch: 147/500... Training loss: 0.1388\n",
      "Epoch: 147/500... Training loss: 0.0324\n",
      "Epoch: 147/500... Training loss: 0.1003\n",
      "Epoch: 147/500... Training loss: 0.0776\n",
      "Epoch: 147/500... Training loss: 0.1716\n",
      "Epoch: 147/500... Training loss: 0.2020\n",
      "Epoch: 147/500... Training loss: 0.0527\n",
      "Epoch: 147/500... Training loss: 0.0608\n",
      "Epoch: 147/500... Training loss: 0.1884\n",
      "Epoch: 147/500... Training loss: 0.0946\n",
      "Epoch: 147/500... Training loss: 0.0934\n",
      "Epoch: 147/500... Training loss: 0.1391\n",
      "Epoch: 147/500... Training loss: 0.2022\n",
      "Epoch: 147/500... Training loss: 0.0358\n",
      "Epoch: 147/500... Training loss: 0.2629\n",
      "Epoch: 147/500... Training loss: 0.0827\n",
      "Epoch: 147/500... Training loss: 0.1166\n",
      "Epoch: 147/500... Training loss: 0.0267\n",
      "Epoch: 147/500... Training loss: 0.0913\n",
      "Epoch: 147/500... Training loss: 0.0537\n",
      "Epoch: 147/500... Training loss: 0.0785\n",
      "Epoch: 147/500... Training loss: 0.0645\n",
      "Epoch: 147/500... Training loss: 0.0599\n",
      "Epoch: 147/500... Training loss: 0.0759\n",
      "Epoch: 148/500... Training loss: 0.1534\n",
      "Epoch: 148/500... Training loss: 0.0995\n",
      "Epoch: 148/500... Training loss: 0.1912\n",
      "Epoch: 148/500... Training loss: 0.1116\n",
      "Epoch: 148/500... Training loss: 0.0559\n",
      "Epoch: 148/500... Training loss: 0.1654\n",
      "Epoch: 148/500... Training loss: 0.0853\n",
      "Epoch: 148/500... Training loss: 0.0797\n",
      "Epoch: 148/500... Training loss: 0.0337\n",
      "Epoch: 148/500... Training loss: 0.1074\n",
      "Epoch: 148/500... Training loss: 0.1774\n",
      "Epoch: 148/500... Training loss: 0.1436\n",
      "Epoch: 148/500... Training loss: 0.2142\n",
      "Epoch: 148/500... Training loss: 0.2047\n",
      "Epoch: 148/500... Training loss: 0.1223\n",
      "Epoch: 148/500... Training loss: 0.0686\n",
      "Epoch: 148/500... Training loss: 0.2730\n",
      "Epoch: 148/500... Training loss: 0.1844\n",
      "Epoch: 148/500... Training loss: 0.1732\n",
      "Epoch: 148/500... Training loss: 0.0296\n",
      "Epoch: 148/500... Training loss: 0.0317\n",
      "Epoch: 148/500... Training loss: 0.0759\n",
      "Epoch: 148/500... Training loss: 0.0959\n",
      "Epoch: 148/500... Training loss: 0.0577\n",
      "Epoch: 148/500... Training loss: 0.0879\n",
      "Epoch: 148/500... Training loss: 0.0441\n",
      "Epoch: 148/500... Training loss: 0.1019\n",
      "Epoch: 148/500... Training loss: 0.0721\n",
      "Epoch: 148/500... Training loss: 0.0395\n",
      "Epoch: 148/500... Training loss: 0.0491\n",
      "Epoch: 148/500... Training loss: 0.0630\n",
      "Epoch: 149/500... Training loss: 0.1938\n",
      "Epoch: 149/500... Training loss: 0.0968\n",
      "Epoch: 149/500... Training loss: 0.1356\n",
      "Epoch: 149/500... Training loss: 0.0972\n",
      "Epoch: 149/500... Training loss: 0.1190\n",
      "Epoch: 149/500... Training loss: 0.1852\n",
      "Epoch: 149/500... Training loss: 0.0579\n",
      "Epoch: 149/500... Training loss: 0.1182\n",
      "Epoch: 149/500... Training loss: 0.0658\n",
      "Epoch: 149/500... Training loss: 0.0898\n",
      "Epoch: 149/500... Training loss: 0.0932\n",
      "Epoch: 149/500... Training loss: 0.1346\n",
      "Epoch: 149/500... Training loss: 0.0907\n",
      "Epoch: 149/500... Training loss: 0.0321\n",
      "Epoch: 149/500... Training loss: 0.0418\n",
      "Epoch: 149/500... Training loss: 0.0329\n",
      "Epoch: 149/500... Training loss: 0.0435\n",
      "Epoch: 149/500... Training loss: 0.1528\n",
      "Epoch: 149/500... Training loss: 0.0778\n",
      "Epoch: 149/500... Training loss: 0.0722\n",
      "Epoch: 149/500... Training loss: 0.1601\n",
      "Epoch: 149/500... Training loss: 0.0947\n",
      "Epoch: 149/500... Training loss: 0.0727\n",
      "Epoch: 149/500... Training loss: 0.1141\n",
      "Epoch: 149/500... Training loss: 0.0211\n",
      "Epoch: 149/500... Training loss: 0.0625\n",
      "Epoch: 149/500... Training loss: 0.0783\n",
      "Epoch: 149/500... Training loss: 0.0620\n",
      "Epoch: 149/500... Training loss: 0.0629\n",
      "Epoch: 149/500... Training loss: 0.0621\n",
      "Epoch: 149/500... Training loss: 0.0333\n",
      "Epoch: 150/500... Training loss: 0.1209\n",
      "Epoch: 150/500... Training loss: 0.0451\n",
      "Epoch: 150/500... Training loss: 0.0834\n",
      "Epoch: 150/500... Training loss: 0.0555\n",
      "Epoch: 150/500... Training loss: 0.1089\n",
      "Epoch: 150/500... Training loss: 0.1085\n",
      "Epoch: 150/500... Training loss: 0.1200\n",
      "Epoch: 150/500... Training loss: 0.1140\n",
      "Epoch: 150/500... Training loss: 0.0975\n",
      "Epoch: 150/500... Training loss: 0.0672\n",
      "Epoch: 150/500... Training loss: 0.0307\n",
      "Epoch: 150/500... Training loss: 0.1118\n",
      "Epoch: 150/500... Training loss: 0.1307\n",
      "Epoch: 150/500... Training loss: 0.0396\n",
      "Epoch: 150/500... Training loss: 0.0535\n",
      "Epoch: 150/500... Training loss: 0.0321\n",
      "Epoch: 150/500... Training loss: 0.1013\n",
      "Epoch: 150/500... Training loss: 0.1021\n",
      "Epoch: 150/500... Training loss: 0.1581\n",
      "Epoch: 150/500... Training loss: 0.0300\n",
      "Epoch: 150/500... Training loss: 0.1094\n",
      "Epoch: 150/500... Training loss: 0.0780\n",
      "Epoch: 150/500... Training loss: 0.1000\n",
      "Epoch: 150/500... Training loss: 0.0526\n",
      "Epoch: 150/500... Training loss: 0.1200\n",
      "Epoch: 150/500... Training loss: 0.0669\n",
      "Epoch: 150/500... Training loss: 0.0570\n",
      "Epoch: 150/500... Training loss: 0.0706\n",
      "Epoch: 150/500... Training loss: 0.0460\n",
      "Epoch: 150/500... Training loss: 0.1359\n",
      "Epoch: 150/500... Training loss: 0.0650\n",
      "Epoch: 151/500... Training loss: 0.1277\n",
      "Epoch: 151/500... Training loss: 0.1141\n",
      "Epoch: 151/500... Training loss: 0.1222\n",
      "Epoch: 151/500... Training loss: 0.1591\n",
      "Epoch: 151/500... Training loss: 0.1536\n",
      "Epoch: 151/500... Training loss: 0.0551\n",
      "Epoch: 151/500... Training loss: 0.0360\n",
      "Epoch: 151/500... Training loss: 0.0623\n",
      "Epoch: 151/500... Training loss: 0.0886\n",
      "Epoch: 151/500... Training loss: 0.0406\n",
      "Epoch: 151/500... Training loss: 0.2011\n",
      "Epoch: 151/500... Training loss: 0.1246\n",
      "Epoch: 151/500... Training loss: 0.2104\n",
      "Epoch: 151/500... Training loss: 0.0765\n",
      "Epoch: 151/500... Training loss: 0.1139\n",
      "Epoch: 151/500... Training loss: 0.1066\n",
      "Epoch: 151/500... Training loss: 0.0832\n",
      "Epoch: 151/500... Training loss: 0.1411\n",
      "Epoch: 151/500... Training loss: 0.1681\n",
      "Epoch: 151/500... Training loss: 0.0437\n",
      "Epoch: 151/500... Training loss: 0.0249\n",
      "Epoch: 151/500... Training loss: 0.1312\n",
      "Epoch: 151/500... Training loss: 0.0569\n",
      "Epoch: 151/500... Training loss: 0.1383\n",
      "Epoch: 151/500... Training loss: 0.1101\n",
      "Epoch: 151/500... Training loss: 0.0484\n",
      "Epoch: 151/500... Training loss: 0.0838\n",
      "Epoch: 151/500... Training loss: 0.1118\n",
      "Epoch: 151/500... Training loss: 0.0987\n",
      "Epoch: 151/500... Training loss: 0.0835\n",
      "Epoch: 151/500... Training loss: 0.0739\n",
      "Epoch: 152/500... Training loss: 0.1025\n",
      "Epoch: 152/500... Training loss: 0.1169\n",
      "Epoch: 152/500... Training loss: 0.1173\n",
      "Epoch: 152/500... Training loss: 0.1140\n",
      "Epoch: 152/500... Training loss: 0.2215\n",
      "Epoch: 152/500... Training loss: 0.0441\n",
      "Epoch: 152/500... Training loss: 0.0838\n",
      "Epoch: 152/500... Training loss: 0.1525\n",
      "Epoch: 152/500... Training loss: 0.1273\n",
      "Epoch: 152/500... Training loss: 0.1752\n",
      "Epoch: 152/500... Training loss: 0.1513\n",
      "Epoch: 152/500... Training loss: 0.1860\n",
      "Epoch: 152/500... Training loss: 0.1490\n",
      "Epoch: 152/500... Training loss: 0.0615\n",
      "Epoch: 152/500... Training loss: 0.2430\n",
      "Epoch: 152/500... Training loss: 0.0695\n",
      "Epoch: 152/500... Training loss: 0.1247\n",
      "Epoch: 152/500... Training loss: 0.0922\n",
      "Epoch: 152/500... Training loss: 0.2002\n",
      "Epoch: 152/500... Training loss: 0.1193\n",
      "Epoch: 152/500... Training loss: 0.0881\n",
      "Epoch: 152/500... Training loss: 0.1321\n",
      "Epoch: 152/500... Training loss: 0.0862\n",
      "Epoch: 152/500... Training loss: 0.1059\n",
      "Epoch: 152/500... Training loss: 0.0535\n",
      "Epoch: 152/500... Training loss: 0.0857\n",
      "Epoch: 152/500... Training loss: 0.0974\n",
      "Epoch: 152/500... Training loss: 0.2063\n",
      "Epoch: 152/500... Training loss: 0.0386\n",
      "Epoch: 152/500... Training loss: 0.0453\n",
      "Epoch: 152/500... Training loss: 0.0491\n",
      "Epoch: 153/500... Training loss: 0.1952\n",
      "Epoch: 153/500... Training loss: 0.0794\n",
      "Epoch: 153/500... Training loss: 0.1406\n",
      "Epoch: 153/500... Training loss: 0.1547\n",
      "Epoch: 153/500... Training loss: 0.0793\n",
      "Epoch: 153/500... Training loss: 0.1684\n",
      "Epoch: 153/500... Training loss: 0.0441\n",
      "Epoch: 153/500... Training loss: 0.0618\n",
      "Epoch: 153/500... Training loss: 0.1241\n",
      "Epoch: 153/500... Training loss: 0.1635\n",
      "Epoch: 153/500... Training loss: 0.1303\n",
      "Epoch: 153/500... Training loss: 0.0686\n",
      "Epoch: 153/500... Training loss: 0.1413\n",
      "Epoch: 153/500... Training loss: 0.0644\n",
      "Epoch: 153/500... Training loss: 0.0507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153/500... Training loss: 0.0444\n",
      "Epoch: 153/500... Training loss: 0.0581\n",
      "Epoch: 153/500... Training loss: 0.1490\n",
      "Epoch: 153/500... Training loss: 0.1049\n",
      "Epoch: 153/500... Training loss: 0.1223\n",
      "Epoch: 153/500... Training loss: 0.1907\n",
      "Epoch: 153/500... Training loss: 0.1738\n",
      "Epoch: 153/500... Training loss: 0.0656\n",
      "Epoch: 153/500... Training loss: 0.0773\n",
      "Epoch: 153/500... Training loss: 0.0387\n",
      "Epoch: 153/500... Training loss: 0.0460\n",
      "Epoch: 153/500... Training loss: 0.0635\n",
      "Epoch: 153/500... Training loss: 0.0905\n",
      "Epoch: 153/500... Training loss: 0.0249\n",
      "Epoch: 153/500... Training loss: 0.0968\n",
      "Epoch: 153/500... Training loss: 0.1080\n",
      "Epoch: 154/500... Training loss: 0.1060\n",
      "Epoch: 154/500... Training loss: 0.2125\n",
      "Epoch: 154/500... Training loss: 0.0922\n",
      "Epoch: 154/500... Training loss: 0.1164\n",
      "Epoch: 154/500... Training loss: 0.1044\n",
      "Epoch: 154/500... Training loss: 0.0822\n",
      "Epoch: 154/500... Training loss: 0.2049\n",
      "Epoch: 154/500... Training loss: 0.1973\n",
      "Epoch: 154/500... Training loss: 0.0547\n",
      "Epoch: 154/500... Training loss: 0.1175\n",
      "Epoch: 154/500... Training loss: 0.1848\n",
      "Epoch: 154/500... Training loss: 0.1803\n",
      "Epoch: 154/500... Training loss: 0.1743\n",
      "Epoch: 154/500... Training loss: 0.0259\n",
      "Epoch: 154/500... Training loss: 0.1481\n",
      "Epoch: 154/500... Training loss: 0.0413\n",
      "Epoch: 154/500... Training loss: 0.1192\n",
      "Epoch: 154/500... Training loss: 0.0495\n",
      "Epoch: 154/500... Training loss: 0.0990\n",
      "Epoch: 154/500... Training loss: 0.0429\n",
      "Epoch: 154/500... Training loss: 0.0590\n",
      "Epoch: 154/500... Training loss: 0.0428\n",
      "Epoch: 154/500... Training loss: 0.1232\n",
      "Epoch: 154/500... Training loss: 0.0861\n",
      "Epoch: 154/500... Training loss: 0.0557\n",
      "Epoch: 154/500... Training loss: 0.0528\n",
      "Epoch: 154/500... Training loss: 0.1019\n",
      "Epoch: 154/500... Training loss: 0.0915\n",
      "Epoch: 154/500... Training loss: 0.0627\n",
      "Epoch: 154/500... Training loss: 0.0727\n",
      "Epoch: 154/500... Training loss: 0.0477\n",
      "Epoch: 155/500... Training loss: 0.0504\n",
      "Epoch: 155/500... Training loss: 0.1783\n",
      "Epoch: 155/500... Training loss: 0.0933\n",
      "Epoch: 155/500... Training loss: 0.2136\n",
      "Epoch: 155/500... Training loss: 0.1012\n",
      "Epoch: 155/500... Training loss: 0.0857\n",
      "Epoch: 155/500... Training loss: 0.0601\n",
      "Epoch: 155/500... Training loss: 0.0757\n",
      "Epoch: 155/500... Training loss: 0.1276\n",
      "Epoch: 155/500... Training loss: 0.1069\n",
      "Epoch: 155/500... Training loss: 0.1605\n",
      "Epoch: 155/500... Training loss: 0.1361\n",
      "Epoch: 155/500... Training loss: 0.1190\n",
      "Epoch: 155/500... Training loss: 0.2838\n",
      "Epoch: 155/500... Training loss: 0.0672\n",
      "Epoch: 155/500... Training loss: 0.0683\n",
      "Epoch: 155/500... Training loss: 0.0406\n",
      "Epoch: 155/500... Training loss: 0.1025\n",
      "Epoch: 155/500... Training loss: 0.1148\n",
      "Epoch: 155/500... Training loss: 0.0426\n",
      "Epoch: 155/500... Training loss: 0.2157\n",
      "Epoch: 155/500... Training loss: 0.1441\n",
      "Epoch: 155/500... Training loss: 0.1000\n",
      "Epoch: 155/500... Training loss: 0.0613\n",
      "Epoch: 155/500... Training loss: 0.0647\n",
      "Epoch: 155/500... Training loss: 0.0693\n",
      "Epoch: 155/500... Training loss: 0.0763\n",
      "Epoch: 155/500... Training loss: 0.0925\n",
      "Epoch: 155/500... Training loss: 0.0148\n",
      "Epoch: 155/500... Training loss: 0.0783\n",
      "Epoch: 155/500... Training loss: 0.0364\n",
      "Epoch: 156/500... Training loss: 0.1031\n",
      "Epoch: 156/500... Training loss: 0.0544\n",
      "Epoch: 156/500... Training loss: 0.0473\n",
      "Epoch: 156/500... Training loss: 0.1167\n",
      "Epoch: 156/500... Training loss: 0.0742\n",
      "Epoch: 156/500... Training loss: 0.1393\n",
      "Epoch: 156/500... Training loss: 0.1384\n",
      "Epoch: 156/500... Training loss: 0.0813\n",
      "Epoch: 156/500... Training loss: 0.0740\n",
      "Epoch: 156/500... Training loss: 0.1012\n",
      "Epoch: 156/500... Training loss: 0.2519\n",
      "Epoch: 156/500... Training loss: 0.1858\n",
      "Epoch: 156/500... Training loss: 0.0962\n",
      "Epoch: 156/500... Training loss: 0.1315\n",
      "Epoch: 156/500... Training loss: 0.0685\n",
      "Epoch: 156/500... Training loss: 0.0612\n",
      "Epoch: 156/500... Training loss: 0.0524\n",
      "Epoch: 156/500... Training loss: 0.0546\n",
      "Epoch: 156/500... Training loss: 0.0339\n",
      "Epoch: 156/500... Training loss: 0.0176\n",
      "Epoch: 156/500... Training loss: 0.0549\n",
      "Epoch: 156/500... Training loss: 0.0540\n",
      "Epoch: 156/500... Training loss: 0.0783\n",
      "Epoch: 156/500... Training loss: 0.1693\n",
      "Epoch: 156/500... Training loss: 0.1265\n",
      "Epoch: 156/500... Training loss: 0.0627\n",
      "Epoch: 156/500... Training loss: 0.1314\n",
      "Epoch: 156/500... Training loss: 0.0911\n",
      "Epoch: 156/500... Training loss: 0.0689\n",
      "Epoch: 156/500... Training loss: 0.0461\n",
      "Epoch: 156/500... Training loss: 0.0722\n",
      "Epoch: 157/500... Training loss: 0.0382\n",
      "Epoch: 157/500... Training loss: 0.1365\n",
      "Epoch: 157/500... Training loss: 0.0530\n",
      "Epoch: 157/500... Training loss: 0.0970\n",
      "Epoch: 157/500... Training loss: 0.2802\n",
      "Epoch: 157/500... Training loss: 0.1601\n",
      "Epoch: 157/500... Training loss: 0.1078\n",
      "Epoch: 157/500... Training loss: 0.0984\n",
      "Epoch: 157/500... Training loss: 0.1243\n",
      "Epoch: 157/500... Training loss: 0.0896\n",
      "Epoch: 157/500... Training loss: 0.1353\n",
      "Epoch: 157/500... Training loss: 0.1773\n",
      "Epoch: 157/500... Training loss: 0.0693\n",
      "Epoch: 157/500... Training loss: 0.0447\n",
      "Epoch: 157/500... Training loss: 0.1636\n",
      "Epoch: 157/500... Training loss: 0.0343\n",
      "Epoch: 157/500... Training loss: 0.0365\n",
      "Epoch: 157/500... Training loss: 0.1538\n",
      "Epoch: 157/500... Training loss: 0.0480\n",
      "Epoch: 157/500... Training loss: 0.0592\n",
      "Epoch: 157/500... Training loss: 0.0404\n",
      "Epoch: 157/500... Training loss: 0.1213\n",
      "Epoch: 157/500... Training loss: 0.0644\n",
      "Epoch: 157/500... Training loss: 0.0738\n",
      "Epoch: 157/500... Training loss: 0.1379\n",
      "Epoch: 157/500... Training loss: 0.0433\n",
      "Epoch: 157/500... Training loss: 0.1250\n",
      "Epoch: 157/500... Training loss: 0.0553\n",
      "Epoch: 157/500... Training loss: 0.0400\n",
      "Epoch: 157/500... Training loss: 0.0252\n",
      "Epoch: 157/500... Training loss: 0.0355\n",
      "Epoch: 158/500... Training loss: 0.2485\n",
      "Epoch: 158/500... Training loss: 0.0566\n",
      "Epoch: 158/500... Training loss: 0.1006\n",
      "Epoch: 158/500... Training loss: 0.1075\n",
      "Epoch: 158/500... Training loss: 0.1290\n",
      "Epoch: 158/500... Training loss: 0.1478\n",
      "Epoch: 158/500... Training loss: 0.1453\n",
      "Epoch: 158/500... Training loss: 0.1013\n",
      "Epoch: 158/500... Training loss: 0.0429\n",
      "Epoch: 158/500... Training loss: 0.0994\n",
      "Epoch: 158/500... Training loss: 0.2469\n",
      "Epoch: 158/500... Training loss: 0.1344\n",
      "Epoch: 158/500... Training loss: 0.1776\n",
      "Epoch: 158/500... Training loss: 0.1092\n",
      "Epoch: 158/500... Training loss: 0.0708\n",
      "Epoch: 158/500... Training loss: 0.0810\n",
      "Epoch: 158/500... Training loss: 0.0402\n",
      "Epoch: 158/500... Training loss: 0.0570\n",
      "Epoch: 158/500... Training loss: 0.0786\n",
      "Epoch: 158/500... Training loss: 0.0587\n",
      "Epoch: 158/500... Training loss: 0.0406\n",
      "Epoch: 158/500... Training loss: 0.1763\n",
      "Epoch: 158/500... Training loss: 0.0399\n",
      "Epoch: 158/500... Training loss: 0.0724\n",
      "Epoch: 158/500... Training loss: 0.0366\n",
      "Epoch: 158/500... Training loss: 0.0290\n",
      "Epoch: 158/500... Training loss: 0.1053\n",
      "Epoch: 158/500... Training loss: 0.0557\n",
      "Epoch: 158/500... Training loss: 0.0466\n",
      "Epoch: 158/500... Training loss: 0.0770\n",
      "Epoch: 158/500... Training loss: 0.0182\n",
      "Epoch: 159/500... Training loss: 0.0315\n",
      "Epoch: 159/500... Training loss: 0.1084\n",
      "Epoch: 159/500... Training loss: 0.0729\n",
      "Epoch: 159/500... Training loss: 0.0661\n",
      "Epoch: 159/500... Training loss: 0.0486\n",
      "Epoch: 159/500... Training loss: 0.0684\n",
      "Epoch: 159/500... Training loss: 0.1322\n",
      "Epoch: 159/500... Training loss: 0.1642\n",
      "Epoch: 159/500... Training loss: 0.0942\n",
      "Epoch: 159/500... Training loss: 0.0375\n",
      "Epoch: 159/500... Training loss: 0.0939\n",
      "Epoch: 159/500... Training loss: 0.1017\n",
      "Epoch: 159/500... Training loss: 0.0980\n",
      "Epoch: 159/500... Training loss: 0.0951\n",
      "Epoch: 159/500... Training loss: 0.0611\n",
      "Epoch: 159/500... Training loss: 0.0396\n",
      "Epoch: 159/500... Training loss: 0.0915\n",
      "Epoch: 159/500... Training loss: 0.0223\n",
      "Epoch: 159/500... Training loss: 0.2003\n",
      "Epoch: 159/500... Training loss: 0.0315\n",
      "Epoch: 159/500... Training loss: 0.0828\n",
      "Epoch: 159/500... Training loss: 0.0891\n",
      "Epoch: 159/500... Training loss: 0.0740\n",
      "Epoch: 159/500... Training loss: 0.0451\n",
      "Epoch: 159/500... Training loss: 0.0472\n",
      "Epoch: 159/500... Training loss: 0.1224\n",
      "Epoch: 159/500... Training loss: 0.0317\n",
      "Epoch: 159/500... Training loss: 0.0432\n",
      "Epoch: 159/500... Training loss: 0.0180\n",
      "Epoch: 159/500... Training loss: 0.0261\n",
      "Epoch: 159/500... Training loss: 0.0460\n",
      "Epoch: 160/500... Training loss: 0.1072\n",
      "Epoch: 160/500... Training loss: 0.0435\n",
      "Epoch: 160/500... Training loss: 0.1045\n",
      "Epoch: 160/500... Training loss: 0.0536\n",
      "Epoch: 160/500... Training loss: 0.0879\n",
      "Epoch: 160/500... Training loss: 0.0585\n",
      "Epoch: 160/500... Training loss: 0.0687\n",
      "Epoch: 160/500... Training loss: 0.0874\n",
      "Epoch: 160/500... Training loss: 0.0985\n",
      "Epoch: 160/500... Training loss: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160/500... Training loss: 0.0586\n",
      "Epoch: 160/500... Training loss: 0.1672\n",
      "Epoch: 160/500... Training loss: 0.0495\n",
      "Epoch: 160/500... Training loss: 0.0581\n",
      "Epoch: 160/500... Training loss: 0.0931\n",
      "Epoch: 160/500... Training loss: 0.0638\n",
      "Epoch: 160/500... Training loss: 0.1384\n",
      "Epoch: 160/500... Training loss: 0.0476\n",
      "Epoch: 160/500... Training loss: 0.0814\n",
      "Epoch: 160/500... Training loss: 0.1152\n",
      "Epoch: 160/500... Training loss: 0.0485\n",
      "Epoch: 160/500... Training loss: 0.0732\n",
      "Epoch: 160/500... Training loss: 0.0325\n",
      "Epoch: 160/500... Training loss: 0.0584\n",
      "Epoch: 160/500... Training loss: 0.0414\n",
      "Epoch: 160/500... Training loss: 0.0770\n",
      "Epoch: 160/500... Training loss: 0.0517\n",
      "Epoch: 160/500... Training loss: 0.0951\n",
      "Epoch: 160/500... Training loss: 0.0598\n",
      "Epoch: 160/500... Training loss: 0.0862\n",
      "Epoch: 160/500... Training loss: 0.0521\n",
      "Epoch: 161/500... Training loss: 0.0317\n",
      "Epoch: 161/500... Training loss: 0.0710\n",
      "Epoch: 161/500... Training loss: 0.1220\n",
      "Epoch: 161/500... Training loss: 0.0767\n",
      "Epoch: 161/500... Training loss: 0.0390\n",
      "Epoch: 161/500... Training loss: 0.0927\n",
      "Epoch: 161/500... Training loss: 0.2165\n",
      "Epoch: 161/500... Training loss: 0.1140\n",
      "Epoch: 161/500... Training loss: 0.0666\n",
      "Epoch: 161/500... Training loss: 0.0905\n",
      "Epoch: 161/500... Training loss: 0.0745\n",
      "Epoch: 161/500... Training loss: 0.0691\n",
      "Epoch: 161/500... Training loss: 0.1556\n",
      "Epoch: 161/500... Training loss: 0.0911\n",
      "Epoch: 161/500... Training loss: 0.0470\n",
      "Epoch: 161/500... Training loss: 0.0503\n",
      "Epoch: 161/500... Training loss: 0.0724\n",
      "Epoch: 161/500... Training loss: 0.0681\n",
      "Epoch: 161/500... Training loss: 0.1250\n",
      "Epoch: 161/500... Training loss: 0.1316\n",
      "Epoch: 161/500... Training loss: 0.0617\n",
      "Epoch: 161/500... Training loss: 0.0903\n",
      "Epoch: 161/500... Training loss: 0.0259\n",
      "Epoch: 161/500... Training loss: 0.0899\n",
      "Epoch: 161/500... Training loss: 0.0917\n",
      "Epoch: 161/500... Training loss: 0.1082\n",
      "Epoch: 161/500... Training loss: 0.0906\n",
      "Epoch: 161/500... Training loss: 0.0501\n",
      "Epoch: 161/500... Training loss: 0.1767\n",
      "Epoch: 161/500... Training loss: 0.0505\n",
      "Epoch: 161/500... Training loss: 0.0419\n",
      "Epoch: 162/500... Training loss: 0.0471\n",
      "Epoch: 162/500... Training loss: 0.2172\n",
      "Epoch: 162/500... Training loss: 0.0494\n",
      "Epoch: 162/500... Training loss: 0.0815\n",
      "Epoch: 162/500... Training loss: 0.0970\n",
      "Epoch: 162/500... Training loss: 0.0602\n",
      "Epoch: 162/500... Training loss: 0.0669\n",
      "Epoch: 162/500... Training loss: 0.0650\n",
      "Epoch: 162/500... Training loss: 0.0728\n",
      "Epoch: 162/500... Training loss: 0.0539\n",
      "Epoch: 162/500... Training loss: 0.1769\n",
      "Epoch: 162/500... Training loss: 0.2006\n",
      "Epoch: 162/500... Training loss: 0.1075\n",
      "Epoch: 162/500... Training loss: 0.1160\n",
      "Epoch: 162/500... Training loss: 0.0369\n",
      "Epoch: 162/500... Training loss: 0.0396\n",
      "Epoch: 162/500... Training loss: 0.0582\n",
      "Epoch: 162/500... Training loss: 0.0683\n",
      "Epoch: 162/500... Training loss: 0.1283\n",
      "Epoch: 162/500... Training loss: 0.0275\n",
      "Epoch: 162/500... Training loss: 0.0635\n",
      "Epoch: 162/500... Training loss: 0.1782\n",
      "Epoch: 162/500... Training loss: 0.0687\n",
      "Epoch: 162/500... Training loss: 0.0825\n",
      "Epoch: 162/500... Training loss: 0.0311\n",
      "Epoch: 162/500... Training loss: 0.1827\n",
      "Epoch: 162/500... Training loss: 0.0606\n",
      "Epoch: 162/500... Training loss: 0.0598\n",
      "Epoch: 162/500... Training loss: 0.0915\n",
      "Epoch: 162/500... Training loss: 0.0649\n",
      "Epoch: 162/500... Training loss: 0.1366\n",
      "Epoch: 163/500... Training loss: 0.0637\n",
      "Epoch: 163/500... Training loss: 0.1602\n",
      "Epoch: 163/500... Training loss: 0.0664\n",
      "Epoch: 163/500... Training loss: 0.1215\n",
      "Epoch: 163/500... Training loss: 0.0568\n",
      "Epoch: 163/500... Training loss: 0.0789\n",
      "Epoch: 163/500... Training loss: 0.0646\n",
      "Epoch: 163/500... Training loss: 0.0623\n",
      "Epoch: 163/500... Training loss: 0.0438\n",
      "Epoch: 163/500... Training loss: 0.0532\n",
      "Epoch: 163/500... Training loss: 0.1247\n",
      "Epoch: 163/500... Training loss: 0.1271\n",
      "Epoch: 163/500... Training loss: 0.1554\n",
      "Epoch: 163/500... Training loss: 0.0562\n",
      "Epoch: 163/500... Training loss: 0.0398\n",
      "Epoch: 163/500... Training loss: 0.0251\n",
      "Epoch: 163/500... Training loss: 0.0963\n",
      "Epoch: 163/500... Training loss: 0.1215\n",
      "Epoch: 163/500... Training loss: 0.0732\n",
      "Epoch: 163/500... Training loss: 0.0455\n",
      "Epoch: 163/500... Training loss: 0.1057\n",
      "Epoch: 163/500... Training loss: 0.0978\n",
      "Epoch: 163/500... Training loss: 0.1921\n",
      "Epoch: 163/500... Training loss: 0.0665\n",
      "Epoch: 163/500... Training loss: 0.0861\n",
      "Epoch: 163/500... Training loss: 0.0583\n",
      "Epoch: 163/500... Training loss: 0.1182\n",
      "Epoch: 163/500... Training loss: 0.0833\n",
      "Epoch: 163/500... Training loss: 0.0814\n",
      "Epoch: 163/500... Training loss: 0.0702\n",
      "Epoch: 163/500... Training loss: 0.0197\n",
      "Epoch: 164/500... Training loss: 0.0531\n",
      "Epoch: 164/500... Training loss: 0.0566\n",
      "Epoch: 164/500... Training loss: 0.0779\n",
      "Epoch: 164/500... Training loss: 0.1225\n",
      "Epoch: 164/500... Training loss: 0.1134\n",
      "Epoch: 164/500... Training loss: 0.0798\n",
      "Epoch: 164/500... Training loss: 0.0658\n",
      "Epoch: 164/500... Training loss: 0.0537\n",
      "Epoch: 164/500... Training loss: 0.0907\n",
      "Epoch: 164/500... Training loss: 0.0780\n",
      "Epoch: 164/500... Training loss: 0.1370\n",
      "Epoch: 164/500... Training loss: 0.1949\n",
      "Epoch: 164/500... Training loss: 0.1007\n",
      "Epoch: 164/500... Training loss: 0.0470\n",
      "Epoch: 164/500... Training loss: 0.0873\n",
      "Epoch: 164/500... Training loss: 0.0476\n",
      "Epoch: 164/500... Training loss: 0.1718\n",
      "Epoch: 164/500... Training loss: 0.0601\n",
      "Epoch: 164/500... Training loss: 0.1197\n",
      "Epoch: 164/500... Training loss: 0.0330\n",
      "Epoch: 164/500... Training loss: 0.0444\n",
      "Epoch: 164/500... Training loss: 0.1720\n",
      "Epoch: 164/500... Training loss: 0.0530\n",
      "Epoch: 164/500... Training loss: 0.1110\n",
      "Epoch: 164/500... Training loss: 0.0252\n",
      "Epoch: 164/500... Training loss: 0.0645\n",
      "Epoch: 164/500... Training loss: 0.0471\n",
      "Epoch: 164/500... Training loss: 0.1258\n",
      "Epoch: 164/500... Training loss: 0.0402\n",
      "Epoch: 164/500... Training loss: 0.1280\n",
      "Epoch: 164/500... Training loss: 0.0585\n",
      "Epoch: 165/500... Training loss: 0.1032\n",
      "Epoch: 165/500... Training loss: 0.0701\n",
      "Epoch: 165/500... Training loss: 0.0419\n",
      "Epoch: 165/500... Training loss: 0.0659\n",
      "Epoch: 165/500... Training loss: 0.1234\n",
      "Epoch: 165/500... Training loss: 0.1143\n",
      "Epoch: 165/500... Training loss: 0.0312\n",
      "Epoch: 165/500... Training loss: 0.1259\n",
      "Epoch: 165/500... Training loss: 0.0960\n",
      "Epoch: 165/500... Training loss: 0.0803\n",
      "Epoch: 165/500... Training loss: 0.1637\n",
      "Epoch: 165/500... Training loss: 0.0807\n",
      "Epoch: 165/500... Training loss: 0.0762\n",
      "Epoch: 165/500... Training loss: 0.0826\n",
      "Epoch: 165/500... Training loss: 0.0435\n",
      "Epoch: 165/500... Training loss: 0.1308\n",
      "Epoch: 165/500... Training loss: 0.0463\n",
      "Epoch: 165/500... Training loss: 0.0877\n",
      "Epoch: 165/500... Training loss: 0.0696\n",
      "Epoch: 165/500... Training loss: 0.0986\n",
      "Epoch: 165/500... Training loss: 0.0396\n",
      "Epoch: 165/500... Training loss: 0.0193\n",
      "Epoch: 165/500... Training loss: 0.0464\n",
      "Epoch: 165/500... Training loss: 0.0849\n",
      "Epoch: 165/500... Training loss: 0.0312\n",
      "Epoch: 165/500... Training loss: 0.0210\n",
      "Epoch: 165/500... Training loss: 0.0520\n",
      "Epoch: 165/500... Training loss: 0.0778\n",
      "Epoch: 165/500... Training loss: 0.1229\n",
      "Epoch: 165/500... Training loss: 0.0610\n",
      "Epoch: 165/500... Training loss: 0.0822\n",
      "Epoch: 166/500... Training loss: 0.0848\n",
      "Epoch: 166/500... Training loss: 0.1193\n",
      "Epoch: 166/500... Training loss: 0.0534\n",
      "Epoch: 166/500... Training loss: 0.0466\n",
      "Epoch: 166/500... Training loss: 0.0748\n",
      "Epoch: 166/500... Training loss: 0.2019\n",
      "Epoch: 166/500... Training loss: 0.0973\n",
      "Epoch: 166/500... Training loss: 0.0696\n",
      "Epoch: 166/500... Training loss: 0.0496\n",
      "Epoch: 166/500... Training loss: 0.1090\n",
      "Epoch: 166/500... Training loss: 0.0616\n",
      "Epoch: 166/500... Training loss: 0.0965\n",
      "Epoch: 166/500... Training loss: 0.2123\n",
      "Epoch: 166/500... Training loss: 0.0521\n",
      "Epoch: 166/500... Training loss: 0.0310\n",
      "Epoch: 166/500... Training loss: 0.0797\n",
      "Epoch: 166/500... Training loss: 0.0866\n",
      "Epoch: 166/500... Training loss: 0.1477\n",
      "Epoch: 166/500... Training loss: 0.1050\n",
      "Epoch: 166/500... Training loss: 0.0959\n",
      "Epoch: 166/500... Training loss: 0.0322\n",
      "Epoch: 166/500... Training loss: 0.0221\n",
      "Epoch: 166/500... Training loss: 0.1053\n",
      "Epoch: 166/500... Training loss: 0.1036\n",
      "Epoch: 166/500... Training loss: 0.0773\n",
      "Epoch: 166/500... Training loss: 0.0723\n",
      "Epoch: 166/500... Training loss: 0.0578\n",
      "Epoch: 166/500... Training loss: 0.1742\n",
      "Epoch: 166/500... Training loss: 0.0665\n",
      "Epoch: 166/500... Training loss: 0.1070\n",
      "Epoch: 166/500... Training loss: 0.0526\n",
      "Epoch: 167/500... Training loss: 0.1247\n",
      "Epoch: 167/500... Training loss: 0.0767\n",
      "Epoch: 167/500... Training loss: 0.0402\n",
      "Epoch: 167/500... Training loss: 0.1494\n",
      "Epoch: 167/500... Training loss: 0.0498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167/500... Training loss: 0.0858\n",
      "Epoch: 167/500... Training loss: 0.0735\n",
      "Epoch: 167/500... Training loss: 0.0889\n",
      "Epoch: 167/500... Training loss: 0.0941\n",
      "Epoch: 167/500... Training loss: 0.0737\n",
      "Epoch: 167/500... Training loss: 0.0999\n",
      "Epoch: 167/500... Training loss: 0.0847\n",
      "Epoch: 167/500... Training loss: 0.1354\n",
      "Epoch: 167/500... Training loss: 0.0685\n",
      "Epoch: 167/500... Training loss: 0.1035\n",
      "Epoch: 167/500... Training loss: 0.1600\n",
      "Epoch: 167/500... Training loss: 0.0480\n",
      "Epoch: 167/500... Training loss: 0.0979\n",
      "Epoch: 167/500... Training loss: 0.0462\n",
      "Epoch: 167/500... Training loss: 0.0445\n",
      "Epoch: 167/500... Training loss: 0.0863\n",
      "Epoch: 167/500... Training loss: 0.1269\n",
      "Epoch: 167/500... Training loss: 0.0414\n",
      "Epoch: 167/500... Training loss: 0.0311\n",
      "Epoch: 167/500... Training loss: 0.0901\n",
      "Epoch: 167/500... Training loss: 0.0377\n",
      "Epoch: 167/500... Training loss: 0.0432\n",
      "Epoch: 167/500... Training loss: 0.1832\n",
      "Epoch: 167/500... Training loss: 0.0373\n",
      "Epoch: 167/500... Training loss: 0.1268\n",
      "Epoch: 167/500... Training loss: 0.0250\n",
      "Epoch: 168/500... Training loss: 0.0801\n",
      "Epoch: 168/500... Training loss: 0.0664\n",
      "Epoch: 168/500... Training loss: 0.2246\n",
      "Epoch: 168/500... Training loss: 0.0851\n",
      "Epoch: 168/500... Training loss: 0.0428\n",
      "Epoch: 168/500... Training loss: 0.0833\n",
      "Epoch: 168/500... Training loss: 0.0449\n",
      "Epoch: 168/500... Training loss: 0.0318\n",
      "Epoch: 168/500... Training loss: 0.0507\n",
      "Epoch: 168/500... Training loss: 0.0858\n",
      "Epoch: 168/500... Training loss: 0.1235\n",
      "Epoch: 168/500... Training loss: 0.2189\n",
      "Epoch: 168/500... Training loss: 0.1164\n",
      "Epoch: 168/500... Training loss: 0.0450\n",
      "Epoch: 168/500... Training loss: 0.0724\n",
      "Epoch: 168/500... Training loss: 0.0601\n",
      "Epoch: 168/500... Training loss: 0.0985\n",
      "Epoch: 168/500... Training loss: 0.0631\n",
      "Epoch: 168/500... Training loss: 0.0430\n",
      "Epoch: 168/500... Training loss: 0.1095\n",
      "Epoch: 168/500... Training loss: 0.0978\n",
      "Epoch: 168/500... Training loss: 0.1027\n",
      "Epoch: 168/500... Training loss: 0.0566\n",
      "Epoch: 168/500... Training loss: 0.0557\n",
      "Epoch: 168/500... Training loss: 0.0321\n",
      "Epoch: 168/500... Training loss: 0.0822\n",
      "Epoch: 168/500... Training loss: 0.0447\n",
      "Epoch: 168/500... Training loss: 0.0389\n",
      "Epoch: 168/500... Training loss: 0.0609\n",
      "Epoch: 168/500... Training loss: 0.0283\n",
      "Epoch: 168/500... Training loss: 0.0290\n",
      "Epoch: 169/500... Training loss: 0.1864\n",
      "Epoch: 169/500... Training loss: 0.1267\n",
      "Epoch: 169/500... Training loss: 0.0687\n",
      "Epoch: 169/500... Training loss: 0.0576\n",
      "Epoch: 169/500... Training loss: 0.0664\n",
      "Epoch: 169/500... Training loss: 0.0221\n",
      "Epoch: 169/500... Training loss: 0.0547\n",
      "Epoch: 169/500... Training loss: 0.1017\n",
      "Epoch: 169/500... Training loss: 0.0183\n",
      "Epoch: 169/500... Training loss: 0.0262\n",
      "Epoch: 169/500... Training loss: 0.0965\n",
      "Epoch: 169/500... Training loss: 0.0659\n",
      "Epoch: 169/500... Training loss: 0.2163\n",
      "Epoch: 169/500... Training loss: 0.0273\n",
      "Epoch: 169/500... Training loss: 0.0730\n",
      "Epoch: 169/500... Training loss: 0.0692\n",
      "Epoch: 169/500... Training loss: 0.0588\n",
      "Epoch: 169/500... Training loss: 0.0802\n",
      "Epoch: 169/500... Training loss: 0.0736\n",
      "Epoch: 169/500... Training loss: 0.0517\n",
      "Epoch: 169/500... Training loss: 0.0609\n",
      "Epoch: 169/500... Training loss: 0.0817\n",
      "Epoch: 169/500... Training loss: 0.0475\n",
      "Epoch: 169/500... Training loss: 0.0627\n",
      "Epoch: 169/500... Training loss: 0.0512\n",
      "Epoch: 169/500... Training loss: 0.0352\n",
      "Epoch: 169/500... Training loss: 0.0440\n",
      "Epoch: 169/500... Training loss: 0.0308\n",
      "Epoch: 169/500... Training loss: 0.1077\n",
      "Epoch: 169/500... Training loss: 0.0968\n",
      "Epoch: 169/500... Training loss: 0.0368\n",
      "Epoch: 170/500... Training loss: 0.0843\n",
      "Epoch: 170/500... Training loss: 0.0496\n",
      "Epoch: 170/500... Training loss: 0.1276\n",
      "Epoch: 170/500... Training loss: 0.0720\n",
      "Epoch: 170/500... Training loss: 0.2493\n",
      "Epoch: 170/500... Training loss: 0.1092\n",
      "Epoch: 170/500... Training loss: 0.0729\n",
      "Epoch: 170/500... Training loss: 0.0555\n",
      "Epoch: 170/500... Training loss: 0.1143\n",
      "Epoch: 170/500... Training loss: 0.0441\n",
      "Epoch: 170/500... Training loss: 0.1146\n",
      "Epoch: 170/500... Training loss: 0.1553\n",
      "Epoch: 170/500... Training loss: 0.0862\n",
      "Epoch: 170/500... Training loss: 0.1961\n",
      "Epoch: 170/500... Training loss: 0.1044\n",
      "Epoch: 170/500... Training loss: 0.1269\n",
      "Epoch: 170/500... Training loss: 0.0363\n",
      "Epoch: 170/500... Training loss: 0.1987\n",
      "Epoch: 170/500... Training loss: 0.0607\n",
      "Epoch: 170/500... Training loss: 0.0909\n",
      "Epoch: 170/500... Training loss: 0.1684\n",
      "Epoch: 170/500... Training loss: 0.0878\n",
      "Epoch: 170/500... Training loss: 0.0336\n",
      "Epoch: 170/500... Training loss: 0.0175\n",
      "Epoch: 170/500... Training loss: 0.0487\n",
      "Epoch: 170/500... Training loss: 0.0233\n",
      "Epoch: 170/500... Training loss: 0.0317\n",
      "Epoch: 170/500... Training loss: 0.0768\n",
      "Epoch: 170/500... Training loss: 0.1124\n",
      "Epoch: 170/500... Training loss: 0.0443\n",
      "Epoch: 170/500... Training loss: 0.0504\n",
      "Epoch: 171/500... Training loss: 0.0842\n",
      "Epoch: 171/500... Training loss: 0.0598\n",
      "Epoch: 171/500... Training loss: 0.0663\n",
      "Epoch: 171/500... Training loss: 0.0423\n",
      "Epoch: 171/500... Training loss: 0.1124\n",
      "Epoch: 171/500... Training loss: 0.0405\n",
      "Epoch: 171/500... Training loss: 0.0316\n",
      "Epoch: 171/500... Training loss: 0.1085\n",
      "Epoch: 171/500... Training loss: 0.0757\n",
      "Epoch: 171/500... Training loss: 0.0319\n",
      "Epoch: 171/500... Training loss: 0.2345\n",
      "Epoch: 171/500... Training loss: 0.1361\n",
      "Epoch: 171/500... Training loss: 0.1998\n",
      "Epoch: 171/500... Training loss: 0.0924\n",
      "Epoch: 171/500... Training loss: 0.0926\n",
      "Epoch: 171/500... Training loss: 0.0225\n",
      "Epoch: 171/500... Training loss: 0.0313\n",
      "Epoch: 171/500... Training loss: 0.0266\n",
      "Epoch: 171/500... Training loss: 0.0828\n",
      "Epoch: 171/500... Training loss: 0.1131\n",
      "Epoch: 171/500... Training loss: 0.0281\n",
      "Epoch: 171/500... Training loss: 0.0582\n",
      "Epoch: 171/500... Training loss: 0.0646\n",
      "Epoch: 171/500... Training loss: 0.1743\n",
      "Epoch: 171/500... Training loss: 0.0943\n",
      "Epoch: 171/500... Training loss: 0.1106\n",
      "Epoch: 171/500... Training loss: 0.0385\n",
      "Epoch: 171/500... Training loss: 0.0414\n",
      "Epoch: 171/500... Training loss: 0.0790\n",
      "Epoch: 171/500... Training loss: 0.0705\n",
      "Epoch: 171/500... Training loss: 0.0639\n",
      "Epoch: 172/500... Training loss: 0.0371\n",
      "Epoch: 172/500... Training loss: 0.0457\n",
      "Epoch: 172/500... Training loss: 0.0559\n",
      "Epoch: 172/500... Training loss: 0.0971\n",
      "Epoch: 172/500... Training loss: 0.1486\n",
      "Epoch: 172/500... Training loss: 0.0416\n",
      "Epoch: 172/500... Training loss: 0.1133\n",
      "Epoch: 172/500... Training loss: 0.0354\n",
      "Epoch: 172/500... Training loss: 0.0351\n",
      "Epoch: 172/500... Training loss: 0.1495\n",
      "Epoch: 172/500... Training loss: 0.1618\n",
      "Epoch: 172/500... Training loss: 0.1005\n",
      "Epoch: 172/500... Training loss: 0.1196\n",
      "Epoch: 172/500... Training loss: 0.0909\n",
      "Epoch: 172/500... Training loss: 0.0610\n",
      "Epoch: 172/500... Training loss: 0.0322\n",
      "Epoch: 172/500... Training loss: 0.0598\n",
      "Epoch: 172/500... Training loss: 0.0799\n",
      "Epoch: 172/500... Training loss: 0.2230\n",
      "Epoch: 172/500... Training loss: 0.0905\n",
      "Epoch: 172/500... Training loss: 0.0856\n",
      "Epoch: 172/500... Training loss: 0.0856\n",
      "Epoch: 172/500... Training loss: 0.0780\n",
      "Epoch: 172/500... Training loss: 0.0433\n",
      "Epoch: 172/500... Training loss: 0.1110\n",
      "Epoch: 172/500... Training loss: 0.0738\n",
      "Epoch: 172/500... Training loss: 0.0894\n",
      "Epoch: 172/500... Training loss: 0.0560\n",
      "Epoch: 172/500... Training loss: 0.1910\n",
      "Epoch: 172/500... Training loss: 0.0194\n",
      "Epoch: 172/500... Training loss: 0.0735\n",
      "Epoch: 173/500... Training loss: 0.0781\n",
      "Epoch: 173/500... Training loss: 0.0590\n",
      "Epoch: 173/500... Training loss: 0.0646\n",
      "Epoch: 173/500... Training loss: 0.1291\n",
      "Epoch: 173/500... Training loss: 0.0783\n",
      "Epoch: 173/500... Training loss: 0.0492\n",
      "Epoch: 173/500... Training loss: 0.0639\n",
      "Epoch: 173/500... Training loss: 0.0976\n",
      "Epoch: 173/500... Training loss: 0.0238\n",
      "Epoch: 173/500... Training loss: 0.1617\n",
      "Epoch: 173/500... Training loss: 0.1396\n",
      "Epoch: 173/500... Training loss: 0.1449\n",
      "Epoch: 173/500... Training loss: 0.1107\n",
      "Epoch: 173/500... Training loss: 0.2136\n",
      "Epoch: 173/500... Training loss: 0.0602\n",
      "Epoch: 173/500... Training loss: 0.0338\n",
      "Epoch: 173/500... Training loss: 0.0243\n",
      "Epoch: 173/500... Training loss: 0.0608\n",
      "Epoch: 173/500... Training loss: 0.0457\n",
      "Epoch: 173/500... Training loss: 0.2721\n",
      "Epoch: 173/500... Training loss: 0.0243\n",
      "Epoch: 173/500... Training loss: 0.1197\n",
      "Epoch: 173/500... Training loss: 0.0412\n",
      "Epoch: 173/500... Training loss: 0.0919\n",
      "Epoch: 173/500... Training loss: 0.1176\n",
      "Epoch: 173/500... Training loss: 0.0444\n",
      "Epoch: 173/500... Training loss: 0.0437\n",
      "Epoch: 173/500... Training loss: 0.0986\n",
      "Epoch: 173/500... Training loss: 0.0541\n",
      "Epoch: 173/500... Training loss: 0.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173/500... Training loss: 0.1004\n",
      "Epoch: 174/500... Training loss: 0.0712\n",
      "Epoch: 174/500... Training loss: 0.0703\n",
      "Epoch: 174/500... Training loss: 0.0835\n",
      "Epoch: 174/500... Training loss: 0.1091\n",
      "Epoch: 174/500... Training loss: 0.1026\n",
      "Epoch: 174/500... Training loss: 0.0422\n",
      "Epoch: 174/500... Training loss: 0.0554\n",
      "Epoch: 174/500... Training loss: 0.0271\n",
      "Epoch: 174/500... Training loss: 0.0990\n",
      "Epoch: 174/500... Training loss: 0.0593\n",
      "Epoch: 174/500... Training loss: 0.1738\n",
      "Epoch: 174/500... Training loss: 0.1590\n",
      "Epoch: 174/500... Training loss: 0.0782\n",
      "Epoch: 174/500... Training loss: 0.0657\n",
      "Epoch: 174/500... Training loss: 0.2134\n",
      "Epoch: 174/500... Training loss: 0.0426\n",
      "Epoch: 174/500... Training loss: 0.0506\n",
      "Epoch: 174/500... Training loss: 0.0411\n",
      "Epoch: 174/500... Training loss: 0.0911\n",
      "Epoch: 174/500... Training loss: 0.1445\n",
      "Epoch: 174/500... Training loss: 0.1554\n",
      "Epoch: 174/500... Training loss: 0.1407\n",
      "Epoch: 174/500... Training loss: 0.0117\n",
      "Epoch: 174/500... Training loss: 0.0674\n",
      "Epoch: 174/500... Training loss: 0.0679\n",
      "Epoch: 174/500... Training loss: 0.1157\n",
      "Epoch: 174/500... Training loss: 0.0628\n",
      "Epoch: 174/500... Training loss: 0.0935\n",
      "Epoch: 174/500... Training loss: 0.1421\n",
      "Epoch: 174/500... Training loss: 0.1374\n",
      "Epoch: 174/500... Training loss: 0.0559\n",
      "Epoch: 175/500... Training loss: 0.0395\n",
      "Epoch: 175/500... Training loss: 0.0695\n",
      "Epoch: 175/500... Training loss: 0.1674\n",
      "Epoch: 175/500... Training loss: 0.0288\n",
      "Epoch: 175/500... Training loss: 0.0623\n",
      "Epoch: 175/500... Training loss: 0.1694\n",
      "Epoch: 175/500... Training loss: 0.1443\n",
      "Epoch: 175/500... Training loss: 0.0568\n",
      "Epoch: 175/500... Training loss: 0.0625\n",
      "Epoch: 175/500... Training loss: 0.0514\n",
      "Epoch: 175/500... Training loss: 0.0606\n",
      "Epoch: 175/500... Training loss: 0.0810\n",
      "Epoch: 175/500... Training loss: 0.1070\n",
      "Epoch: 175/500... Training loss: 0.0435\n",
      "Epoch: 175/500... Training loss: 0.0149\n",
      "Epoch: 175/500... Training loss: 0.0442\n",
      "Epoch: 175/500... Training loss: 0.0505\n",
      "Epoch: 175/500... Training loss: 0.0764\n",
      "Epoch: 175/500... Training loss: 0.1978\n",
      "Epoch: 175/500... Training loss: 0.1173\n",
      "Epoch: 175/500... Training loss: 0.1087\n",
      "Epoch: 175/500... Training loss: 0.0512\n",
      "Epoch: 175/500... Training loss: 0.0981\n",
      "Epoch: 175/500... Training loss: 0.0201\n",
      "Epoch: 175/500... Training loss: 0.0955\n",
      "Epoch: 175/500... Training loss: 0.0255\n",
      "Epoch: 175/500... Training loss: 0.0807\n",
      "Epoch: 175/500... Training loss: 0.0278\n",
      "Epoch: 175/500... Training loss: 0.0271\n",
      "Epoch: 175/500... Training loss: 0.0949\n",
      "Epoch: 175/500... Training loss: 0.0729\n",
      "Epoch: 176/500... Training loss: 0.0853\n",
      "Epoch: 176/500... Training loss: 0.0235\n",
      "Epoch: 176/500... Training loss: 0.0530\n",
      "Epoch: 176/500... Training loss: 0.1098\n",
      "Epoch: 176/500... Training loss: 0.1286\n",
      "Epoch: 176/500... Training loss: 0.0521\n",
      "Epoch: 176/500... Training loss: 0.0223\n",
      "Epoch: 176/500... Training loss: 0.0734\n",
      "Epoch: 176/500... Training loss: 0.0449\n",
      "Epoch: 176/500... Training loss: 0.0387\n",
      "Epoch: 176/500... Training loss: 0.0668\n",
      "Epoch: 176/500... Training loss: 0.1180\n",
      "Epoch: 176/500... Training loss: 0.0506\n",
      "Epoch: 176/500... Training loss: 0.0283\n",
      "Epoch: 176/500... Training loss: 0.0668\n",
      "Epoch: 176/500... Training loss: 0.0250\n",
      "Epoch: 176/500... Training loss: 0.0576\n",
      "Epoch: 176/500... Training loss: 0.1585\n",
      "Epoch: 176/500... Training loss: 0.0507\n",
      "Epoch: 176/500... Training loss: 0.0443\n",
      "Epoch: 176/500... Training loss: 0.0570\n",
      "Epoch: 176/500... Training loss: 0.0840\n",
      "Epoch: 176/500... Training loss: 0.0766\n",
      "Epoch: 176/500... Training loss: 0.0679\n",
      "Epoch: 176/500... Training loss: 0.0811\n",
      "Epoch: 176/500... Training loss: 0.1208\n",
      "Epoch: 176/500... Training loss: 0.0846\n",
      "Epoch: 176/500... Training loss: 0.2238\n",
      "Epoch: 176/500... Training loss: 0.0137\n",
      "Epoch: 176/500... Training loss: 0.0214\n",
      "Epoch: 176/500... Training loss: 0.0482\n",
      "Epoch: 177/500... Training loss: 0.1233\n",
      "Epoch: 177/500... Training loss: 0.1839\n",
      "Epoch: 177/500... Training loss: 0.0259\n",
      "Epoch: 177/500... Training loss: 0.1066\n",
      "Epoch: 177/500... Training loss: 0.0734\n",
      "Epoch: 177/500... Training loss: 0.1164\n",
      "Epoch: 177/500... Training loss: 0.0229\n",
      "Epoch: 177/500... Training loss: 0.0758\n",
      "Epoch: 177/500... Training loss: 0.0322\n",
      "Epoch: 177/500... Training loss: 0.0362\n",
      "Epoch: 177/500... Training loss: 0.1450\n",
      "Epoch: 177/500... Training loss: 0.1153\n",
      "Epoch: 177/500... Training loss: 0.1513\n",
      "Epoch: 177/500... Training loss: 0.0521\n",
      "Epoch: 177/500... Training loss: 0.0236\n",
      "Epoch: 177/500... Training loss: 0.0173\n",
      "Epoch: 177/500... Training loss: 0.0320\n",
      "Epoch: 177/500... Training loss: 0.0799\n",
      "Epoch: 177/500... Training loss: 0.1123\n",
      "Epoch: 177/500... Training loss: 0.0108\n",
      "Epoch: 177/500... Training loss: 0.0530\n",
      "Epoch: 177/500... Training loss: 0.0982\n",
      "Epoch: 177/500... Training loss: 0.0258\n",
      "Epoch: 177/500... Training loss: 0.0526\n",
      "Epoch: 177/500... Training loss: 0.0675\n",
      "Epoch: 177/500... Training loss: 0.0280\n",
      "Epoch: 177/500... Training loss: 0.0218\n",
      "Epoch: 177/500... Training loss: 0.0600\n",
      "Epoch: 177/500... Training loss: 0.0764\n",
      "Epoch: 177/500... Training loss: 0.0361\n",
      "Epoch: 177/500... Training loss: 0.1214\n",
      "Epoch: 178/500... Training loss: 0.1214\n",
      "Epoch: 178/500... Training loss: 0.0126\n",
      "Epoch: 178/500... Training loss: 0.0471\n",
      "Epoch: 178/500... Training loss: 0.0998\n",
      "Epoch: 178/500... Training loss: 0.0480\n",
      "Epoch: 178/500... Training loss: 0.0898\n",
      "Epoch: 178/500... Training loss: 0.0317\n",
      "Epoch: 178/500... Training loss: 0.1224\n",
      "Epoch: 178/500... Training loss: 0.0475\n",
      "Epoch: 178/500... Training loss: 0.1525\n",
      "Epoch: 178/500... Training loss: 0.0978\n",
      "Epoch: 178/500... Training loss: 0.0869\n",
      "Epoch: 178/500... Training loss: 0.1214\n",
      "Epoch: 178/500... Training loss: 0.0181\n",
      "Epoch: 178/500... Training loss: 0.0648\n",
      "Epoch: 178/500... Training loss: 0.0163\n",
      "Epoch: 178/500... Training loss: 0.0364\n",
      "Epoch: 178/500... Training loss: 0.0499\n",
      "Epoch: 178/500... Training loss: 0.0681\n",
      "Epoch: 178/500... Training loss: 0.0615\n",
      "Epoch: 178/500... Training loss: 0.0278\n",
      "Epoch: 178/500... Training loss: 0.0412\n",
      "Epoch: 178/500... Training loss: 0.0772\n",
      "Epoch: 178/500... Training loss: 0.0118\n",
      "Epoch: 178/500... Training loss: 0.0296\n",
      "Epoch: 178/500... Training loss: 0.0469\n",
      "Epoch: 178/500... Training loss: 0.0177\n",
      "Epoch: 178/500... Training loss: 0.0319\n",
      "Epoch: 178/500... Training loss: 0.0822\n",
      "Epoch: 178/500... Training loss: 0.0315\n",
      "Epoch: 178/500... Training loss: 0.0972\n",
      "Epoch: 179/500... Training loss: 0.3381\n",
      "Epoch: 179/500... Training loss: 0.0349\n",
      "Epoch: 179/500... Training loss: 0.0620\n",
      "Epoch: 179/500... Training loss: 0.0473\n",
      "Epoch: 179/500... Training loss: 0.0254\n",
      "Epoch: 179/500... Training loss: 0.0269\n",
      "Epoch: 179/500... Training loss: 0.0366\n",
      "Epoch: 179/500... Training loss: 0.0477\n",
      "Epoch: 179/500... Training loss: 0.0246\n",
      "Epoch: 179/500... Training loss: 0.1230\n",
      "Epoch: 179/500... Training loss: 0.0236\n",
      "Epoch: 179/500... Training loss: 0.0660\n",
      "Epoch: 179/500... Training loss: 0.1320\n",
      "Epoch: 179/500... Training loss: 0.0582\n",
      "Epoch: 179/500... Training loss: 0.0827\n",
      "Epoch: 179/500... Training loss: 0.0737\n",
      "Epoch: 179/500... Training loss: 0.0331\n",
      "Epoch: 179/500... Training loss: 0.0447\n",
      "Epoch: 179/500... Training loss: 0.0515\n",
      "Epoch: 179/500... Training loss: 0.0860\n",
      "Epoch: 179/500... Training loss: 0.0713\n",
      "Epoch: 179/500... Training loss: 0.0734\n",
      "Epoch: 179/500... Training loss: 0.0222\n",
      "Epoch: 179/500... Training loss: 0.0605\n",
      "Epoch: 179/500... Training loss: 0.0366\n",
      "Epoch: 179/500... Training loss: 0.0654\n",
      "Epoch: 179/500... Training loss: 0.0518\n",
      "Epoch: 179/500... Training loss: 0.0367\n",
      "Epoch: 179/500... Training loss: 0.0325\n",
      "Epoch: 179/500... Training loss: 0.0653\n",
      "Epoch: 179/500... Training loss: 0.0421\n",
      "Epoch: 180/500... Training loss: 0.0660\n",
      "Epoch: 180/500... Training loss: 0.0661\n",
      "Epoch: 180/500... Training loss: 0.1068\n",
      "Epoch: 180/500... Training loss: 0.0616\n",
      "Epoch: 180/500... Training loss: 0.0721\n",
      "Epoch: 180/500... Training loss: 0.0252\n",
      "Epoch: 180/500... Training loss: 0.0151\n",
      "Epoch: 180/500... Training loss: 0.0317\n",
      "Epoch: 180/500... Training loss: 0.0378\n",
      "Epoch: 180/500... Training loss: 0.0898\n",
      "Epoch: 180/500... Training loss: 0.1121\n",
      "Epoch: 180/500... Training loss: 0.0445\n",
      "Epoch: 180/500... Training loss: 0.0440\n",
      "Epoch: 180/500... Training loss: 0.0318\n",
      "Epoch: 180/500... Training loss: 0.0811\n",
      "Epoch: 180/500... Training loss: 0.0448\n",
      "Epoch: 180/500... Training loss: 0.0463\n",
      "Epoch: 180/500... Training loss: 0.0959\n",
      "Epoch: 180/500... Training loss: 0.1366\n",
      "Epoch: 180/500... Training loss: 0.1025\n",
      "Epoch: 180/500... Training loss: 0.1021\n",
      "Epoch: 180/500... Training loss: 0.0723\n",
      "Epoch: 180/500... Training loss: 0.0675\n",
      "Epoch: 180/500... Training loss: 0.0249\n",
      "Epoch: 180/500... Training loss: 0.0661\n",
      "Epoch: 180/500... Training loss: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180/500... Training loss: 0.0197\n",
      "Epoch: 180/500... Training loss: 0.0496\n",
      "Epoch: 180/500... Training loss: 0.0149\n",
      "Epoch: 180/500... Training loss: 0.0660\n",
      "Epoch: 180/500... Training loss: 0.0650\n",
      "Epoch: 181/500... Training loss: 0.0840\n",
      "Epoch: 181/500... Training loss: 0.1006\n",
      "Epoch: 181/500... Training loss: 0.0928\n",
      "Epoch: 181/500... Training loss: 0.1931\n",
      "Epoch: 181/500... Training loss: 0.0410\n",
      "Epoch: 181/500... Training loss: 0.0388\n",
      "Epoch: 181/500... Training loss: 0.1038\n",
      "Epoch: 181/500... Training loss: 0.0406\n",
      "Epoch: 181/500... Training loss: 0.0163\n",
      "Epoch: 181/500... Training loss: 0.0229\n",
      "Epoch: 181/500... Training loss: 0.1460\n",
      "Epoch: 181/500... Training loss: 0.0904\n",
      "Epoch: 181/500... Training loss: 0.0838\n",
      "Epoch: 181/500... Training loss: 0.0329\n",
      "Epoch: 181/500... Training loss: 0.0521\n",
      "Epoch: 181/500... Training loss: 0.0124\n",
      "Epoch: 181/500... Training loss: 0.0381\n",
      "Epoch: 181/500... Training loss: 0.1816\n",
      "Epoch: 181/500... Training loss: 0.0798\n",
      "Epoch: 181/500... Training loss: 0.1299\n",
      "Epoch: 181/500... Training loss: 0.0755\n",
      "Epoch: 181/500... Training loss: 0.1188\n",
      "Epoch: 181/500... Training loss: 0.1262\n",
      "Epoch: 181/500... Training loss: 0.0816\n",
      "Epoch: 181/500... Training loss: 0.0698\n",
      "Epoch: 181/500... Training loss: 0.0219\n",
      "Epoch: 181/500... Training loss: 0.0417\n",
      "Epoch: 181/500... Training loss: 0.0829\n",
      "Epoch: 181/500... Training loss: 0.0536\n",
      "Epoch: 181/500... Training loss: 0.0197\n",
      "Epoch: 181/500... Training loss: 0.0329\n",
      "Epoch: 182/500... Training loss: 0.0331\n",
      "Epoch: 182/500... Training loss: 0.0497\n",
      "Epoch: 182/500... Training loss: 0.1021\n",
      "Epoch: 182/500... Training loss: 0.0485\n",
      "Epoch: 182/500... Training loss: 0.1247\n",
      "Epoch: 182/500... Training loss: 0.0403\n",
      "Epoch: 182/500... Training loss: 0.0312\n",
      "Epoch: 182/500... Training loss: 0.0236\n",
      "Epoch: 182/500... Training loss: 0.0597\n",
      "Epoch: 182/500... Training loss: 0.1004\n",
      "Epoch: 182/500... Training loss: 0.1011\n",
      "Epoch: 182/500... Training loss: 0.1051\n",
      "Epoch: 182/500... Training loss: 0.1118\n",
      "Epoch: 182/500... Training loss: 0.0408\n",
      "Epoch: 182/500... Training loss: 0.0590\n",
      "Epoch: 182/500... Training loss: 0.0160\n",
      "Epoch: 182/500... Training loss: 0.0189\n",
      "Epoch: 182/500... Training loss: 0.0295\n",
      "Epoch: 182/500... Training loss: 0.0961\n",
      "Epoch: 182/500... Training loss: 0.0724\n",
      "Epoch: 182/500... Training loss: 0.1089\n",
      "Epoch: 182/500... Training loss: 0.1089\n",
      "Epoch: 182/500... Training loss: 0.0450\n",
      "Epoch: 182/500... Training loss: 0.0270\n",
      "Epoch: 182/500... Training loss: 0.0386\n",
      "Epoch: 182/500... Training loss: 0.0712\n",
      "Epoch: 182/500... Training loss: 0.0358\n",
      "Epoch: 182/500... Training loss: 0.1144\n",
      "Epoch: 182/500... Training loss: 0.0605\n",
      "Epoch: 182/500... Training loss: 0.0445\n",
      "Epoch: 182/500... Training loss: 0.0365\n",
      "Epoch: 183/500... Training loss: 0.0803\n",
      "Epoch: 183/500... Training loss: 0.1131\n",
      "Epoch: 183/500... Training loss: 0.0801\n",
      "Epoch: 183/500... Training loss: 0.0913\n",
      "Epoch: 183/500... Training loss: 0.0544\n",
      "Epoch: 183/500... Training loss: 0.0457\n",
      "Epoch: 183/500... Training loss: 0.0443\n",
      "Epoch: 183/500... Training loss: 0.0464\n",
      "Epoch: 183/500... Training loss: 0.0138\n",
      "Epoch: 183/500... Training loss: 0.0541\n",
      "Epoch: 183/500... Training loss: 0.0359\n",
      "Epoch: 183/500... Training loss: 0.0693\n",
      "Epoch: 183/500... Training loss: 0.1273\n",
      "Epoch: 183/500... Training loss: 0.0444\n",
      "Epoch: 183/500... Training loss: 0.0442\n",
      "Epoch: 183/500... Training loss: 0.0184\n",
      "Epoch: 183/500... Training loss: 0.0360\n",
      "Epoch: 183/500... Training loss: 0.0129\n",
      "Epoch: 183/500... Training loss: 0.0344\n",
      "Epoch: 183/500... Training loss: 0.0472\n",
      "Epoch: 183/500... Training loss: 0.0616\n",
      "Epoch: 183/500... Training loss: 0.1227\n",
      "Epoch: 183/500... Training loss: 0.0557\n",
      "Epoch: 183/500... Training loss: 0.0506\n",
      "Epoch: 183/500... Training loss: 0.0638\n",
      "Epoch: 183/500... Training loss: 0.0523\n",
      "Epoch: 183/500... Training loss: 0.0199\n",
      "Epoch: 183/500... Training loss: 0.0334\n",
      "Epoch: 183/500... Training loss: 0.0185\n",
      "Epoch: 183/500... Training loss: 0.0318\n",
      "Epoch: 183/500... Training loss: 0.0878\n",
      "Epoch: 184/500... Training loss: 0.0811\n",
      "Epoch: 184/500... Training loss: 0.0163\n",
      "Epoch: 184/500... Training loss: 0.0426\n",
      "Epoch: 184/500... Training loss: 0.1561\n",
      "Epoch: 184/500... Training loss: 0.0468\n",
      "Epoch: 184/500... Training loss: 0.0375\n",
      "Epoch: 184/500... Training loss: 0.0750\n",
      "Epoch: 184/500... Training loss: 0.0835\n",
      "Epoch: 184/500... Training loss: 0.0362\n",
      "Epoch: 184/500... Training loss: 0.0795\n",
      "Epoch: 184/500... Training loss: 0.1999\n",
      "Epoch: 184/500... Training loss: 0.0238\n",
      "Epoch: 184/500... Training loss: 0.0814\n",
      "Epoch: 184/500... Training loss: 0.0096\n",
      "Epoch: 184/500... Training loss: 0.1149\n",
      "Epoch: 184/500... Training loss: 0.0578\n",
      "Epoch: 184/500... Training loss: 0.1048\n",
      "Epoch: 184/500... Training loss: 0.0681\n",
      "Epoch: 184/500... Training loss: 0.0517\n",
      "Epoch: 184/500... Training loss: 0.0814\n",
      "Epoch: 184/500... Training loss: 0.0864\n",
      "Epoch: 184/500... Training loss: 0.0646\n",
      "Epoch: 184/500... Training loss: 0.0275\n",
      "Epoch: 184/500... Training loss: 0.0526\n",
      "Epoch: 184/500... Training loss: 0.0699\n",
      "Epoch: 184/500... Training loss: 0.1008\n",
      "Epoch: 184/500... Training loss: 0.0498\n",
      "Epoch: 184/500... Training loss: 0.1050\n",
      "Epoch: 184/500... Training loss: 0.0619\n",
      "Epoch: 184/500... Training loss: 0.0271\n",
      "Epoch: 184/500... Training loss: 0.0159\n",
      "Epoch: 185/500... Training loss: 0.1217\n",
      "Epoch: 185/500... Training loss: 0.0328\n",
      "Epoch: 185/500... Training loss: 0.0418\n",
      "Epoch: 185/500... Training loss: 0.1799\n",
      "Epoch: 185/500... Training loss: 0.1785\n",
      "Epoch: 185/500... Training loss: 0.0389\n",
      "Epoch: 185/500... Training loss: 0.0350\n",
      "Epoch: 185/500... Training loss: 0.0618\n",
      "Epoch: 185/500... Training loss: 0.0858\n",
      "Epoch: 185/500... Training loss: 0.0976\n",
      "Epoch: 185/500... Training loss: 0.0971\n",
      "Epoch: 185/500... Training loss: 0.0740\n",
      "Epoch: 185/500... Training loss: 0.1131\n",
      "Epoch: 185/500... Training loss: 0.0301\n",
      "Epoch: 185/500... Training loss: 0.0196\n",
      "Epoch: 185/500... Training loss: 0.0551\n",
      "Epoch: 185/500... Training loss: 0.1021\n",
      "Epoch: 185/500... Training loss: 0.1547\n",
      "Epoch: 185/500... Training loss: 0.0368\n",
      "Epoch: 185/500... Training loss: 0.0289\n",
      "Epoch: 185/500... Training loss: 0.0189\n",
      "Epoch: 185/500... Training loss: 0.1374\n",
      "Epoch: 185/500... Training loss: 0.0279\n",
      "Epoch: 185/500... Training loss: 0.0376\n",
      "Epoch: 185/500... Training loss: 0.0801\n",
      "Epoch: 185/500... Training loss: 0.0677\n",
      "Epoch: 185/500... Training loss: 0.0206\n",
      "Epoch: 185/500... Training loss: 0.0584\n",
      "Epoch: 185/500... Training loss: 0.0228\n",
      "Epoch: 185/500... Training loss: 0.0685\n",
      "Epoch: 185/500... Training loss: 0.0293\n",
      "Epoch: 186/500... Training loss: 0.0567\n",
      "Epoch: 186/500... Training loss: 0.0337\n",
      "Epoch: 186/500... Training loss: 0.0695\n",
      "Epoch: 186/500... Training loss: 0.1106\n",
      "Epoch: 186/500... Training loss: 0.0969\n",
      "Epoch: 186/500... Training loss: 0.1817\n",
      "Epoch: 186/500... Training loss: 0.0691\n",
      "Epoch: 186/500... Training loss: 0.0711\n",
      "Epoch: 186/500... Training loss: 0.0758\n",
      "Epoch: 186/500... Training loss: 0.0434\n",
      "Epoch: 186/500... Training loss: 0.1559\n",
      "Epoch: 186/500... Training loss: 0.1079\n",
      "Epoch: 186/500... Training loss: 0.0279\n",
      "Epoch: 186/500... Training loss: 0.0370\n",
      "Epoch: 186/500... Training loss: 0.0323\n",
      "Epoch: 186/500... Training loss: 0.0232\n",
      "Epoch: 186/500... Training loss: 0.0200\n",
      "Epoch: 186/500... Training loss: 0.0337\n",
      "Epoch: 186/500... Training loss: 0.0916\n",
      "Epoch: 186/500... Training loss: 0.1162\n",
      "Epoch: 186/500... Training loss: 0.1029\n",
      "Epoch: 186/500... Training loss: 0.0938\n",
      "Epoch: 186/500... Training loss: 0.0185\n",
      "Epoch: 186/500... Training loss: 0.0369\n",
      "Epoch: 186/500... Training loss: 0.0146\n",
      "Epoch: 186/500... Training loss: 0.0457\n",
      "Epoch: 186/500... Training loss: 0.0606\n",
      "Epoch: 186/500... Training loss: 0.0490\n",
      "Epoch: 186/500... Training loss: 0.0351\n",
      "Epoch: 186/500... Training loss: 0.0316\n",
      "Epoch: 186/500... Training loss: 0.0783\n",
      "Epoch: 187/500... Training loss: 0.0615\n",
      "Epoch: 187/500... Training loss: 0.0335\n",
      "Epoch: 187/500... Training loss: 0.0732\n",
      "Epoch: 187/500... Training loss: 0.1102\n",
      "Epoch: 187/500... Training loss: 0.0153\n",
      "Epoch: 187/500... Training loss: 0.1766\n",
      "Epoch: 187/500... Training loss: 0.0512\n",
      "Epoch: 187/500... Training loss: 0.0340\n",
      "Epoch: 187/500... Training loss: 0.0365\n",
      "Epoch: 187/500... Training loss: 0.1088\n",
      "Epoch: 187/500... Training loss: 0.0527\n",
      "Epoch: 187/500... Training loss: 0.1160\n",
      "Epoch: 187/500... Training loss: 0.0669\n",
      "Epoch: 187/500... Training loss: 0.0303\n",
      "Epoch: 187/500... Training loss: 0.0400\n",
      "Epoch: 187/500... Training loss: 0.0646\n",
      "Epoch: 187/500... Training loss: 0.0439\n",
      "Epoch: 187/500... Training loss: 0.1429\n",
      "Epoch: 187/500... Training loss: 0.1284\n",
      "Epoch: 187/500... Training loss: 0.0207\n",
      "Epoch: 187/500... Training loss: 0.0198\n",
      "Epoch: 187/500... Training loss: 0.0615\n",
      "Epoch: 187/500... Training loss: 0.0600\n",
      "Epoch: 187/500... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187/500... Training loss: 0.0352\n",
      "Epoch: 187/500... Training loss: 0.0139\n",
      "Epoch: 187/500... Training loss: 0.0408\n",
      "Epoch: 187/500... Training loss: 0.1188\n",
      "Epoch: 187/500... Training loss: 0.0279\n",
      "Epoch: 187/500... Training loss: 0.0170\n",
      "Epoch: 187/500... Training loss: 0.0513\n",
      "Epoch: 188/500... Training loss: 0.0555\n",
      "Epoch: 188/500... Training loss: 0.0474\n",
      "Epoch: 188/500... Training loss: 0.0340\n",
      "Epoch: 188/500... Training loss: 0.0331\n",
      "Epoch: 188/500... Training loss: 0.0798\n",
      "Epoch: 188/500... Training loss: 0.0349\n",
      "Epoch: 188/500... Training loss: 0.0572\n",
      "Epoch: 188/500... Training loss: 0.0421\n",
      "Epoch: 188/500... Training loss: 0.0786\n",
      "Epoch: 188/500... Training loss: 0.0494\n",
      "Epoch: 188/500... Training loss: 0.0363\n",
      "Epoch: 188/500... Training loss: 0.1251\n",
      "Epoch: 188/500... Training loss: 0.0409\n",
      "Epoch: 188/500... Training loss: 0.0688\n",
      "Epoch: 188/500... Training loss: 0.1564\n",
      "Epoch: 188/500... Training loss: 0.0521\n",
      "Epoch: 188/500... Training loss: 0.0403\n",
      "Epoch: 188/500... Training loss: 0.0849\n",
      "Epoch: 188/500... Training loss: 0.0400\n",
      "Epoch: 188/500... Training loss: 0.0404\n",
      "Epoch: 188/500... Training loss: 0.0424\n",
      "Epoch: 188/500... Training loss: 0.0830\n",
      "Epoch: 188/500... Training loss: 0.0864\n",
      "Epoch: 188/500... Training loss: 0.0727\n",
      "Epoch: 188/500... Training loss: 0.0679\n",
      "Epoch: 188/500... Training loss: 0.0226\n",
      "Epoch: 188/500... Training loss: 0.0867\n",
      "Epoch: 188/500... Training loss: 0.0403\n",
      "Epoch: 188/500... Training loss: 0.1048\n",
      "Epoch: 188/500... Training loss: 0.0113\n",
      "Epoch: 188/500... Training loss: 0.0223\n",
      "Epoch: 189/500... Training loss: 0.0883\n",
      "Epoch: 189/500... Training loss: 0.0370\n",
      "Epoch: 189/500... Training loss: 0.0364\n",
      "Epoch: 189/500... Training loss: 0.0392\n",
      "Epoch: 189/500... Training loss: 0.0780\n",
      "Epoch: 189/500... Training loss: 0.0283\n",
      "Epoch: 189/500... Training loss: 0.0653\n",
      "Epoch: 189/500... Training loss: 0.0906\n",
      "Epoch: 189/500... Training loss: 0.0361\n",
      "Epoch: 189/500... Training loss: 0.0225\n",
      "Epoch: 189/500... Training loss: 0.0867\n",
      "Epoch: 189/500... Training loss: 0.1626\n",
      "Epoch: 189/500... Training loss: 0.1079\n",
      "Epoch: 189/500... Training loss: 0.0622\n",
      "Epoch: 189/500... Training loss: 0.0289\n",
      "Epoch: 189/500... Training loss: 0.0614\n",
      "Epoch: 189/500... Training loss: 0.0254\n",
      "Epoch: 189/500... Training loss: 0.0532\n",
      "Epoch: 189/500... Training loss: 0.0237\n",
      "Epoch: 189/500... Training loss: 0.0287\n",
      "Epoch: 189/500... Training loss: 0.0125\n",
      "Epoch: 189/500... Training loss: 0.0409\n",
      "Epoch: 189/500... Training loss: 0.1564\n",
      "Epoch: 189/500... Training loss: 0.0948\n",
      "Epoch: 189/500... Training loss: 0.0611\n",
      "Epoch: 189/500... Training loss: 0.1151\n",
      "Epoch: 189/500... Training loss: 0.0464\n",
      "Epoch: 189/500... Training loss: 0.0159\n",
      "Epoch: 189/500... Training loss: 0.0252\n",
      "Epoch: 189/500... Training loss: 0.0425\n",
      "Epoch: 189/500... Training loss: 0.0238\n",
      "Epoch: 190/500... Training loss: 0.0347\n",
      "Epoch: 190/500... Training loss: 0.0497\n",
      "Epoch: 190/500... Training loss: 0.0662\n",
      "Epoch: 190/500... Training loss: 0.0454\n",
      "Epoch: 190/500... Training loss: 0.0926\n",
      "Epoch: 190/500... Training loss: 0.1197\n",
      "Epoch: 190/500... Training loss: 0.0189\n",
      "Epoch: 190/500... Training loss: 0.0346\n",
      "Epoch: 190/500... Training loss: 0.0482\n",
      "Epoch: 190/500... Training loss: 0.0149\n",
      "Epoch: 190/500... Training loss: 0.0412\n",
      "Epoch: 190/500... Training loss: 0.0861\n",
      "Epoch: 190/500... Training loss: 0.2517\n",
      "Epoch: 190/500... Training loss: 0.0777\n",
      "Epoch: 190/500... Training loss: 0.0075\n",
      "Epoch: 190/500... Training loss: 0.0723\n",
      "Epoch: 190/500... Training loss: 0.0177\n",
      "Epoch: 190/500... Training loss: 0.0274\n",
      "Epoch: 190/500... Training loss: 0.0959\n",
      "Epoch: 190/500... Training loss: 0.0336\n",
      "Epoch: 190/500... Training loss: 0.0180\n",
      "Epoch: 190/500... Training loss: 0.0386\n",
      "Epoch: 190/500... Training loss: 0.0538\n",
      "Epoch: 190/500... Training loss: 0.0980\n",
      "Epoch: 190/500... Training loss: 0.0657\n",
      "Epoch: 190/500... Training loss: 0.0561\n",
      "Epoch: 190/500... Training loss: 0.0451\n",
      "Epoch: 190/500... Training loss: 0.0294\n",
      "Epoch: 190/500... Training loss: 0.0459\n",
      "Epoch: 190/500... Training loss: 0.0294\n",
      "Epoch: 190/500... Training loss: 0.1063\n",
      "Epoch: 191/500... Training loss: 0.0240\n",
      "Epoch: 191/500... Training loss: 0.0722\n",
      "Epoch: 191/500... Training loss: 0.1254\n",
      "Epoch: 191/500... Training loss: 0.0363\n",
      "Epoch: 191/500... Training loss: 0.0412\n",
      "Epoch: 191/500... Training loss: 0.0282\n",
      "Epoch: 191/500... Training loss: 0.1113\n",
      "Epoch: 191/500... Training loss: 0.0404\n",
      "Epoch: 191/500... Training loss: 0.0129\n",
      "Epoch: 191/500... Training loss: 0.0285\n",
      "Epoch: 191/500... Training loss: 0.1221\n",
      "Epoch: 191/500... Training loss: 0.0757\n",
      "Epoch: 191/500... Training loss: 0.0490\n",
      "Epoch: 191/500... Training loss: 0.0270\n",
      "Epoch: 191/500... Training loss: 0.0239\n",
      "Epoch: 191/500... Training loss: 0.0599\n",
      "Epoch: 191/500... Training loss: 0.0383\n",
      "Epoch: 191/500... Training loss: 0.0182\n",
      "Epoch: 191/500... Training loss: 0.0578\n",
      "Epoch: 191/500... Training loss: 0.0335\n",
      "Epoch: 191/500... Training loss: 0.0152\n",
      "Epoch: 191/500... Training loss: 0.1021\n",
      "Epoch: 191/500... Training loss: 0.0728\n",
      "Epoch: 191/500... Training loss: 0.0527\n",
      "Epoch: 191/500... Training loss: 0.0145\n",
      "Epoch: 191/500... Training loss: 0.0272\n",
      "Epoch: 191/500... Training loss: 0.0645\n",
      "Epoch: 191/500... Training loss: 0.0574\n",
      "Epoch: 191/500... Training loss: 0.0194\n",
      "Epoch: 191/500... Training loss: 0.0346\n",
      "Epoch: 191/500... Training loss: 0.0540\n",
      "Epoch: 192/500... Training loss: 0.0338\n",
      "Epoch: 192/500... Training loss: 0.0605\n",
      "Epoch: 192/500... Training loss: 0.1801\n",
      "Epoch: 192/500... Training loss: 0.0847\n",
      "Epoch: 192/500... Training loss: 0.2046\n",
      "Epoch: 192/500... Training loss: 0.0906\n",
      "Epoch: 192/500... Training loss: 0.0147\n",
      "Epoch: 192/500... Training loss: 0.0844\n",
      "Epoch: 192/500... Training loss: 0.0640\n",
      "Epoch: 192/500... Training loss: 0.0673\n",
      "Epoch: 192/500... Training loss: 0.1849\n",
      "Epoch: 192/500... Training loss: 0.0706\n",
      "Epoch: 192/500... Training loss: 0.0589\n",
      "Epoch: 192/500... Training loss: 0.0315\n",
      "Epoch: 192/500... Training loss: 0.0305\n",
      "Epoch: 192/500... Training loss: 0.0450\n",
      "Epoch: 192/500... Training loss: 0.1256\n",
      "Epoch: 192/500... Training loss: 0.0090\n",
      "Epoch: 192/500... Training loss: 0.0989\n",
      "Epoch: 192/500... Training loss: 0.0323\n",
      "Epoch: 192/500... Training loss: 0.0486\n",
      "Epoch: 192/500... Training loss: 0.1057\n",
      "Epoch: 192/500... Training loss: 0.0405\n",
      "Epoch: 192/500... Training loss: 0.0740\n",
      "Epoch: 192/500... Training loss: 0.0606\n",
      "Epoch: 192/500... Training loss: 0.0283\n",
      "Epoch: 192/500... Training loss: 0.0344\n",
      "Epoch: 192/500... Training loss: 0.0320\n",
      "Epoch: 192/500... Training loss: 0.0976\n",
      "Epoch: 192/500... Training loss: 0.0101\n",
      "Epoch: 192/500... Training loss: 0.0401\n",
      "Epoch: 193/500... Training loss: 0.0278\n",
      "Epoch: 193/500... Training loss: 0.0342\n",
      "Epoch: 193/500... Training loss: 0.0987\n",
      "Epoch: 193/500... Training loss: 0.0360\n",
      "Epoch: 193/500... Training loss: 0.0132\n",
      "Epoch: 193/500... Training loss: 0.0238\n",
      "Epoch: 193/500... Training loss: 0.1109\n",
      "Epoch: 193/500... Training loss: 0.0447\n",
      "Epoch: 193/500... Training loss: 0.1109\n",
      "Epoch: 193/500... Training loss: 0.0154\n",
      "Epoch: 193/500... Training loss: 0.1092\n",
      "Epoch: 193/500... Training loss: 0.0756\n",
      "Epoch: 193/500... Training loss: 0.0697\n",
      "Epoch: 193/500... Training loss: 0.1052\n",
      "Epoch: 193/500... Training loss: 0.0748\n",
      "Epoch: 193/500... Training loss: 0.0370\n",
      "Epoch: 193/500... Training loss: 0.0499\n",
      "Epoch: 193/500... Training loss: 0.0567\n",
      "Epoch: 193/500... Training loss: 0.0940\n",
      "Epoch: 193/500... Training loss: 0.0091\n",
      "Epoch: 193/500... Training loss: 0.0230\n",
      "Epoch: 193/500... Training loss: 0.1084\n",
      "Epoch: 193/500... Training loss: 0.0460\n",
      "Epoch: 193/500... Training loss: 0.0421\n",
      "Epoch: 193/500... Training loss: 0.0633\n",
      "Epoch: 193/500... Training loss: 0.0289\n",
      "Epoch: 193/500... Training loss: 0.0323\n",
      "Epoch: 193/500... Training loss: 0.0325\n",
      "Epoch: 193/500... Training loss: 0.0205\n",
      "Epoch: 193/500... Training loss: 0.1051\n",
      "Epoch: 193/500... Training loss: 0.0149\n",
      "Epoch: 194/500... Training loss: 0.0611\n",
      "Epoch: 194/500... Training loss: 0.0172\n",
      "Epoch: 194/500... Training loss: 0.0838\n",
      "Epoch: 194/500... Training loss: 0.0553\n",
      "Epoch: 194/500... Training loss: 0.0308\n",
      "Epoch: 194/500... Training loss: 0.1286\n",
      "Epoch: 194/500... Training loss: 0.0739\n",
      "Epoch: 194/500... Training loss: 0.0705\n",
      "Epoch: 194/500... Training loss: 0.0372\n",
      "Epoch: 194/500... Training loss: 0.0434\n",
      "Epoch: 194/500... Training loss: 0.0868\n",
      "Epoch: 194/500... Training loss: 0.1427\n",
      "Epoch: 194/500... Training loss: 0.0528\n",
      "Epoch: 194/500... Training loss: 0.0323\n",
      "Epoch: 194/500... Training loss: 0.0389\n",
      "Epoch: 194/500... Training loss: 0.0551\n",
      "Epoch: 194/500... Training loss: 0.0728\n",
      "Epoch: 194/500... Training loss: 0.0826\n",
      "Epoch: 194/500... Training loss: 0.0598\n",
      "Epoch: 194/500... Training loss: 0.0828\n",
      "Epoch: 194/500... Training loss: 0.0138\n",
      "Epoch: 194/500... Training loss: 0.0685\n",
      "Epoch: 194/500... Training loss: 0.0520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 194/500... Training loss: 0.0325\n",
      "Epoch: 194/500... Training loss: 0.0554\n",
      "Epoch: 194/500... Training loss: 0.0207\n",
      "Epoch: 194/500... Training loss: 0.0368\n",
      "Epoch: 194/500... Training loss: 0.0731\n",
      "Epoch: 194/500... Training loss: 0.0782\n",
      "Epoch: 194/500... Training loss: 0.0484\n",
      "Epoch: 194/500... Training loss: 0.0691\n",
      "Epoch: 195/500... Training loss: 0.0218\n",
      "Epoch: 195/500... Training loss: 0.1039\n",
      "Epoch: 195/500... Training loss: 0.1666\n",
      "Epoch: 195/500... Training loss: 0.2250\n",
      "Epoch: 195/500... Training loss: 0.0592\n",
      "Epoch: 195/500... Training loss: 0.0435\n",
      "Epoch: 195/500... Training loss: 0.1111\n",
      "Epoch: 195/500... Training loss: 0.0724\n",
      "Epoch: 195/500... Training loss: 0.0182\n",
      "Epoch: 195/500... Training loss: 0.0247\n",
      "Epoch: 195/500... Training loss: 0.0418\n",
      "Epoch: 195/500... Training loss: 0.0680\n",
      "Epoch: 195/500... Training loss: 0.0839\n",
      "Epoch: 195/500... Training loss: 0.0368\n",
      "Epoch: 195/500... Training loss: 0.0533\n",
      "Epoch: 195/500... Training loss: 0.0363\n",
      "Epoch: 195/500... Training loss: 0.0419\n",
      "Epoch: 195/500... Training loss: 0.0429\n",
      "Epoch: 195/500... Training loss: 0.0758\n",
      "Epoch: 195/500... Training loss: 0.0058\n",
      "Epoch: 195/500... Training loss: 0.0362\n",
      "Epoch: 195/500... Training loss: 0.1142\n",
      "Epoch: 195/500... Training loss: 0.0608\n",
      "Epoch: 195/500... Training loss: 0.0190\n",
      "Epoch: 195/500... Training loss: 0.0576\n",
      "Epoch: 195/500... Training loss: 0.0247\n",
      "Epoch: 195/500... Training loss: 0.0109\n",
      "Epoch: 195/500... Training loss: 0.0355\n",
      "Epoch: 195/500... Training loss: 0.0098\n",
      "Epoch: 195/500... Training loss: 0.0326\n",
      "Epoch: 195/500... Training loss: 0.1506\n",
      "Epoch: 196/500... Training loss: 0.0667\n",
      "Epoch: 196/500... Training loss: 0.1282\n",
      "Epoch: 196/500... Training loss: 0.0451\n",
      "Epoch: 196/500... Training loss: 0.1293\n",
      "Epoch: 196/500... Training loss: 0.1207\n",
      "Epoch: 196/500... Training loss: 0.0377\n",
      "Epoch: 196/500... Training loss: 0.0361\n",
      "Epoch: 196/500... Training loss: 0.0324\n",
      "Epoch: 196/500... Training loss: 0.0955\n",
      "Epoch: 196/500... Training loss: 0.0153\n",
      "Epoch: 196/500... Training loss: 0.0539\n",
      "Epoch: 196/500... Training loss: 0.1647\n",
      "Epoch: 196/500... Training loss: 0.0239\n",
      "Epoch: 196/500... Training loss: 0.0280\n",
      "Epoch: 196/500... Training loss: 0.1055\n",
      "Epoch: 196/500... Training loss: 0.0401\n",
      "Epoch: 196/500... Training loss: 0.0365\n",
      "Epoch: 196/500... Training loss: 0.0992\n",
      "Epoch: 196/500... Training loss: 0.0915\n",
      "Epoch: 196/500... Training loss: 0.0154\n",
      "Epoch: 196/500... Training loss: 0.0078\n",
      "Epoch: 196/500... Training loss: 0.0634\n",
      "Epoch: 196/500... Training loss: 0.0773\n",
      "Epoch: 196/500... Training loss: 0.0180\n",
      "Epoch: 196/500... Training loss: 0.1183\n",
      "Epoch: 196/500... Training loss: 0.0506\n",
      "Epoch: 196/500... Training loss: 0.1147\n",
      "Epoch: 196/500... Training loss: 0.0942\n",
      "Epoch: 196/500... Training loss: 0.0538\n",
      "Epoch: 196/500... Training loss: 0.0329\n",
      "Epoch: 196/500... Training loss: 0.0192\n",
      "Epoch: 197/500... Training loss: 0.0760\n",
      "Epoch: 197/500... Training loss: 0.0568\n",
      "Epoch: 197/500... Training loss: 0.0535\n",
      "Epoch: 197/500... Training loss: 0.0903\n",
      "Epoch: 197/500... Training loss: 0.0091\n",
      "Epoch: 197/500... Training loss: 0.0710\n",
      "Epoch: 197/500... Training loss: 0.0207\n",
      "Epoch: 197/500... Training loss: 0.1422\n",
      "Epoch: 197/500... Training loss: 0.0114\n",
      "Epoch: 197/500... Training loss: 0.0204\n",
      "Epoch: 197/500... Training loss: 0.0286\n",
      "Epoch: 197/500... Training loss: 0.0520\n",
      "Epoch: 197/500... Training loss: 0.0996\n",
      "Epoch: 197/500... Training loss: 0.0201\n",
      "Epoch: 197/500... Training loss: 0.0674\n",
      "Epoch: 197/500... Training loss: 0.0369\n",
      "Epoch: 197/500... Training loss: 0.0873\n",
      "Epoch: 197/500... Training loss: 0.0481\n",
      "Epoch: 197/500... Training loss: 0.0256\n",
      "Epoch: 197/500... Training loss: 0.0440\n",
      "Epoch: 197/500... Training loss: 0.0132\n",
      "Epoch: 197/500... Training loss: 0.2379\n",
      "Epoch: 197/500... Training loss: 0.0830\n",
      "Epoch: 197/500... Training loss: 0.0319\n",
      "Epoch: 197/500... Training loss: 0.0071\n",
      "Epoch: 197/500... Training loss: 0.0122\n",
      "Epoch: 197/500... Training loss: 0.0544\n",
      "Epoch: 197/500... Training loss: 0.0221\n",
      "Epoch: 197/500... Training loss: 0.0262\n",
      "Epoch: 197/500... Training loss: 0.0715\n",
      "Epoch: 197/500... Training loss: 0.0369\n",
      "Epoch: 198/500... Training loss: 0.0910\n",
      "Epoch: 198/500... Training loss: 0.1327\n",
      "Epoch: 198/500... Training loss: 0.0509\n",
      "Epoch: 198/500... Training loss: 0.0662\n",
      "Epoch: 198/500... Training loss: 0.0379\n",
      "Epoch: 198/500... Training loss: 0.1199\n",
      "Epoch: 198/500... Training loss: 0.0812\n",
      "Epoch: 198/500... Training loss: 0.0149\n",
      "Epoch: 198/500... Training loss: 0.0616\n",
      "Epoch: 198/500... Training loss: 0.0535\n",
      "Epoch: 198/500... Training loss: 0.0717\n",
      "Epoch: 198/500... Training loss: 0.0484\n",
      "Epoch: 198/500... Training loss: 0.0582\n",
      "Epoch: 198/500... Training loss: 0.0316\n",
      "Epoch: 198/500... Training loss: 0.1592\n",
      "Epoch: 198/500... Training loss: 0.0356\n",
      "Epoch: 198/500... Training loss: 0.0450\n",
      "Epoch: 198/500... Training loss: 0.1368\n",
      "Epoch: 198/500... Training loss: 0.0565\n",
      "Epoch: 198/500... Training loss: 0.0210\n",
      "Epoch: 198/500... Training loss: 0.0131\n",
      "Epoch: 198/500... Training loss: 0.0224\n",
      "Epoch: 198/500... Training loss: 0.0764\n",
      "Epoch: 198/500... Training loss: 0.0507\n",
      "Epoch: 198/500... Training loss: 0.0438\n",
      "Epoch: 198/500... Training loss: 0.0160\n",
      "Epoch: 198/500... Training loss: 0.0109\n",
      "Epoch: 198/500... Training loss: 0.0480\n",
      "Epoch: 198/500... Training loss: 0.0478\n",
      "Epoch: 198/500... Training loss: 0.0473\n",
      "Epoch: 198/500... Training loss: 0.0152\n",
      "Epoch: 199/500... Training loss: 0.1071\n",
      "Epoch: 199/500... Training loss: 0.0606\n",
      "Epoch: 199/500... Training loss: 0.0755\n",
      "Epoch: 199/500... Training loss: 0.1268\n",
      "Epoch: 199/500... Training loss: 0.0504\n",
      "Epoch: 199/500... Training loss: 0.0799\n",
      "Epoch: 199/500... Training loss: 0.0617\n",
      "Epoch: 199/500... Training loss: 0.1172\n",
      "Epoch: 199/500... Training loss: 0.0947\n",
      "Epoch: 199/500... Training loss: 0.1275\n",
      "Epoch: 199/500... Training loss: 0.0577\n",
      "Epoch: 199/500... Training loss: 0.1250\n",
      "Epoch: 199/500... Training loss: 0.2180\n",
      "Epoch: 199/500... Training loss: 0.0618\n",
      "Epoch: 199/500... Training loss: 0.0940\n",
      "Epoch: 199/500... Training loss: 0.0566\n",
      "Epoch: 199/500... Training loss: 0.0424\n",
      "Epoch: 199/500... Training loss: 0.0566\n",
      "Epoch: 199/500... Training loss: 0.0500\n",
      "Epoch: 199/500... Training loss: 0.0137\n",
      "Epoch: 199/500... Training loss: 0.0304\n",
      "Epoch: 199/500... Training loss: 0.0303\n",
      "Epoch: 199/500... Training loss: 0.0143\n",
      "Epoch: 199/500... Training loss: 0.0374\n",
      "Epoch: 199/500... Training loss: 0.0424\n",
      "Epoch: 199/500... Training loss: 0.0375\n",
      "Epoch: 199/500... Training loss: 0.0200\n",
      "Epoch: 199/500... Training loss: 0.0732\n",
      "Epoch: 199/500... Training loss: 0.0221\n",
      "Epoch: 199/500... Training loss: 0.1386\n",
      "Epoch: 199/500... Training loss: 0.0249\n",
      "Epoch: 200/500... Training loss: 0.2334\n",
      "Epoch: 200/500... Training loss: 0.0616\n",
      "Epoch: 200/500... Training loss: 0.2348\n",
      "Epoch: 200/500... Training loss: 0.0232\n",
      "Epoch: 200/500... Training loss: 0.0101\n",
      "Epoch: 200/500... Training loss: 0.0615\n",
      "Epoch: 200/500... Training loss: 0.0762\n",
      "Epoch: 200/500... Training loss: 0.0375\n",
      "Epoch: 200/500... Training loss: 0.0710\n",
      "Epoch: 200/500... Training loss: 0.0726\n",
      "Epoch: 200/500... Training loss: 0.0788\n",
      "Epoch: 200/500... Training loss: 0.0265\n",
      "Epoch: 200/500... Training loss: 0.0278\n",
      "Epoch: 200/500... Training loss: 0.0239\n",
      "Epoch: 200/500... Training loss: 0.0318\n",
      "Epoch: 200/500... Training loss: 0.0316\n",
      "Epoch: 200/500... Training loss: 0.0898\n",
      "Epoch: 200/500... Training loss: 0.1478\n",
      "Epoch: 200/500... Training loss: 0.0118\n",
      "Epoch: 200/500... Training loss: 0.0260\n",
      "Epoch: 200/500... Training loss: 0.1287\n",
      "Epoch: 200/500... Training loss: 0.0484\n",
      "Epoch: 200/500... Training loss: 0.0157\n",
      "Epoch: 200/500... Training loss: 0.0553\n",
      "Epoch: 200/500... Training loss: 0.0303\n",
      "Epoch: 200/500... Training loss: 0.0092\n",
      "Epoch: 200/500... Training loss: 0.0264\n",
      "Epoch: 200/500... Training loss: 0.0598\n",
      "Epoch: 200/500... Training loss: 0.0150\n",
      "Epoch: 200/500... Training loss: 0.0697\n",
      "Epoch: 200/500... Training loss: 0.0172\n",
      "Epoch: 201/500... Training loss: 0.1244\n",
      "Epoch: 201/500... Training loss: 0.1576\n",
      "Epoch: 201/500... Training loss: 0.0538\n",
      "Epoch: 201/500... Training loss: 0.0412\n",
      "Epoch: 201/500... Training loss: 0.1160\n",
      "Epoch: 201/500... Training loss: 0.0792\n",
      "Epoch: 201/500... Training loss: 0.0422\n",
      "Epoch: 201/500... Training loss: 0.0303\n",
      "Epoch: 201/500... Training loss: 0.0397\n",
      "Epoch: 201/500... Training loss: 0.0645\n",
      "Epoch: 201/500... Training loss: 0.0546\n",
      "Epoch: 201/500... Training loss: 0.0834\n",
      "Epoch: 201/500... Training loss: 0.0124\n",
      "Epoch: 201/500... Training loss: 0.0432\n",
      "Epoch: 201/500... Training loss: 0.0332\n",
      "Epoch: 201/500... Training loss: 0.0246\n",
      "Epoch: 201/500... Training loss: 0.0616\n",
      "Epoch: 201/500... Training loss: 0.0972\n",
      "Epoch: 201/500... Training loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/500... Training loss: 0.0434\n",
      "Epoch: 201/500... Training loss: 0.0623\n",
      "Epoch: 201/500... Training loss: 0.0469\n",
      "Epoch: 201/500... Training loss: 0.0779\n",
      "Epoch: 201/500... Training loss: 0.0336\n",
      "Epoch: 201/500... Training loss: 0.0275\n",
      "Epoch: 201/500... Training loss: 0.0388\n",
      "Epoch: 201/500... Training loss: 0.0142\n",
      "Epoch: 201/500... Training loss: 0.0302\n",
      "Epoch: 201/500... Training loss: 0.0290\n",
      "Epoch: 201/500... Training loss: 0.0121\n",
      "Epoch: 201/500... Training loss: 0.0050\n",
      "Epoch: 202/500... Training loss: 0.0411\n",
      "Epoch: 202/500... Training loss: 0.1044\n",
      "Epoch: 202/500... Training loss: 0.0430\n",
      "Epoch: 202/500... Training loss: 0.2102\n",
      "Epoch: 202/500... Training loss: 0.0697\n",
      "Epoch: 202/500... Training loss: 0.1626\n",
      "Epoch: 202/500... Training loss: 0.1005\n",
      "Epoch: 202/500... Training loss: 0.0185\n",
      "Epoch: 202/500... Training loss: 0.0466\n",
      "Epoch: 202/500... Training loss: 0.0707\n",
      "Epoch: 202/500... Training loss: 0.0204\n",
      "Epoch: 202/500... Training loss: 0.0248\n",
      "Epoch: 202/500... Training loss: 0.0351\n",
      "Epoch: 202/500... Training loss: 0.0508\n",
      "Epoch: 202/500... Training loss: 0.0533\n",
      "Epoch: 202/500... Training loss: 0.0113\n",
      "Epoch: 202/500... Training loss: 0.0092\n",
      "Epoch: 202/500... Training loss: 0.1061\n",
      "Epoch: 202/500... Training loss: 0.0367\n",
      "Epoch: 202/500... Training loss: 0.0267\n",
      "Epoch: 202/500... Training loss: 0.0308\n",
      "Epoch: 202/500... Training loss: 0.0410\n",
      "Epoch: 202/500... Training loss: 0.0775\n",
      "Epoch: 202/500... Training loss: 0.0816\n",
      "Epoch: 202/500... Training loss: 0.0257\n",
      "Epoch: 202/500... Training loss: 0.0403\n",
      "Epoch: 202/500... Training loss: 0.0405\n",
      "Epoch: 202/500... Training loss: 0.0066\n",
      "Epoch: 202/500... Training loss: 0.0368\n",
      "Epoch: 202/500... Training loss: 0.0623\n",
      "Epoch: 202/500... Training loss: 0.0557\n",
      "Epoch: 203/500... Training loss: 0.0717\n",
      "Epoch: 203/500... Training loss: 0.0224\n",
      "Epoch: 203/500... Training loss: 0.0389\n",
      "Epoch: 203/500... Training loss: 0.0693\n",
      "Epoch: 203/500... Training loss: 0.0965\n",
      "Epoch: 203/500... Training loss: 0.0422\n",
      "Epoch: 203/500... Training loss: 0.0740\n",
      "Epoch: 203/500... Training loss: 0.0325\n",
      "Epoch: 203/500... Training loss: 0.0561\n",
      "Epoch: 203/500... Training loss: 0.0295\n",
      "Epoch: 203/500... Training loss: 0.0172\n",
      "Epoch: 203/500... Training loss: 0.0640\n",
      "Epoch: 203/500... Training loss: 0.0756\n",
      "Epoch: 203/500... Training loss: 0.0322\n",
      "Epoch: 203/500... Training loss: 0.1156\n",
      "Epoch: 203/500... Training loss: 0.0643\n",
      "Epoch: 203/500... Training loss: 0.0736\n",
      "Epoch: 203/500... Training loss: 0.0656\n",
      "Epoch: 203/500... Training loss: 0.0276\n",
      "Epoch: 203/500... Training loss: 0.0600\n",
      "Epoch: 203/500... Training loss: 0.0383\n",
      "Epoch: 203/500... Training loss: 0.0492\n",
      "Epoch: 203/500... Training loss: 0.1287\n",
      "Epoch: 203/500... Training loss: 0.0513\n",
      "Epoch: 203/500... Training loss: 0.1250\n",
      "Epoch: 203/500... Training loss: 0.0149\n",
      "Epoch: 203/500... Training loss: 0.0264\n",
      "Epoch: 203/500... Training loss: 0.0273\n",
      "Epoch: 203/500... Training loss: 0.0279\n",
      "Epoch: 203/500... Training loss: 0.0457\n",
      "Epoch: 203/500... Training loss: 0.0169\n",
      "Epoch: 204/500... Training loss: 0.1282\n",
      "Epoch: 204/500... Training loss: 0.0532\n",
      "Epoch: 204/500... Training loss: 0.0501\n",
      "Epoch: 204/500... Training loss: 0.0428\n",
      "Epoch: 204/500... Training loss: 0.0611\n",
      "Epoch: 204/500... Training loss: 0.1198\n",
      "Epoch: 204/500... Training loss: 0.0668\n",
      "Epoch: 204/500... Training loss: 0.1239\n",
      "Epoch: 204/500... Training loss: 0.0722\n",
      "Epoch: 204/500... Training loss: 0.0465\n",
      "Epoch: 204/500... Training loss: 0.0161\n",
      "Epoch: 204/500... Training loss: 0.0625\n",
      "Epoch: 204/500... Training loss: 0.0354\n",
      "Epoch: 204/500... Training loss: 0.0245\n",
      "Epoch: 204/500... Training loss: 0.0980\n",
      "Epoch: 204/500... Training loss: 0.0668\n",
      "Epoch: 204/500... Training loss: 0.0702\n",
      "Epoch: 204/500... Training loss: 0.0555\n",
      "Epoch: 204/500... Training loss: 0.0546\n",
      "Epoch: 204/500... Training loss: 0.0396\n",
      "Epoch: 204/500... Training loss: 0.0287\n",
      "Epoch: 204/500... Training loss: 0.0298\n",
      "Epoch: 204/500... Training loss: 0.1430\n",
      "Epoch: 204/500... Training loss: 0.0458\n",
      "Epoch: 204/500... Training loss: 0.0176\n",
      "Epoch: 204/500... Training loss: 0.0645\n",
      "Epoch: 204/500... Training loss: 0.0270\n",
      "Epoch: 204/500... Training loss: 0.0103\n",
      "Epoch: 204/500... Training loss: 0.0323\n",
      "Epoch: 204/500... Training loss: 0.0222\n",
      "Epoch: 204/500... Training loss: 0.0219\n",
      "Epoch: 205/500... Training loss: 0.0539\n",
      "Epoch: 205/500... Training loss: 0.0142\n",
      "Epoch: 205/500... Training loss: 0.0632\n",
      "Epoch: 205/500... Training loss: 0.0475\n",
      "Epoch: 205/500... Training loss: 0.0512\n",
      "Epoch: 205/500... Training loss: 0.1280\n",
      "Epoch: 205/500... Training loss: 0.1135\n",
      "Epoch: 205/500... Training loss: 0.0136\n",
      "Epoch: 205/500... Training loss: 0.0378\n",
      "Epoch: 205/500... Training loss: 0.0203\n",
      "Epoch: 205/500... Training loss: 0.0078\n",
      "Epoch: 205/500... Training loss: 0.0734\n",
      "Epoch: 205/500... Training loss: 0.1183\n",
      "Epoch: 205/500... Training loss: 0.0434\n",
      "Epoch: 205/500... Training loss: 0.0577\n",
      "Epoch: 205/500... Training loss: 0.0158\n",
      "Epoch: 205/500... Training loss: 0.0799\n",
      "Epoch: 205/500... Training loss: 0.1097\n",
      "Epoch: 205/500... Training loss: 0.0684\n",
      "Epoch: 205/500... Training loss: 0.0196\n",
      "Epoch: 205/500... Training loss: 0.0489\n",
      "Epoch: 205/500... Training loss: 0.0547\n",
      "Epoch: 205/500... Training loss: 0.1179\n",
      "Epoch: 205/500... Training loss: 0.0157\n",
      "Epoch: 205/500... Training loss: 0.2273\n",
      "Epoch: 205/500... Training loss: 0.0514\n",
      "Epoch: 205/500... Training loss: 0.0256\n",
      "Epoch: 205/500... Training loss: 0.0631\n",
      "Epoch: 205/500... Training loss: 0.0844\n",
      "Epoch: 205/500... Training loss: 0.0489\n",
      "Epoch: 205/500... Training loss: 0.0164\n",
      "Epoch: 206/500... Training loss: 0.0843\n",
      "Epoch: 206/500... Training loss: 0.0153\n",
      "Epoch: 206/500... Training loss: 0.0185\n",
      "Epoch: 206/500... Training loss: 0.0241\n",
      "Epoch: 206/500... Training loss: 0.0383\n",
      "Epoch: 206/500... Training loss: 0.1674\n",
      "Epoch: 206/500... Training loss: 0.1883\n",
      "Epoch: 206/500... Training loss: 0.0601\n",
      "Epoch: 206/500... Training loss: 0.0587\n",
      "Epoch: 206/500... Training loss: 0.0127\n",
      "Epoch: 206/500... Training loss: 0.0253\n",
      "Epoch: 206/500... Training loss: 0.0436\n",
      "Epoch: 206/500... Training loss: 0.0992\n",
      "Epoch: 206/500... Training loss: 0.0451\n",
      "Epoch: 206/500... Training loss: 0.0407\n",
      "Epoch: 206/500... Training loss: 0.0448\n",
      "Epoch: 206/500... Training loss: 0.0318\n",
      "Epoch: 206/500... Training loss: 0.0693\n",
      "Epoch: 206/500... Training loss: 0.0450\n",
      "Epoch: 206/500... Training loss: 0.0151\n",
      "Epoch: 206/500... Training loss: 0.0460\n",
      "Epoch: 206/500... Training loss: 0.0836\n",
      "Epoch: 206/500... Training loss: 0.0190\n",
      "Epoch: 206/500... Training loss: 0.1734\n",
      "Epoch: 206/500... Training loss: 0.0231\n",
      "Epoch: 206/500... Training loss: 0.0081\n",
      "Epoch: 206/500... Training loss: 0.1198\n",
      "Epoch: 206/500... Training loss: 0.0211\n",
      "Epoch: 206/500... Training loss: 0.0660\n",
      "Epoch: 206/500... Training loss: 0.0213\n",
      "Epoch: 206/500... Training loss: 0.0098\n",
      "Epoch: 207/500... Training loss: 0.0640\n",
      "Epoch: 207/500... Training loss: 0.0314\n",
      "Epoch: 207/500... Training loss: 0.0307\n",
      "Epoch: 207/500... Training loss: 0.0331\n",
      "Epoch: 207/500... Training loss: 0.0885\n",
      "Epoch: 207/500... Training loss: 0.0182\n",
      "Epoch: 207/500... Training loss: 0.0469\n",
      "Epoch: 207/500... Training loss: 0.0750\n",
      "Epoch: 207/500... Training loss: 0.0363\n",
      "Epoch: 207/500... Training loss: 0.0434\n",
      "Epoch: 207/500... Training loss: 0.1350\n",
      "Epoch: 207/500... Training loss: 0.0360\n",
      "Epoch: 207/500... Training loss: 0.0950\n",
      "Epoch: 207/500... Training loss: 0.0135\n",
      "Epoch: 207/500... Training loss: 0.0444\n",
      "Epoch: 207/500... Training loss: 0.0196\n",
      "Epoch: 207/500... Training loss: 0.0196\n",
      "Epoch: 207/500... Training loss: 0.0205\n",
      "Epoch: 207/500... Training loss: 0.0266\n",
      "Epoch: 207/500... Training loss: 0.0242\n",
      "Epoch: 207/500... Training loss: 0.0349\n",
      "Epoch: 207/500... Training loss: 0.0433\n",
      "Epoch: 207/500... Training loss: 0.0802\n",
      "Epoch: 207/500... Training loss: 0.0455\n",
      "Epoch: 207/500... Training loss: 0.0406\n",
      "Epoch: 207/500... Training loss: 0.0194\n",
      "Epoch: 207/500... Training loss: 0.0398\n",
      "Epoch: 207/500... Training loss: 0.0186\n",
      "Epoch: 207/500... Training loss: 0.0216\n",
      "Epoch: 207/500... Training loss: 0.0312\n",
      "Epoch: 207/500... Training loss: 0.0264\n",
      "Epoch: 208/500... Training loss: 0.0441\n",
      "Epoch: 208/500... Training loss: 0.0174\n",
      "Epoch: 208/500... Training loss: 0.0953\n",
      "Epoch: 208/500... Training loss: 0.0201\n",
      "Epoch: 208/500... Training loss: 0.0333\n",
      "Epoch: 208/500... Training loss: 0.0252\n",
      "Epoch: 208/500... Training loss: 0.0599\n",
      "Epoch: 208/500... Training loss: 0.0365\n",
      "Epoch: 208/500... Training loss: 0.0345\n",
      "Epoch: 208/500... Training loss: 0.0862\n",
      "Epoch: 208/500... Training loss: 0.0550\n",
      "Epoch: 208/500... Training loss: 0.0356\n",
      "Epoch: 208/500... Training loss: 0.0434\n",
      "Epoch: 208/500... Training loss: 0.0202\n",
      "Epoch: 208/500... Training loss: 0.0453\n",
      "Epoch: 208/500... Training loss: 0.0341\n",
      "Epoch: 208/500... Training loss: 0.0267\n",
      "Epoch: 208/500... Training loss: 0.0221\n",
      "Epoch: 208/500... Training loss: 0.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208/500... Training loss: 0.0091\n",
      "Epoch: 208/500... Training loss: 0.0082\n",
      "Epoch: 208/500... Training loss: 0.0405\n",
      "Epoch: 208/500... Training loss: 0.0333\n",
      "Epoch: 208/500... Training loss: 0.0126\n",
      "Epoch: 208/500... Training loss: 0.1162\n",
      "Epoch: 208/500... Training loss: 0.0145\n",
      "Epoch: 208/500... Training loss: 0.0887\n",
      "Epoch: 208/500... Training loss: 0.0076\n",
      "Epoch: 208/500... Training loss: 0.0533\n",
      "Epoch: 208/500... Training loss: 0.0113\n",
      "Epoch: 208/500... Training loss: 0.0515\n",
      "Epoch: 209/500... Training loss: 0.0470\n",
      "Epoch: 209/500... Training loss: 0.0094\n",
      "Epoch: 209/500... Training loss: 0.1110\n",
      "Epoch: 209/500... Training loss: 0.0260\n",
      "Epoch: 209/500... Training loss: 0.0131\n",
      "Epoch: 209/500... Training loss: 0.0552\n",
      "Epoch: 209/500... Training loss: 0.0611\n",
      "Epoch: 209/500... Training loss: 0.0379\n",
      "Epoch: 209/500... Training loss: 0.0202\n",
      "Epoch: 209/500... Training loss: 0.0365\n",
      "Epoch: 209/500... Training loss: 0.1555\n",
      "Epoch: 209/500... Training loss: 0.0739\n",
      "Epoch: 209/500... Training loss: 0.0881\n",
      "Epoch: 209/500... Training loss: 0.0249\n",
      "Epoch: 209/500... Training loss: 0.0094\n",
      "Epoch: 209/500... Training loss: 0.0220\n",
      "Epoch: 209/500... Training loss: 0.0139\n",
      "Epoch: 209/500... Training loss: 0.0783\n",
      "Epoch: 209/500... Training loss: 0.0583\n",
      "Epoch: 209/500... Training loss: 0.0656\n",
      "Epoch: 209/500... Training loss: 0.0512\n",
      "Epoch: 209/500... Training loss: 0.1211\n",
      "Epoch: 209/500... Training loss: 0.0742\n",
      "Epoch: 209/500... Training loss: 0.0447\n",
      "Epoch: 209/500... Training loss: 0.0290\n",
      "Epoch: 209/500... Training loss: 0.0398\n",
      "Epoch: 209/500... Training loss: 0.0153\n",
      "Epoch: 209/500... Training loss: 0.0205\n",
      "Epoch: 209/500... Training loss: 0.0391\n",
      "Epoch: 209/500... Training loss: 0.0501\n",
      "Epoch: 209/500... Training loss: 0.0222\n",
      "Epoch: 210/500... Training loss: 0.0563\n",
      "Epoch: 210/500... Training loss: 0.0149\n",
      "Epoch: 210/500... Training loss: 0.1968\n",
      "Epoch: 210/500... Training loss: 0.1128\n",
      "Epoch: 210/500... Training loss: 0.0681\n",
      "Epoch: 210/500... Training loss: 0.0438\n",
      "Epoch: 210/500... Training loss: 0.0913\n",
      "Epoch: 210/500... Training loss: 0.0838\n",
      "Epoch: 210/500... Training loss: 0.0638\n",
      "Epoch: 210/500... Training loss: 0.0375\n",
      "Epoch: 210/500... Training loss: 0.1776\n",
      "Epoch: 210/500... Training loss: 0.0086\n",
      "Epoch: 210/500... Training loss: 0.0137\n",
      "Epoch: 210/500... Training loss: 0.0356\n",
      "Epoch: 210/500... Training loss: 0.0484\n",
      "Epoch: 210/500... Training loss: 0.0099\n",
      "Epoch: 210/500... Training loss: 0.0517\n",
      "Epoch: 210/500... Training loss: 0.1162\n",
      "Epoch: 210/500... Training loss: 0.0314\n",
      "Epoch: 210/500... Training loss: 0.0205\n",
      "Epoch: 210/500... Training loss: 0.0430\n",
      "Epoch: 210/500... Training loss: 0.0329\n",
      "Epoch: 210/500... Training loss: 0.0487\n",
      "Epoch: 210/500... Training loss: 0.0324\n",
      "Epoch: 210/500... Training loss: 0.0279\n",
      "Epoch: 210/500... Training loss: 0.0150\n",
      "Epoch: 210/500... Training loss: 0.0999\n",
      "Epoch: 210/500... Training loss: 0.0307\n",
      "Epoch: 210/500... Training loss: 0.0614\n",
      "Epoch: 210/500... Training loss: 0.0341\n",
      "Epoch: 210/500... Training loss: 0.0170\n",
      "Epoch: 211/500... Training loss: 0.0606\n",
      "Epoch: 211/500... Training loss: 0.0228\n",
      "Epoch: 211/500... Training loss: 0.0374\n",
      "Epoch: 211/500... Training loss: 0.0729\n",
      "Epoch: 211/500... Training loss: 0.0642\n",
      "Epoch: 211/500... Training loss: 0.0500\n",
      "Epoch: 211/500... Training loss: 0.0329\n",
      "Epoch: 211/500... Training loss: 0.1365\n",
      "Epoch: 211/500... Training loss: 0.0596\n",
      "Epoch: 211/500... Training loss: 0.0345\n",
      "Epoch: 211/500... Training loss: 0.1074\n",
      "Epoch: 211/500... Training loss: 0.0443\n",
      "Epoch: 211/500... Training loss: 0.0239\n",
      "Epoch: 211/500... Training loss: 0.0169\n",
      "Epoch: 211/500... Training loss: 0.0385\n",
      "Epoch: 211/500... Training loss: 0.0141\n",
      "Epoch: 211/500... Training loss: 0.0246\n",
      "Epoch: 211/500... Training loss: 0.0167\n",
      "Epoch: 211/500... Training loss: 0.0077\n",
      "Epoch: 211/500... Training loss: 0.0830\n",
      "Epoch: 211/500... Training loss: 0.0565\n",
      "Epoch: 211/500... Training loss: 0.0090\n",
      "Epoch: 211/500... Training loss: 0.0643\n",
      "Epoch: 211/500... Training loss: 0.0327\n",
      "Epoch: 211/500... Training loss: 0.0381\n",
      "Epoch: 211/500... Training loss: 0.0279\n",
      "Epoch: 211/500... Training loss: 0.0652\n",
      "Epoch: 211/500... Training loss: 0.0415\n",
      "Epoch: 211/500... Training loss: 0.0120\n",
      "Epoch: 211/500... Training loss: 0.0227\n",
      "Epoch: 211/500... Training loss: 0.0247\n",
      "Epoch: 212/500... Training loss: 0.0669\n",
      "Epoch: 212/500... Training loss: 0.0153\n",
      "Epoch: 212/500... Training loss: 0.0266\n",
      "Epoch: 212/500... Training loss: 0.0695\n",
      "Epoch: 212/500... Training loss: 0.0271\n",
      "Epoch: 212/500... Training loss: 0.0609\n",
      "Epoch: 212/500... Training loss: 0.0614\n",
      "Epoch: 212/500... Training loss: 0.0141\n",
      "Epoch: 212/500... Training loss: 0.0511\n",
      "Epoch: 212/500... Training loss: 0.0705\n",
      "Epoch: 212/500... Training loss: 0.0550\n",
      "Epoch: 212/500... Training loss: 0.0743\n",
      "Epoch: 212/500... Training loss: 0.0326\n",
      "Epoch: 212/500... Training loss: 0.0537\n",
      "Epoch: 212/500... Training loss: 0.0252\n",
      "Epoch: 212/500... Training loss: 0.0107\n",
      "Epoch: 212/500... Training loss: 0.0706\n",
      "Epoch: 212/500... Training loss: 0.0573\n",
      "Epoch: 212/500... Training loss: 0.0147\n",
      "Epoch: 212/500... Training loss: 0.0590\n",
      "Epoch: 212/500... Training loss: 0.0464\n",
      "Epoch: 212/500... Training loss: 0.0464\n",
      "Epoch: 212/500... Training loss: 0.0856\n",
      "Epoch: 212/500... Training loss: 0.1132\n",
      "Epoch: 212/500... Training loss: 0.0084\n",
      "Epoch: 212/500... Training loss: 0.0109\n",
      "Epoch: 212/500... Training loss: 0.1448\n",
      "Epoch: 212/500... Training loss: 0.0398\n",
      "Epoch: 212/500... Training loss: 0.0633\n",
      "Epoch: 212/500... Training loss: 0.0184\n",
      "Epoch: 212/500... Training loss: 0.0697\n",
      "Epoch: 213/500... Training loss: 0.1489\n",
      "Epoch: 213/500... Training loss: 0.0367\n",
      "Epoch: 213/500... Training loss: 0.0425\n",
      "Epoch: 213/500... Training loss: 0.0387\n",
      "Epoch: 213/500... Training loss: 0.1179\n",
      "Epoch: 213/500... Training loss: 0.0426\n",
      "Epoch: 213/500... Training loss: 0.0185\n",
      "Epoch: 213/500... Training loss: 0.1209\n",
      "Epoch: 213/500... Training loss: 0.0214\n",
      "Epoch: 213/500... Training loss: 0.0717\n",
      "Epoch: 213/500... Training loss: 0.1220\n",
      "Epoch: 213/500... Training loss: 0.1273\n",
      "Epoch: 213/500... Training loss: 0.0300\n",
      "Epoch: 213/500... Training loss: 0.0192\n",
      "Epoch: 213/500... Training loss: 0.0336\n",
      "Epoch: 213/500... Training loss: 0.0141\n",
      "Epoch: 213/500... Training loss: 0.0279\n",
      "Epoch: 213/500... Training loss: 0.0094\n",
      "Epoch: 213/500... Training loss: 0.0340\n",
      "Epoch: 213/500... Training loss: 0.0159\n",
      "Epoch: 213/500... Training loss: 0.0253\n",
      "Epoch: 213/500... Training loss: 0.0223\n",
      "Epoch: 213/500... Training loss: 0.0268\n",
      "Epoch: 213/500... Training loss: 0.0284\n",
      "Epoch: 213/500... Training loss: 0.0697\n",
      "Epoch: 213/500... Training loss: 0.0145\n",
      "Epoch: 213/500... Training loss: 0.0261\n",
      "Epoch: 213/500... Training loss: 0.0318\n",
      "Epoch: 213/500... Training loss: 0.0595\n",
      "Epoch: 213/500... Training loss: 0.0663\n",
      "Epoch: 213/500... Training loss: 0.0418\n",
      "Epoch: 214/500... Training loss: 0.0183\n",
      "Epoch: 214/500... Training loss: 0.0773\n",
      "Epoch: 214/500... Training loss: 0.1542\n",
      "Epoch: 214/500... Training loss: 0.0917\n",
      "Epoch: 214/500... Training loss: 0.0682\n",
      "Epoch: 214/500... Training loss: 0.0390\n",
      "Epoch: 214/500... Training loss: 0.0149\n",
      "Epoch: 214/500... Training loss: 0.0403\n",
      "Epoch: 214/500... Training loss: 0.0648\n",
      "Epoch: 214/500... Training loss: 0.0664\n",
      "Epoch: 214/500... Training loss: 0.0361\n",
      "Epoch: 214/500... Training loss: 0.0566\n",
      "Epoch: 214/500... Training loss: 0.0378\n",
      "Epoch: 214/500... Training loss: 0.0571\n",
      "Epoch: 214/500... Training loss: 0.0598\n",
      "Epoch: 214/500... Training loss: 0.0333\n",
      "Epoch: 214/500... Training loss: 0.0551\n",
      "Epoch: 214/500... Training loss: 0.0430\n",
      "Epoch: 214/500... Training loss: 0.0735\n",
      "Epoch: 214/500... Training loss: 0.1032\n",
      "Epoch: 214/500... Training loss: 0.0394\n",
      "Epoch: 214/500... Training loss: 0.0607\n",
      "Epoch: 214/500... Training loss: 0.1606\n",
      "Epoch: 214/500... Training loss: 0.2193\n",
      "Epoch: 214/500... Training loss: 0.0121\n",
      "Epoch: 214/500... Training loss: 0.0397\n",
      "Epoch: 214/500... Training loss: 0.0975\n",
      "Epoch: 214/500... Training loss: 0.0137\n",
      "Epoch: 214/500... Training loss: 0.0633\n",
      "Epoch: 214/500... Training loss: 0.0683\n",
      "Epoch: 214/500... Training loss: 0.1096\n",
      "Epoch: 215/500... Training loss: 0.0864\n",
      "Epoch: 215/500... Training loss: 0.0757\n",
      "Epoch: 215/500... Training loss: 0.0286\n",
      "Epoch: 215/500... Training loss: 0.0368\n",
      "Epoch: 215/500... Training loss: 0.0329\n",
      "Epoch: 215/500... Training loss: 0.1331\n",
      "Epoch: 215/500... Training loss: 0.0077\n",
      "Epoch: 215/500... Training loss: 0.0221\n",
      "Epoch: 215/500... Training loss: 0.0330\n",
      "Epoch: 215/500... Training loss: 0.0289\n",
      "Epoch: 215/500... Training loss: 0.0782\n",
      "Epoch: 215/500... Training loss: 0.0160\n",
      "Epoch: 215/500... Training loss: 0.0361\n",
      "Epoch: 215/500... Training loss: 0.0574\n",
      "Epoch: 215/500... Training loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 215/500... Training loss: 0.0354\n",
      "Epoch: 215/500... Training loss: 0.0383\n",
      "Epoch: 215/500... Training loss: 0.0666\n",
      "Epoch: 215/500... Training loss: 0.1005\n",
      "Epoch: 215/500... Training loss: 0.0058\n",
      "Epoch: 215/500... Training loss: 0.0322\n",
      "Epoch: 215/500... Training loss: 0.0382\n",
      "Epoch: 215/500... Training loss: 0.0516\n",
      "Epoch: 215/500... Training loss: 0.1817\n",
      "Epoch: 215/500... Training loss: 0.0584\n",
      "Epoch: 215/500... Training loss: 0.1535\n",
      "Epoch: 215/500... Training loss: 0.0812\n",
      "Epoch: 215/500... Training loss: 0.0569\n",
      "Epoch: 215/500... Training loss: 0.0586\n",
      "Epoch: 215/500... Training loss: 0.0235\n",
      "Epoch: 215/500... Training loss: 0.0478\n",
      "Epoch: 216/500... Training loss: 0.0248\n",
      "Epoch: 216/500... Training loss: 0.0669\n",
      "Epoch: 216/500... Training loss: 0.0101\n",
      "Epoch: 216/500... Training loss: 0.0266\n",
      "Epoch: 216/500... Training loss: 0.1121\n",
      "Epoch: 216/500... Training loss: 0.0276\n",
      "Epoch: 216/500... Training loss: 0.0208\n",
      "Epoch: 216/500... Training loss: 0.0617\n",
      "Epoch: 216/500... Training loss: 0.1056\n",
      "Epoch: 216/500... Training loss: 0.0699\n",
      "Epoch: 216/500... Training loss: 0.0305\n",
      "Epoch: 216/500... Training loss: 0.0269\n",
      "Epoch: 216/500... Training loss: 0.3147\n",
      "Epoch: 216/500... Training loss: 0.0841\n",
      "Epoch: 216/500... Training loss: 0.1045\n",
      "Epoch: 216/500... Training loss: 0.0287\n",
      "Epoch: 216/500... Training loss: 0.0400\n",
      "Epoch: 216/500... Training loss: 0.0150\n",
      "Epoch: 216/500... Training loss: 0.1202\n",
      "Epoch: 216/500... Training loss: 0.0672\n",
      "Epoch: 216/500... Training loss: 0.0108\n",
      "Epoch: 216/500... Training loss: 0.0571\n",
      "Epoch: 216/500... Training loss: 0.0549\n",
      "Epoch: 216/500... Training loss: 0.1376\n",
      "Epoch: 216/500... Training loss: 0.0822\n",
      "Epoch: 216/500... Training loss: 0.0168\n",
      "Epoch: 216/500... Training loss: 0.0975\n",
      "Epoch: 216/500... Training loss: 0.0408\n",
      "Epoch: 216/500... Training loss: 0.0116\n",
      "Epoch: 216/500... Training loss: 0.0734\n",
      "Epoch: 216/500... Training loss: 0.0109\n",
      "Epoch: 217/500... Training loss: 0.0129\n",
      "Epoch: 217/500... Training loss: 0.1069\n",
      "Epoch: 217/500... Training loss: 0.0349\n",
      "Epoch: 217/500... Training loss: 0.0348\n",
      "Epoch: 217/500... Training loss: 0.0625\n",
      "Epoch: 217/500... Training loss: 0.1832\n",
      "Epoch: 217/500... Training loss: 0.0957\n",
      "Epoch: 217/500... Training loss: 0.0650\n",
      "Epoch: 217/500... Training loss: 0.0381\n",
      "Epoch: 217/500... Training loss: 0.0455\n",
      "Epoch: 217/500... Training loss: 0.0905\n",
      "Epoch: 217/500... Training loss: 0.0706\n",
      "Epoch: 217/500... Training loss: 0.0961\n",
      "Epoch: 217/500... Training loss: 0.0078\n",
      "Epoch: 217/500... Training loss: 0.0307\n",
      "Epoch: 217/500... Training loss: 0.0102\n",
      "Epoch: 217/500... Training loss: 0.0198\n",
      "Epoch: 217/500... Training loss: 0.0160\n",
      "Epoch: 217/500... Training loss: 0.0455\n",
      "Epoch: 217/500... Training loss: 0.0539\n",
      "Epoch: 217/500... Training loss: 0.0246\n",
      "Epoch: 217/500... Training loss: 0.0447\n",
      "Epoch: 217/500... Training loss: 0.0554\n",
      "Epoch: 217/500... Training loss: 0.0075\n",
      "Epoch: 217/500... Training loss: 0.0644\n",
      "Epoch: 217/500... Training loss: 0.0276\n",
      "Epoch: 217/500... Training loss: 0.0196\n",
      "Epoch: 217/500... Training loss: 0.0975\n",
      "Epoch: 217/500... Training loss: 0.0247\n",
      "Epoch: 217/500... Training loss: 0.0494\n",
      "Epoch: 217/500... Training loss: 0.0189\n",
      "Epoch: 218/500... Training loss: 0.0292\n",
      "Epoch: 218/500... Training loss: 0.0318\n",
      "Epoch: 218/500... Training loss: 0.0316\n",
      "Epoch: 218/500... Training loss: 0.0429\n",
      "Epoch: 218/500... Training loss: 0.0139\n",
      "Epoch: 218/500... Training loss: 0.0215\n",
      "Epoch: 218/500... Training loss: 0.0474\n",
      "Epoch: 218/500... Training loss: 0.0254\n",
      "Epoch: 218/500... Training loss: 0.1209\n",
      "Epoch: 218/500... Training loss: 0.0474\n",
      "Epoch: 218/500... Training loss: 0.1680\n",
      "Epoch: 218/500... Training loss: 0.0367\n",
      "Epoch: 218/500... Training loss: 0.0537\n",
      "Epoch: 218/500... Training loss: 0.0181\n",
      "Epoch: 218/500... Training loss: 0.0348\n",
      "Epoch: 218/500... Training loss: 0.0133\n",
      "Epoch: 218/500... Training loss: 0.0436\n",
      "Epoch: 218/500... Training loss: 0.0178\n",
      "Epoch: 218/500... Training loss: 0.0872\n",
      "Epoch: 218/500... Training loss: 0.0350\n",
      "Epoch: 218/500... Training loss: 0.0325\n",
      "Epoch: 218/500... Training loss: 0.0305\n",
      "Epoch: 218/500... Training loss: 0.0271\n",
      "Epoch: 218/500... Training loss: 0.0562\n",
      "Epoch: 218/500... Training loss: 0.0088\n",
      "Epoch: 218/500... Training loss: 0.0333\n",
      "Epoch: 218/500... Training loss: 0.1279\n",
      "Epoch: 218/500... Training loss: 0.0511\n",
      "Epoch: 218/500... Training loss: 0.0114\n",
      "Epoch: 218/500... Training loss: 0.0354\n",
      "Epoch: 218/500... Training loss: 0.0091\n",
      "Epoch: 219/500... Training loss: 0.1230\n",
      "Epoch: 219/500... Training loss: 0.1228\n",
      "Epoch: 219/500... Training loss: 0.0617\n",
      "Epoch: 219/500... Training loss: 0.0855\n",
      "Epoch: 219/500... Training loss: 0.0542\n",
      "Epoch: 219/500... Training loss: 0.0877\n",
      "Epoch: 219/500... Training loss: 0.0648\n",
      "Epoch: 219/500... Training loss: 0.0669\n",
      "Epoch: 219/500... Training loss: 0.0561\n",
      "Epoch: 219/500... Training loss: 0.0343\n",
      "Epoch: 219/500... Training loss: 0.0773\n",
      "Epoch: 219/500... Training loss: 0.0622\n",
      "Epoch: 219/500... Training loss: 0.0683\n",
      "Epoch: 219/500... Training loss: 0.0376\n",
      "Epoch: 219/500... Training loss: 0.0430\n",
      "Epoch: 219/500... Training loss: 0.0376\n",
      "Epoch: 219/500... Training loss: 0.0961\n",
      "Epoch: 219/500... Training loss: 0.0346\n",
      "Epoch: 219/500... Training loss: 0.0164\n",
      "Epoch: 219/500... Training loss: 0.0939\n",
      "Epoch: 219/500... Training loss: 0.1164\n",
      "Epoch: 219/500... Training loss: 0.0287\n",
      "Epoch: 219/500... Training loss: 0.0950\n",
      "Epoch: 219/500... Training loss: 0.0261\n",
      "Epoch: 219/500... Training loss: 0.0301\n",
      "Epoch: 219/500... Training loss: 0.0267\n",
      "Epoch: 219/500... Training loss: 0.0173\n",
      "Epoch: 219/500... Training loss: 0.0096\n",
      "Epoch: 219/500... Training loss: 0.0060\n",
      "Epoch: 219/500... Training loss: 0.0514\n",
      "Epoch: 219/500... Training loss: 0.0686\n",
      "Epoch: 220/500... Training loss: 0.0665\n",
      "Epoch: 220/500... Training loss: 0.0328\n",
      "Epoch: 220/500... Training loss: 0.0130\n",
      "Epoch: 220/500... Training loss: 0.0128\n",
      "Epoch: 220/500... Training loss: 0.0550\n",
      "Epoch: 220/500... Training loss: 0.0978\n",
      "Epoch: 220/500... Training loss: 0.0522\n",
      "Epoch: 220/500... Training loss: 0.0285\n",
      "Epoch: 220/500... Training loss: 0.0424\n",
      "Epoch: 220/500... Training loss: 0.1485\n",
      "Epoch: 220/500... Training loss: 0.1437\n",
      "Epoch: 220/500... Training loss: 0.2098\n",
      "Epoch: 220/500... Training loss: 0.0552\n",
      "Epoch: 220/500... Training loss: 0.0213\n",
      "Epoch: 220/500... Training loss: 0.0146\n",
      "Epoch: 220/500... Training loss: 0.0261\n",
      "Epoch: 220/500... Training loss: 0.0199\n",
      "Epoch: 220/500... Training loss: 0.0922\n",
      "Epoch: 220/500... Training loss: 0.0677\n",
      "Epoch: 220/500... Training loss: 0.0171\n",
      "Epoch: 220/500... Training loss: 0.0194\n",
      "Epoch: 220/500... Training loss: 0.0461\n",
      "Epoch: 220/500... Training loss: 0.0100\n",
      "Epoch: 220/500... Training loss: 0.0222\n",
      "Epoch: 220/500... Training loss: 0.1502\n",
      "Epoch: 220/500... Training loss: 0.0174\n",
      "Epoch: 220/500... Training loss: 0.0044\n",
      "Epoch: 220/500... Training loss: 0.0225\n",
      "Epoch: 220/500... Training loss: 0.0106\n",
      "Epoch: 220/500... Training loss: 0.0083\n",
      "Epoch: 220/500... Training loss: 0.0148\n",
      "Epoch: 221/500... Training loss: 0.0470\n",
      "Epoch: 221/500... Training loss: 0.0144\n",
      "Epoch: 221/500... Training loss: 0.0222\n",
      "Epoch: 221/500... Training loss: 0.0703\n",
      "Epoch: 221/500... Training loss: 0.0499\n",
      "Epoch: 221/500... Training loss: 0.0605\n",
      "Epoch: 221/500... Training loss: 0.1038\n",
      "Epoch: 221/500... Training loss: 0.0794\n",
      "Epoch: 221/500... Training loss: 0.0276\n",
      "Epoch: 221/500... Training loss: 0.0343\n",
      "Epoch: 221/500... Training loss: 0.0987\n",
      "Epoch: 221/500... Training loss: 0.0689\n",
      "Epoch: 221/500... Training loss: 0.0946\n",
      "Epoch: 221/500... Training loss: 0.0151\n",
      "Epoch: 221/500... Training loss: 0.0301\n",
      "Epoch: 221/500... Training loss: 0.0063\n",
      "Epoch: 221/500... Training loss: 0.0290\n",
      "Epoch: 221/500... Training loss: 0.0105\n",
      "Epoch: 221/500... Training loss: 0.0093\n",
      "Epoch: 221/500... Training loss: 0.0398\n",
      "Epoch: 221/500... Training loss: 0.0609\n",
      "Epoch: 221/500... Training loss: 0.1729\n",
      "Epoch: 221/500... Training loss: 0.0459\n",
      "Epoch: 221/500... Training loss: 0.0247\n",
      "Epoch: 221/500... Training loss: 0.0226\n",
      "Epoch: 221/500... Training loss: 0.0391\n",
      "Epoch: 221/500... Training loss: 0.0188\n",
      "Epoch: 221/500... Training loss: 0.0066\n",
      "Epoch: 221/500... Training loss: 0.0591\n",
      "Epoch: 221/500... Training loss: 0.0448\n",
      "Epoch: 221/500... Training loss: 0.0080\n",
      "Epoch: 222/500... Training loss: 0.0242\n",
      "Epoch: 222/500... Training loss: 0.0125\n",
      "Epoch: 222/500... Training loss: 0.0267\n",
      "Epoch: 222/500... Training loss: 0.0405\n",
      "Epoch: 222/500... Training loss: 0.0130\n",
      "Epoch: 222/500... Training loss: 0.0637\n",
      "Epoch: 222/500... Training loss: 0.0273\n",
      "Epoch: 222/500... Training loss: 0.0603\n",
      "Epoch: 222/500... Training loss: 0.0744\n",
      "Epoch: 222/500... Training loss: 0.0609\n",
      "Epoch: 222/500... Training loss: 0.0364\n",
      "Epoch: 222/500... Training loss: 0.1431\n",
      "Epoch: 222/500... Training loss: 0.1238\n",
      "Epoch: 222/500... Training loss: 0.0109\n",
      "Epoch: 222/500... Training loss: 0.0575\n",
      "Epoch: 222/500... Training loss: 0.0744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 222/500... Training loss: 0.0315\n",
      "Epoch: 222/500... Training loss: 0.0298\n",
      "Epoch: 222/500... Training loss: 0.0511\n",
      "Epoch: 222/500... Training loss: 0.0468\n",
      "Epoch: 222/500... Training loss: 0.0119\n",
      "Epoch: 222/500... Training loss: 0.0386\n",
      "Epoch: 222/500... Training loss: 0.0522\n",
      "Epoch: 222/500... Training loss: 0.0089\n",
      "Epoch: 222/500... Training loss: 0.1138\n",
      "Epoch: 222/500... Training loss: 0.0311\n",
      "Epoch: 222/500... Training loss: 0.0182\n",
      "Epoch: 222/500... Training loss: 0.0293\n",
      "Epoch: 222/500... Training loss: 0.0237\n",
      "Epoch: 222/500... Training loss: 0.0813\n",
      "Epoch: 222/500... Training loss: 0.0034\n",
      "Epoch: 223/500... Training loss: 0.1781\n",
      "Epoch: 223/500... Training loss: 0.0187\n",
      "Epoch: 223/500... Training loss: 0.0090\n",
      "Epoch: 223/500... Training loss: 0.0503\n",
      "Epoch: 223/500... Training loss: 0.0400\n",
      "Epoch: 223/500... Training loss: 0.0090\n",
      "Epoch: 223/500... Training loss: 0.0415\n",
      "Epoch: 223/500... Training loss: 0.0261\n",
      "Epoch: 223/500... Training loss: 0.0671\n",
      "Epoch: 223/500... Training loss: 0.0256\n",
      "Epoch: 223/500... Training loss: 0.0411\n",
      "Epoch: 223/500... Training loss: 0.0474\n",
      "Epoch: 223/500... Training loss: 0.1174\n",
      "Epoch: 223/500... Training loss: 0.0112\n",
      "Epoch: 223/500... Training loss: 0.0532\n",
      "Epoch: 223/500... Training loss: 0.0125\n",
      "Epoch: 223/500... Training loss: 0.0303\n",
      "Epoch: 223/500... Training loss: 0.0199\n",
      "Epoch: 223/500... Training loss: 0.0289\n",
      "Epoch: 223/500... Training loss: 0.0138\n",
      "Epoch: 223/500... Training loss: 0.0140\n",
      "Epoch: 223/500... Training loss: 0.0680\n",
      "Epoch: 223/500... Training loss: 0.0481\n",
      "Epoch: 223/500... Training loss: 0.0285\n",
      "Epoch: 223/500... Training loss: 0.0436\n",
      "Epoch: 223/500... Training loss: 0.0060\n",
      "Epoch: 223/500... Training loss: 0.0383\n",
      "Epoch: 223/500... Training loss: 0.0476\n",
      "Epoch: 223/500... Training loss: 0.0045\n",
      "Epoch: 223/500... Training loss: 0.0087\n",
      "Epoch: 223/500... Training loss: 0.0361\n",
      "Epoch: 224/500... Training loss: 0.0598\n",
      "Epoch: 224/500... Training loss: 0.0039\n",
      "Epoch: 224/500... Training loss: 0.0417\n",
      "Epoch: 224/500... Training loss: 0.0782\n",
      "Epoch: 224/500... Training loss: 0.0479\n",
      "Epoch: 224/500... Training loss: 0.0348\n",
      "Epoch: 224/500... Training loss: 0.0263\n",
      "Epoch: 224/500... Training loss: 0.0871\n",
      "Epoch: 224/500... Training loss: 0.0154\n",
      "Epoch: 224/500... Training loss: 0.0087\n",
      "Epoch: 224/500... Training loss: 0.1119\n",
      "Epoch: 224/500... Training loss: 0.1026\n",
      "Epoch: 224/500... Training loss: 0.0631\n",
      "Epoch: 224/500... Training loss: 0.0285\n",
      "Epoch: 224/500... Training loss: 0.0729\n",
      "Epoch: 224/500... Training loss: 0.0731\n",
      "Epoch: 224/500... Training loss: 0.0649\n",
      "Epoch: 224/500... Training loss: 0.1607\n",
      "Epoch: 224/500... Training loss: 0.1012\n",
      "Epoch: 224/500... Training loss: 0.0141\n",
      "Epoch: 224/500... Training loss: 0.0456\n",
      "Epoch: 224/500... Training loss: 0.0877\n",
      "Epoch: 224/500... Training loss: 0.1696\n",
      "Epoch: 224/500... Training loss: 0.0184\n",
      "Epoch: 224/500... Training loss: 0.0076\n",
      "Epoch: 224/500... Training loss: 0.0194\n",
      "Epoch: 224/500... Training loss: 0.0061\n",
      "Epoch: 224/500... Training loss: 0.0808\n",
      "Epoch: 224/500... Training loss: 0.0119\n",
      "Epoch: 224/500... Training loss: 0.0549\n",
      "Epoch: 224/500... Training loss: 0.0868\n",
      "Epoch: 225/500... Training loss: 0.0386\n",
      "Epoch: 225/500... Training loss: 0.0405\n",
      "Epoch: 225/500... Training loss: 0.0334\n",
      "Epoch: 225/500... Training loss: 0.0726\n",
      "Epoch: 225/500... Training loss: 0.0391\n",
      "Epoch: 225/500... Training loss: 0.0620\n",
      "Epoch: 225/500... Training loss: 0.0194\n",
      "Epoch: 225/500... Training loss: 0.0467\n",
      "Epoch: 225/500... Training loss: 0.0347\n",
      "Epoch: 225/500... Training loss: 0.0119\n",
      "Epoch: 225/500... Training loss: 0.0366\n",
      "Epoch: 225/500... Training loss: 0.0383\n",
      "Epoch: 225/500... Training loss: 0.0296\n",
      "Epoch: 225/500... Training loss: 0.0161\n",
      "Epoch: 225/500... Training loss: 0.0551\n",
      "Epoch: 225/500... Training loss: 0.0667\n",
      "Epoch: 225/500... Training loss: 0.0598\n",
      "Epoch: 225/500... Training loss: 0.0362\n",
      "Epoch: 225/500... Training loss: 0.0519\n",
      "Epoch: 225/500... Training loss: 0.0440\n",
      "Epoch: 225/500... Training loss: 0.1012\n",
      "Epoch: 225/500... Training loss: 0.0471\n",
      "Epoch: 225/500... Training loss: 0.0727\n",
      "Epoch: 225/500... Training loss: 0.0179\n",
      "Epoch: 225/500... Training loss: 0.0095\n",
      "Epoch: 225/500... Training loss: 0.0398\n",
      "Epoch: 225/500... Training loss: 0.0491\n",
      "Epoch: 225/500... Training loss: 0.1416\n",
      "Epoch: 225/500... Training loss: 0.0033\n",
      "Epoch: 225/500... Training loss: 0.0192\n",
      "Epoch: 225/500... Training loss: 0.1075\n",
      "Epoch: 226/500... Training loss: 0.0173\n",
      "Epoch: 226/500... Training loss: 0.0634\n",
      "Epoch: 226/500... Training loss: 0.0318\n",
      "Epoch: 226/500... Training loss: 0.0656\n",
      "Epoch: 226/500... Training loss: 0.0275\n",
      "Epoch: 226/500... Training loss: 0.0211\n",
      "Epoch: 226/500... Training loss: 0.0319\n",
      "Epoch: 226/500... Training loss: 0.0060\n",
      "Epoch: 226/500... Training loss: 0.0246\n",
      "Epoch: 226/500... Training loss: 0.0089\n",
      "Epoch: 226/500... Training loss: 0.0820\n",
      "Epoch: 226/500... Training loss: 0.0409\n",
      "Epoch: 226/500... Training loss: 0.0401\n",
      "Epoch: 226/500... Training loss: 0.1005\n",
      "Epoch: 226/500... Training loss: 0.0171\n",
      "Epoch: 226/500... Training loss: 0.0123\n",
      "Epoch: 226/500... Training loss: 0.0548\n",
      "Epoch: 226/500... Training loss: 0.0244\n",
      "Epoch: 226/500... Training loss: 0.0476\n",
      "Epoch: 226/500... Training loss: 0.0664\n",
      "Epoch: 226/500... Training loss: 0.0158\n",
      "Epoch: 226/500... Training loss: 0.0453\n",
      "Epoch: 226/500... Training loss: 0.0426\n",
      "Epoch: 226/500... Training loss: 0.0456\n",
      "Epoch: 226/500... Training loss: 0.0121\n",
      "Epoch: 226/500... Training loss: 0.0162\n",
      "Epoch: 226/500... Training loss: 0.0199\n",
      "Epoch: 226/500... Training loss: 0.0298\n",
      "Epoch: 226/500... Training loss: 0.0968\n",
      "Epoch: 226/500... Training loss: 0.0197\n",
      "Epoch: 226/500... Training loss: 0.0088\n",
      "Epoch: 227/500... Training loss: 0.0601\n",
      "Epoch: 227/500... Training loss: 0.0111\n",
      "Epoch: 227/500... Training loss: 0.0491\n",
      "Epoch: 227/500... Training loss: 0.0475\n",
      "Epoch: 227/500... Training loss: 0.0722\n",
      "Epoch: 227/500... Training loss: 0.0232\n",
      "Epoch: 227/500... Training loss: 0.1007\n",
      "Epoch: 227/500... Training loss: 0.0208\n",
      "Epoch: 227/500... Training loss: 0.0638\n",
      "Epoch: 227/500... Training loss: 0.0893\n",
      "Epoch: 227/500... Training loss: 0.1773\n",
      "Epoch: 227/500... Training loss: 0.1265\n",
      "Epoch: 227/500... Training loss: 0.0594\n",
      "Epoch: 227/500... Training loss: 0.0209\n",
      "Epoch: 227/500... Training loss: 0.0448\n",
      "Epoch: 227/500... Training loss: 0.0675\n",
      "Epoch: 227/500... Training loss: 0.1225\n",
      "Epoch: 227/500... Training loss: 0.0275\n",
      "Epoch: 227/500... Training loss: 0.0444\n",
      "Epoch: 227/500... Training loss: 0.0146\n",
      "Epoch: 227/500... Training loss: 0.0867\n",
      "Epoch: 227/500... Training loss: 0.1008\n",
      "Epoch: 227/500... Training loss: 0.0521\n",
      "Epoch: 227/500... Training loss: 0.0061\n",
      "Epoch: 227/500... Training loss: 0.0293\n",
      "Epoch: 227/500... Training loss: 0.0303\n",
      "Epoch: 227/500... Training loss: 0.0322\n",
      "Epoch: 227/500... Training loss: 0.0247\n",
      "Epoch: 227/500... Training loss: 0.0596\n",
      "Epoch: 227/500... Training loss: 0.0349\n",
      "Epoch: 227/500... Training loss: 0.0701\n",
      "Epoch: 228/500... Training loss: 0.0163\n",
      "Epoch: 228/500... Training loss: 0.0220\n",
      "Epoch: 228/500... Training loss: 0.0933\n",
      "Epoch: 228/500... Training loss: 0.0084\n",
      "Epoch: 228/500... Training loss: 0.0191\n",
      "Epoch: 228/500... Training loss: 0.0938\n",
      "Epoch: 228/500... Training loss: 0.1845\n",
      "Epoch: 228/500... Training loss: 0.0144\n",
      "Epoch: 228/500... Training loss: 0.0433\n",
      "Epoch: 228/500... Training loss: 0.0122\n",
      "Epoch: 228/500... Training loss: 0.1050\n",
      "Epoch: 228/500... Training loss: 0.0642\n",
      "Epoch: 228/500... Training loss: 0.0744\n",
      "Epoch: 228/500... Training loss: 0.0112\n",
      "Epoch: 228/500... Training loss: 0.0359\n",
      "Epoch: 228/500... Training loss: 0.0044\n",
      "Epoch: 228/500... Training loss: 0.0153\n",
      "Epoch: 228/500... Training loss: 0.0961\n",
      "Epoch: 228/500... Training loss: 0.0040\n",
      "Epoch: 228/500... Training loss: 0.1043\n",
      "Epoch: 228/500... Training loss: 0.0288\n",
      "Epoch: 228/500... Training loss: 0.0131\n",
      "Epoch: 228/500... Training loss: 0.0531\n",
      "Epoch: 228/500... Training loss: 0.0656\n",
      "Epoch: 228/500... Training loss: 0.0062\n",
      "Epoch: 228/500... Training loss: 0.0600\n",
      "Epoch: 228/500... Training loss: 0.0231\n",
      "Epoch: 228/500... Training loss: 0.0263\n",
      "Epoch: 228/500... Training loss: 0.0550\n",
      "Epoch: 228/500... Training loss: 0.0190\n",
      "Epoch: 228/500... Training loss: 0.0100\n",
      "Epoch: 229/500... Training loss: 0.0865\n",
      "Epoch: 229/500... Training loss: 0.0053\n",
      "Epoch: 229/500... Training loss: 0.0325\n",
      "Epoch: 229/500... Training loss: 0.0118\n",
      "Epoch: 229/500... Training loss: 0.0379\n",
      "Epoch: 229/500... Training loss: 0.0603\n",
      "Epoch: 229/500... Training loss: 0.0089\n",
      "Epoch: 229/500... Training loss: 0.0629\n",
      "Epoch: 229/500... Training loss: 0.0664\n",
      "Epoch: 229/500... Training loss: 0.0106\n",
      "Epoch: 229/500... Training loss: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 229/500... Training loss: 0.0412\n",
      "Epoch: 229/500... Training loss: 0.0629\n",
      "Epoch: 229/500... Training loss: 0.0665\n",
      "Epoch: 229/500... Training loss: 0.0456\n",
      "Epoch: 229/500... Training loss: 0.0070\n",
      "Epoch: 229/500... Training loss: 0.0052\n",
      "Epoch: 229/500... Training loss: 0.0141\n",
      "Epoch: 229/500... Training loss: 0.0489\n",
      "Epoch: 229/500... Training loss: 0.0234\n",
      "Epoch: 229/500... Training loss: 0.0211\n",
      "Epoch: 229/500... Training loss: 0.0418\n",
      "Epoch: 229/500... Training loss: 0.0477\n",
      "Epoch: 229/500... Training loss: 0.0134\n",
      "Epoch: 229/500... Training loss: 0.0373\n",
      "Epoch: 229/500... Training loss: 0.0125\n",
      "Epoch: 229/500... Training loss: 0.0190\n",
      "Epoch: 229/500... Training loss: 0.0134\n",
      "Epoch: 229/500... Training loss: 0.1050\n",
      "Epoch: 229/500... Training loss: 0.0285\n",
      "Epoch: 229/500... Training loss: 0.0437\n",
      "Epoch: 230/500... Training loss: 0.0800\n",
      "Epoch: 230/500... Training loss: 0.0212\n",
      "Epoch: 230/500... Training loss: 0.0223\n",
      "Epoch: 230/500... Training loss: 0.1054\n",
      "Epoch: 230/500... Training loss: 0.0115\n",
      "Epoch: 230/500... Training loss: 0.0527\n",
      "Epoch: 230/500... Training loss: 0.0088\n",
      "Epoch: 230/500... Training loss: 0.0133\n",
      "Epoch: 230/500... Training loss: 0.0650\n",
      "Epoch: 230/500... Training loss: 0.0665\n",
      "Epoch: 230/500... Training loss: 0.0364\n",
      "Epoch: 230/500... Training loss: 0.0284\n",
      "Epoch: 230/500... Training loss: 0.0623\n",
      "Epoch: 230/500... Training loss: 0.0144\n",
      "Epoch: 230/500... Training loss: 0.0252\n",
      "Epoch: 230/500... Training loss: 0.0102\n",
      "Epoch: 230/500... Training loss: 0.0551\n",
      "Epoch: 230/500... Training loss: 0.0599\n",
      "Epoch: 230/500... Training loss: 0.0088\n",
      "Epoch: 230/500... Training loss: 0.0120\n",
      "Epoch: 230/500... Training loss: 0.0170\n",
      "Epoch: 230/500... Training loss: 0.0674\n",
      "Epoch: 230/500... Training loss: 0.1097\n",
      "Epoch: 230/500... Training loss: 0.0112\n",
      "Epoch: 230/500... Training loss: 0.0081\n",
      "Epoch: 230/500... Training loss: 0.0179\n",
      "Epoch: 230/500... Training loss: 0.1339\n",
      "Epoch: 230/500... Training loss: 0.0200\n",
      "Epoch: 230/500... Training loss: 0.0157\n",
      "Epoch: 230/500... Training loss: 0.0079\n",
      "Epoch: 230/500... Training loss: 0.0695\n",
      "Epoch: 231/500... Training loss: 0.0238\n",
      "Epoch: 231/500... Training loss: 0.0254\n",
      "Epoch: 231/500... Training loss: 0.0889\n",
      "Epoch: 231/500... Training loss: 0.0368\n",
      "Epoch: 231/500... Training loss: 0.0213\n",
      "Epoch: 231/500... Training loss: 0.0834\n",
      "Epoch: 231/500... Training loss: 0.0070\n",
      "Epoch: 231/500... Training loss: 0.0773\n",
      "Epoch: 231/500... Training loss: 0.0533\n",
      "Epoch: 231/500... Training loss: 0.0644\n",
      "Epoch: 231/500... Training loss: 0.0182\n",
      "Epoch: 231/500... Training loss: 0.0098\n",
      "Epoch: 231/500... Training loss: 0.0220\n",
      "Epoch: 231/500... Training loss: 0.0652\n",
      "Epoch: 231/500... Training loss: 0.0465\n",
      "Epoch: 231/500... Training loss: 0.0033\n",
      "Epoch: 231/500... Training loss: 0.0948\n",
      "Epoch: 231/500... Training loss: 0.0087\n",
      "Epoch: 231/500... Training loss: 0.0048\n",
      "Epoch: 231/500... Training loss: 0.0197\n",
      "Epoch: 231/500... Training loss: 0.0749\n",
      "Epoch: 231/500... Training loss: 0.0142\n",
      "Epoch: 231/500... Training loss: 0.1771\n",
      "Epoch: 231/500... Training loss: 0.0022\n",
      "Epoch: 231/500... Training loss: 0.0097\n",
      "Epoch: 231/500... Training loss: 0.0185\n",
      "Epoch: 231/500... Training loss: 0.0082\n",
      "Epoch: 231/500... Training loss: 0.0063\n",
      "Epoch: 231/500... Training loss: 0.0464\n",
      "Epoch: 231/500... Training loss: 0.0168\n",
      "Epoch: 231/500... Training loss: 0.0628\n",
      "Epoch: 232/500... Training loss: 0.1228\n",
      "Epoch: 232/500... Training loss: 0.0119\n",
      "Epoch: 232/500... Training loss: 0.0202\n",
      "Epoch: 232/500... Training loss: 0.0295\n",
      "Epoch: 232/500... Training loss: 0.0121\n",
      "Epoch: 232/500... Training loss: 0.0346\n",
      "Epoch: 232/500... Training loss: 0.0273\n",
      "Epoch: 232/500... Training loss: 0.1974\n",
      "Epoch: 232/500... Training loss: 0.0273\n",
      "Epoch: 232/500... Training loss: 0.0508\n",
      "Epoch: 232/500... Training loss: 0.1096\n",
      "Epoch: 232/500... Training loss: 0.0231\n",
      "Epoch: 232/500... Training loss: 0.0840\n",
      "Epoch: 232/500... Training loss: 0.0250\n",
      "Epoch: 232/500... Training loss: 0.0399\n",
      "Epoch: 232/500... Training loss: 0.0162\n",
      "Epoch: 232/500... Training loss: 0.0275\n",
      "Epoch: 232/500... Training loss: 0.0051\n",
      "Epoch: 232/500... Training loss: 0.0174\n",
      "Epoch: 232/500... Training loss: 0.0359\n",
      "Epoch: 232/500... Training loss: 0.0258\n",
      "Epoch: 232/500... Training loss: 0.0278\n",
      "Epoch: 232/500... Training loss: 0.0067\n",
      "Epoch: 232/500... Training loss: 0.0326\n",
      "Epoch: 232/500... Training loss: 0.0281\n",
      "Epoch: 232/500... Training loss: 0.0049\n",
      "Epoch: 232/500... Training loss: 0.1457\n",
      "Epoch: 232/500... Training loss: 0.1519\n",
      "Epoch: 232/500... Training loss: 0.0856\n",
      "Epoch: 232/500... Training loss: 0.0133\n",
      "Epoch: 232/500... Training loss: 0.0254\n",
      "Epoch: 233/500... Training loss: 0.0117\n",
      "Epoch: 233/500... Training loss: 0.0217\n",
      "Epoch: 233/500... Training loss: 0.0327\n",
      "Epoch: 233/500... Training loss: 0.0724\n",
      "Epoch: 233/500... Training loss: 0.0315\n",
      "Epoch: 233/500... Training loss: 0.0113\n",
      "Epoch: 233/500... Training loss: 0.0382\n",
      "Epoch: 233/500... Training loss: 0.0165\n",
      "Epoch: 233/500... Training loss: 0.0163\n",
      "Epoch: 233/500... Training loss: 0.0160\n",
      "Epoch: 233/500... Training loss: 0.0317\n",
      "Epoch: 233/500... Training loss: 0.0084\n",
      "Epoch: 233/500... Training loss: 0.0544\n",
      "Epoch: 233/500... Training loss: 0.0062\n",
      "Epoch: 233/500... Training loss: 0.0539\n",
      "Epoch: 233/500... Training loss: 0.0048\n",
      "Epoch: 233/500... Training loss: 0.0172\n",
      "Epoch: 233/500... Training loss: 0.0139\n",
      "Epoch: 233/500... Training loss: 0.0684\n",
      "Epoch: 233/500... Training loss: 0.1419\n",
      "Epoch: 233/500... Training loss: 0.0150\n",
      "Epoch: 233/500... Training loss: 0.0216\n",
      "Epoch: 233/500... Training loss: 0.0463\n",
      "Epoch: 233/500... Training loss: 0.0069\n",
      "Epoch: 233/500... Training loss: 0.0120\n",
      "Epoch: 233/500... Training loss: 0.0192\n",
      "Epoch: 233/500... Training loss: 0.0635\n",
      "Epoch: 233/500... Training loss: 0.0141\n",
      "Epoch: 233/500... Training loss: 0.2074\n",
      "Epoch: 233/500... Training loss: 0.0557\n",
      "Epoch: 233/500... Training loss: 0.0350\n",
      "Epoch: 234/500... Training loss: 0.0169\n",
      "Epoch: 234/500... Training loss: 0.0184\n",
      "Epoch: 234/500... Training loss: 0.0197\n",
      "Epoch: 234/500... Training loss: 0.0374\n",
      "Epoch: 234/500... Training loss: 0.0712\n",
      "Epoch: 234/500... Training loss: 0.0707\n",
      "Epoch: 234/500... Training loss: 0.0235\n",
      "Epoch: 234/500... Training loss: 0.0410\n",
      "Epoch: 234/500... Training loss: 0.0271\n",
      "Epoch: 234/500... Training loss: 0.0211\n",
      "Epoch: 234/500... Training loss: 0.0307\n",
      "Epoch: 234/500... Training loss: 0.0367\n",
      "Epoch: 234/500... Training loss: 0.0263\n",
      "Epoch: 234/500... Training loss: 0.0170\n",
      "Epoch: 234/500... Training loss: 0.0347\n",
      "Epoch: 234/500... Training loss: 0.0078\n",
      "Epoch: 234/500... Training loss: 0.0112\n",
      "Epoch: 234/500... Training loss: 0.0837\n",
      "Epoch: 234/500... Training loss: 0.0035\n",
      "Epoch: 234/500... Training loss: 0.0334\n",
      "Epoch: 234/500... Training loss: 0.0147\n",
      "Epoch: 234/500... Training loss: 0.0121\n",
      "Epoch: 234/500... Training loss: 0.0768\n",
      "Epoch: 234/500... Training loss: 0.0185\n",
      "Epoch: 234/500... Training loss: 0.0541\n",
      "Epoch: 234/500... Training loss: 0.0059\n",
      "Epoch: 234/500... Training loss: 0.0075\n",
      "Epoch: 234/500... Training loss: 0.0134\n",
      "Epoch: 234/500... Training loss: 0.0133\n",
      "Epoch: 234/500... Training loss: 0.0063\n",
      "Epoch: 234/500... Training loss: 0.0147\n",
      "Epoch: 235/500... Training loss: 0.0443\n",
      "Epoch: 235/500... Training loss: 0.1303\n",
      "Epoch: 235/500... Training loss: 0.0855\n",
      "Epoch: 235/500... Training loss: 0.0702\n",
      "Epoch: 235/500... Training loss: 0.1205\n",
      "Epoch: 235/500... Training loss: 0.0313\n",
      "Epoch: 235/500... Training loss: 0.0441\n",
      "Epoch: 235/500... Training loss: 0.0048\n",
      "Epoch: 235/500... Training loss: 0.0125\n",
      "Epoch: 235/500... Training loss: 0.0094\n",
      "Epoch: 235/500... Training loss: 0.0215\n",
      "Epoch: 235/500... Training loss: 0.0571\n",
      "Epoch: 235/500... Training loss: 0.0113\n",
      "Epoch: 235/500... Training loss: 0.0614\n",
      "Epoch: 235/500... Training loss: 0.0079\n",
      "Epoch: 235/500... Training loss: 0.0375\n",
      "Epoch: 235/500... Training loss: 0.0439\n",
      "Epoch: 235/500... Training loss: 0.0369\n",
      "Epoch: 235/500... Training loss: 0.0288\n",
      "Epoch: 235/500... Training loss: 0.0433\n",
      "Epoch: 235/500... Training loss: 0.0398\n",
      "Epoch: 235/500... Training loss: 0.0592\n",
      "Epoch: 235/500... Training loss: 0.0785\n",
      "Epoch: 235/500... Training loss: 0.0293\n",
      "Epoch: 235/500... Training loss: 0.0566\n",
      "Epoch: 235/500... Training loss: 0.0603\n",
      "Epoch: 235/500... Training loss: 0.0063\n",
      "Epoch: 235/500... Training loss: 0.0972\n",
      "Epoch: 235/500... Training loss: 0.0193\n",
      "Epoch: 235/500... Training loss: 0.0350\n",
      "Epoch: 235/500... Training loss: 0.0077\n",
      "Epoch: 236/500... Training loss: 0.0248\n",
      "Epoch: 236/500... Training loss: 0.0362\n",
      "Epoch: 236/500... Training loss: 0.0767\n",
      "Epoch: 236/500... Training loss: 0.0392\n",
      "Epoch: 236/500... Training loss: 0.0286\n",
      "Epoch: 236/500... Training loss: 0.0239\n",
      "Epoch: 236/500... Training loss: 0.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 236/500... Training loss: 0.0307\n",
      "Epoch: 236/500... Training loss: 0.0244\n",
      "Epoch: 236/500... Training loss: 0.0132\n",
      "Epoch: 236/500... Training loss: 0.1418\n",
      "Epoch: 236/500... Training loss: 0.0476\n",
      "Epoch: 236/500... Training loss: 0.1426\n",
      "Epoch: 236/500... Training loss: 0.0402\n",
      "Epoch: 236/500... Training loss: 0.0160\n",
      "Epoch: 236/500... Training loss: 0.0144\n",
      "Epoch: 236/500... Training loss: 0.0880\n",
      "Epoch: 236/500... Training loss: 0.0457\n",
      "Epoch: 236/500... Training loss: 0.0684\n",
      "Epoch: 236/500... Training loss: 0.0976\n",
      "Epoch: 236/500... Training loss: 0.0747\n",
      "Epoch: 236/500... Training loss: 0.0219\n",
      "Epoch: 236/500... Training loss: 0.0869\n",
      "Epoch: 236/500... Training loss: 0.0331\n",
      "Epoch: 236/500... Training loss: 0.0190\n",
      "Epoch: 236/500... Training loss: 0.0724\n",
      "Epoch: 236/500... Training loss: 0.0249\n",
      "Epoch: 236/500... Training loss: 0.0479\n",
      "Epoch: 236/500... Training loss: 0.0182\n",
      "Epoch: 236/500... Training loss: 0.0084\n",
      "Epoch: 236/500... Training loss: 0.0713\n",
      "Epoch: 237/500... Training loss: 0.0519\n",
      "Epoch: 237/500... Training loss: 0.0522\n",
      "Epoch: 237/500... Training loss: 0.0864\n",
      "Epoch: 237/500... Training loss: 0.0824\n",
      "Epoch: 237/500... Training loss: 0.0611\n",
      "Epoch: 237/500... Training loss: 0.0654\n",
      "Epoch: 237/500... Training loss: 0.0370\n",
      "Epoch: 237/500... Training loss: 0.0083\n",
      "Epoch: 237/500... Training loss: 0.0182\n",
      "Epoch: 237/500... Training loss: 0.0906\n",
      "Epoch: 237/500... Training loss: 0.0237\n",
      "Epoch: 237/500... Training loss: 0.0534\n",
      "Epoch: 237/500... Training loss: 0.0723\n",
      "Epoch: 237/500... Training loss: 0.0104\n",
      "Epoch: 237/500... Training loss: 0.0161\n",
      "Epoch: 237/500... Training loss: 0.0258\n",
      "Epoch: 237/500... Training loss: 0.0204\n",
      "Epoch: 237/500... Training loss: 0.0401\n",
      "Epoch: 237/500... Training loss: 0.0113\n",
      "Epoch: 237/500... Training loss: 0.0176\n",
      "Epoch: 237/500... Training loss: 0.0088\n",
      "Epoch: 237/500... Training loss: 0.0526\n",
      "Epoch: 237/500... Training loss: 0.0214\n",
      "Epoch: 237/500... Training loss: 0.0166\n",
      "Epoch: 237/500... Training loss: 0.0073\n",
      "Epoch: 237/500... Training loss: 0.3386\n",
      "Epoch: 237/500... Training loss: 0.0122\n",
      "Epoch: 237/500... Training loss: 0.0819\n",
      "Epoch: 237/500... Training loss: 0.0225\n",
      "Epoch: 237/500... Training loss: 0.0077\n",
      "Epoch: 237/500... Training loss: 0.0206\n",
      "Epoch: 238/500... Training loss: 0.1445\n",
      "Epoch: 238/500... Training loss: 0.0725\n",
      "Epoch: 238/500... Training loss: 0.0524\n",
      "Epoch: 238/500... Training loss: 0.0320\n",
      "Epoch: 238/500... Training loss: 0.0602\n",
      "Epoch: 238/500... Training loss: 0.0418\n",
      "Epoch: 238/500... Training loss: 0.0896\n",
      "Epoch: 238/500... Training loss: 0.0890\n",
      "Epoch: 238/500... Training loss: 0.0338\n",
      "Epoch: 238/500... Training loss: 0.0277\n",
      "Epoch: 238/500... Training loss: 0.0241\n",
      "Epoch: 238/500... Training loss: 0.0397\n",
      "Epoch: 238/500... Training loss: 0.0856\n",
      "Epoch: 238/500... Training loss: 0.0368\n",
      "Epoch: 238/500... Training loss: 0.0502\n",
      "Epoch: 238/500... Training loss: 0.0131\n",
      "Epoch: 238/500... Training loss: 0.0496\n",
      "Epoch: 238/500... Training loss: 0.0387\n",
      "Epoch: 238/500... Training loss: 0.0738\n",
      "Epoch: 238/500... Training loss: 0.0295\n",
      "Epoch: 238/500... Training loss: 0.0237\n",
      "Epoch: 238/500... Training loss: 0.0155\n",
      "Epoch: 238/500... Training loss: 0.0197\n",
      "Epoch: 238/500... Training loss: 0.0213\n",
      "Epoch: 238/500... Training loss: 0.0533\n",
      "Epoch: 238/500... Training loss: 0.0052\n",
      "Epoch: 238/500... Training loss: 0.0533\n",
      "Epoch: 238/500... Training loss: 0.0510\n",
      "Epoch: 238/500... Training loss: 0.0104\n",
      "Epoch: 238/500... Training loss: 0.0567\n",
      "Epoch: 238/500... Training loss: 0.0078\n",
      "Epoch: 239/500... Training loss: 0.1364\n",
      "Epoch: 239/500... Training loss: 0.0151\n",
      "Epoch: 239/500... Training loss: 0.0094\n",
      "Epoch: 239/500... Training loss: 0.0187\n",
      "Epoch: 239/500... Training loss: 0.1038\n",
      "Epoch: 239/500... Training loss: 0.0729\n",
      "Epoch: 239/500... Training loss: 0.0319\n",
      "Epoch: 239/500... Training loss: 0.0445\n",
      "Epoch: 239/500... Training loss: 0.0178\n",
      "Epoch: 239/500... Training loss: 0.0456\n",
      "Epoch: 239/500... Training loss: 0.0412\n",
      "Epoch: 239/500... Training loss: 0.0942\n",
      "Epoch: 239/500... Training loss: 0.0374\n",
      "Epoch: 239/500... Training loss: 0.0617\n",
      "Epoch: 239/500... Training loss: 0.0151\n",
      "Epoch: 239/500... Training loss: 0.0439\n",
      "Epoch: 239/500... Training loss: 0.0390\n",
      "Epoch: 239/500... Training loss: 0.0133\n",
      "Epoch: 239/500... Training loss: 0.0103\n",
      "Epoch: 239/500... Training loss: 0.0066\n",
      "Epoch: 239/500... Training loss: 0.0867\n",
      "Epoch: 239/500... Training loss: 0.0240\n",
      "Epoch: 239/500... Training loss: 0.0218\n",
      "Epoch: 239/500... Training loss: 0.0705\n",
      "Epoch: 239/500... Training loss: 0.0094\n",
      "Epoch: 239/500... Training loss: 0.0567\n",
      "Epoch: 239/500... Training loss: 0.0032\n",
      "Epoch: 239/500... Training loss: 0.0206\n",
      "Epoch: 239/500... Training loss: 0.0310\n",
      "Epoch: 239/500... Training loss: 0.0239\n",
      "Epoch: 239/500... Training loss: 0.0133\n",
      "Epoch: 240/500... Training loss: 0.0158\n",
      "Epoch: 240/500... Training loss: 0.0168\n",
      "Epoch: 240/500... Training loss: 0.0080\n",
      "Epoch: 240/500... Training loss: 0.0424\n",
      "Epoch: 240/500... Training loss: 0.0113\n",
      "Epoch: 240/500... Training loss: 0.0260\n",
      "Epoch: 240/500... Training loss: 0.0544\n",
      "Epoch: 240/500... Training loss: 0.0086\n",
      "Epoch: 240/500... Training loss: 0.0421\n",
      "Epoch: 240/500... Training loss: 0.0218\n",
      "Epoch: 240/500... Training loss: 0.0693\n",
      "Epoch: 240/500... Training loss: 0.0612\n",
      "Epoch: 240/500... Training loss: 0.0541\n",
      "Epoch: 240/500... Training loss: 0.0239\n",
      "Epoch: 240/500... Training loss: 0.0069\n",
      "Epoch: 240/500... Training loss: 0.0430\n",
      "Epoch: 240/500... Training loss: 0.0057\n",
      "Epoch: 240/500... Training loss: 0.0115\n",
      "Epoch: 240/500... Training loss: 0.0725\n",
      "Epoch: 240/500... Training loss: 0.0271\n",
      "Epoch: 240/500... Training loss: 0.0210\n",
      "Epoch: 240/500... Training loss: 0.0126\n",
      "Epoch: 240/500... Training loss: 0.0775\n",
      "Epoch: 240/500... Training loss: 0.0160\n",
      "Epoch: 240/500... Training loss: 0.0199\n",
      "Epoch: 240/500... Training loss: 0.0156\n",
      "Epoch: 240/500... Training loss: 0.0153\n",
      "Epoch: 240/500... Training loss: 0.0069\n",
      "Epoch: 240/500... Training loss: 0.0168\n",
      "Epoch: 240/500... Training loss: 0.0179\n",
      "Epoch: 240/500... Training loss: 0.0101\n",
      "Epoch: 241/500... Training loss: 0.1418\n",
      "Epoch: 241/500... Training loss: 0.0105\n",
      "Epoch: 241/500... Training loss: 0.0069\n",
      "Epoch: 241/500... Training loss: 0.0118\n",
      "Epoch: 241/500... Training loss: 0.0498\n",
      "Epoch: 241/500... Training loss: 0.0214\n",
      "Epoch: 241/500... Training loss: 0.1950\n",
      "Epoch: 241/500... Training loss: 0.0287\n",
      "Epoch: 241/500... Training loss: 0.0420\n",
      "Epoch: 241/500... Training loss: 0.0082\n",
      "Epoch: 241/500... Training loss: 0.0664\n",
      "Epoch: 241/500... Training loss: 0.0269\n",
      "Epoch: 241/500... Training loss: 0.0069\n",
      "Epoch: 241/500... Training loss: 0.0162\n",
      "Epoch: 241/500... Training loss: 0.0112\n",
      "Epoch: 241/500... Training loss: 0.0168\n",
      "Epoch: 241/500... Training loss: 0.0531\n",
      "Epoch: 241/500... Training loss: 0.0118\n",
      "Epoch: 241/500... Training loss: 0.0068\n",
      "Epoch: 241/500... Training loss: 0.0282\n",
      "Epoch: 241/500... Training loss: 0.0044\n",
      "Epoch: 241/500... Training loss: 0.0089\n",
      "Epoch: 241/500... Training loss: 0.0191\n",
      "Epoch: 241/500... Training loss: 0.0137\n",
      "Epoch: 241/500... Training loss: 0.0084\n",
      "Epoch: 241/500... Training loss: 0.0062\n",
      "Epoch: 241/500... Training loss: 0.0108\n",
      "Epoch: 241/500... Training loss: 0.0185\n",
      "Epoch: 241/500... Training loss: 0.0286\n",
      "Epoch: 241/500... Training loss: 0.0088\n",
      "Epoch: 241/500... Training loss: 0.0033\n",
      "Epoch: 242/500... Training loss: 0.0106\n",
      "Epoch: 242/500... Training loss: 0.0226\n",
      "Epoch: 242/500... Training loss: 0.0117\n",
      "Epoch: 242/500... Training loss: 0.0278\n",
      "Epoch: 242/500... Training loss: 0.0061\n",
      "Epoch: 242/500... Training loss: 0.0321\n",
      "Epoch: 242/500... Training loss: 0.1262\n",
      "Epoch: 242/500... Training loss: 0.0064\n",
      "Epoch: 242/500... Training loss: 0.0777\n",
      "Epoch: 242/500... Training loss: 0.0101\n",
      "Epoch: 242/500... Training loss: 0.0102\n",
      "Epoch: 242/500... Training loss: 0.0442\n",
      "Epoch: 242/500... Training loss: 0.0087\n",
      "Epoch: 242/500... Training loss: 0.0051\n",
      "Epoch: 242/500... Training loss: 0.0636\n",
      "Epoch: 242/500... Training loss: 0.0051\n",
      "Epoch: 242/500... Training loss: 0.0601\n",
      "Epoch: 242/500... Training loss: 0.0796\n",
      "Epoch: 242/500... Training loss: 0.0055\n",
      "Epoch: 242/500... Training loss: 0.0153\n",
      "Epoch: 242/500... Training loss: 0.0605\n",
      "Epoch: 242/500... Training loss: 0.0437\n",
      "Epoch: 242/500... Training loss: 0.0990\n",
      "Epoch: 242/500... Training loss: 0.0036\n",
      "Epoch: 242/500... Training loss: 0.0139\n",
      "Epoch: 242/500... Training loss: 0.0403\n",
      "Epoch: 242/500... Training loss: 0.0416\n",
      "Epoch: 242/500... Training loss: 0.0219\n",
      "Epoch: 242/500... Training loss: 0.0057\n",
      "Epoch: 242/500... Training loss: 0.0228\n",
      "Epoch: 242/500... Training loss: 0.0533\n",
      "Epoch: 243/500... Training loss: 0.0650\n",
      "Epoch: 243/500... Training loss: 0.0269\n",
      "Epoch: 243/500... Training loss: 0.0105\n",
      "Epoch: 243/500... Training loss: 0.0816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 243/500... Training loss: 0.0086\n",
      "Epoch: 243/500... Training loss: 0.0129\n",
      "Epoch: 243/500... Training loss: 0.0114\n",
      "Epoch: 243/500... Training loss: 0.0282\n",
      "Epoch: 243/500... Training loss: 0.0265\n",
      "Epoch: 243/500... Training loss: 0.0262\n",
      "Epoch: 243/500... Training loss: 0.0159\n",
      "Epoch: 243/500... Training loss: 0.0443\n",
      "Epoch: 243/500... Training loss: 0.0202\n",
      "Epoch: 243/500... Training loss: 0.0027\n",
      "Epoch: 243/500... Training loss: 0.0418\n",
      "Epoch: 243/500... Training loss: 0.0101\n",
      "Epoch: 243/500... Training loss: 0.0237\n",
      "Epoch: 243/500... Training loss: 0.0169\n",
      "Epoch: 243/500... Training loss: 0.0164\n",
      "Epoch: 243/500... Training loss: 0.0023\n",
      "Epoch: 243/500... Training loss: 0.0306\n",
      "Epoch: 243/500... Training loss: 0.0168\n",
      "Epoch: 243/500... Training loss: 0.0657\n",
      "Epoch: 243/500... Training loss: 0.0169\n",
      "Epoch: 243/500... Training loss: 0.0074\n",
      "Epoch: 243/500... Training loss: 0.0140\n",
      "Epoch: 243/500... Training loss: 0.0062\n",
      "Epoch: 243/500... Training loss: 0.0219\n",
      "Epoch: 243/500... Training loss: 0.0128\n",
      "Epoch: 243/500... Training loss: 0.0058\n",
      "Epoch: 243/500... Training loss: 0.0093\n",
      "Epoch: 244/500... Training loss: 0.0591\n",
      "Epoch: 244/500... Training loss: 0.0242\n",
      "Epoch: 244/500... Training loss: 0.0766\n",
      "Epoch: 244/500... Training loss: 0.0475\n",
      "Epoch: 244/500... Training loss: 0.0089\n",
      "Epoch: 244/500... Training loss: 0.0920\n",
      "Epoch: 244/500... Training loss: 0.0398\n",
      "Epoch: 244/500... Training loss: 0.0058\n",
      "Epoch: 244/500... Training loss: 0.0050\n",
      "Epoch: 244/500... Training loss: 0.0056\n",
      "Epoch: 244/500... Training loss: 0.0675\n",
      "Epoch: 244/500... Training loss: 0.0274\n",
      "Epoch: 244/500... Training loss: 0.0060\n",
      "Epoch: 244/500... Training loss: 0.0110\n",
      "Epoch: 244/500... Training loss: 0.0094\n",
      "Epoch: 244/500... Training loss: 0.1452\n",
      "Epoch: 244/500... Training loss: 0.0154\n",
      "Epoch: 244/500... Training loss: 0.0448\n",
      "Epoch: 244/500... Training loss: 0.0461\n",
      "Epoch: 244/500... Training loss: 0.1562\n",
      "Epoch: 244/500... Training loss: 0.0432\n",
      "Epoch: 244/500... Training loss: 0.0014\n",
      "Epoch: 244/500... Training loss: 0.1015\n",
      "Epoch: 244/500... Training loss: 0.0167\n",
      "Epoch: 244/500... Training loss: 0.0315\n",
      "Epoch: 244/500... Training loss: 0.0155\n",
      "Epoch: 244/500... Training loss: 0.0031\n",
      "Epoch: 244/500... Training loss: 0.0341\n",
      "Epoch: 244/500... Training loss: 0.0772\n",
      "Epoch: 244/500... Training loss: 0.0809\n",
      "Epoch: 244/500... Training loss: 0.0296\n",
      "Epoch: 245/500... Training loss: 0.0899\n",
      "Epoch: 245/500... Training loss: 0.0111\n",
      "Epoch: 245/500... Training loss: 0.0201\n",
      "Epoch: 245/500... Training loss: 0.0664\n",
      "Epoch: 245/500... Training loss: 0.0493\n",
      "Epoch: 245/500... Training loss: 0.0335\n",
      "Epoch: 245/500... Training loss: 0.0074\n",
      "Epoch: 245/500... Training loss: 0.0507\n",
      "Epoch: 245/500... Training loss: 0.0114\n",
      "Epoch: 245/500... Training loss: 0.0359\n",
      "Epoch: 245/500... Training loss: 0.0357\n",
      "Epoch: 245/500... Training loss: 0.0250\n",
      "Epoch: 245/500... Training loss: 0.0593\n",
      "Epoch: 245/500... Training loss: 0.0457\n",
      "Epoch: 245/500... Training loss: 0.0103\n",
      "Epoch: 245/500... Training loss: 0.0083\n",
      "Epoch: 245/500... Training loss: 0.0066\n",
      "Epoch: 245/500... Training loss: 0.0366\n",
      "Epoch: 245/500... Training loss: 0.0591\n",
      "Epoch: 245/500... Training loss: 0.0084\n",
      "Epoch: 245/500... Training loss: 0.0452\n",
      "Epoch: 245/500... Training loss: 0.0043\n",
      "Epoch: 245/500... Training loss: 0.0935\n",
      "Epoch: 245/500... Training loss: 0.1441\n",
      "Epoch: 245/500... Training loss: 0.0636\n",
      "Epoch: 245/500... Training loss: 0.0436\n",
      "Epoch: 245/500... Training loss: 0.0141\n",
      "Epoch: 245/500... Training loss: 0.0136\n",
      "Epoch: 245/500... Training loss: 0.0162\n",
      "Epoch: 245/500... Training loss: 0.0160\n",
      "Epoch: 245/500... Training loss: 0.0219\n",
      "Epoch: 246/500... Training loss: 0.0296\n",
      "Epoch: 246/500... Training loss: 0.0370\n",
      "Epoch: 246/500... Training loss: 0.0457\n",
      "Epoch: 246/500... Training loss: 0.0335\n",
      "Epoch: 246/500... Training loss: 0.0390\n",
      "Epoch: 246/500... Training loss: 0.0090\n",
      "Epoch: 246/500... Training loss: 0.0050\n",
      "Epoch: 246/500... Training loss: 0.0180\n",
      "Epoch: 246/500... Training loss: 0.0040\n",
      "Epoch: 246/500... Training loss: 0.0398\n",
      "Epoch: 246/500... Training loss: 0.0368\n",
      "Epoch: 246/500... Training loss: 0.0710\n",
      "Epoch: 246/500... Training loss: 0.0302\n",
      "Epoch: 246/500... Training loss: 0.0075\n",
      "Epoch: 246/500... Training loss: 0.0114\n",
      "Epoch: 246/500... Training loss: 0.0265\n",
      "Epoch: 246/500... Training loss: 0.0316\n",
      "Epoch: 246/500... Training loss: 0.1326\n",
      "Epoch: 246/500... Training loss: 0.1331\n",
      "Epoch: 246/500... Training loss: 0.0640\n",
      "Epoch: 246/500... Training loss: 0.0639\n",
      "Epoch: 246/500... Training loss: 0.0386\n",
      "Epoch: 246/500... Training loss: 0.0144\n",
      "Epoch: 246/500... Training loss: 0.0171\n",
      "Epoch: 246/500... Training loss: 0.0043\n",
      "Epoch: 246/500... Training loss: 0.0209\n",
      "Epoch: 246/500... Training loss: 0.0155\n",
      "Epoch: 246/500... Training loss: 0.0137\n",
      "Epoch: 246/500... Training loss: 0.0048\n",
      "Epoch: 246/500... Training loss: 0.0415\n",
      "Epoch: 246/500... Training loss: 0.0119\n",
      "Epoch: 247/500... Training loss: 0.0699\n",
      "Epoch: 247/500... Training loss: 0.0225\n",
      "Epoch: 247/500... Training loss: 0.0428\n",
      "Epoch: 247/500... Training loss: 0.0676\n",
      "Epoch: 247/500... Training loss: 0.0266\n",
      "Epoch: 247/500... Training loss: 0.1988\n",
      "Epoch: 247/500... Training loss: 0.0286\n",
      "Epoch: 247/500... Training loss: 0.0181\n",
      "Epoch: 247/500... Training loss: 0.0105\n",
      "Epoch: 247/500... Training loss: 0.0614\n",
      "Epoch: 247/500... Training loss: 0.0092\n",
      "Epoch: 247/500... Training loss: 0.0701\n",
      "Epoch: 247/500... Training loss: 0.0147\n",
      "Epoch: 247/500... Training loss: 0.0094\n",
      "Epoch: 247/500... Training loss: 0.0518\n",
      "Epoch: 247/500... Training loss: 0.0038\n",
      "Epoch: 247/500... Training loss: 0.0237\n",
      "Epoch: 247/500... Training loss: 0.0489\n",
      "Epoch: 247/500... Training loss: 0.0173\n",
      "Epoch: 247/500... Training loss: 0.0138\n",
      "Epoch: 247/500... Training loss: 0.0205\n",
      "Epoch: 247/500... Training loss: 0.0338\n",
      "Epoch: 247/500... Training loss: 0.0043\n",
      "Epoch: 247/500... Training loss: 0.0492\n",
      "Epoch: 247/500... Training loss: 0.0072\n",
      "Epoch: 247/500... Training loss: 0.0110\n",
      "Epoch: 247/500... Training loss: 0.0984\n",
      "Epoch: 247/500... Training loss: 0.0055\n",
      "Epoch: 247/500... Training loss: 0.1498\n",
      "Epoch: 247/500... Training loss: 0.0175\n",
      "Epoch: 247/500... Training loss: 0.0063\n",
      "Epoch: 248/500... Training loss: 0.0105\n",
      "Epoch: 248/500... Training loss: 0.0095\n",
      "Epoch: 248/500... Training loss: 0.0268\n",
      "Epoch: 248/500... Training loss: 0.0165\n",
      "Epoch: 248/500... Training loss: 0.0163\n",
      "Epoch: 248/500... Training loss: 0.0850\n",
      "Epoch: 248/500... Training loss: 0.0468\n",
      "Epoch: 248/500... Training loss: 0.0912\n",
      "Epoch: 248/500... Training loss: 0.0203\n",
      "Epoch: 248/500... Training loss: 0.0653\n",
      "Epoch: 248/500... Training loss: 0.0074\n",
      "Epoch: 248/500... Training loss: 0.0435\n",
      "Epoch: 248/500... Training loss: 0.0115\n",
      "Epoch: 248/500... Training loss: 0.0107\n",
      "Epoch: 248/500... Training loss: 0.0487\n",
      "Epoch: 248/500... Training loss: 0.0174\n",
      "Epoch: 248/500... Training loss: 0.0077\n",
      "Epoch: 248/500... Training loss: 0.0067\n",
      "Epoch: 248/500... Training loss: 0.0643\n",
      "Epoch: 248/500... Training loss: 0.0044\n",
      "Epoch: 248/500... Training loss: 0.0264\n",
      "Epoch: 248/500... Training loss: 0.0054\n",
      "Epoch: 248/500... Training loss: 0.0522\n",
      "Epoch: 248/500... Training loss: 0.0067\n",
      "Epoch: 248/500... Training loss: 0.0043\n",
      "Epoch: 248/500... Training loss: 0.0423\n",
      "Epoch: 248/500... Training loss: 0.1022\n",
      "Epoch: 248/500... Training loss: 0.0415\n",
      "Epoch: 248/500... Training loss: 0.0073\n",
      "Epoch: 248/500... Training loss: 0.0031\n",
      "Epoch: 248/500... Training loss: 0.0091\n",
      "Epoch: 249/500... Training loss: 0.0376\n",
      "Epoch: 249/500... Training loss: 0.0201\n",
      "Epoch: 249/500... Training loss: 0.0094\n",
      "Epoch: 249/500... Training loss: 0.0358\n",
      "Epoch: 249/500... Training loss: 0.0291\n",
      "Epoch: 249/500... Training loss: 0.0595\n",
      "Epoch: 249/500... Training loss: 0.0154\n",
      "Epoch: 249/500... Training loss: 0.0128\n",
      "Epoch: 249/500... Training loss: 0.0093\n",
      "Epoch: 249/500... Training loss: 0.0234\n",
      "Epoch: 249/500... Training loss: 0.0134\n",
      "Epoch: 249/500... Training loss: 0.0224\n",
      "Epoch: 249/500... Training loss: 0.0732\n",
      "Epoch: 249/500... Training loss: 0.0086\n",
      "Epoch: 249/500... Training loss: 0.0208\n",
      "Epoch: 249/500... Training loss: 0.0705\n",
      "Epoch: 249/500... Training loss: 0.0733\n",
      "Epoch: 249/500... Training loss: 0.0074\n",
      "Epoch: 249/500... Training loss: 0.0412\n",
      "Epoch: 249/500... Training loss: 0.0099\n",
      "Epoch: 249/500... Training loss: 0.0209\n",
      "Epoch: 249/500... Training loss: 0.0090\n",
      "Epoch: 249/500... Training loss: 0.1283\n",
      "Epoch: 249/500... Training loss: 0.1474\n",
      "Epoch: 249/500... Training loss: 0.0079\n",
      "Epoch: 249/500... Training loss: 0.0170\n",
      "Epoch: 249/500... Training loss: 0.0440\n",
      "Epoch: 249/500... Training loss: 0.0295\n",
      "Epoch: 249/500... Training loss: 0.0129\n",
      "Epoch: 249/500... Training loss: 0.0127\n",
      "Epoch: 249/500... Training loss: 0.0049\n",
      "Epoch: 250/500... Training loss: 0.0107\n",
      "Epoch: 250/500... Training loss: 0.0440\n",
      "Epoch: 250/500... Training loss: 0.0415\n",
      "Epoch: 250/500... Training loss: 0.0103\n",
      "Epoch: 250/500... Training loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250/500... Training loss: 0.0093\n",
      "Epoch: 250/500... Training loss: 0.0143\n",
      "Epoch: 250/500... Training loss: 0.0223\n",
      "Epoch: 250/500... Training loss: 0.0060\n",
      "Epoch: 250/500... Training loss: 0.1026\n",
      "Epoch: 250/500... Training loss: 0.0428\n",
      "Epoch: 250/500... Training loss: 0.0137\n",
      "Epoch: 250/500... Training loss: 0.0076\n",
      "Epoch: 250/500... Training loss: 0.0738\n",
      "Epoch: 250/500... Training loss: 0.0172\n",
      "Epoch: 250/500... Training loss: 0.0208\n",
      "Epoch: 250/500... Training loss: 0.0213\n",
      "Epoch: 250/500... Training loss: 0.0213\n",
      "Epoch: 250/500... Training loss: 0.0169\n",
      "Epoch: 250/500... Training loss: 0.0688\n",
      "Epoch: 250/500... Training loss: 0.0334\n",
      "Epoch: 250/500... Training loss: 0.0093\n",
      "Epoch: 250/500... Training loss: 0.0465\n",
      "Epoch: 250/500... Training loss: 0.0201\n",
      "Epoch: 250/500... Training loss: 0.0287\n",
      "Epoch: 250/500... Training loss: 0.0218\n",
      "Epoch: 250/500... Training loss: 0.0643\n",
      "Epoch: 250/500... Training loss: 0.0154\n",
      "Epoch: 250/500... Training loss: 0.0135\n",
      "Epoch: 250/500... Training loss: 0.0236\n",
      "Epoch: 250/500... Training loss: 0.0111\n",
      "Epoch: 251/500... Training loss: 0.0651\n",
      "Epoch: 251/500... Training loss: 0.1261\n",
      "Epoch: 251/500... Training loss: 0.0360\n",
      "Epoch: 251/500... Training loss: 0.0096\n",
      "Epoch: 251/500... Training loss: 0.1812\n",
      "Epoch: 251/500... Training loss: 0.0368\n",
      "Epoch: 251/500... Training loss: 0.0113\n",
      "Epoch: 251/500... Training loss: 0.0269\n",
      "Epoch: 251/500... Training loss: 0.0348\n",
      "Epoch: 251/500... Training loss: 0.0086\n",
      "Epoch: 251/500... Training loss: 0.0318\n",
      "Epoch: 251/500... Training loss: 0.0766\n",
      "Epoch: 251/500... Training loss: 0.0461\n",
      "Epoch: 251/500... Training loss: 0.0187\n",
      "Epoch: 251/500... Training loss: 0.0610\n",
      "Epoch: 251/500... Training loss: 0.0140\n",
      "Epoch: 251/500... Training loss: 0.0118\n",
      "Epoch: 251/500... Training loss: 0.0270\n",
      "Epoch: 251/500... Training loss: 0.0071\n",
      "Epoch: 251/500... Training loss: 0.0888\n",
      "Epoch: 251/500... Training loss: 0.0405\n",
      "Epoch: 251/500... Training loss: 0.0041\n",
      "Epoch: 251/500... Training loss: 0.1493\n",
      "Epoch: 251/500... Training loss: 0.0045\n",
      "Epoch: 251/500... Training loss: 0.0323\n",
      "Epoch: 251/500... Training loss: 0.0315\n",
      "Epoch: 251/500... Training loss: 0.0156\n",
      "Epoch: 251/500... Training loss: 0.0342\n",
      "Epoch: 251/500... Training loss: 0.0323\n",
      "Epoch: 251/500... Training loss: 0.0437\n",
      "Epoch: 251/500... Training loss: 0.0160\n",
      "Epoch: 252/500... Training loss: 0.0223\n",
      "Epoch: 252/500... Training loss: 0.0444\n",
      "Epoch: 252/500... Training loss: 0.0759\n",
      "Epoch: 252/500... Training loss: 0.0167\n",
      "Epoch: 252/500... Training loss: 0.0333\n",
      "Epoch: 252/500... Training loss: 0.0588\n",
      "Epoch: 252/500... Training loss: 0.0332\n",
      "Epoch: 252/500... Training loss: 0.0340\n",
      "Epoch: 252/500... Training loss: 0.0264\n",
      "Epoch: 252/500... Training loss: 0.0581\n",
      "Epoch: 252/500... Training loss: 0.0709\n",
      "Epoch: 252/500... Training loss: 0.0615\n",
      "Epoch: 252/500... Training loss: 0.0196\n",
      "Epoch: 252/500... Training loss: 0.0244\n",
      "Epoch: 252/500... Training loss: 0.0258\n",
      "Epoch: 252/500... Training loss: 0.0125\n",
      "Epoch: 252/500... Training loss: 0.0489\n",
      "Epoch: 252/500... Training loss: 0.0213\n",
      "Epoch: 252/500... Training loss: 0.1163\n",
      "Epoch: 252/500... Training loss: 0.0132\n",
      "Epoch: 252/500... Training loss: 0.0470\n",
      "Epoch: 252/500... Training loss: 0.0080\n",
      "Epoch: 252/500... Training loss: 0.0341\n",
      "Epoch: 252/500... Training loss: 0.0065\n",
      "Epoch: 252/500... Training loss: 0.0308\n",
      "Epoch: 252/500... Training loss: 0.0371\n",
      "Epoch: 252/500... Training loss: 0.0095\n",
      "Epoch: 252/500... Training loss: 0.0395\n",
      "Epoch: 252/500... Training loss: 0.0403\n",
      "Epoch: 252/500... Training loss: 0.0533\n",
      "Epoch: 252/500... Training loss: 0.0082\n",
      "Epoch: 253/500... Training loss: 0.0051\n",
      "Epoch: 253/500... Training loss: 0.0200\n",
      "Epoch: 253/500... Training loss: 0.0291\n",
      "Epoch: 253/500... Training loss: 0.0194\n",
      "Epoch: 253/500... Training loss: 0.1562\n",
      "Epoch: 253/500... Training loss: 0.0331\n",
      "Epoch: 253/500... Training loss: 0.0169\n",
      "Epoch: 253/500... Training loss: 0.0144\n",
      "Epoch: 253/500... Training loss: 0.0097\n",
      "Epoch: 253/500... Training loss: 0.0509\n",
      "Epoch: 253/500... Training loss: 0.0332\n",
      "Epoch: 253/500... Training loss: 0.0225\n",
      "Epoch: 253/500... Training loss: 0.0611\n",
      "Epoch: 253/500... Training loss: 0.0285\n",
      "Epoch: 253/500... Training loss: 0.0275\n",
      "Epoch: 253/500... Training loss: 0.0067\n",
      "Epoch: 253/500... Training loss: 0.0134\n",
      "Epoch: 253/500... Training loss: 0.0673\n",
      "Epoch: 253/500... Training loss: 0.0179\n",
      "Epoch: 253/500... Training loss: 0.0693\n",
      "Epoch: 253/500... Training loss: 0.0294\n",
      "Epoch: 253/500... Training loss: 0.0023\n",
      "Epoch: 253/500... Training loss: 0.0733\n",
      "Epoch: 253/500... Training loss: 0.0103\n",
      "Epoch: 253/500... Training loss: 0.0314\n",
      "Epoch: 253/500... Training loss: 0.0053\n",
      "Epoch: 253/500... Training loss: 0.0340\n",
      "Epoch: 253/500... Training loss: 0.0211\n",
      "Epoch: 253/500... Training loss: 0.0394\n",
      "Epoch: 253/500... Training loss: 0.0263\n",
      "Epoch: 253/500... Training loss: 0.0211\n",
      "Epoch: 254/500... Training loss: 0.0039\n",
      "Epoch: 254/500... Training loss: 0.0578\n",
      "Epoch: 254/500... Training loss: 0.2117\n",
      "Epoch: 254/500... Training loss: 0.0147\n",
      "Epoch: 254/500... Training loss: 0.1134\n",
      "Epoch: 254/500... Training loss: 0.0980\n",
      "Epoch: 254/500... Training loss: 0.0369\n",
      "Epoch: 254/500... Training loss: 0.0242\n",
      "Epoch: 254/500... Training loss: 0.0278\n",
      "Epoch: 254/500... Training loss: 0.0366\n",
      "Epoch: 254/500... Training loss: 0.0401\n",
      "Epoch: 254/500... Training loss: 0.0456\n",
      "Epoch: 254/500... Training loss: 0.1338\n",
      "Epoch: 254/500... Training loss: 0.0122\n",
      "Epoch: 254/500... Training loss: 0.0274\n",
      "Epoch: 254/500... Training loss: 0.0349\n",
      "Epoch: 254/500... Training loss: 0.0436\n",
      "Epoch: 254/500... Training loss: 0.0456\n",
      "Epoch: 254/500... Training loss: 0.0310\n",
      "Epoch: 254/500... Training loss: 0.0198\n",
      "Epoch: 254/500... Training loss: 0.0223\n",
      "Epoch: 254/500... Training loss: 0.0035\n",
      "Epoch: 254/500... Training loss: 0.1227\n",
      "Epoch: 254/500... Training loss: 0.0036\n",
      "Epoch: 254/500... Training loss: 0.0284\n",
      "Epoch: 254/500... Training loss: 0.1555\n",
      "Epoch: 254/500... Training loss: 0.0506\n",
      "Epoch: 254/500... Training loss: 0.0236\n",
      "Epoch: 254/500... Training loss: 0.1308\n",
      "Epoch: 254/500... Training loss: 0.0063\n",
      "Epoch: 254/500... Training loss: 0.0089\n",
      "Epoch: 255/500... Training loss: 0.0637\n",
      "Epoch: 255/500... Training loss: 0.0426\n",
      "Epoch: 255/500... Training loss: 0.0509\n",
      "Epoch: 255/500... Training loss: 0.0485\n",
      "Epoch: 255/500... Training loss: 0.0706\n",
      "Epoch: 255/500... Training loss: 0.0436\n",
      "Epoch: 255/500... Training loss: 0.0454\n",
      "Epoch: 255/500... Training loss: 0.0359\n",
      "Epoch: 255/500... Training loss: 0.0388\n",
      "Epoch: 255/500... Training loss: 0.0288\n",
      "Epoch: 255/500... Training loss: 0.1777\n",
      "Epoch: 255/500... Training loss: 0.0428\n",
      "Epoch: 255/500... Training loss: 0.0877\n",
      "Epoch: 255/500... Training loss: 0.1271\n",
      "Epoch: 255/500... Training loss: 0.0422\n",
      "Epoch: 255/500... Training loss: 0.0121\n",
      "Epoch: 255/500... Training loss: 0.0698\n",
      "Epoch: 255/500... Training loss: 0.0485\n",
      "Epoch: 255/500... Training loss: 0.0539\n",
      "Epoch: 255/500... Training loss: 0.0299\n",
      "Epoch: 255/500... Training loss: 0.0710\n",
      "Epoch: 255/500... Training loss: 0.0546\n",
      "Epoch: 255/500... Training loss: 0.0209\n",
      "Epoch: 255/500... Training loss: 0.0340\n",
      "Epoch: 255/500... Training loss: 0.0159\n",
      "Epoch: 255/500... Training loss: 0.0161\n",
      "Epoch: 255/500... Training loss: 0.0530\n",
      "Epoch: 255/500... Training loss: 0.0277\n",
      "Epoch: 255/500... Training loss: 0.0261\n",
      "Epoch: 255/500... Training loss: 0.0102\n",
      "Epoch: 255/500... Training loss: 0.0149\n",
      "Epoch: 256/500... Training loss: 0.0468\n",
      "Epoch: 256/500... Training loss: 0.0050\n",
      "Epoch: 256/500... Training loss: 0.0691\n",
      "Epoch: 256/500... Training loss: 0.0652\n",
      "Epoch: 256/500... Training loss: 0.0349\n",
      "Epoch: 256/500... Training loss: 0.0447\n",
      "Epoch: 256/500... Training loss: 0.0115\n",
      "Epoch: 256/500... Training loss: 0.0141\n",
      "Epoch: 256/500... Training loss: 0.0187\n",
      "Epoch: 256/500... Training loss: 0.0350\n",
      "Epoch: 256/500... Training loss: 0.0136\n",
      "Epoch: 256/500... Training loss: 0.0259\n",
      "Epoch: 256/500... Training loss: 0.0432\n",
      "Epoch: 256/500... Training loss: 0.0144\n",
      "Epoch: 256/500... Training loss: 0.0485\n",
      "Epoch: 256/500... Training loss: 0.0075\n",
      "Epoch: 256/500... Training loss: 0.0091\n",
      "Epoch: 256/500... Training loss: 0.0103\n",
      "Epoch: 256/500... Training loss: 0.0310\n",
      "Epoch: 256/500... Training loss: 0.0097\n",
      "Epoch: 256/500... Training loss: 0.0198\n",
      "Epoch: 256/500... Training loss: 0.0116\n",
      "Epoch: 256/500... Training loss: 0.0364\n",
      "Epoch: 256/500... Training loss: 0.0095\n",
      "Epoch: 256/500... Training loss: 0.0049\n",
      "Epoch: 256/500... Training loss: 0.0846\n",
      "Epoch: 256/500... Training loss: 0.0244\n",
      "Epoch: 256/500... Training loss: 0.0206\n",
      "Epoch: 256/500... Training loss: 0.0165\n",
      "Epoch: 256/500... Training loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 256/500... Training loss: 0.0823\n",
      "Epoch: 257/500... Training loss: 0.1837\n",
      "Epoch: 257/500... Training loss: 0.0173\n",
      "Epoch: 257/500... Training loss: 0.0120\n",
      "Epoch: 257/500... Training loss: 0.0104\n",
      "Epoch: 257/500... Training loss: 0.0324\n",
      "Epoch: 257/500... Training loss: 0.1223\n",
      "Epoch: 257/500... Training loss: 0.0410\n",
      "Epoch: 257/500... Training loss: 0.0705\n",
      "Epoch: 257/500... Training loss: 0.0311\n",
      "Epoch: 257/500... Training loss: 0.0301\n",
      "Epoch: 257/500... Training loss: 0.0210\n",
      "Epoch: 257/500... Training loss: 0.0157\n",
      "Epoch: 257/500... Training loss: 0.0148\n",
      "Epoch: 257/500... Training loss: 0.0648\n",
      "Epoch: 257/500... Training loss: 0.0739\n",
      "Epoch: 257/500... Training loss: 0.0034\n",
      "Epoch: 257/500... Training loss: 0.0879\n",
      "Epoch: 257/500... Training loss: 0.0081\n",
      "Epoch: 257/500... Training loss: 0.0283\n",
      "Epoch: 257/500... Training loss: 0.0191\n",
      "Epoch: 257/500... Training loss: 0.0348\n",
      "Epoch: 257/500... Training loss: 0.0101\n",
      "Epoch: 257/500... Training loss: 0.1145\n",
      "Epoch: 257/500... Training loss: 0.0258\n",
      "Epoch: 257/500... Training loss: 0.0063\n",
      "Epoch: 257/500... Training loss: 0.0180\n",
      "Epoch: 257/500... Training loss: 0.0131\n",
      "Epoch: 257/500... Training loss: 0.0041\n",
      "Epoch: 257/500... Training loss: 0.0246\n",
      "Epoch: 257/500... Training loss: 0.0326\n",
      "Epoch: 257/500... Training loss: 0.0078\n",
      "Epoch: 258/500... Training loss: 0.0066\n",
      "Epoch: 258/500... Training loss: 0.0162\n",
      "Epoch: 258/500... Training loss: 0.0144\n",
      "Epoch: 258/500... Training loss: 0.0143\n",
      "Epoch: 258/500... Training loss: 0.1065\n",
      "Epoch: 258/500... Training loss: 0.0156\n",
      "Epoch: 258/500... Training loss: 0.0315\n",
      "Epoch: 258/500... Training loss: 0.0662\n",
      "Epoch: 258/500... Training loss: 0.0047\n",
      "Epoch: 258/500... Training loss: 0.0341\n",
      "Epoch: 258/500... Training loss: 0.0212\n",
      "Epoch: 258/500... Training loss: 0.0612\n",
      "Epoch: 258/500... Training loss: 0.1952\n",
      "Epoch: 258/500... Training loss: 0.0959\n",
      "Epoch: 258/500... Training loss: 0.0133\n",
      "Epoch: 258/500... Training loss: 0.0054\n",
      "Epoch: 258/500... Training loss: 0.0686\n",
      "Epoch: 258/500... Training loss: 0.0407\n",
      "Epoch: 258/500... Training loss: 0.0043\n",
      "Epoch: 258/500... Training loss: 0.0085\n",
      "Epoch: 258/500... Training loss: 0.0146\n",
      "Epoch: 258/500... Training loss: 0.0245\n",
      "Epoch: 258/500... Training loss: 0.0433\n",
      "Epoch: 258/500... Training loss: 0.0110\n",
      "Epoch: 258/500... Training loss: 0.0104\n",
      "Epoch: 258/500... Training loss: 0.0418\n",
      "Epoch: 258/500... Training loss: 0.0361\n",
      "Epoch: 258/500... Training loss: 0.0048\n",
      "Epoch: 258/500... Training loss: 0.0115\n",
      "Epoch: 258/500... Training loss: 0.0570\n",
      "Epoch: 258/500... Training loss: 0.0366\n",
      "Epoch: 259/500... Training loss: 0.0932\n",
      "Epoch: 259/500... Training loss: 0.0600\n",
      "Epoch: 259/500... Training loss: 0.0836\n",
      "Epoch: 259/500... Training loss: 0.0864\n",
      "Epoch: 259/500... Training loss: 0.0395\n",
      "Epoch: 259/500... Training loss: 0.0278\n",
      "Epoch: 259/500... Training loss: 0.0051\n",
      "Epoch: 259/500... Training loss: 0.0061\n",
      "Epoch: 259/500... Training loss: 0.0283\n",
      "Epoch: 259/500... Training loss: 0.2049\n",
      "Epoch: 259/500... Training loss: 0.1338\n",
      "Epoch: 259/500... Training loss: 0.0161\n",
      "Epoch: 259/500... Training loss: 0.0215\n",
      "Epoch: 259/500... Training loss: 0.0162\n",
      "Epoch: 259/500... Training loss: 0.0305\n",
      "Epoch: 259/500... Training loss: 0.0151\n",
      "Epoch: 259/500... Training loss: 0.0122\n",
      "Epoch: 259/500... Training loss: 0.0819\n",
      "Epoch: 259/500... Training loss: 0.1088\n",
      "Epoch: 259/500... Training loss: 0.0527\n",
      "Epoch: 259/500... Training loss: 0.0083\n",
      "Epoch: 259/500... Training loss: 0.0894\n",
      "Epoch: 259/500... Training loss: 0.0131\n",
      "Epoch: 259/500... Training loss: 0.0151\n",
      "Epoch: 259/500... Training loss: 0.0168\n",
      "Epoch: 259/500... Training loss: 0.0113\n",
      "Epoch: 259/500... Training loss: 0.0123\n",
      "Epoch: 259/500... Training loss: 0.0197\n",
      "Epoch: 259/500... Training loss: 0.0352\n",
      "Epoch: 259/500... Training loss: 0.0331\n",
      "Epoch: 259/500... Training loss: 0.0034\n",
      "Epoch: 260/500... Training loss: 0.1454\n",
      "Epoch: 260/500... Training loss: 0.1413\n",
      "Epoch: 260/500... Training loss: 0.0732\n",
      "Epoch: 260/500... Training loss: 0.0410\n",
      "Epoch: 260/500... Training loss: 0.0802\n",
      "Epoch: 260/500... Training loss: 0.0276\n",
      "Epoch: 260/500... Training loss: 0.0060\n",
      "Epoch: 260/500... Training loss: 0.0597\n",
      "Epoch: 260/500... Training loss: 0.0115\n",
      "Epoch: 260/500... Training loss: 0.0306\n",
      "Epoch: 260/500... Training loss: 0.0236\n",
      "Epoch: 260/500... Training loss: 0.0372\n",
      "Epoch: 260/500... Training loss: 0.0556\n",
      "Epoch: 260/500... Training loss: 0.0087\n",
      "Epoch: 260/500... Training loss: 0.0615\n",
      "Epoch: 260/500... Training loss: 0.0346\n",
      "Epoch: 260/500... Training loss: 0.0151\n",
      "Epoch: 260/500... Training loss: 0.0448\n",
      "Epoch: 260/500... Training loss: 0.0613\n",
      "Epoch: 260/500... Training loss: 0.0602\n",
      "Epoch: 260/500... Training loss: 0.1371\n",
      "Epoch: 260/500... Training loss: 0.0827\n",
      "Epoch: 260/500... Training loss: 0.0964\n",
      "Epoch: 260/500... Training loss: 0.0202\n",
      "Epoch: 260/500... Training loss: 0.0200\n",
      "Epoch: 260/500... Training loss: 0.0240\n",
      "Epoch: 260/500... Training loss: 0.0533\n",
      "Epoch: 260/500... Training loss: 0.0265\n",
      "Epoch: 260/500... Training loss: 0.0719\n",
      "Epoch: 260/500... Training loss: 0.0506\n",
      "Epoch: 260/500... Training loss: 0.0163\n",
      "Epoch: 261/500... Training loss: 0.1185\n",
      "Epoch: 261/500... Training loss: 0.0409\n",
      "Epoch: 261/500... Training loss: 0.0464\n",
      "Epoch: 261/500... Training loss: 0.0411\n",
      "Epoch: 261/500... Training loss: 0.0138\n",
      "Epoch: 261/500... Training loss: 0.0386\n",
      "Epoch: 261/500... Training loss: 0.0213\n",
      "Epoch: 261/500... Training loss: 0.0810\n",
      "Epoch: 261/500... Training loss: 0.0324\n",
      "Epoch: 261/500... Training loss: 0.0140\n",
      "Epoch: 261/500... Training loss: 0.0427\n",
      "Epoch: 261/500... Training loss: 0.0469\n",
      "Epoch: 261/500... Training loss: 0.1497\n",
      "Epoch: 261/500... Training loss: 0.0449\n",
      "Epoch: 261/500... Training loss: 0.0084\n",
      "Epoch: 261/500... Training loss: 0.0134\n",
      "Epoch: 261/500... Training loss: 0.0135\n",
      "Epoch: 261/500... Training loss: 0.1249\n",
      "Epoch: 261/500... Training loss: 0.0269\n",
      "Epoch: 261/500... Training loss: 0.0052\n",
      "Epoch: 261/500... Training loss: 0.0406\n",
      "Epoch: 261/500... Training loss: 0.0620\n",
      "Epoch: 261/500... Training loss: 0.0375\n",
      "Epoch: 261/500... Training loss: 0.0468\n",
      "Epoch: 261/500... Training loss: 0.0136\n",
      "Epoch: 261/500... Training loss: 0.0095\n",
      "Epoch: 261/500... Training loss: 0.0088\n",
      "Epoch: 261/500... Training loss: 0.0157\n",
      "Epoch: 261/500... Training loss: 0.0430\n",
      "Epoch: 261/500... Training loss: 0.0273\n",
      "Epoch: 261/500... Training loss: 0.0220\n",
      "Epoch: 262/500... Training loss: 0.0503\n",
      "Epoch: 262/500... Training loss: 0.0084\n",
      "Epoch: 262/500... Training loss: 0.1442\n",
      "Epoch: 262/500... Training loss: 0.0100\n",
      "Epoch: 262/500... Training loss: 0.0215\n",
      "Epoch: 262/500... Training loss: 0.0252\n",
      "Epoch: 262/500... Training loss: 0.0155\n",
      "Epoch: 262/500... Training loss: 0.0301\n",
      "Epoch: 262/500... Training loss: 0.0160\n",
      "Epoch: 262/500... Training loss: 0.0575\n",
      "Epoch: 262/500... Training loss: 0.0151\n",
      "Epoch: 262/500... Training loss: 0.1340\n",
      "Epoch: 262/500... Training loss: 0.0603\n",
      "Epoch: 262/500... Training loss: 0.0210\n",
      "Epoch: 262/500... Training loss: 0.0117\n",
      "Epoch: 262/500... Training loss: 0.0087\n",
      "Epoch: 262/500... Training loss: 0.0600\n",
      "Epoch: 262/500... Training loss: 0.0144\n",
      "Epoch: 262/500... Training loss: 0.0068\n",
      "Epoch: 262/500... Training loss: 0.0248\n",
      "Epoch: 262/500... Training loss: 0.0207\n",
      "Epoch: 262/500... Training loss: 0.1430\n",
      "Epoch: 262/500... Training loss: 0.0065\n",
      "Epoch: 262/500... Training loss: 0.0649\n",
      "Epoch: 262/500... Training loss: 0.0681\n",
      "Epoch: 262/500... Training loss: 0.0084\n",
      "Epoch: 262/500... Training loss: 0.0055\n",
      "Epoch: 262/500... Training loss: 0.0243\n",
      "Epoch: 262/500... Training loss: 0.0182\n",
      "Epoch: 262/500... Training loss: 0.0073\n",
      "Epoch: 262/500... Training loss: 0.0079\n",
      "Epoch: 263/500... Training loss: 0.0795\n",
      "Epoch: 263/500... Training loss: 0.0095\n",
      "Epoch: 263/500... Training loss: 0.0275\n",
      "Epoch: 263/500... Training loss: 0.0214\n",
      "Epoch: 263/500... Training loss: 0.0277\n",
      "Epoch: 263/500... Training loss: 0.0390\n",
      "Epoch: 263/500... Training loss: 0.0577\n",
      "Epoch: 263/500... Training loss: 0.0180\n",
      "Epoch: 263/500... Training loss: 0.0414\n",
      "Epoch: 263/500... Training loss: 0.0393\n",
      "Epoch: 263/500... Training loss: 0.0347\n",
      "Epoch: 263/500... Training loss: 0.0411\n",
      "Epoch: 263/500... Training loss: 0.1124\n",
      "Epoch: 263/500... Training loss: 0.0034\n",
      "Epoch: 263/500... Training loss: 0.0125\n",
      "Epoch: 263/500... Training loss: 0.0111\n",
      "Epoch: 263/500... Training loss: 0.0284\n",
      "Epoch: 263/500... Training loss: 0.0769\n",
      "Epoch: 263/500... Training loss: 0.0272\n",
      "Epoch: 263/500... Training loss: 0.0113\n",
      "Epoch: 263/500... Training loss: 0.0391\n",
      "Epoch: 263/500... Training loss: 0.0177\n",
      "Epoch: 263/500... Training loss: 0.0057\n",
      "Epoch: 263/500... Training loss: 0.0266\n",
      "Epoch: 263/500... Training loss: 0.0201\n",
      "Epoch: 263/500... Training loss: 0.0101\n",
      "Epoch: 263/500... Training loss: 0.0087\n",
      "Epoch: 263/500... Training loss: 0.0248\n",
      "Epoch: 263/500... Training loss: 0.0472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263/500... Training loss: 0.0101\n",
      "Epoch: 263/500... Training loss: 0.0093\n",
      "Epoch: 264/500... Training loss: 0.0146\n",
      "Epoch: 264/500... Training loss: 0.0083\n",
      "Epoch: 264/500... Training loss: 0.0167\n",
      "Epoch: 264/500... Training loss: 0.0117\n",
      "Epoch: 264/500... Training loss: 0.0180\n",
      "Epoch: 264/500... Training loss: 0.0078\n",
      "Epoch: 264/500... Training loss: 0.0543\n",
      "Epoch: 264/500... Training loss: 0.0275\n",
      "Epoch: 264/500... Training loss: 0.0319\n",
      "Epoch: 264/500... Training loss: 0.0098\n",
      "Epoch: 264/500... Training loss: 0.0548\n",
      "Epoch: 264/500... Training loss: 0.0166\n",
      "Epoch: 264/500... Training loss: 0.0227\n",
      "Epoch: 264/500... Training loss: 0.0117\n",
      "Epoch: 264/500... Training loss: 0.0116\n",
      "Epoch: 264/500... Training loss: 0.0042\n",
      "Epoch: 264/500... Training loss: 0.2102\n",
      "Epoch: 264/500... Training loss: 0.0896\n",
      "Epoch: 264/500... Training loss: 0.0288\n",
      "Epoch: 264/500... Training loss: 0.0209\n",
      "Epoch: 264/500... Training loss: 0.0845\n",
      "Epoch: 264/500... Training loss: 0.0563\n",
      "Epoch: 264/500... Training loss: 0.0503\n",
      "Epoch: 264/500... Training loss: 0.0426\n",
      "Epoch: 264/500... Training loss: 0.0360\n",
      "Epoch: 264/500... Training loss: 0.0067\n",
      "Epoch: 264/500... Training loss: 0.0661\n",
      "Epoch: 264/500... Training loss: 0.0070\n",
      "Epoch: 264/500... Training loss: 0.0717\n",
      "Epoch: 264/500... Training loss: 0.0176\n",
      "Epoch: 264/500... Training loss: 0.0259\n",
      "Epoch: 265/500... Training loss: 0.0204\n",
      "Epoch: 265/500... Training loss: 0.0123\n",
      "Epoch: 265/500... Training loss: 0.0626\n",
      "Epoch: 265/500... Training loss: 0.0228\n",
      "Epoch: 265/500... Training loss: 0.0232\n",
      "Epoch: 265/500... Training loss: 0.0093\n",
      "Epoch: 265/500... Training loss: 0.0031\n",
      "Epoch: 265/500... Training loss: 0.0102\n",
      "Epoch: 265/500... Training loss: 0.0037\n",
      "Epoch: 265/500... Training loss: 0.1017\n",
      "Epoch: 265/500... Training loss: 0.0220\n",
      "Epoch: 265/500... Training loss: 0.0114\n",
      "Epoch: 265/500... Training loss: 0.0310\n",
      "Epoch: 265/500... Training loss: 0.0054\n",
      "Epoch: 265/500... Training loss: 0.0218\n",
      "Epoch: 265/500... Training loss: 0.0719\n",
      "Epoch: 265/500... Training loss: 0.0287\n",
      "Epoch: 265/500... Training loss: 0.0381\n",
      "Epoch: 265/500... Training loss: 0.0123\n",
      "Epoch: 265/500... Training loss: 0.0094\n",
      "Epoch: 265/500... Training loss: 0.0404\n",
      "Epoch: 265/500... Training loss: 0.0272\n",
      "Epoch: 265/500... Training loss: 0.0499\n",
      "Epoch: 265/500... Training loss: 0.0705\n",
      "Epoch: 265/500... Training loss: 0.0677\n",
      "Epoch: 265/500... Training loss: 0.0290\n",
      "Epoch: 265/500... Training loss: 0.0079\n",
      "Epoch: 265/500... Training loss: 0.1580\n",
      "Epoch: 265/500... Training loss: 0.0341\n",
      "Epoch: 265/500... Training loss: 0.0581\n",
      "Epoch: 265/500... Training loss: 0.0080\n",
      "Epoch: 266/500... Training loss: 0.0624\n",
      "Epoch: 266/500... Training loss: 0.0252\n",
      "Epoch: 266/500... Training loss: 0.0234\n",
      "Epoch: 266/500... Training loss: 0.1256\n",
      "Epoch: 266/500... Training loss: 0.0609\n",
      "Epoch: 266/500... Training loss: 0.0399\n",
      "Epoch: 266/500... Training loss: 0.0101\n",
      "Epoch: 266/500... Training loss: 0.0068\n",
      "Epoch: 266/500... Training loss: 0.0111\n",
      "Epoch: 266/500... Training loss: 0.0055\n",
      "Epoch: 266/500... Training loss: 0.0794\n",
      "Epoch: 266/500... Training loss: 0.0271\n",
      "Epoch: 266/500... Training loss: 0.0818\n",
      "Epoch: 266/500... Training loss: 0.0242\n",
      "Epoch: 266/500... Training loss: 0.0097\n",
      "Epoch: 266/500... Training loss: 0.0177\n",
      "Epoch: 266/500... Training loss: 0.0363\n",
      "Epoch: 266/500... Training loss: 0.0138\n",
      "Epoch: 266/500... Training loss: 0.0224\n",
      "Epoch: 266/500... Training loss: 0.0482\n",
      "Epoch: 266/500... Training loss: 0.0671\n",
      "Epoch: 266/500... Training loss: 0.0203\n",
      "Epoch: 266/500... Training loss: 0.0399\n",
      "Epoch: 266/500... Training loss: 0.0513\n",
      "Epoch: 266/500... Training loss: 0.0053\n",
      "Epoch: 266/500... Training loss: 0.0057\n",
      "Epoch: 266/500... Training loss: 0.0912\n",
      "Epoch: 266/500... Training loss: 0.0140\n",
      "Epoch: 266/500... Training loss: 0.0246\n",
      "Epoch: 266/500... Training loss: 0.0300\n",
      "Epoch: 266/500... Training loss: 0.0124\n",
      "Epoch: 267/500... Training loss: 0.0642\n",
      "Epoch: 267/500... Training loss: 0.0680\n",
      "Epoch: 267/500... Training loss: 0.0064\n",
      "Epoch: 267/500... Training loss: 0.0243\n",
      "Epoch: 267/500... Training loss: 0.0441\n",
      "Epoch: 267/500... Training loss: 0.0376\n",
      "Epoch: 267/500... Training loss: 0.0212\n",
      "Epoch: 267/500... Training loss: 0.0195\n",
      "Epoch: 267/500... Training loss: 0.0566\n",
      "Epoch: 267/500... Training loss: 0.0449\n",
      "Epoch: 267/500... Training loss: 0.0564\n",
      "Epoch: 267/500... Training loss: 0.0401\n",
      "Epoch: 267/500... Training loss: 0.0167\n",
      "Epoch: 267/500... Training loss: 0.0131\n",
      "Epoch: 267/500... Training loss: 0.0177\n",
      "Epoch: 267/500... Training loss: 0.0474\n",
      "Epoch: 267/500... Training loss: 0.0102\n",
      "Epoch: 267/500... Training loss: 0.0172\n",
      "Epoch: 267/500... Training loss: 0.0037\n",
      "Epoch: 267/500... Training loss: 0.0334\n",
      "Epoch: 267/500... Training loss: 0.0350\n",
      "Epoch: 267/500... Training loss: 0.0041\n",
      "Epoch: 267/500... Training loss: 0.2321\n",
      "Epoch: 267/500... Training loss: 0.0065\n",
      "Epoch: 267/500... Training loss: 0.0089\n",
      "Epoch: 267/500... Training loss: 0.0447\n",
      "Epoch: 267/500... Training loss: 0.0214\n",
      "Epoch: 267/500... Training loss: 0.0129\n",
      "Epoch: 267/500... Training loss: 0.0137\n",
      "Epoch: 267/500... Training loss: 0.1033\n",
      "Epoch: 267/500... Training loss: 0.0090\n",
      "Epoch: 268/500... Training loss: 0.2442\n",
      "Epoch: 268/500... Training loss: 0.0247\n",
      "Epoch: 268/500... Training loss: 0.0082\n",
      "Epoch: 268/500... Training loss: 0.0930\n",
      "Epoch: 268/500... Training loss: 0.1106\n",
      "Epoch: 268/500... Training loss: 0.0564\n",
      "Epoch: 268/500... Training loss: 0.0041\n",
      "Epoch: 268/500... Training loss: 0.1303\n",
      "Epoch: 268/500... Training loss: 0.0113\n",
      "Epoch: 268/500... Training loss: 0.0117\n",
      "Epoch: 268/500... Training loss: 0.0228\n",
      "Epoch: 268/500... Training loss: 0.0497\n",
      "Epoch: 268/500... Training loss: 0.0189\n",
      "Epoch: 268/500... Training loss: 0.0210\n",
      "Epoch: 268/500... Training loss: 0.0258\n",
      "Epoch: 268/500... Training loss: 0.0311\n",
      "Epoch: 268/500... Training loss: 0.0100\n",
      "Epoch: 268/500... Training loss: 0.0140\n",
      "Epoch: 268/500... Training loss: 0.0223\n",
      "Epoch: 268/500... Training loss: 0.0236\n",
      "Epoch: 268/500... Training loss: 0.0048\n",
      "Epoch: 268/500... Training loss: 0.0560\n",
      "Epoch: 268/500... Training loss: 0.1208\n",
      "Epoch: 268/500... Training loss: 0.0114\n",
      "Epoch: 268/500... Training loss: 0.0530\n",
      "Epoch: 268/500... Training loss: 0.0090\n",
      "Epoch: 268/500... Training loss: 0.0442\n",
      "Epoch: 268/500... Training loss: 0.0114\n",
      "Epoch: 268/500... Training loss: 0.0663\n",
      "Epoch: 268/500... Training loss: 0.0071\n",
      "Epoch: 268/500... Training loss: 0.0165\n",
      "Epoch: 269/500... Training loss: 0.0388\n",
      "Epoch: 269/500... Training loss: 0.0055\n",
      "Epoch: 269/500... Training loss: 0.0040\n",
      "Epoch: 269/500... Training loss: 0.0740\n",
      "Epoch: 269/500... Training loss: 0.0234\n",
      "Epoch: 269/500... Training loss: 0.0803\n",
      "Epoch: 269/500... Training loss: 0.0102\n",
      "Epoch: 269/500... Training loss: 0.0531\n",
      "Epoch: 269/500... Training loss: 0.0402\n",
      "Epoch: 269/500... Training loss: 0.0833\n",
      "Epoch: 269/500... Training loss: 0.0526\n",
      "Epoch: 269/500... Training loss: 0.0111\n",
      "Epoch: 269/500... Training loss: 0.0256\n",
      "Epoch: 269/500... Training loss: 0.0117\n",
      "Epoch: 269/500... Training loss: 0.0173\n",
      "Epoch: 269/500... Training loss: 0.0263\n",
      "Epoch: 269/500... Training loss: 0.0070\n",
      "Epoch: 269/500... Training loss: 0.0270\n",
      "Epoch: 269/500... Training loss: 0.0431\n",
      "Epoch: 269/500... Training loss: 0.0321\n",
      "Epoch: 269/500... Training loss: 0.0225\n",
      "Epoch: 269/500... Training loss: 0.0318\n",
      "Epoch: 269/500... Training loss: 0.0792\n",
      "Epoch: 269/500... Training loss: 0.0376\n",
      "Epoch: 269/500... Training loss: 0.0065\n",
      "Epoch: 269/500... Training loss: 0.0152\n",
      "Epoch: 269/500... Training loss: 0.0390\n",
      "Epoch: 269/500... Training loss: 0.0648\n",
      "Epoch: 269/500... Training loss: 0.0134\n",
      "Epoch: 269/500... Training loss: 0.0097\n",
      "Epoch: 269/500... Training loss: 0.0068\n",
      "Epoch: 270/500... Training loss: 0.0166\n",
      "Epoch: 270/500... Training loss: 0.0645\n",
      "Epoch: 270/500... Training loss: 0.0689\n",
      "Epoch: 270/500... Training loss: 0.0302\n",
      "Epoch: 270/500... Training loss: 0.1127\n",
      "Epoch: 270/500... Training loss: 0.0921\n",
      "Epoch: 270/500... Training loss: 0.0690\n",
      "Epoch: 270/500... Training loss: 0.0278\n",
      "Epoch: 270/500... Training loss: 0.0441\n",
      "Epoch: 270/500... Training loss: 0.0035\n",
      "Epoch: 270/500... Training loss: 0.0050\n",
      "Epoch: 270/500... Training loss: 0.0222\n",
      "Epoch: 270/500... Training loss: 0.0179\n",
      "Epoch: 270/500... Training loss: 0.0254\n",
      "Epoch: 270/500... Training loss: 0.0124\n",
      "Epoch: 270/500... Training loss: 0.0047\n",
      "Epoch: 270/500... Training loss: 0.0073\n",
      "Epoch: 270/500... Training loss: 0.1089\n",
      "Epoch: 270/500... Training loss: 0.0264\n",
      "Epoch: 270/500... Training loss: 0.0163\n",
      "Epoch: 270/500... Training loss: 0.0181\n",
      "Epoch: 270/500... Training loss: 0.0055\n",
      "Epoch: 270/500... Training loss: 0.0574\n",
      "Epoch: 270/500... Training loss: 0.0266\n",
      "Epoch: 270/500... Training loss: 0.0653\n",
      "Epoch: 270/500... Training loss: 0.0574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270/500... Training loss: 0.0718\n",
      "Epoch: 270/500... Training loss: 0.0058\n",
      "Epoch: 270/500... Training loss: 0.0105\n",
      "Epoch: 270/500... Training loss: 0.0253\n",
      "Epoch: 270/500... Training loss: 0.0158\n",
      "Epoch: 271/500... Training loss: 0.1725\n",
      "Epoch: 271/500... Training loss: 0.0448\n",
      "Epoch: 271/500... Training loss: 0.0109\n",
      "Epoch: 271/500... Training loss: 0.0152\n",
      "Epoch: 271/500... Training loss: 0.0101\n",
      "Epoch: 271/500... Training loss: 0.0497\n",
      "Epoch: 271/500... Training loss: 0.0093\n",
      "Epoch: 271/500... Training loss: 0.0124\n",
      "Epoch: 271/500... Training loss: 0.1332\n",
      "Epoch: 271/500... Training loss: 0.0068\n",
      "Epoch: 271/500... Training loss: 0.0100\n",
      "Epoch: 271/500... Training loss: 0.0040\n",
      "Epoch: 271/500... Training loss: 0.0093\n",
      "Epoch: 271/500... Training loss: 0.0302\n",
      "Epoch: 271/500... Training loss: 0.0096\n",
      "Epoch: 271/500... Training loss: 0.0373\n",
      "Epoch: 271/500... Training loss: 0.0061\n",
      "Epoch: 271/500... Training loss: 0.0882\n",
      "Epoch: 271/500... Training loss: 0.1358\n",
      "Epoch: 271/500... Training loss: 0.0386\n",
      "Epoch: 271/500... Training loss: 0.0133\n",
      "Epoch: 271/500... Training loss: 0.0046\n",
      "Epoch: 271/500... Training loss: 0.0212\n",
      "Epoch: 271/500... Training loss: 0.1268\n",
      "Epoch: 271/500... Training loss: 0.0464\n",
      "Epoch: 271/500... Training loss: 0.0136\n",
      "Epoch: 271/500... Training loss: 0.0248\n",
      "Epoch: 271/500... Training loss: 0.1014\n",
      "Epoch: 271/500... Training loss: 0.0164\n",
      "Epoch: 271/500... Training loss: 0.0207\n",
      "Epoch: 271/500... Training loss: 0.0270\n",
      "Epoch: 272/500... Training loss: 0.0027\n",
      "Epoch: 272/500... Training loss: 0.0092\n",
      "Epoch: 272/500... Training loss: 0.0072\n",
      "Epoch: 272/500... Training loss: 0.0138\n",
      "Epoch: 272/500... Training loss: 0.0732\n",
      "Epoch: 272/500... Training loss: 0.0058\n",
      "Epoch: 272/500... Training loss: 0.1753\n",
      "Epoch: 272/500... Training loss: 0.0071\n",
      "Epoch: 272/500... Training loss: 0.0847\n",
      "Epoch: 272/500... Training loss: 0.0031\n",
      "Epoch: 272/500... Training loss: 0.0113\n",
      "Epoch: 272/500... Training loss: 0.0126\n",
      "Epoch: 272/500... Training loss: 0.0033\n",
      "Epoch: 272/500... Training loss: 0.0026\n",
      "Epoch: 272/500... Training loss: 0.0113\n",
      "Epoch: 272/500... Training loss: 0.0141\n",
      "Epoch: 272/500... Training loss: 0.0094\n",
      "Epoch: 272/500... Training loss: 0.0457\n",
      "Epoch: 272/500... Training loss: 0.0346\n",
      "Epoch: 272/500... Training loss: 0.0034\n",
      "Epoch: 272/500... Training loss: 0.0055\n",
      "Epoch: 272/500... Training loss: 0.0133\n",
      "Epoch: 272/500... Training loss: 0.0632\n",
      "Epoch: 272/500... Training loss: 0.1307\n",
      "Epoch: 272/500... Training loss: 0.0135\n",
      "Epoch: 272/500... Training loss: 0.0481\n",
      "Epoch: 272/500... Training loss: 0.0056\n",
      "Epoch: 272/500... Training loss: 0.0046\n",
      "Epoch: 272/500... Training loss: 0.1259\n",
      "Epoch: 272/500... Training loss: 0.0129\n",
      "Epoch: 272/500... Training loss: 0.0326\n",
      "Epoch: 273/500... Training loss: 0.0220\n",
      "Epoch: 273/500... Training loss: 0.0048\n",
      "Epoch: 273/500... Training loss: 0.0240\n",
      "Epoch: 273/500... Training loss: 0.0145\n",
      "Epoch: 273/500... Training loss: 0.0083\n",
      "Epoch: 273/500... Training loss: 0.0056\n",
      "Epoch: 273/500... Training loss: 0.0388\n",
      "Epoch: 273/500... Training loss: 0.0441\n",
      "Epoch: 273/500... Training loss: 0.0097\n",
      "Epoch: 273/500... Training loss: 0.0046\n",
      "Epoch: 273/500... Training loss: 0.0226\n",
      "Epoch: 273/500... Training loss: 0.0293\n",
      "Epoch: 273/500... Training loss: 0.0199\n",
      "Epoch: 273/500... Training loss: 0.0675\n",
      "Epoch: 273/500... Training loss: 0.0163\n",
      "Epoch: 273/500... Training loss: 0.0314\n",
      "Epoch: 273/500... Training loss: 0.0507\n",
      "Epoch: 273/500... Training loss: 0.0752\n",
      "Epoch: 273/500... Training loss: 0.0033\n",
      "Epoch: 273/500... Training loss: 0.1127\n",
      "Epoch: 273/500... Training loss: 0.0154\n",
      "Epoch: 273/500... Training loss: 0.0043\n",
      "Epoch: 273/500... Training loss: 0.0476\n",
      "Epoch: 273/500... Training loss: 0.0177\n",
      "Epoch: 273/500... Training loss: 0.0072\n",
      "Epoch: 273/500... Training loss: 0.0563\n",
      "Epoch: 273/500... Training loss: 0.0093\n",
      "Epoch: 273/500... Training loss: 0.0661\n",
      "Epoch: 273/500... Training loss: 0.0161\n",
      "Epoch: 273/500... Training loss: 0.0468\n",
      "Epoch: 273/500... Training loss: 0.0144\n",
      "Epoch: 274/500... Training loss: 0.0862\n",
      "Epoch: 274/500... Training loss: 0.0448\n",
      "Epoch: 274/500... Training loss: 0.0271\n",
      "Epoch: 274/500... Training loss: 0.0278\n",
      "Epoch: 274/500... Training loss: 0.0660\n",
      "Epoch: 274/500... Training loss: 0.0323\n",
      "Epoch: 274/500... Training loss: 0.0063\n",
      "Epoch: 274/500... Training loss: 0.1251\n",
      "Epoch: 274/500... Training loss: 0.0030\n",
      "Epoch: 274/500... Training loss: 0.0041\n",
      "Epoch: 274/500... Training loss: 0.0059\n",
      "Epoch: 274/500... Training loss: 0.0174\n",
      "Epoch: 274/500... Training loss: 0.0737\n",
      "Epoch: 274/500... Training loss: 0.0030\n",
      "Epoch: 274/500... Training loss: 0.0403\n",
      "Epoch: 274/500... Training loss: 0.0093\n",
      "Epoch: 274/500... Training loss: 0.0132\n",
      "Epoch: 274/500... Training loss: 0.0619\n",
      "Epoch: 274/500... Training loss: 0.0081\n",
      "Epoch: 274/500... Training loss: 0.0616\n",
      "Epoch: 274/500... Training loss: 0.0089\n",
      "Epoch: 274/500... Training loss: 0.1105\n",
      "Epoch: 274/500... Training loss: 0.0623\n",
      "Epoch: 274/500... Training loss: 0.0160\n",
      "Epoch: 274/500... Training loss: 0.0195\n",
      "Epoch: 274/500... Training loss: 0.0085\n",
      "Epoch: 274/500... Training loss: 0.0154\n",
      "Epoch: 274/500... Training loss: 0.0205\n",
      "Epoch: 274/500... Training loss: 0.0408\n",
      "Epoch: 274/500... Training loss: 0.0069\n",
      "Epoch: 274/500... Training loss: 0.0083\n",
      "Epoch: 275/500... Training loss: 0.0570\n",
      "Epoch: 275/500... Training loss: 0.0328\n",
      "Epoch: 275/500... Training loss: 0.0491\n",
      "Epoch: 275/500... Training loss: 0.0117\n",
      "Epoch: 275/500... Training loss: 0.0527\n",
      "Epoch: 275/500... Training loss: 0.0320\n",
      "Epoch: 275/500... Training loss: 0.0258\n",
      "Epoch: 275/500... Training loss: 0.0243\n",
      "Epoch: 275/500... Training loss: 0.0054\n",
      "Epoch: 275/500... Training loss: 0.0064\n",
      "Epoch: 275/500... Training loss: 0.0353\n",
      "Epoch: 275/500... Training loss: 0.0174\n",
      "Epoch: 275/500... Training loss: 0.0040\n",
      "Epoch: 275/500... Training loss: 0.0286\n",
      "Epoch: 275/500... Training loss: 0.0068\n",
      "Epoch: 275/500... Training loss: 0.0072\n",
      "Epoch: 275/500... Training loss: 0.0062\n",
      "Epoch: 275/500... Training loss: 0.0045\n",
      "Epoch: 275/500... Training loss: 0.0174\n",
      "Epoch: 275/500... Training loss: 0.1609\n",
      "Epoch: 275/500... Training loss: 0.0880\n",
      "Epoch: 275/500... Training loss: 0.0362\n",
      "Epoch: 275/500... Training loss: 0.0091\n",
      "Epoch: 275/500... Training loss: 0.0417\n",
      "Epoch: 275/500... Training loss: 0.0206\n",
      "Epoch: 275/500... Training loss: 0.0078\n",
      "Epoch: 275/500... Training loss: 0.0427\n",
      "Epoch: 275/500... Training loss: 0.0661\n",
      "Epoch: 275/500... Training loss: 0.0194\n",
      "Epoch: 275/500... Training loss: 0.0202\n",
      "Epoch: 275/500... Training loss: 0.0123\n",
      "Epoch: 276/500... Training loss: 0.0656\n",
      "Epoch: 276/500... Training loss: 0.0467\n",
      "Epoch: 276/500... Training loss: 0.0052\n",
      "Epoch: 276/500... Training loss: 0.0247\n",
      "Epoch: 276/500... Training loss: 0.0169\n",
      "Epoch: 276/500... Training loss: 0.0608\n",
      "Epoch: 276/500... Training loss: 0.0174\n",
      "Epoch: 276/500... Training loss: 0.0228\n",
      "Epoch: 276/500... Training loss: 0.0469\n",
      "Epoch: 276/500... Training loss: 0.0312\n",
      "Epoch: 276/500... Training loss: 0.0229\n",
      "Epoch: 276/500... Training loss: 0.1189\n",
      "Epoch: 276/500... Training loss: 0.0060\n",
      "Epoch: 276/500... Training loss: 0.0027\n",
      "Epoch: 276/500... Training loss: 0.0263\n",
      "Epoch: 276/500... Training loss: 0.0078\n",
      "Epoch: 276/500... Training loss: 0.0286\n",
      "Epoch: 276/500... Training loss: 0.0155\n",
      "Epoch: 276/500... Training loss: 0.0623\n",
      "Epoch: 276/500... Training loss: 0.0281\n",
      "Epoch: 276/500... Training loss: 0.0041\n",
      "Epoch: 276/500... Training loss: 0.0863\n",
      "Epoch: 276/500... Training loss: 0.0177\n",
      "Epoch: 276/500... Training loss: 0.0235\n",
      "Epoch: 276/500... Training loss: 0.0179\n",
      "Epoch: 276/500... Training loss: 0.0160\n",
      "Epoch: 276/500... Training loss: 0.0072\n",
      "Epoch: 276/500... Training loss: 0.0215\n",
      "Epoch: 276/500... Training loss: 0.0038\n",
      "Epoch: 276/500... Training loss: 0.0200\n",
      "Epoch: 276/500... Training loss: 0.0611\n",
      "Epoch: 277/500... Training loss: 0.0123\n",
      "Epoch: 277/500... Training loss: 0.0320\n",
      "Epoch: 277/500... Training loss: 0.0291\n",
      "Epoch: 277/500... Training loss: 0.0127\n",
      "Epoch: 277/500... Training loss: 0.0202\n",
      "Epoch: 277/500... Training loss: 0.0291\n",
      "Epoch: 277/500... Training loss: 0.0494\n",
      "Epoch: 277/500... Training loss: 0.0283\n",
      "Epoch: 277/500... Training loss: 0.0183\n",
      "Epoch: 277/500... Training loss: 0.0168\n",
      "Epoch: 277/500... Training loss: 0.0429\n",
      "Epoch: 277/500... Training loss: 0.0990\n",
      "Epoch: 277/500... Training loss: 0.0063\n",
      "Epoch: 277/500... Training loss: 0.0244\n",
      "Epoch: 277/500... Training loss: 0.1077\n",
      "Epoch: 277/500... Training loss: 0.0058\n",
      "Epoch: 277/500... Training loss: 0.0211\n",
      "Epoch: 277/500... Training loss: 0.0420\n",
      "Epoch: 277/500... Training loss: 0.0388\n",
      "Epoch: 277/500... Training loss: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 277/500... Training loss: 0.0109\n",
      "Epoch: 277/500... Training loss: 0.0266\n",
      "Epoch: 277/500... Training loss: 0.0314\n",
      "Epoch: 277/500... Training loss: 0.0050\n",
      "Epoch: 277/500... Training loss: 0.0509\n",
      "Epoch: 277/500... Training loss: 0.0152\n",
      "Epoch: 277/500... Training loss: 0.0878\n",
      "Epoch: 277/500... Training loss: 0.0128\n",
      "Epoch: 277/500... Training loss: 0.0456\n",
      "Epoch: 277/500... Training loss: 0.0061\n",
      "Epoch: 277/500... Training loss: 0.0120\n",
      "Epoch: 278/500... Training loss: 0.0122\n",
      "Epoch: 278/500... Training loss: 0.0401\n",
      "Epoch: 278/500... Training loss: 0.0300\n",
      "Epoch: 278/500... Training loss: 0.0093\n",
      "Epoch: 278/500... Training loss: 0.0074\n",
      "Epoch: 278/500... Training loss: 0.0836\n",
      "Epoch: 278/500... Training loss: 0.0158\n",
      "Epoch: 278/500... Training loss: 0.0061\n",
      "Epoch: 278/500... Training loss: 0.0105\n",
      "Epoch: 278/500... Training loss: 0.0120\n",
      "Epoch: 278/500... Training loss: 0.0958\n",
      "Epoch: 278/500... Training loss: 0.0112\n",
      "Epoch: 278/500... Training loss: 0.0289\n",
      "Epoch: 278/500... Training loss: 0.0143\n",
      "Epoch: 278/500... Training loss: 0.0410\n",
      "Epoch: 278/500... Training loss: 0.1249\n",
      "Epoch: 278/500... Training loss: 0.0046\n",
      "Epoch: 278/500... Training loss: 0.0093\n",
      "Epoch: 278/500... Training loss: 0.0212\n",
      "Epoch: 278/500... Training loss: 0.0220\n",
      "Epoch: 278/500... Training loss: 0.0553\n",
      "Epoch: 278/500... Training loss: 0.0282\n",
      "Epoch: 278/500... Training loss: 0.1569\n",
      "Epoch: 278/500... Training loss: 0.0479\n",
      "Epoch: 278/500... Training loss: 0.0146\n",
      "Epoch: 278/500... Training loss: 0.0056\n",
      "Epoch: 278/500... Training loss: 0.0051\n",
      "Epoch: 278/500... Training loss: 0.0185\n",
      "Epoch: 278/500... Training loss: 0.0853\n",
      "Epoch: 278/500... Training loss: 0.0942\n",
      "Epoch: 278/500... Training loss: 0.0383\n",
      "Epoch: 279/500... Training loss: 0.0090\n",
      "Epoch: 279/500... Training loss: 0.0075\n",
      "Epoch: 279/500... Training loss: 0.0117\n",
      "Epoch: 279/500... Training loss: 0.0821\n",
      "Epoch: 279/500... Training loss: 0.0086\n",
      "Epoch: 279/500... Training loss: 0.0087\n",
      "Epoch: 279/500... Training loss: 0.0772\n",
      "Epoch: 279/500... Training loss: 0.0530\n",
      "Epoch: 279/500... Training loss: 0.0613\n",
      "Epoch: 279/500... Training loss: 0.0529\n",
      "Epoch: 279/500... Training loss: 0.0861\n",
      "Epoch: 279/500... Training loss: 0.0179\n",
      "Epoch: 279/500... Training loss: 0.0137\n",
      "Epoch: 279/500... Training loss: 0.0327\n",
      "Epoch: 279/500... Training loss: 0.0124\n",
      "Epoch: 279/500... Training loss: 0.0204\n",
      "Epoch: 279/500... Training loss: 0.0188\n",
      "Epoch: 279/500... Training loss: 0.0294\n",
      "Epoch: 279/500... Training loss: 0.0582\n",
      "Epoch: 279/500... Training loss: 0.0042\n",
      "Epoch: 279/500... Training loss: 0.0045\n",
      "Epoch: 279/500... Training loss: 0.0037\n",
      "Epoch: 279/500... Training loss: 0.0968\n",
      "Epoch: 279/500... Training loss: 0.0054\n",
      "Epoch: 279/500... Training loss: 0.0225\n",
      "Epoch: 279/500... Training loss: 0.0463\n",
      "Epoch: 279/500... Training loss: 0.0090\n",
      "Epoch: 279/500... Training loss: 0.0820\n",
      "Epoch: 279/500... Training loss: 0.0045\n",
      "Epoch: 279/500... Training loss: 0.0389\n",
      "Epoch: 279/500... Training loss: 0.0073\n",
      "Epoch: 280/500... Training loss: 0.1444\n",
      "Epoch: 280/500... Training loss: 0.0166\n",
      "Epoch: 280/500... Training loss: 0.0229\n",
      "Epoch: 280/500... Training loss: 0.0091\n",
      "Epoch: 280/500... Training loss: 0.0526\n",
      "Epoch: 280/500... Training loss: 0.0219\n",
      "Epoch: 280/500... Training loss: 0.0045\n",
      "Epoch: 280/500... Training loss: 0.0187\n",
      "Epoch: 280/500... Training loss: 0.0105\n",
      "Epoch: 280/500... Training loss: 0.0064\n",
      "Epoch: 280/500... Training loss: 0.0457\n",
      "Epoch: 280/500... Training loss: 0.0668\n",
      "Epoch: 280/500... Training loss: 0.0252\n",
      "Epoch: 280/500... Training loss: 0.0104\n",
      "Epoch: 280/500... Training loss: 0.0075\n",
      "Epoch: 280/500... Training loss: 0.0074\n",
      "Epoch: 280/500... Training loss: 0.0470\n",
      "Epoch: 280/500... Training loss: 0.0119\n",
      "Epoch: 280/500... Training loss: 0.0259\n",
      "Epoch: 280/500... Training loss: 0.0314\n",
      "Epoch: 280/500... Training loss: 0.0321\n",
      "Epoch: 280/500... Training loss: 0.0104\n",
      "Epoch: 280/500... Training loss: 0.0119\n",
      "Epoch: 280/500... Training loss: 0.0119\n",
      "Epoch: 280/500... Training loss: 0.0267\n",
      "Epoch: 280/500... Training loss: 0.0104\n",
      "Epoch: 280/500... Training loss: 0.0409\n",
      "Epoch: 280/500... Training loss: 0.0238\n",
      "Epoch: 280/500... Training loss: 0.0484\n",
      "Epoch: 280/500... Training loss: 0.0134\n",
      "Epoch: 280/500... Training loss: 0.0662\n",
      "Epoch: 281/500... Training loss: 0.0023\n",
      "Epoch: 281/500... Training loss: 0.0102\n",
      "Epoch: 281/500... Training loss: 0.0567\n",
      "Epoch: 281/500... Training loss: 0.0547\n",
      "Epoch: 281/500... Training loss: 0.0286\n",
      "Epoch: 281/500... Training loss: 0.0077\n",
      "Epoch: 281/500... Training loss: 0.0444\n",
      "Epoch: 281/500... Training loss: 0.0045\n",
      "Epoch: 281/500... Training loss: 0.1158\n",
      "Epoch: 281/500... Training loss: 0.0330\n",
      "Epoch: 281/500... Training loss: 0.0099\n",
      "Epoch: 281/500... Training loss: 0.0052\n",
      "Epoch: 281/500... Training loss: 0.0538\n",
      "Epoch: 281/500... Training loss: 0.0049\n",
      "Epoch: 281/500... Training loss: 0.0275\n",
      "Epoch: 281/500... Training loss: 0.0099\n",
      "Epoch: 281/500... Training loss: 0.0141\n",
      "Epoch: 281/500... Training loss: 0.0071\n",
      "Epoch: 281/500... Training loss: 0.0290\n",
      "Epoch: 281/500... Training loss: 0.0760\n",
      "Epoch: 281/500... Training loss: 0.0066\n",
      "Epoch: 281/500... Training loss: 0.0213\n",
      "Epoch: 281/500... Training loss: 0.0357\n",
      "Epoch: 281/500... Training loss: 0.0051\n",
      "Epoch: 281/500... Training loss: 0.0129\n",
      "Epoch: 281/500... Training loss: 0.0033\n",
      "Epoch: 281/500... Training loss: 0.0509\n",
      "Epoch: 281/500... Training loss: 0.0248\n",
      "Epoch: 281/500... Training loss: 0.0153\n",
      "Epoch: 281/500... Training loss: 0.0051\n",
      "Epoch: 281/500... Training loss: 0.0215\n",
      "Epoch: 282/500... Training loss: 0.0701\n",
      "Epoch: 282/500... Training loss: 0.0349\n",
      "Epoch: 282/500... Training loss: 0.0534\n",
      "Epoch: 282/500... Training loss: 0.0312\n",
      "Epoch: 282/500... Training loss: 0.0451\n",
      "Epoch: 282/500... Training loss: 0.0143\n",
      "Epoch: 282/500... Training loss: 0.0049\n",
      "Epoch: 282/500... Training loss: 0.0135\n",
      "Epoch: 282/500... Training loss: 0.0301\n",
      "Epoch: 282/500... Training loss: 0.0038\n",
      "Epoch: 282/500... Training loss: 0.0354\n",
      "Epoch: 282/500... Training loss: 0.0192\n",
      "Epoch: 282/500... Training loss: 0.0118\n",
      "Epoch: 282/500... Training loss: 0.0261\n",
      "Epoch: 282/500... Training loss: 0.0147\n",
      "Epoch: 282/500... Training loss: 0.0107\n",
      "Epoch: 282/500... Training loss: 0.0090\n",
      "Epoch: 282/500... Training loss: 0.0120\n",
      "Epoch: 282/500... Training loss: 0.0022\n",
      "Epoch: 282/500... Training loss: 0.0090\n",
      "Epoch: 282/500... Training loss: 0.0125\n",
      "Epoch: 282/500... Training loss: 0.0063\n",
      "Epoch: 282/500... Training loss: 0.0398\n",
      "Epoch: 282/500... Training loss: 0.0095\n",
      "Epoch: 282/500... Training loss: 0.0251\n",
      "Epoch: 282/500... Training loss: 0.0115\n",
      "Epoch: 282/500... Training loss: 0.0026\n",
      "Epoch: 282/500... Training loss: 0.1001\n",
      "Epoch: 282/500... Training loss: 0.0065\n",
      "Epoch: 282/500... Training loss: 0.0057\n",
      "Epoch: 282/500... Training loss: 0.0348\n",
      "Epoch: 283/500... Training loss: 0.1005\n",
      "Epoch: 283/500... Training loss: 0.0390\n",
      "Epoch: 283/500... Training loss: 0.0235\n",
      "Epoch: 283/500... Training loss: 0.0123\n",
      "Epoch: 283/500... Training loss: 0.0311\n",
      "Epoch: 283/500... Training loss: 0.0297\n",
      "Epoch: 283/500... Training loss: 0.0173\n",
      "Epoch: 283/500... Training loss: 0.0109\n",
      "Epoch: 283/500... Training loss: 0.0093\n",
      "Epoch: 283/500... Training loss: 0.0520\n",
      "Epoch: 283/500... Training loss: 0.0526\n",
      "Epoch: 283/500... Training loss: 0.0244\n",
      "Epoch: 283/500... Training loss: 0.0122\n",
      "Epoch: 283/500... Training loss: 0.0320\n",
      "Epoch: 283/500... Training loss: 0.0273\n",
      "Epoch: 283/500... Training loss: 0.0018\n",
      "Epoch: 283/500... Training loss: 0.0064\n",
      "Epoch: 283/500... Training loss: 0.0229\n",
      "Epoch: 283/500... Training loss: 0.0590\n",
      "Epoch: 283/500... Training loss: 0.0402\n",
      "Epoch: 283/500... Training loss: 0.0141\n",
      "Epoch: 283/500... Training loss: 0.0054\n",
      "Epoch: 283/500... Training loss: 0.0078\n",
      "Epoch: 283/500... Training loss: 0.0047\n",
      "Epoch: 283/500... Training loss: 0.0022\n",
      "Epoch: 283/500... Training loss: 0.0082\n",
      "Epoch: 283/500... Training loss: 0.0063\n",
      "Epoch: 283/500... Training loss: 0.1694\n",
      "Epoch: 283/500... Training loss: 0.0413\n",
      "Epoch: 283/500... Training loss: 0.0037\n",
      "Epoch: 283/500... Training loss: 0.0137\n",
      "Epoch: 284/500... Training loss: 0.0564\n",
      "Epoch: 284/500... Training loss: 0.1105\n",
      "Epoch: 284/500... Training loss: 0.0260\n",
      "Epoch: 284/500... Training loss: 0.0711\n",
      "Epoch: 284/500... Training loss: 0.0175\n",
      "Epoch: 284/500... Training loss: 0.0052\n",
      "Epoch: 284/500... Training loss: 0.0019\n",
      "Epoch: 284/500... Training loss: 0.0230\n",
      "Epoch: 284/500... Training loss: 0.0136\n",
      "Epoch: 284/500... Training loss: 0.0081\n",
      "Epoch: 284/500... Training loss: 0.0802\n",
      "Epoch: 284/500... Training loss: 0.0672\n",
      "Epoch: 284/500... Training loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 284/500... Training loss: 0.0401\n",
      "Epoch: 284/500... Training loss: 0.0174\n",
      "Epoch: 284/500... Training loss: 0.0067\n",
      "Epoch: 284/500... Training loss: 0.0031\n",
      "Epoch: 284/500... Training loss: 0.0034\n",
      "Epoch: 284/500... Training loss: 0.0113\n",
      "Epoch: 284/500... Training loss: 0.0354\n",
      "Epoch: 284/500... Training loss: 0.0028\n",
      "Epoch: 284/500... Training loss: 0.0033\n",
      "Epoch: 284/500... Training loss: 0.0233\n",
      "Epoch: 284/500... Training loss: 0.0040\n",
      "Epoch: 284/500... Training loss: 0.0072\n",
      "Epoch: 284/500... Training loss: 0.0179\n",
      "Epoch: 284/500... Training loss: 0.0197\n",
      "Epoch: 284/500... Training loss: 0.0683\n",
      "Epoch: 284/500... Training loss: 0.0334\n",
      "Epoch: 284/500... Training loss: 0.0307\n",
      "Epoch: 284/500... Training loss: 0.0199\n",
      "Epoch: 285/500... Training loss: 0.1037\n",
      "Epoch: 285/500... Training loss: 0.0555\n",
      "Epoch: 285/500... Training loss: 0.0587\n",
      "Epoch: 285/500... Training loss: 0.0138\n",
      "Epoch: 285/500... Training loss: 0.0848\n",
      "Epoch: 285/500... Training loss: 0.0186\n",
      "Epoch: 285/500... Training loss: 0.0091\n",
      "Epoch: 285/500... Training loss: 0.0181\n",
      "Epoch: 285/500... Training loss: 0.0083\n",
      "Epoch: 285/500... Training loss: 0.0048\n",
      "Epoch: 285/500... Training loss: 0.0719\n",
      "Epoch: 285/500... Training loss: 0.0860\n",
      "Epoch: 285/500... Training loss: 0.1234\n",
      "Epoch: 285/500... Training loss: 0.0673\n",
      "Epoch: 285/500... Training loss: 0.0132\n",
      "Epoch: 285/500... Training loss: 0.0023\n",
      "Epoch: 285/500... Training loss: 0.0461\n",
      "Epoch: 285/500... Training loss: 0.0026\n",
      "Epoch: 285/500... Training loss: 0.0457\n",
      "Epoch: 285/500... Training loss: 0.0197\n",
      "Epoch: 285/500... Training loss: 0.0345\n",
      "Epoch: 285/500... Training loss: 0.0019\n",
      "Epoch: 285/500... Training loss: 0.0345\n",
      "Epoch: 285/500... Training loss: 0.0050\n",
      "Epoch: 285/500... Training loss: 0.0100\n",
      "Epoch: 285/500... Training loss: 0.0124\n",
      "Epoch: 285/500... Training loss: 0.0050\n",
      "Epoch: 285/500... Training loss: 0.0072\n",
      "Epoch: 285/500... Training loss: 0.0196\n",
      "Epoch: 285/500... Training loss: 0.0077\n",
      "Epoch: 285/500... Training loss: 0.0496\n",
      "Epoch: 286/500... Training loss: 0.0663\n",
      "Epoch: 286/500... Training loss: 0.1161\n",
      "Epoch: 286/500... Training loss: 0.1933\n",
      "Epoch: 286/500... Training loss: 0.1290\n",
      "Epoch: 286/500... Training loss: 0.0206\n",
      "Epoch: 286/500... Training loss: 0.0144\n",
      "Epoch: 286/500... Training loss: 0.0084\n",
      "Epoch: 286/500... Training loss: 0.0692\n",
      "Epoch: 286/500... Training loss: 0.0085\n",
      "Epoch: 286/500... Training loss: 0.0386\n",
      "Epoch: 286/500... Training loss: 0.0234\n",
      "Epoch: 286/500... Training loss: 0.0402\n",
      "Epoch: 286/500... Training loss: 0.1096\n",
      "Epoch: 286/500... Training loss: 0.0074\n",
      "Epoch: 286/500... Training loss: 0.0233\n",
      "Epoch: 286/500... Training loss: 0.0252\n",
      "Epoch: 286/500... Training loss: 0.0106\n",
      "Epoch: 286/500... Training loss: 0.0490\n",
      "Epoch: 286/500... Training loss: 0.0048\n",
      "Epoch: 286/500... Training loss: 0.0047\n",
      "Epoch: 286/500... Training loss: 0.0292\n",
      "Epoch: 286/500... Training loss: 0.0112\n",
      "Epoch: 286/500... Training loss: 0.0398\n",
      "Epoch: 286/500... Training loss: 0.0039\n",
      "Epoch: 286/500... Training loss: 0.0643\n",
      "Epoch: 286/500... Training loss: 0.0247\n",
      "Epoch: 286/500... Training loss: 0.0071\n",
      "Epoch: 286/500... Training loss: 0.0074\n",
      "Epoch: 286/500... Training loss: 0.0022\n",
      "Epoch: 286/500... Training loss: 0.0230\n",
      "Epoch: 286/500... Training loss: 0.0103\n",
      "Epoch: 287/500... Training loss: 0.0919\n",
      "Epoch: 287/500... Training loss: 0.1669\n",
      "Epoch: 287/500... Training loss: 0.0035\n",
      "Epoch: 287/500... Training loss: 0.0268\n",
      "Epoch: 287/500... Training loss: 0.0719\n",
      "Epoch: 287/500... Training loss: 0.0265\n",
      "Epoch: 287/500... Training loss: 0.0113\n",
      "Epoch: 287/500... Training loss: 0.0030\n",
      "Epoch: 287/500... Training loss: 0.0699\n",
      "Epoch: 287/500... Training loss: 0.0119\n",
      "Epoch: 287/500... Training loss: 0.0635\n",
      "Epoch: 287/500... Training loss: 0.0333\n",
      "Epoch: 287/500... Training loss: 0.0501\n",
      "Epoch: 287/500... Training loss: 0.0552\n",
      "Epoch: 287/500... Training loss: 0.0225\n",
      "Epoch: 287/500... Training loss: 0.0334\n",
      "Epoch: 287/500... Training loss: 0.1450\n",
      "Epoch: 287/500... Training loss: 0.0047\n",
      "Epoch: 287/500... Training loss: 0.0977\n",
      "Epoch: 287/500... Training loss: 0.0300\n",
      "Epoch: 287/500... Training loss: 0.0019\n",
      "Epoch: 287/500... Training loss: 0.0099\n",
      "Epoch: 287/500... Training loss: 0.0687\n",
      "Epoch: 287/500... Training loss: 0.0074\n",
      "Epoch: 287/500... Training loss: 0.0122\n",
      "Epoch: 287/500... Training loss: 0.0033\n",
      "Epoch: 287/500... Training loss: 0.0564\n",
      "Epoch: 287/500... Training loss: 0.0218\n",
      "Epoch: 287/500... Training loss: 0.0067\n",
      "Epoch: 287/500... Training loss: 0.0546\n",
      "Epoch: 287/500... Training loss: 0.0487\n",
      "Epoch: 288/500... Training loss: 0.0105\n",
      "Epoch: 288/500... Training loss: 0.0362\n",
      "Epoch: 288/500... Training loss: 0.0189\n",
      "Epoch: 288/500... Training loss: 0.0736\n",
      "Epoch: 288/500... Training loss: 0.0108\n",
      "Epoch: 288/500... Training loss: 0.0139\n",
      "Epoch: 288/500... Training loss: 0.0725\n",
      "Epoch: 288/500... Training loss: 0.0657\n",
      "Epoch: 288/500... Training loss: 0.0044\n",
      "Epoch: 288/500... Training loss: 0.0042\n",
      "Epoch: 288/500... Training loss: 0.0824\n",
      "Epoch: 288/500... Training loss: 0.1081\n",
      "Epoch: 288/500... Training loss: 0.0398\n",
      "Epoch: 288/500... Training loss: 0.0556\n",
      "Epoch: 288/500... Training loss: 0.0544\n",
      "Epoch: 288/500... Training loss: 0.0567\n",
      "Epoch: 288/500... Training loss: 0.0080\n",
      "Epoch: 288/500... Training loss: 0.0072\n",
      "Epoch: 288/500... Training loss: 0.0789\n",
      "Epoch: 288/500... Training loss: 0.0055\n",
      "Epoch: 288/500... Training loss: 0.0121\n",
      "Epoch: 288/500... Training loss: 0.0241\n",
      "Epoch: 288/500... Training loss: 0.0168\n",
      "Epoch: 288/500... Training loss: 0.0232\n",
      "Epoch: 288/500... Training loss: 0.0166\n",
      "Epoch: 288/500... Training loss: 0.0255\n",
      "Epoch: 288/500... Training loss: 0.0046\n",
      "Epoch: 288/500... Training loss: 0.0532\n",
      "Epoch: 288/500... Training loss: 0.0119\n",
      "Epoch: 288/500... Training loss: 0.0064\n",
      "Epoch: 288/500... Training loss: 0.1635\n",
      "Epoch: 289/500... Training loss: 0.0231\n",
      "Epoch: 289/500... Training loss: 0.0712\n",
      "Epoch: 289/500... Training loss: 0.0257\n",
      "Epoch: 289/500... Training loss: 0.0290\n",
      "Epoch: 289/500... Training loss: 0.0223\n",
      "Epoch: 289/500... Training loss: 0.0200\n",
      "Epoch: 289/500... Training loss: 0.0072\n",
      "Epoch: 289/500... Training loss: 0.0342\n",
      "Epoch: 289/500... Training loss: 0.0212\n",
      "Epoch: 289/500... Training loss: 0.0028\n",
      "Epoch: 289/500... Training loss: 0.0741\n",
      "Epoch: 289/500... Training loss: 0.0191\n",
      "Epoch: 289/500... Training loss: 0.0367\n",
      "Epoch: 289/500... Training loss: 0.0057\n",
      "Epoch: 289/500... Training loss: 0.0203\n",
      "Epoch: 289/500... Training loss: 0.0139\n",
      "Epoch: 289/500... Training loss: 0.0264\n",
      "Epoch: 289/500... Training loss: 0.0132\n",
      "Epoch: 289/500... Training loss: 0.0050\n",
      "Epoch: 289/500... Training loss: 0.0177\n",
      "Epoch: 289/500... Training loss: 0.0054\n",
      "Epoch: 289/500... Training loss: 0.0301\n",
      "Epoch: 289/500... Training loss: 0.0328\n",
      "Epoch: 289/500... Training loss: 0.0030\n",
      "Epoch: 289/500... Training loss: 0.0114\n",
      "Epoch: 289/500... Training loss: 0.0274\n",
      "Epoch: 289/500... Training loss: 0.0198\n",
      "Epoch: 289/500... Training loss: 0.0632\n",
      "Epoch: 289/500... Training loss: 0.0101\n",
      "Epoch: 289/500... Training loss: 0.0074\n",
      "Epoch: 289/500... Training loss: 0.0086\n",
      "Epoch: 290/500... Training loss: 0.0077\n",
      "Epoch: 290/500... Training loss: 0.0250\n",
      "Epoch: 290/500... Training loss: 0.0320\n",
      "Epoch: 290/500... Training loss: 0.0405\n",
      "Epoch: 290/500... Training loss: 0.0184\n",
      "Epoch: 290/500... Training loss: 0.0174\n",
      "Epoch: 290/500... Training loss: 0.0494\n",
      "Epoch: 290/500... Training loss: 0.0071\n",
      "Epoch: 290/500... Training loss: 0.0242\n",
      "Epoch: 290/500... Training loss: 0.0092\n",
      "Epoch: 290/500... Training loss: 0.0114\n",
      "Epoch: 290/500... Training loss: 0.1227\n",
      "Epoch: 290/500... Training loss: 0.0407\n",
      "Epoch: 290/500... Training loss: 0.0209\n",
      "Epoch: 290/500... Training loss: 0.1025\n",
      "Epoch: 290/500... Training loss: 0.0241\n",
      "Epoch: 290/500... Training loss: 0.0235\n",
      "Epoch: 290/500... Training loss: 0.0479\n",
      "Epoch: 290/500... Training loss: 0.0066\n",
      "Epoch: 290/500... Training loss: 0.0100\n",
      "Epoch: 290/500... Training loss: 0.0029\n",
      "Epoch: 290/500... Training loss: 0.0055\n",
      "Epoch: 290/500... Training loss: 0.0244\n",
      "Epoch: 290/500... Training loss: 0.0458\n",
      "Epoch: 290/500... Training loss: 0.0031\n",
      "Epoch: 290/500... Training loss: 0.0156\n",
      "Epoch: 290/500... Training loss: 0.0300\n",
      "Epoch: 290/500... Training loss: 0.0125\n",
      "Epoch: 290/500... Training loss: 0.0154\n",
      "Epoch: 290/500... Training loss: 0.0128\n",
      "Epoch: 290/500... Training loss: 0.0079\n",
      "Epoch: 291/500... Training loss: 0.0075\n",
      "Epoch: 291/500... Training loss: 0.0302\n",
      "Epoch: 291/500... Training loss: 0.0098\n",
      "Epoch: 291/500... Training loss: 0.0054\n",
      "Epoch: 291/500... Training loss: 0.0052\n",
      "Epoch: 291/500... Training loss: 0.0074\n",
      "Epoch: 291/500... Training loss: 0.0078\n",
      "Epoch: 291/500... Training loss: 0.0348\n",
      "Epoch: 291/500... Training loss: 0.0205\n",
      "Epoch: 291/500... Training loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 291/500... Training loss: 0.0056\n",
      "Epoch: 291/500... Training loss: 0.0287\n",
      "Epoch: 291/500... Training loss: 0.0069\n",
      "Epoch: 291/500... Training loss: 0.0045\n",
      "Epoch: 291/500... Training loss: 0.0204\n",
      "Epoch: 291/500... Training loss: 0.0066\n",
      "Epoch: 291/500... Training loss: 0.0356\n",
      "Epoch: 291/500... Training loss: 0.0076\n",
      "Epoch: 291/500... Training loss: 0.0440\n",
      "Epoch: 291/500... Training loss: 0.0030\n",
      "Epoch: 291/500... Training loss: 0.0066\n",
      "Epoch: 291/500... Training loss: 0.0116\n",
      "Epoch: 291/500... Training loss: 0.0299\n",
      "Epoch: 291/500... Training loss: 0.0658\n",
      "Epoch: 291/500... Training loss: 0.0020\n",
      "Epoch: 291/500... Training loss: 0.0242\n",
      "Epoch: 291/500... Training loss: 0.0286\n",
      "Epoch: 291/500... Training loss: 0.0057\n",
      "Epoch: 291/500... Training loss: 0.0067\n",
      "Epoch: 291/500... Training loss: 0.0110\n",
      "Epoch: 291/500... Training loss: 0.0043\n",
      "Epoch: 292/500... Training loss: 0.0177\n",
      "Epoch: 292/500... Training loss: 0.0092\n",
      "Epoch: 292/500... Training loss: 0.0027\n",
      "Epoch: 292/500... Training loss: 0.0072\n",
      "Epoch: 292/500... Training loss: 0.0268\n",
      "Epoch: 292/500... Training loss: 0.0205\n",
      "Epoch: 292/500... Training loss: 0.0042\n",
      "Epoch: 292/500... Training loss: 0.0019\n",
      "Epoch: 292/500... Training loss: 0.0055\n",
      "Epoch: 292/500... Training loss: 0.0987\n",
      "Epoch: 292/500... Training loss: 0.0136\n",
      "Epoch: 292/500... Training loss: 0.0138\n",
      "Epoch: 292/500... Training loss: 0.0024\n",
      "Epoch: 292/500... Training loss: 0.0195\n",
      "Epoch: 292/500... Training loss: 0.0063\n",
      "Epoch: 292/500... Training loss: 0.0154\n",
      "Epoch: 292/500... Training loss: 0.0048\n",
      "Epoch: 292/500... Training loss: 0.0874\n",
      "Epoch: 292/500... Training loss: 0.0153\n",
      "Epoch: 292/500... Training loss: 0.0811\n",
      "Epoch: 292/500... Training loss: 0.0159\n",
      "Epoch: 292/500... Training loss: 0.0067\n",
      "Epoch: 292/500... Training loss: 0.1347\n",
      "Epoch: 292/500... Training loss: 0.0062\n",
      "Epoch: 292/500... Training loss: 0.0090\n",
      "Epoch: 292/500... Training loss: 0.0736\n",
      "Epoch: 292/500... Training loss: 0.0195\n",
      "Epoch: 292/500... Training loss: 0.0029\n",
      "Epoch: 292/500... Training loss: 0.0118\n",
      "Epoch: 292/500... Training loss: 0.0015\n",
      "Epoch: 292/500... Training loss: 0.0084\n",
      "Epoch: 293/500... Training loss: 0.0244\n",
      "Epoch: 293/500... Training loss: 0.0363\n",
      "Epoch: 293/500... Training loss: 0.0034\n",
      "Epoch: 293/500... Training loss: 0.0122\n",
      "Epoch: 293/500... Training loss: 0.0379\n",
      "Epoch: 293/500... Training loss: 0.0063\n",
      "Epoch: 293/500... Training loss: 0.0546\n",
      "Epoch: 293/500... Training loss: 0.0266\n",
      "Epoch: 293/500... Training loss: 0.0197\n",
      "Epoch: 293/500... Training loss: 0.0052\n",
      "Epoch: 293/500... Training loss: 0.0033\n",
      "Epoch: 293/500... Training loss: 0.0640\n",
      "Epoch: 293/500... Training loss: 0.0073\n",
      "Epoch: 293/500... Training loss: 0.0072\n",
      "Epoch: 293/500... Training loss: 0.0299\n",
      "Epoch: 293/500... Training loss: 0.0202\n",
      "Epoch: 293/500... Training loss: 0.0116\n",
      "Epoch: 293/500... Training loss: 0.0055\n",
      "Epoch: 293/500... Training loss: 0.0146\n",
      "Epoch: 293/500... Training loss: 0.0992\n",
      "Epoch: 293/500... Training loss: 0.0093\n",
      "Epoch: 293/500... Training loss: 0.0022\n",
      "Epoch: 293/500... Training loss: 0.0786\n",
      "Epoch: 293/500... Training loss: 0.0060\n",
      "Epoch: 293/500... Training loss: 0.0097\n",
      "Epoch: 293/500... Training loss: 0.0277\n",
      "Epoch: 293/500... Training loss: 0.0080\n",
      "Epoch: 293/500... Training loss: 0.0211\n",
      "Epoch: 293/500... Training loss: 0.0187\n",
      "Epoch: 293/500... Training loss: 0.0199\n",
      "Epoch: 293/500... Training loss: 0.0025\n",
      "Epoch: 294/500... Training loss: 0.0083\n",
      "Epoch: 294/500... Training loss: 0.0394\n",
      "Epoch: 294/500... Training loss: 0.0082\n",
      "Epoch: 294/500... Training loss: 0.1091\n",
      "Epoch: 294/500... Training loss: 0.0259\n",
      "Epoch: 294/500... Training loss: 0.0168\n",
      "Epoch: 294/500... Training loss: 0.0369\n",
      "Epoch: 294/500... Training loss: 0.0054\n",
      "Epoch: 294/500... Training loss: 0.0057\n",
      "Epoch: 294/500... Training loss: 0.0106\n",
      "Epoch: 294/500... Training loss: 0.0428\n",
      "Epoch: 294/500... Training loss: 0.0171\n",
      "Epoch: 294/500... Training loss: 0.0103\n",
      "Epoch: 294/500... Training loss: 0.0029\n",
      "Epoch: 294/500... Training loss: 0.0182\n",
      "Epoch: 294/500... Training loss: 0.0082\n",
      "Epoch: 294/500... Training loss: 0.0054\n",
      "Epoch: 294/500... Training loss: 0.0258\n",
      "Epoch: 294/500... Training loss: 0.0078\n",
      "Epoch: 294/500... Training loss: 0.0036\n",
      "Epoch: 294/500... Training loss: 0.0221\n",
      "Epoch: 294/500... Training loss: 0.0147\n",
      "Epoch: 294/500... Training loss: 0.0189\n",
      "Epoch: 294/500... Training loss: 0.0070\n",
      "Epoch: 294/500... Training loss: 0.0026\n",
      "Epoch: 294/500... Training loss: 0.1521\n",
      "Epoch: 294/500... Training loss: 0.0593\n",
      "Epoch: 294/500... Training loss: 0.0202\n",
      "Epoch: 294/500... Training loss: 0.0395\n",
      "Epoch: 294/500... Training loss: 0.0038\n",
      "Epoch: 294/500... Training loss: 0.0442\n",
      "Epoch: 295/500... Training loss: 0.0275\n",
      "Epoch: 295/500... Training loss: 0.0449\n",
      "Epoch: 295/500... Training loss: 0.0076\n",
      "Epoch: 295/500... Training loss: 0.0060\n",
      "Epoch: 295/500... Training loss: 0.0106\n",
      "Epoch: 295/500... Training loss: 0.0194\n",
      "Epoch: 295/500... Training loss: 0.0234\n",
      "Epoch: 295/500... Training loss: 0.0043\n",
      "Epoch: 295/500... Training loss: 0.0859\n",
      "Epoch: 295/500... Training loss: 0.0248\n",
      "Epoch: 295/500... Training loss: 0.0776\n",
      "Epoch: 295/500... Training loss: 0.0209\n",
      "Epoch: 295/500... Training loss: 0.0177\n",
      "Epoch: 295/500... Training loss: 0.0343\n",
      "Epoch: 295/500... Training loss: 0.0212\n",
      "Epoch: 295/500... Training loss: 0.0230\n",
      "Epoch: 295/500... Training loss: 0.0207\n",
      "Epoch: 295/500... Training loss: 0.0076\n",
      "Epoch: 295/500... Training loss: 0.0972\n",
      "Epoch: 295/500... Training loss: 0.0387\n",
      "Epoch: 295/500... Training loss: 0.0175\n",
      "Epoch: 295/500... Training loss: 0.0052\n",
      "Epoch: 295/500... Training loss: 0.1072\n",
      "Epoch: 295/500... Training loss: 0.0093\n",
      "Epoch: 295/500... Training loss: 0.0201\n",
      "Epoch: 295/500... Training loss: 0.0374\n",
      "Epoch: 295/500... Training loss: 0.0045\n",
      "Epoch: 295/500... Training loss: 0.0593\n",
      "Epoch: 295/500... Training loss: 0.0602\n",
      "Epoch: 295/500... Training loss: 0.0031\n",
      "Epoch: 295/500... Training loss: 0.0100\n",
      "Epoch: 296/500... Training loss: 0.0487\n",
      "Epoch: 296/500... Training loss: 0.0323\n",
      "Epoch: 296/500... Training loss: 0.0052\n",
      "Epoch: 296/500... Training loss: 0.0432\n",
      "Epoch: 296/500... Training loss: 0.0245\n",
      "Epoch: 296/500... Training loss: 0.0092\n",
      "Epoch: 296/500... Training loss: 0.0034\n",
      "Epoch: 296/500... Training loss: 0.0048\n",
      "Epoch: 296/500... Training loss: 0.0422\n",
      "Epoch: 296/500... Training loss: 0.0030\n",
      "Epoch: 296/500... Training loss: 0.0423\n",
      "Epoch: 296/500... Training loss: 0.0172\n",
      "Epoch: 296/500... Training loss: 0.0063\n",
      "Epoch: 296/500... Training loss: 0.0083\n",
      "Epoch: 296/500... Training loss: 0.0190\n",
      "Epoch: 296/500... Training loss: 0.0035\n",
      "Epoch: 296/500... Training loss: 0.0037\n",
      "Epoch: 296/500... Training loss: 0.0166\n",
      "Epoch: 296/500... Training loss: 0.0172\n",
      "Epoch: 296/500... Training loss: 0.0240\n",
      "Epoch: 296/500... Training loss: 0.0091\n",
      "Epoch: 296/500... Training loss: 0.0220\n",
      "Epoch: 296/500... Training loss: 0.0170\n",
      "Epoch: 296/500... Training loss: 0.0034\n",
      "Epoch: 296/500... Training loss: 0.0547\n",
      "Epoch: 296/500... Training loss: 0.0121\n",
      "Epoch: 296/500... Training loss: 0.0034\n",
      "Epoch: 296/500... Training loss: 0.0105\n",
      "Epoch: 296/500... Training loss: 0.0298\n",
      "Epoch: 296/500... Training loss: 0.0047\n",
      "Epoch: 296/500... Training loss: 0.0066\n",
      "Epoch: 297/500... Training loss: 0.0392\n",
      "Epoch: 297/500... Training loss: 0.0487\n",
      "Epoch: 297/500... Training loss: 0.0125\n",
      "Epoch: 297/500... Training loss: 0.0048\n",
      "Epoch: 297/500... Training loss: 0.0313\n",
      "Epoch: 297/500... Training loss: 0.0335\n",
      "Epoch: 297/500... Training loss: 0.0704\n",
      "Epoch: 297/500... Training loss: 0.0078\n",
      "Epoch: 297/500... Training loss: 0.0105\n",
      "Epoch: 297/500... Training loss: 0.0072\n",
      "Epoch: 297/500... Training loss: 0.0041\n",
      "Epoch: 297/500... Training loss: 0.0218\n",
      "Epoch: 297/500... Training loss: 0.0351\n",
      "Epoch: 297/500... Training loss: 0.0094\n",
      "Epoch: 297/500... Training loss: 0.0035\n",
      "Epoch: 297/500... Training loss: 0.0074\n",
      "Epoch: 297/500... Training loss: 0.1402\n",
      "Epoch: 297/500... Training loss: 0.0108\n",
      "Epoch: 297/500... Training loss: 0.0129\n",
      "Epoch: 297/500... Training loss: 0.0292\n",
      "Epoch: 297/500... Training loss: 0.0103\n",
      "Epoch: 297/500... Training loss: 0.0019\n",
      "Epoch: 297/500... Training loss: 0.1548\n",
      "Epoch: 297/500... Training loss: 0.0026\n",
      "Epoch: 297/500... Training loss: 0.0128\n",
      "Epoch: 297/500... Training loss: 0.1403\n",
      "Epoch: 297/500... Training loss: 0.0034\n",
      "Epoch: 297/500... Training loss: 0.0189\n",
      "Epoch: 297/500... Training loss: 0.0042\n",
      "Epoch: 297/500... Training loss: 0.0900\n",
      "Epoch: 297/500... Training loss: 0.0131\n",
      "Epoch: 298/500... Training loss: 0.0248\n",
      "Epoch: 298/500... Training loss: 0.0383\n",
      "Epoch: 298/500... Training loss: 0.0283\n",
      "Epoch: 298/500... Training loss: 0.0031\n",
      "Epoch: 298/500... Training loss: 0.0038\n",
      "Epoch: 298/500... Training loss: 0.0146\n",
      "Epoch: 298/500... Training loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 298/500... Training loss: 0.0077\n",
      "Epoch: 298/500... Training loss: 0.0037\n",
      "Epoch: 298/500... Training loss: 0.0050\n",
      "Epoch: 298/500... Training loss: 0.0214\n",
      "Epoch: 298/500... Training loss: 0.0035\n",
      "Epoch: 298/500... Training loss: 0.0460\n",
      "Epoch: 298/500... Training loss: 0.0219\n",
      "Epoch: 298/500... Training loss: 0.2122\n",
      "Epoch: 298/500... Training loss: 0.0356\n",
      "Epoch: 298/500... Training loss: 0.0086\n",
      "Epoch: 298/500... Training loss: 0.0476\n",
      "Epoch: 298/500... Training loss: 0.0054\n",
      "Epoch: 298/500... Training loss: 0.0020\n",
      "Epoch: 298/500... Training loss: 0.0274\n",
      "Epoch: 298/500... Training loss: 0.0058\n",
      "Epoch: 298/500... Training loss: 0.0477\n",
      "Epoch: 298/500... Training loss: 0.1341\n",
      "Epoch: 298/500... Training loss: 0.0056\n",
      "Epoch: 298/500... Training loss: 0.0467\n",
      "Epoch: 298/500... Training loss: 0.0359\n",
      "Epoch: 298/500... Training loss: 0.0195\n",
      "Epoch: 298/500... Training loss: 0.0148\n",
      "Epoch: 298/500... Training loss: 0.0030\n",
      "Epoch: 298/500... Training loss: 0.0084\n",
      "Epoch: 299/500... Training loss: 0.0053\n",
      "Epoch: 299/500... Training loss: 0.0044\n",
      "Epoch: 299/500... Training loss: 0.1112\n",
      "Epoch: 299/500... Training loss: 0.0203\n",
      "Epoch: 299/500... Training loss: 0.0322\n",
      "Epoch: 299/500... Training loss: 0.0212\n",
      "Epoch: 299/500... Training loss: 0.0205\n",
      "Epoch: 299/500... Training loss: 0.0080\n",
      "Epoch: 299/500... Training loss: 0.1050\n",
      "Epoch: 299/500... Training loss: 0.0218\n",
      "Epoch: 299/500... Training loss: 0.0097\n",
      "Epoch: 299/500... Training loss: 0.0039\n",
      "Epoch: 299/500... Training loss: 0.0183\n",
      "Epoch: 299/500... Training loss: 0.0044\n",
      "Epoch: 299/500... Training loss: 0.0111\n",
      "Epoch: 299/500... Training loss: 0.0143\n",
      "Epoch: 299/500... Training loss: 0.0089\n",
      "Epoch: 299/500... Training loss: 0.0041\n",
      "Epoch: 299/500... Training loss: 0.0381\n",
      "Epoch: 299/500... Training loss: 0.0053\n",
      "Epoch: 299/500... Training loss: 0.0018\n",
      "Epoch: 299/500... Training loss: 0.0083\n",
      "Epoch: 299/500... Training loss: 0.1231\n",
      "Epoch: 299/500... Training loss: 0.0227\n",
      "Epoch: 299/500... Training loss: 0.0108\n",
      "Epoch: 299/500... Training loss: 0.0508\n",
      "Epoch: 299/500... Training loss: 0.0063\n",
      "Epoch: 299/500... Training loss: 0.0660\n",
      "Epoch: 299/500... Training loss: 0.0429\n",
      "Epoch: 299/500... Training loss: 0.0011\n",
      "Epoch: 299/500... Training loss: 0.0558\n",
      "Epoch: 300/500... Training loss: 0.0068\n",
      "Epoch: 300/500... Training loss: 0.0046\n",
      "Epoch: 300/500... Training loss: 0.0095\n",
      "Epoch: 300/500... Training loss: 0.0081\n",
      "Epoch: 300/500... Training loss: 0.1405\n",
      "Epoch: 300/500... Training loss: 0.0212\n",
      "Epoch: 300/500... Training loss: 0.0496\n",
      "Epoch: 300/500... Training loss: 0.0393\n",
      "Epoch: 300/500... Training loss: 0.0135\n",
      "Epoch: 300/500... Training loss: 0.0039\n",
      "Epoch: 300/500... Training loss: 0.0911\n",
      "Epoch: 300/500... Training loss: 0.0103\n",
      "Epoch: 300/500... Training loss: 0.0915\n",
      "Epoch: 300/500... Training loss: 0.0139\n",
      "Epoch: 300/500... Training loss: 0.0064\n",
      "Epoch: 300/500... Training loss: 0.0026\n",
      "Epoch: 300/500... Training loss: 0.0066\n",
      "Epoch: 300/500... Training loss: 0.0283\n",
      "Epoch: 300/500... Training loss: 0.0333\n",
      "Epoch: 300/500... Training loss: 0.0108\n",
      "Epoch: 300/500... Training loss: 0.0075\n",
      "Epoch: 300/500... Training loss: 0.0808\n",
      "Epoch: 300/500... Training loss: 0.0096\n",
      "Epoch: 300/500... Training loss: 0.0100\n",
      "Epoch: 300/500... Training loss: 0.0166\n",
      "Epoch: 300/500... Training loss: 0.0082\n",
      "Epoch: 300/500... Training loss: 0.0032\n",
      "Epoch: 300/500... Training loss: 0.0031\n",
      "Epoch: 300/500... Training loss: 0.0302\n",
      "Epoch: 300/500... Training loss: 0.0046\n",
      "Epoch: 300/500... Training loss: 0.0085\n",
      "Epoch: 301/500... Training loss: 0.0052\n",
      "Epoch: 301/500... Training loss: 0.0129\n",
      "Epoch: 301/500... Training loss: 0.0165\n",
      "Epoch: 301/500... Training loss: 0.0798\n",
      "Epoch: 301/500... Training loss: 0.0276\n",
      "Epoch: 301/500... Training loss: 0.0566\n",
      "Epoch: 301/500... Training loss: 0.0093\n",
      "Epoch: 301/500... Training loss: 0.0150\n",
      "Epoch: 301/500... Training loss: 0.0203\n",
      "Epoch: 301/500... Training loss: 0.0338\n",
      "Epoch: 301/500... Training loss: 0.0885\n",
      "Epoch: 301/500... Training loss: 0.0112\n",
      "Epoch: 301/500... Training loss: 0.0073\n",
      "Epoch: 301/500... Training loss: 0.0359\n",
      "Epoch: 301/500... Training loss: 0.0030\n",
      "Epoch: 301/500... Training loss: 0.0202\n",
      "Epoch: 301/500... Training loss: 0.0083\n",
      "Epoch: 301/500... Training loss: 0.0031\n",
      "Epoch: 301/500... Training loss: 0.0152\n",
      "Epoch: 301/500... Training loss: 0.0105\n",
      "Epoch: 301/500... Training loss: 0.0205\n",
      "Epoch: 301/500... Training loss: 0.0849\n",
      "Epoch: 301/500... Training loss: 0.2557\n",
      "Epoch: 301/500... Training loss: 0.0237\n",
      "Epoch: 301/500... Training loss: 0.1127\n",
      "Epoch: 301/500... Training loss: 0.0071\n",
      "Epoch: 301/500... Training loss: 0.0117\n",
      "Epoch: 301/500... Training loss: 0.0054\n",
      "Epoch: 301/500... Training loss: 0.0182\n",
      "Epoch: 301/500... Training loss: 0.0049\n",
      "Epoch: 301/500... Training loss: 0.0152\n",
      "Epoch: 302/500... Training loss: 0.0379\n",
      "Epoch: 302/500... Training loss: 0.0085\n",
      "Epoch: 302/500... Training loss: 0.0079\n",
      "Epoch: 302/500... Training loss: 0.0133\n",
      "Epoch: 302/500... Training loss: 0.0140\n",
      "Epoch: 302/500... Training loss: 0.0530\n",
      "Epoch: 302/500... Training loss: 0.0098\n",
      "Epoch: 302/500... Training loss: 0.0690\n",
      "Epoch: 302/500... Training loss: 0.0255\n",
      "Epoch: 302/500... Training loss: 0.0413\n",
      "Epoch: 302/500... Training loss: 0.0508\n",
      "Epoch: 302/500... Training loss: 0.0142\n",
      "Epoch: 302/500... Training loss: 0.0153\n",
      "Epoch: 302/500... Training loss: 0.0254\n",
      "Epoch: 302/500... Training loss: 0.0224\n",
      "Epoch: 302/500... Training loss: 0.0156\n",
      "Epoch: 302/500... Training loss: 0.0139\n",
      "Epoch: 302/500... Training loss: 0.0097\n",
      "Epoch: 302/500... Training loss: 0.0753\n",
      "Epoch: 302/500... Training loss: 0.0196\n",
      "Epoch: 302/500... Training loss: 0.0025\n",
      "Epoch: 302/500... Training loss: 0.0963\n",
      "Epoch: 302/500... Training loss: 0.1134\n",
      "Epoch: 302/500... Training loss: 0.0429\n",
      "Epoch: 302/500... Training loss: 0.0305\n",
      "Epoch: 302/500... Training loss: 0.0107\n",
      "Epoch: 302/500... Training loss: 0.0056\n",
      "Epoch: 302/500... Training loss: 0.0086\n",
      "Epoch: 302/500... Training loss: 0.0460\n",
      "Epoch: 302/500... Training loss: 0.0696\n",
      "Epoch: 302/500... Training loss: 0.0087\n",
      "Epoch: 303/500... Training loss: 0.0045\n",
      "Epoch: 303/500... Training loss: 0.0053\n",
      "Epoch: 303/500... Training loss: 0.0093\n",
      "Epoch: 303/500... Training loss: 0.0152\n",
      "Epoch: 303/500... Training loss: 0.0320\n",
      "Epoch: 303/500... Training loss: 0.0118\n",
      "Epoch: 303/500... Training loss: 0.0195\n",
      "Epoch: 303/500... Training loss: 0.0141\n",
      "Epoch: 303/500... Training loss: 0.0672\n",
      "Epoch: 303/500... Training loss: 0.0868\n",
      "Epoch: 303/500... Training loss: 0.0190\n",
      "Epoch: 303/500... Training loss: 0.0590\n",
      "Epoch: 303/500... Training loss: 0.0529\n",
      "Epoch: 303/500... Training loss: 0.0091\n",
      "Epoch: 303/500... Training loss: 0.0202\n",
      "Epoch: 303/500... Training loss: 0.0214\n",
      "Epoch: 303/500... Training loss: 0.0088\n",
      "Epoch: 303/500... Training loss: 0.0244\n",
      "Epoch: 303/500... Training loss: 0.0181\n",
      "Epoch: 303/500... Training loss: 0.0045\n",
      "Epoch: 303/500... Training loss: 0.0128\n",
      "Epoch: 303/500... Training loss: 0.0215\n",
      "Epoch: 303/500... Training loss: 0.0112\n",
      "Epoch: 303/500... Training loss: 0.0811\n",
      "Epoch: 303/500... Training loss: 0.0898\n",
      "Epoch: 303/500... Training loss: 0.0169\n",
      "Epoch: 303/500... Training loss: 0.0102\n",
      "Epoch: 303/500... Training loss: 0.0577\n",
      "Epoch: 303/500... Training loss: 0.0031\n",
      "Epoch: 303/500... Training loss: 0.0058\n",
      "Epoch: 303/500... Training loss: 0.0112\n",
      "Epoch: 304/500... Training loss: 0.0155\n",
      "Epoch: 304/500... Training loss: 0.0292\n",
      "Epoch: 304/500... Training loss: 0.0172\n",
      "Epoch: 304/500... Training loss: 0.0284\n",
      "Epoch: 304/500... Training loss: 0.0226\n",
      "Epoch: 304/500... Training loss: 0.0268\n",
      "Epoch: 304/500... Training loss: 0.0585\n",
      "Epoch: 304/500... Training loss: 0.0084\n",
      "Epoch: 304/500... Training loss: 0.0137\n",
      "Epoch: 304/500... Training loss: 0.0177\n",
      "Epoch: 304/500... Training loss: 0.0049\n",
      "Epoch: 304/500... Training loss: 0.0035\n",
      "Epoch: 304/500... Training loss: 0.0173\n",
      "Epoch: 304/500... Training loss: 0.0032\n",
      "Epoch: 304/500... Training loss: 0.0069\n",
      "Epoch: 304/500... Training loss: 0.0218\n",
      "Epoch: 304/500... Training loss: 0.0186\n",
      "Epoch: 304/500... Training loss: 0.0385\n",
      "Epoch: 304/500... Training loss: 0.0554\n",
      "Epoch: 304/500... Training loss: 0.0450\n",
      "Epoch: 304/500... Training loss: 0.0057\n",
      "Epoch: 304/500... Training loss: 0.0232\n",
      "Epoch: 304/500... Training loss: 0.0087\n",
      "Epoch: 304/500... Training loss: 0.0134\n",
      "Epoch: 304/500... Training loss: 0.0035\n",
      "Epoch: 304/500... Training loss: 0.0078\n",
      "Epoch: 304/500... Training loss: 0.0319\n",
      "Epoch: 304/500... Training loss: 0.0073\n",
      "Epoch: 304/500... Training loss: 0.0331\n",
      "Epoch: 304/500... Training loss: 0.0794\n",
      "Epoch: 304/500... Training loss: 0.0094\n",
      "Epoch: 305/500... Training loss: 0.0532\n",
      "Epoch: 305/500... Training loss: 0.0425\n",
      "Epoch: 305/500... Training loss: 0.0018\n",
      "Epoch: 305/500... Training loss: 0.0062\n",
      "Epoch: 305/500... Training loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305/500... Training loss: 0.0656\n",
      "Epoch: 305/500... Training loss: 0.0077\n",
      "Epoch: 305/500... Training loss: 0.0119\n",
      "Epoch: 305/500... Training loss: 0.0390\n",
      "Epoch: 305/500... Training loss: 0.0282\n",
      "Epoch: 305/500... Training loss: 0.0110\n",
      "Epoch: 305/500... Training loss: 0.0118\n",
      "Epoch: 305/500... Training loss: 0.0085\n",
      "Epoch: 305/500... Training loss: 0.0092\n",
      "Epoch: 305/500... Training loss: 0.0100\n",
      "Epoch: 305/500... Training loss: 0.0538\n",
      "Epoch: 305/500... Training loss: 0.0093\n",
      "Epoch: 305/500... Training loss: 0.0274\n",
      "Epoch: 305/500... Training loss: 0.0403\n",
      "Epoch: 305/500... Training loss: 0.0077\n",
      "Epoch: 305/500... Training loss: 0.0053\n",
      "Epoch: 305/500... Training loss: 0.0429\n",
      "Epoch: 305/500... Training loss: 0.0370\n",
      "Epoch: 305/500... Training loss: 0.0080\n",
      "Epoch: 305/500... Training loss: 0.0270\n",
      "Epoch: 305/500... Training loss: 0.0157\n",
      "Epoch: 305/500... Training loss: 0.0069\n",
      "Epoch: 305/500... Training loss: 0.0101\n",
      "Epoch: 305/500... Training loss: 0.0017\n",
      "Epoch: 305/500... Training loss: 0.0270\n",
      "Epoch: 305/500... Training loss: 0.0409\n",
      "Epoch: 306/500... Training loss: 0.0883\n",
      "Epoch: 306/500... Training loss: 0.1161\n",
      "Epoch: 306/500... Training loss: 0.0164\n",
      "Epoch: 306/500... Training loss: 0.0171\n",
      "Epoch: 306/500... Training loss: 0.0032\n",
      "Epoch: 306/500... Training loss: 0.0071\n",
      "Epoch: 306/500... Training loss: 0.0095\n",
      "Epoch: 306/500... Training loss: 0.0105\n",
      "Epoch: 306/500... Training loss: 0.0040\n",
      "Epoch: 306/500... Training loss: 0.0137\n",
      "Epoch: 306/500... Training loss: 0.0079\n",
      "Epoch: 306/500... Training loss: 0.0123\n",
      "Epoch: 306/500... Training loss: 0.0083\n",
      "Epoch: 306/500... Training loss: 0.0685\n",
      "Epoch: 306/500... Training loss: 0.0105\n",
      "Epoch: 306/500... Training loss: 0.0074\n",
      "Epoch: 306/500... Training loss: 0.0532\n",
      "Epoch: 306/500... Training loss: 0.0461\n",
      "Epoch: 306/500... Training loss: 0.0760\n",
      "Epoch: 306/500... Training loss: 0.0058\n",
      "Epoch: 306/500... Training loss: 0.0070\n",
      "Epoch: 306/500... Training loss: 0.0023\n",
      "Epoch: 306/500... Training loss: 0.0540\n",
      "Epoch: 306/500... Training loss: 0.1375\n",
      "Epoch: 306/500... Training loss: 0.0062\n",
      "Epoch: 306/500... Training loss: 0.0107\n",
      "Epoch: 306/500... Training loss: 0.0033\n",
      "Epoch: 306/500... Training loss: 0.0128\n",
      "Epoch: 306/500... Training loss: 0.0173\n",
      "Epoch: 306/500... Training loss: 0.0341\n",
      "Epoch: 306/500... Training loss: 0.0078\n",
      "Epoch: 307/500... Training loss: 0.0046\n",
      "Epoch: 307/500... Training loss: 0.0297\n",
      "Epoch: 307/500... Training loss: 0.0362\n",
      "Epoch: 307/500... Training loss: 0.0073\n",
      "Epoch: 307/500... Training loss: 0.0167\n",
      "Epoch: 307/500... Training loss: 0.0081\n",
      "Epoch: 307/500... Training loss: 0.0156\n",
      "Epoch: 307/500... Training loss: 0.0370\n",
      "Epoch: 307/500... Training loss: 0.0474\n",
      "Epoch: 307/500... Training loss: 0.0081\n",
      "Epoch: 307/500... Training loss: 0.0223\n",
      "Epoch: 307/500... Training loss: 0.0197\n",
      "Epoch: 307/500... Training loss: 0.0139\n",
      "Epoch: 307/500... Training loss: 0.0539\n",
      "Epoch: 307/500... Training loss: 0.0278\n",
      "Epoch: 307/500... Training loss: 0.0166\n",
      "Epoch: 307/500... Training loss: 0.0594\n",
      "Epoch: 307/500... Training loss: 0.0054\n",
      "Epoch: 307/500... Training loss: 0.0291\n",
      "Epoch: 307/500... Training loss: 0.0018\n",
      "Epoch: 307/500... Training loss: 0.0023\n",
      "Epoch: 307/500... Training loss: 0.0639\n",
      "Epoch: 307/500... Training loss: 0.0286\n",
      "Epoch: 307/500... Training loss: 0.0354\n",
      "Epoch: 307/500... Training loss: 0.0319\n",
      "Epoch: 307/500... Training loss: 0.0790\n",
      "Epoch: 307/500... Training loss: 0.0020\n",
      "Epoch: 307/500... Training loss: 0.0217\n",
      "Epoch: 307/500... Training loss: 0.0238\n",
      "Epoch: 307/500... Training loss: 0.0320\n",
      "Epoch: 307/500... Training loss: 0.0199\n",
      "Epoch: 308/500... Training loss: 0.0959\n",
      "Epoch: 308/500... Training loss: 0.0057\n",
      "Epoch: 308/500... Training loss: 0.0330\n",
      "Epoch: 308/500... Training loss: 0.0382\n",
      "Epoch: 308/500... Training loss: 0.0576\n",
      "Epoch: 308/500... Training loss: 0.0086\n",
      "Epoch: 308/500... Training loss: 0.0199\n",
      "Epoch: 308/500... Training loss: 0.0422\n",
      "Epoch: 308/500... Training loss: 0.0095\n",
      "Epoch: 308/500... Training loss: 0.0358\n",
      "Epoch: 308/500... Training loss: 0.0217\n",
      "Epoch: 308/500... Training loss: 0.0067\n",
      "Epoch: 308/500... Training loss: 0.0115\n",
      "Epoch: 308/500... Training loss: 0.0393\n",
      "Epoch: 308/500... Training loss: 0.0268\n",
      "Epoch: 308/500... Training loss: 0.0133\n",
      "Epoch: 308/500... Training loss: 0.0260\n",
      "Epoch: 308/500... Training loss: 0.0944\n",
      "Epoch: 308/500... Training loss: 0.0033\n",
      "Epoch: 308/500... Training loss: 0.0393\n",
      "Epoch: 308/500... Training loss: 0.0063\n",
      "Epoch: 308/500... Training loss: 0.0098\n",
      "Epoch: 308/500... Training loss: 0.0058\n",
      "Epoch: 308/500... Training loss: 0.0830\n",
      "Epoch: 308/500... Training loss: 0.0447\n",
      "Epoch: 308/500... Training loss: 0.1426\n",
      "Epoch: 308/500... Training loss: 0.0026\n",
      "Epoch: 308/500... Training loss: 0.0027\n",
      "Epoch: 308/500... Training loss: 0.0168\n",
      "Epoch: 308/500... Training loss: 0.0105\n",
      "Epoch: 308/500... Training loss: 0.0174\n",
      "Epoch: 309/500... Training loss: 0.1530\n",
      "Epoch: 309/500... Training loss: 0.0165\n",
      "Epoch: 309/500... Training loss: 0.0357\n",
      "Epoch: 309/500... Training loss: 0.0156\n",
      "Epoch: 309/500... Training loss: 0.0069\n",
      "Epoch: 309/500... Training loss: 0.0377\n",
      "Epoch: 309/500... Training loss: 0.0089\n",
      "Epoch: 309/500... Training loss: 0.0260\n",
      "Epoch: 309/500... Training loss: 0.0393\n",
      "Epoch: 309/500... Training loss: 0.0182\n",
      "Epoch: 309/500... Training loss: 0.0951\n",
      "Epoch: 309/500... Training loss: 0.0082\n",
      "Epoch: 309/500... Training loss: 0.0035\n",
      "Epoch: 309/500... Training loss: 0.0747\n",
      "Epoch: 309/500... Training loss: 0.0104\n",
      "Epoch: 309/500... Training loss: 0.0030\n",
      "Epoch: 309/500... Training loss: 0.0090\n",
      "Epoch: 309/500... Training loss: 0.0079\n",
      "Epoch: 309/500... Training loss: 0.0254\n",
      "Epoch: 309/500... Training loss: 0.0159\n",
      "Epoch: 309/500... Training loss: 0.0058\n",
      "Epoch: 309/500... Training loss: 0.0191\n",
      "Epoch: 309/500... Training loss: 0.0269\n",
      "Epoch: 309/500... Training loss: 0.0070\n",
      "Epoch: 309/500... Training loss: 0.0150\n",
      "Epoch: 309/500... Training loss: 0.0553\n",
      "Epoch: 309/500... Training loss: 0.0040\n",
      "Epoch: 309/500... Training loss: 0.0287\n",
      "Epoch: 309/500... Training loss: 0.0743\n",
      "Epoch: 309/500... Training loss: 0.0388\n",
      "Epoch: 309/500... Training loss: 0.0283\n",
      "Epoch: 310/500... Training loss: 0.0046\n",
      "Epoch: 310/500... Training loss: 0.0094\n",
      "Epoch: 310/500... Training loss: 0.0094\n",
      "Epoch: 310/500... Training loss: 0.0027\n",
      "Epoch: 310/500... Training loss: 0.0050\n",
      "Epoch: 310/500... Training loss: 0.0095\n",
      "Epoch: 310/500... Training loss: 0.0118\n",
      "Epoch: 310/500... Training loss: 0.0179\n",
      "Epoch: 310/500... Training loss: 0.0172\n",
      "Epoch: 310/500... Training loss: 0.0773\n",
      "Epoch: 310/500... Training loss: 0.0322\n",
      "Epoch: 310/500... Training loss: 0.0043\n",
      "Epoch: 310/500... Training loss: 0.0063\n",
      "Epoch: 310/500... Training loss: 0.0167\n",
      "Epoch: 310/500... Training loss: 0.0266\n",
      "Epoch: 310/500... Training loss: 0.0020\n",
      "Epoch: 310/500... Training loss: 0.0231\n",
      "Epoch: 310/500... Training loss: 0.0018\n",
      "Epoch: 310/500... Training loss: 0.0054\n",
      "Epoch: 310/500... Training loss: 0.0149\n",
      "Epoch: 310/500... Training loss: 0.0215\n",
      "Epoch: 310/500... Training loss: 0.0087\n",
      "Epoch: 310/500... Training loss: 0.0248\n",
      "Epoch: 310/500... Training loss: 0.0123\n",
      "Epoch: 310/500... Training loss: 0.0025\n",
      "Epoch: 310/500... Training loss: 0.0207\n",
      "Epoch: 310/500... Training loss: 0.0184\n",
      "Epoch: 310/500... Training loss: 0.0399\n",
      "Epoch: 310/500... Training loss: 0.0193\n",
      "Epoch: 310/500... Training loss: 0.0117\n",
      "Epoch: 310/500... Training loss: 0.0225\n",
      "Epoch: 311/500... Training loss: 0.0442\n",
      "Epoch: 311/500... Training loss: 0.0103\n",
      "Epoch: 311/500... Training loss: 0.0026\n",
      "Epoch: 311/500... Training loss: 0.0607\n",
      "Epoch: 311/500... Training loss: 0.0068\n",
      "Epoch: 311/500... Training loss: 0.0137\n",
      "Epoch: 311/500... Training loss: 0.0405\n",
      "Epoch: 311/500... Training loss: 0.0275\n",
      "Epoch: 311/500... Training loss: 0.0165\n",
      "Epoch: 311/500... Training loss: 0.0154\n",
      "Epoch: 311/500... Training loss: 0.1245\n",
      "Epoch: 311/500... Training loss: 0.0443\n",
      "Epoch: 311/500... Training loss: 0.0078\n",
      "Epoch: 311/500... Training loss: 0.0364\n",
      "Epoch: 311/500... Training loss: 0.0538\n",
      "Epoch: 311/500... Training loss: 0.0273\n",
      "Epoch: 311/500... Training loss: 0.0091\n",
      "Epoch: 311/500... Training loss: 0.0218\n",
      "Epoch: 311/500... Training loss: 0.0103\n",
      "Epoch: 311/500... Training loss: 0.0235\n",
      "Epoch: 311/500... Training loss: 0.0426\n",
      "Epoch: 311/500... Training loss: 0.0466\n",
      "Epoch: 311/500... Training loss: 0.0472\n",
      "Epoch: 311/500... Training loss: 0.0466\n",
      "Epoch: 311/500... Training loss: 0.0150\n",
      "Epoch: 311/500... Training loss: 0.0056\n",
      "Epoch: 311/500... Training loss: 0.0246\n",
      "Epoch: 311/500... Training loss: 0.0059\n",
      "Epoch: 311/500... Training loss: 0.0050\n",
      "Epoch: 311/500... Training loss: 0.0091\n",
      "Epoch: 311/500... Training loss: 0.0050\n",
      "Epoch: 312/500... Training loss: 0.0019\n",
      "Epoch: 312/500... Training loss: 0.0129\n",
      "Epoch: 312/500... Training loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 312/500... Training loss: 0.0269\n",
      "Epoch: 312/500... Training loss: 0.0661\n",
      "Epoch: 312/500... Training loss: 0.1038\n",
      "Epoch: 312/500... Training loss: 0.0056\n",
      "Epoch: 312/500... Training loss: 0.0174\n",
      "Epoch: 312/500... Training loss: 0.0124\n",
      "Epoch: 312/500... Training loss: 0.0844\n",
      "Epoch: 312/500... Training loss: 0.0379\n",
      "Epoch: 312/500... Training loss: 0.0344\n",
      "Epoch: 312/500... Training loss: 0.0125\n",
      "Epoch: 312/500... Training loss: 0.0250\n",
      "Epoch: 312/500... Training loss: 0.0133\n",
      "Epoch: 312/500... Training loss: 0.0145\n",
      "Epoch: 312/500... Training loss: 0.0530\n",
      "Epoch: 312/500... Training loss: 0.0306\n",
      "Epoch: 312/500... Training loss: 0.0040\n",
      "Epoch: 312/500... Training loss: 0.0033\n",
      "Epoch: 312/500... Training loss: 0.0430\n",
      "Epoch: 312/500... Training loss: 0.0036\n",
      "Epoch: 312/500... Training loss: 0.1479\n",
      "Epoch: 312/500... Training loss: 0.1314\n",
      "Epoch: 312/500... Training loss: 0.0293\n",
      "Epoch: 312/500... Training loss: 0.0067\n",
      "Epoch: 312/500... Training loss: 0.0332\n",
      "Epoch: 312/500... Training loss: 0.0049\n",
      "Epoch: 312/500... Training loss: 0.0149\n",
      "Epoch: 312/500... Training loss: 0.0202\n",
      "Epoch: 312/500... Training loss: 0.0150\n",
      "Epoch: 313/500... Training loss: 0.0441\n",
      "Epoch: 313/500... Training loss: 0.0214\n",
      "Epoch: 313/500... Training loss: 0.0090\n",
      "Epoch: 313/500... Training loss: 0.0082\n",
      "Epoch: 313/500... Training loss: 0.0033\n",
      "Epoch: 313/500... Training loss: 0.0136\n",
      "Epoch: 313/500... Training loss: 0.1153\n",
      "Epoch: 313/500... Training loss: 0.0545\n",
      "Epoch: 313/500... Training loss: 0.0099\n",
      "Epoch: 313/500... Training loss: 0.0444\n",
      "Epoch: 313/500... Training loss: 0.0401\n",
      "Epoch: 313/500... Training loss: 0.0290\n",
      "Epoch: 313/500... Training loss: 0.0053\n",
      "Epoch: 313/500... Training loss: 0.0032\n",
      "Epoch: 313/500... Training loss: 0.0157\n",
      "Epoch: 313/500... Training loss: 0.0563\n",
      "Epoch: 313/500... Training loss: 0.0050\n",
      "Epoch: 313/500... Training loss: 0.0082\n",
      "Epoch: 313/500... Training loss: 0.0154\n",
      "Epoch: 313/500... Training loss: 0.0150\n",
      "Epoch: 313/500... Training loss: 0.0478\n",
      "Epoch: 313/500... Training loss: 0.0040\n",
      "Epoch: 313/500... Training loss: 0.0450\n",
      "Epoch: 313/500... Training loss: 0.0044\n",
      "Epoch: 313/500... Training loss: 0.0053\n",
      "Epoch: 313/500... Training loss: 0.0195\n",
      "Epoch: 313/500... Training loss: 0.0100\n",
      "Epoch: 313/500... Training loss: 0.0076\n",
      "Epoch: 313/500... Training loss: 0.0019\n",
      "Epoch: 313/500... Training loss: 0.0810\n",
      "Epoch: 313/500... Training loss: 0.0243\n",
      "Epoch: 314/500... Training loss: 0.0754\n",
      "Epoch: 314/500... Training loss: 0.0309\n",
      "Epoch: 314/500... Training loss: 0.0050\n",
      "Epoch: 314/500... Training loss: 0.0398\n",
      "Epoch: 314/500... Training loss: 0.0039\n",
      "Epoch: 314/500... Training loss: 0.0304\n",
      "Epoch: 314/500... Training loss: 0.0086\n",
      "Epoch: 314/500... Training loss: 0.0557\n",
      "Epoch: 314/500... Training loss: 0.0341\n",
      "Epoch: 314/500... Training loss: 0.0395\n",
      "Epoch: 314/500... Training loss: 0.0342\n",
      "Epoch: 314/500... Training loss: 0.0201\n",
      "Epoch: 314/500... Training loss: 0.0274\n",
      "Epoch: 314/500... Training loss: 0.0322\n",
      "Epoch: 314/500... Training loss: 0.0051\n",
      "Epoch: 314/500... Training loss: 0.0238\n",
      "Epoch: 314/500... Training loss: 0.0458\n",
      "Epoch: 314/500... Training loss: 0.0615\n",
      "Epoch: 314/500... Training loss: 0.0147\n",
      "Epoch: 314/500... Training loss: 0.0012\n",
      "Epoch: 314/500... Training loss: 0.0056\n",
      "Epoch: 314/500... Training loss: 0.0026\n",
      "Epoch: 314/500... Training loss: 0.0264\n",
      "Epoch: 314/500... Training loss: 0.0392\n",
      "Epoch: 314/500... Training loss: 0.1047\n",
      "Epoch: 314/500... Training loss: 0.0124\n",
      "Epoch: 314/500... Training loss: 0.0095\n",
      "Epoch: 314/500... Training loss: 0.0060\n",
      "Epoch: 314/500... Training loss: 0.0040\n",
      "Epoch: 314/500... Training loss: 0.0104\n",
      "Epoch: 314/500... Training loss: 0.0014\n",
      "Epoch: 315/500... Training loss: 0.0224\n",
      "Epoch: 315/500... Training loss: 0.0086\n",
      "Epoch: 315/500... Training loss: 0.0371\n",
      "Epoch: 315/500... Training loss: 0.0023\n",
      "Epoch: 315/500... Training loss: 0.0091\n",
      "Epoch: 315/500... Training loss: 0.0242\n",
      "Epoch: 315/500... Training loss: 0.0418\n",
      "Epoch: 315/500... Training loss: 0.0021\n",
      "Epoch: 315/500... Training loss: 0.0772\n",
      "Epoch: 315/500... Training loss: 0.0068\n",
      "Epoch: 315/500... Training loss: 0.0746\n",
      "Epoch: 315/500... Training loss: 0.0467\n",
      "Epoch: 315/500... Training loss: 0.0033\n",
      "Epoch: 315/500... Training loss: 0.0796\n",
      "Epoch: 315/500... Training loss: 0.0451\n",
      "Epoch: 315/500... Training loss: 0.0022\n",
      "Epoch: 315/500... Training loss: 0.1062\n",
      "Epoch: 315/500... Training loss: 0.0547\n",
      "Epoch: 315/500... Training loss: 0.0870\n",
      "Epoch: 315/500... Training loss: 0.0014\n",
      "Epoch: 315/500... Training loss: 0.0095\n",
      "Epoch: 315/500... Training loss: 0.0059\n",
      "Epoch: 315/500... Training loss: 0.0744\n",
      "Epoch: 315/500... Training loss: 0.0419\n",
      "Epoch: 315/500... Training loss: 0.0438\n",
      "Epoch: 315/500... Training loss: 0.0116\n",
      "Epoch: 315/500... Training loss: 0.0028\n",
      "Epoch: 315/500... Training loss: 0.0060\n",
      "Epoch: 315/500... Training loss: 0.0071\n",
      "Epoch: 315/500... Training loss: 0.0108\n",
      "Epoch: 315/500... Training loss: 0.0070\n",
      "Epoch: 316/500... Training loss: 0.0141\n",
      "Epoch: 316/500... Training loss: 0.0080\n",
      "Epoch: 316/500... Training loss: 0.0078\n",
      "Epoch: 316/500... Training loss: 0.0223\n",
      "Epoch: 316/500... Training loss: 0.0326\n",
      "Epoch: 316/500... Training loss: 0.0118\n",
      "Epoch: 316/500... Training loss: 0.0101\n",
      "Epoch: 316/500... Training loss: 0.0176\n",
      "Epoch: 316/500... Training loss: 0.0040\n",
      "Epoch: 316/500... Training loss: 0.0073\n",
      "Epoch: 316/500... Training loss: 0.0074\n",
      "Epoch: 316/500... Training loss: 0.0014\n",
      "Epoch: 316/500... Training loss: 0.0068\n",
      "Epoch: 316/500... Training loss: 0.1064\n",
      "Epoch: 316/500... Training loss: 0.1316\n",
      "Epoch: 316/500... Training loss: 0.0025\n",
      "Epoch: 316/500... Training loss: 0.0080\n",
      "Epoch: 316/500... Training loss: 0.0049\n",
      "Epoch: 316/500... Training loss: 0.0476\n",
      "Epoch: 316/500... Training loss: 0.0049\n",
      "Epoch: 316/500... Training loss: 0.0161\n",
      "Epoch: 316/500... Training loss: 0.0348\n",
      "Epoch: 316/500... Training loss: 0.0384\n",
      "Epoch: 316/500... Training loss: 0.0419\n",
      "Epoch: 316/500... Training loss: 0.0155\n",
      "Epoch: 316/500... Training loss: 0.0548\n",
      "Epoch: 316/500... Training loss: 0.0021\n",
      "Epoch: 316/500... Training loss: 0.0037\n",
      "Epoch: 316/500... Training loss: 0.0108\n",
      "Epoch: 316/500... Training loss: 0.0029\n",
      "Epoch: 316/500... Training loss: 0.0197\n",
      "Epoch: 317/500... Training loss: 0.0080\n",
      "Epoch: 317/500... Training loss: 0.0030\n",
      "Epoch: 317/500... Training loss: 0.0036\n",
      "Epoch: 317/500... Training loss: 0.0865\n",
      "Epoch: 317/500... Training loss: 0.1427\n",
      "Epoch: 317/500... Training loss: 0.0233\n",
      "Epoch: 317/500... Training loss: 0.0645\n",
      "Epoch: 317/500... Training loss: 0.0088\n",
      "Epoch: 317/500... Training loss: 0.0156\n",
      "Epoch: 317/500... Training loss: 0.0735\n",
      "Epoch: 317/500... Training loss: 0.0237\n",
      "Epoch: 317/500... Training loss: 0.0245\n",
      "Epoch: 317/500... Training loss: 0.0032\n",
      "Epoch: 317/500... Training loss: 0.0494\n",
      "Epoch: 317/500... Training loss: 0.0120\n",
      "Epoch: 317/500... Training loss: 0.0160\n",
      "Epoch: 317/500... Training loss: 0.0039\n",
      "Epoch: 317/500... Training loss: 0.0471\n",
      "Epoch: 317/500... Training loss: 0.0071\n",
      "Epoch: 317/500... Training loss: 0.0155\n",
      "Epoch: 317/500... Training loss: 0.0851\n",
      "Epoch: 317/500... Training loss: 0.0087\n",
      "Epoch: 317/500... Training loss: 0.0196\n",
      "Epoch: 317/500... Training loss: 0.0428\n",
      "Epoch: 317/500... Training loss: 0.0035\n",
      "Epoch: 317/500... Training loss: 0.0030\n",
      "Epoch: 317/500... Training loss: 0.0254\n",
      "Epoch: 317/500... Training loss: 0.0501\n",
      "Epoch: 317/500... Training loss: 0.0134\n",
      "Epoch: 317/500... Training loss: 0.0071\n",
      "Epoch: 317/500... Training loss: 0.0035\n",
      "Epoch: 318/500... Training loss: 0.0427\n",
      "Epoch: 318/500... Training loss: 0.0028\n",
      "Epoch: 318/500... Training loss: 0.0128\n",
      "Epoch: 318/500... Training loss: 0.0204\n",
      "Epoch: 318/500... Training loss: 0.0968\n",
      "Epoch: 318/500... Training loss: 0.0597\n",
      "Epoch: 318/500... Training loss: 0.0621\n",
      "Epoch: 318/500... Training loss: 0.0076\n",
      "Epoch: 318/500... Training loss: 0.0024\n",
      "Epoch: 318/500... Training loss: 0.0104\n",
      "Epoch: 318/500... Training loss: 0.0022\n",
      "Epoch: 318/500... Training loss: 0.1002\n",
      "Epoch: 318/500... Training loss: 0.0373\n",
      "Epoch: 318/500... Training loss: 0.0129\n",
      "Epoch: 318/500... Training loss: 0.1842\n",
      "Epoch: 318/500... Training loss: 0.0196\n",
      "Epoch: 318/500... Training loss: 0.0198\n",
      "Epoch: 318/500... Training loss: 0.0282\n",
      "Epoch: 318/500... Training loss: 0.0145\n",
      "Epoch: 318/500... Training loss: 0.0019\n",
      "Epoch: 318/500... Training loss: 0.0158\n",
      "Epoch: 318/500... Training loss: 0.0036\n",
      "Epoch: 318/500... Training loss: 0.0041\n",
      "Epoch: 318/500... Training loss: 0.0037\n",
      "Epoch: 318/500... Training loss: 0.0066\n",
      "Epoch: 318/500... Training loss: 0.0041\n",
      "Epoch: 318/500... Training loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 318/500... Training loss: 0.0520\n",
      "Epoch: 318/500... Training loss: 0.0050\n",
      "Epoch: 318/500... Training loss: 0.0591\n",
      "Epoch: 318/500... Training loss: 0.0038\n",
      "Epoch: 319/500... Training loss: 0.0235\n",
      "Epoch: 319/500... Training loss: 0.0119\n",
      "Epoch: 319/500... Training loss: 0.0352\n",
      "Epoch: 319/500... Training loss: 0.0984\n",
      "Epoch: 319/500... Training loss: 0.0075\n",
      "Epoch: 319/500... Training loss: 0.0173\n",
      "Epoch: 319/500... Training loss: 0.1249\n",
      "Epoch: 319/500... Training loss: 0.1116\n",
      "Epoch: 319/500... Training loss: 0.0380\n",
      "Epoch: 319/500... Training loss: 0.0216\n",
      "Epoch: 319/500... Training loss: 0.0093\n",
      "Epoch: 319/500... Training loss: 0.0621\n",
      "Epoch: 319/500... Training loss: 0.0026\n",
      "Epoch: 319/500... Training loss: 0.0031\n",
      "Epoch: 319/500... Training loss: 0.0256\n",
      "Epoch: 319/500... Training loss: 0.0118\n",
      "Epoch: 319/500... Training loss: 0.0034\n",
      "Epoch: 319/500... Training loss: 0.0399\n",
      "Epoch: 319/500... Training loss: 0.0220\n",
      "Epoch: 319/500... Training loss: 0.0328\n",
      "Epoch: 319/500... Training loss: 0.0028\n",
      "Epoch: 319/500... Training loss: 0.0047\n",
      "Epoch: 319/500... Training loss: 0.0259\n",
      "Epoch: 319/500... Training loss: 0.1103\n",
      "Epoch: 319/500... Training loss: 0.0061\n",
      "Epoch: 319/500... Training loss: 0.0620\n",
      "Epoch: 319/500... Training loss: 0.0055\n",
      "Epoch: 319/500... Training loss: 0.0041\n",
      "Epoch: 319/500... Training loss: 0.0125\n",
      "Epoch: 319/500... Training loss: 0.0034\n",
      "Epoch: 319/500... Training loss: 0.0808\n",
      "Epoch: 320/500... Training loss: 0.0143\n",
      "Epoch: 320/500... Training loss: 0.0326\n",
      "Epoch: 320/500... Training loss: 0.0201\n",
      "Epoch: 320/500... Training loss: 0.0356\n",
      "Epoch: 320/500... Training loss: 0.0348\n",
      "Epoch: 320/500... Training loss: 0.0150\n",
      "Epoch: 320/500... Training loss: 0.0980\n",
      "Epoch: 320/500... Training loss: 0.0224\n",
      "Epoch: 320/500... Training loss: 0.0092\n",
      "Epoch: 320/500... Training loss: 0.0112\n",
      "Epoch: 320/500... Training loss: 0.0090\n",
      "Epoch: 320/500... Training loss: 0.0258\n",
      "Epoch: 320/500... Training loss: 0.0048\n",
      "Epoch: 320/500... Training loss: 0.0055\n",
      "Epoch: 320/500... Training loss: 0.0267\n",
      "Epoch: 320/500... Training loss: 0.0038\n",
      "Epoch: 320/500... Training loss: 0.0273\n",
      "Epoch: 320/500... Training loss: 0.0787\n",
      "Epoch: 320/500... Training loss: 0.0091\n",
      "Epoch: 320/500... Training loss: 0.0085\n",
      "Epoch: 320/500... Training loss: 0.0303\n",
      "Epoch: 320/500... Training loss: 0.0058\n",
      "Epoch: 320/500... Training loss: 0.0882\n",
      "Epoch: 320/500... Training loss: 0.0116\n",
      "Epoch: 320/500... Training loss: 0.0123\n",
      "Epoch: 320/500... Training loss: 0.0408\n",
      "Epoch: 320/500... Training loss: 0.0081\n",
      "Epoch: 320/500... Training loss: 0.0066\n",
      "Epoch: 320/500... Training loss: 0.0172\n",
      "Epoch: 320/500... Training loss: 0.0045\n",
      "Epoch: 320/500... Training loss: 0.0045\n",
      "Epoch: 321/500... Training loss: 0.0023\n",
      "Epoch: 321/500... Training loss: 0.0291\n",
      "Epoch: 321/500... Training loss: 0.0030\n",
      "Epoch: 321/500... Training loss: 0.0152\n",
      "Epoch: 321/500... Training loss: 0.0081\n",
      "Epoch: 321/500... Training loss: 0.0096\n",
      "Epoch: 321/500... Training loss: 0.0348\n",
      "Epoch: 321/500... Training loss: 0.0101\n",
      "Epoch: 321/500... Training loss: 0.0049\n",
      "Epoch: 321/500... Training loss: 0.0200\n",
      "Epoch: 321/500... Training loss: 0.0047\n",
      "Epoch: 321/500... Training loss: 0.0681\n",
      "Epoch: 321/500... Training loss: 0.0167\n",
      "Epoch: 321/500... Training loss: 0.0035\n",
      "Epoch: 321/500... Training loss: 0.0548\n",
      "Epoch: 321/500... Training loss: 0.0208\n",
      "Epoch: 321/500... Training loss: 0.0051\n",
      "Epoch: 321/500... Training loss: 0.0093\n",
      "Epoch: 321/500... Training loss: 0.0111\n",
      "Epoch: 321/500... Training loss: 0.0041\n",
      "Epoch: 321/500... Training loss: 0.0430\n",
      "Epoch: 321/500... Training loss: 0.0021\n",
      "Epoch: 321/500... Training loss: 0.0794\n",
      "Epoch: 321/500... Training loss: 0.0094\n",
      "Epoch: 321/500... Training loss: 0.0027\n",
      "Epoch: 321/500... Training loss: 0.0092\n",
      "Epoch: 321/500... Training loss: 0.0018\n",
      "Epoch: 321/500... Training loss: 0.0121\n",
      "Epoch: 321/500... Training loss: 0.0545\n",
      "Epoch: 321/500... Training loss: 0.0905\n",
      "Epoch: 321/500... Training loss: 0.0025\n",
      "Epoch: 322/500... Training loss: 0.0092\n",
      "Epoch: 322/500... Training loss: 0.0087\n",
      "Epoch: 322/500... Training loss: 0.0064\n",
      "Epoch: 322/500... Training loss: 0.0080\n",
      "Epoch: 322/500... Training loss: 0.0038\n",
      "Epoch: 322/500... Training loss: 0.0235\n",
      "Epoch: 322/500... Training loss: 0.0766\n",
      "Epoch: 322/500... Training loss: 0.0719\n",
      "Epoch: 322/500... Training loss: 0.0170\n",
      "Epoch: 322/500... Training loss: 0.0214\n",
      "Epoch: 322/500... Training loss: 0.0050\n",
      "Epoch: 322/500... Training loss: 0.0141\n",
      "Epoch: 322/500... Training loss: 0.0330\n",
      "Epoch: 322/500... Training loss: 0.0038\n",
      "Epoch: 322/500... Training loss: 0.0646\n",
      "Epoch: 322/500... Training loss: 0.0288\n",
      "Epoch: 322/500... Training loss: 0.0176\n",
      "Epoch: 322/500... Training loss: 0.0701\n",
      "Epoch: 322/500... Training loss: 0.0087\n",
      "Epoch: 322/500... Training loss: 0.0094\n",
      "Epoch: 322/500... Training loss: 0.0398\n",
      "Epoch: 322/500... Training loss: 0.0024\n",
      "Epoch: 322/500... Training loss: 0.0136\n",
      "Epoch: 322/500... Training loss: 0.0453\n",
      "Epoch: 322/500... Training loss: 0.0178\n",
      "Epoch: 322/500... Training loss: 0.0020\n",
      "Epoch: 322/500... Training loss: 0.0038\n",
      "Epoch: 322/500... Training loss: 0.0146\n",
      "Epoch: 322/500... Training loss: 0.0038\n",
      "Epoch: 322/500... Training loss: 0.0119\n",
      "Epoch: 322/500... Training loss: 0.0272\n",
      "Epoch: 323/500... Training loss: 0.0069\n",
      "Epoch: 323/500... Training loss: 0.0033\n",
      "Epoch: 323/500... Training loss: 0.0218\n",
      "Epoch: 323/500... Training loss: 0.0070\n",
      "Epoch: 323/500... Training loss: 0.0163\n",
      "Epoch: 323/500... Training loss: 0.0026\n",
      "Epoch: 323/500... Training loss: 0.0139\n",
      "Epoch: 323/500... Training loss: 0.0080\n",
      "Epoch: 323/500... Training loss: 0.0071\n",
      "Epoch: 323/500... Training loss: 0.0657\n",
      "Epoch: 323/500... Training loss: 0.0056\n",
      "Epoch: 323/500... Training loss: 0.0562\n",
      "Epoch: 323/500... Training loss: 0.0365\n",
      "Epoch: 323/500... Training loss: 0.0066\n",
      "Epoch: 323/500... Training loss: 0.0179\n",
      "Epoch: 323/500... Training loss: 0.0125\n",
      "Epoch: 323/500... Training loss: 0.0562\n",
      "Epoch: 323/500... Training loss: 0.0060\n",
      "Epoch: 323/500... Training loss: 0.0124\n",
      "Epoch: 323/500... Training loss: 0.0109\n",
      "Epoch: 323/500... Training loss: 0.0050\n",
      "Epoch: 323/500... Training loss: 0.0036\n",
      "Epoch: 323/500... Training loss: 0.0303\n",
      "Epoch: 323/500... Training loss: 0.0114\n",
      "Epoch: 323/500... Training loss: 0.0272\n",
      "Epoch: 323/500... Training loss: 0.0072\n",
      "Epoch: 323/500... Training loss: 0.0170\n",
      "Epoch: 323/500... Training loss: 0.0164\n",
      "Epoch: 323/500... Training loss: 0.0067\n",
      "Epoch: 323/500... Training loss: 0.1420\n",
      "Epoch: 323/500... Training loss: 0.0118\n",
      "Epoch: 324/500... Training loss: 0.0175\n",
      "Epoch: 324/500... Training loss: 0.0892\n",
      "Epoch: 324/500... Training loss: 0.0083\n",
      "Epoch: 324/500... Training loss: 0.0074\n",
      "Epoch: 324/500... Training loss: 0.0353\n",
      "Epoch: 324/500... Training loss: 0.0145\n",
      "Epoch: 324/500... Training loss: 0.0049\n",
      "Epoch: 324/500... Training loss: 0.0033\n",
      "Epoch: 324/500... Training loss: 0.0297\n",
      "Epoch: 324/500... Training loss: 0.0038\n",
      "Epoch: 324/500... Training loss: 0.0093\n",
      "Epoch: 324/500... Training loss: 0.0502\n",
      "Epoch: 324/500... Training loss: 0.0359\n",
      "Epoch: 324/500... Training loss: 0.0067\n",
      "Epoch: 324/500... Training loss: 0.0211\n",
      "Epoch: 324/500... Training loss: 0.0025\n",
      "Epoch: 324/500... Training loss: 0.0680\n",
      "Epoch: 324/500... Training loss: 0.0025\n",
      "Epoch: 324/500... Training loss: 0.0130\n",
      "Epoch: 324/500... Training loss: 0.0122\n",
      "Epoch: 324/500... Training loss: 0.0020\n",
      "Epoch: 324/500... Training loss: 0.0245\n",
      "Epoch: 324/500... Training loss: 0.0391\n",
      "Epoch: 324/500... Training loss: 0.0261\n",
      "Epoch: 324/500... Training loss: 0.0070\n",
      "Epoch: 324/500... Training loss: 0.0273\n",
      "Epoch: 324/500... Training loss: 0.0134\n",
      "Epoch: 324/500... Training loss: 0.0206\n",
      "Epoch: 324/500... Training loss: 0.0233\n",
      "Epoch: 324/500... Training loss: 0.0188\n",
      "Epoch: 324/500... Training loss: 0.0215\n",
      "Epoch: 325/500... Training loss: 0.0018\n",
      "Epoch: 325/500... Training loss: 0.0095\n",
      "Epoch: 325/500... Training loss: 0.0088\n",
      "Epoch: 325/500... Training loss: 0.0186\n",
      "Epoch: 325/500... Training loss: 0.0199\n",
      "Epoch: 325/500... Training loss: 0.0118\n",
      "Epoch: 325/500... Training loss: 0.0042\n",
      "Epoch: 325/500... Training loss: 0.0023\n",
      "Epoch: 325/500... Training loss: 0.0095\n",
      "Epoch: 325/500... Training loss: 0.0022\n",
      "Epoch: 325/500... Training loss: 0.0051\n",
      "Epoch: 325/500... Training loss: 0.0334\n",
      "Epoch: 325/500... Training loss: 0.1320\n",
      "Epoch: 325/500... Training loss: 0.0039\n",
      "Epoch: 325/500... Training loss: 0.0225\n",
      "Epoch: 325/500... Training loss: 0.0083\n",
      "Epoch: 325/500... Training loss: 0.0228\n",
      "Epoch: 325/500... Training loss: 0.0039\n",
      "Epoch: 325/500... Training loss: 0.0159\n",
      "Epoch: 325/500... Training loss: 0.0641\n",
      "Epoch: 325/500... Training loss: 0.0099\n",
      "Epoch: 325/500... Training loss: 0.0114\n",
      "Epoch: 325/500... Training loss: 0.0398\n",
      "Epoch: 325/500... Training loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 325/500... Training loss: 0.0065\n",
      "Epoch: 325/500... Training loss: 0.0765\n",
      "Epoch: 325/500... Training loss: 0.0879\n",
      "Epoch: 325/500... Training loss: 0.0036\n",
      "Epoch: 325/500... Training loss: 0.0448\n",
      "Epoch: 325/500... Training loss: 0.0040\n",
      "Epoch: 325/500... Training loss: 0.0061\n",
      "Epoch: 326/500... Training loss: 0.0045\n",
      "Epoch: 326/500... Training loss: 0.0030\n",
      "Epoch: 326/500... Training loss: 0.0039\n",
      "Epoch: 326/500... Training loss: 0.0987\n",
      "Epoch: 326/500... Training loss: 0.0042\n",
      "Epoch: 326/500... Training loss: 0.0208\n",
      "Epoch: 326/500... Training loss: 0.0357\n",
      "Epoch: 326/500... Training loss: 0.0081\n",
      "Epoch: 326/500... Training loss: 0.0167\n",
      "Epoch: 326/500... Training loss: 0.0118\n",
      "Epoch: 326/500... Training loss: 0.0242\n",
      "Epoch: 326/500... Training loss: 0.0652\n",
      "Epoch: 326/500... Training loss: 0.0390\n",
      "Epoch: 326/500... Training loss: 0.0020\n",
      "Epoch: 326/500... Training loss: 0.0061\n",
      "Epoch: 326/500... Training loss: 0.0116\n",
      "Epoch: 326/500... Training loss: 0.0180\n",
      "Epoch: 326/500... Training loss: 0.0055\n",
      "Epoch: 326/500... Training loss: 0.0205\n",
      "Epoch: 326/500... Training loss: 0.0132\n",
      "Epoch: 326/500... Training loss: 0.1345\n",
      "Epoch: 326/500... Training loss: 0.0519\n",
      "Epoch: 326/500... Training loss: 0.0772\n",
      "Epoch: 326/500... Training loss: 0.0033\n",
      "Epoch: 326/500... Training loss: 0.0057\n",
      "Epoch: 326/500... Training loss: 0.0028\n",
      "Epoch: 326/500... Training loss: 0.0050\n",
      "Epoch: 326/500... Training loss: 0.0037\n",
      "Epoch: 326/500... Training loss: 0.0168\n",
      "Epoch: 326/500... Training loss: 0.0022\n",
      "Epoch: 326/500... Training loss: 0.0171\n",
      "Epoch: 327/500... Training loss: 0.0064\n",
      "Epoch: 327/500... Training loss: 0.0056\n",
      "Epoch: 327/500... Training loss: 0.0094\n",
      "Epoch: 327/500... Training loss: 0.0139\n",
      "Epoch: 327/500... Training loss: 0.0050\n",
      "Epoch: 327/500... Training loss: 0.0088\n",
      "Epoch: 327/500... Training loss: 0.0873\n",
      "Epoch: 327/500... Training loss: 0.0066\n",
      "Epoch: 327/500... Training loss: 0.0075\n",
      "Epoch: 327/500... Training loss: 0.0267\n",
      "Epoch: 327/500... Training loss: 0.0274\n",
      "Epoch: 327/500... Training loss: 0.0246\n",
      "Epoch: 327/500... Training loss: 0.0029\n",
      "Epoch: 327/500... Training loss: 0.0035\n",
      "Epoch: 327/500... Training loss: 0.0917\n",
      "Epoch: 327/500... Training loss: 0.0309\n",
      "Epoch: 327/500... Training loss: 0.0043\n",
      "Epoch: 327/500... Training loss: 0.0043\n",
      "Epoch: 327/500... Training loss: 0.0040\n",
      "Epoch: 327/500... Training loss: 0.0069\n",
      "Epoch: 327/500... Training loss: 0.0305\n",
      "Epoch: 327/500... Training loss: 0.0097\n",
      "Epoch: 327/500... Training loss: 0.0039\n",
      "Epoch: 327/500... Training loss: 0.0118\n",
      "Epoch: 327/500... Training loss: 0.0046\n",
      "Epoch: 327/500... Training loss: 0.0064\n",
      "Epoch: 327/500... Training loss: 0.0020\n",
      "Epoch: 327/500... Training loss: 0.0136\n",
      "Epoch: 327/500... Training loss: 0.0042\n",
      "Epoch: 327/500... Training loss: 0.0044\n",
      "Epoch: 327/500... Training loss: 0.0118\n",
      "Epoch: 328/500... Training loss: 0.0025\n",
      "Epoch: 328/500... Training loss: 0.0079\n",
      "Epoch: 328/500... Training loss: 0.0355\n",
      "Epoch: 328/500... Training loss: 0.0313\n",
      "Epoch: 328/500... Training loss: 0.0297\n",
      "Epoch: 328/500... Training loss: 0.0303\n",
      "Epoch: 328/500... Training loss: 0.0179\n",
      "Epoch: 328/500... Training loss: 0.0082\n",
      "Epoch: 328/500... Training loss: 0.0095\n",
      "Epoch: 328/500... Training loss: 0.0175\n",
      "Epoch: 328/500... Training loss: 0.0149\n",
      "Epoch: 328/500... Training loss: 0.0124\n",
      "Epoch: 328/500... Training loss: 0.0031\n",
      "Epoch: 328/500... Training loss: 0.0139\n",
      "Epoch: 328/500... Training loss: 0.0047\n",
      "Epoch: 328/500... Training loss: 0.0053\n",
      "Epoch: 328/500... Training loss: 0.0863\n",
      "Epoch: 328/500... Training loss: 0.0094\n",
      "Epoch: 328/500... Training loss: 0.0258\n",
      "Epoch: 328/500... Training loss: 0.0015\n",
      "Epoch: 328/500... Training loss: 0.0067\n",
      "Epoch: 328/500... Training loss: 0.0024\n",
      "Epoch: 328/500... Training loss: 0.0084\n",
      "Epoch: 328/500... Training loss: 0.0022\n",
      "Epoch: 328/500... Training loss: 0.0330\n",
      "Epoch: 328/500... Training loss: 0.0107\n",
      "Epoch: 328/500... Training loss: 0.0101\n",
      "Epoch: 328/500... Training loss: 0.0459\n",
      "Epoch: 328/500... Training loss: 0.0079\n",
      "Epoch: 328/500... Training loss: 0.0060\n",
      "Epoch: 328/500... Training loss: 0.0031\n",
      "Epoch: 329/500... Training loss: 0.0055\n",
      "Epoch: 329/500... Training loss: 0.0135\n",
      "Epoch: 329/500... Training loss: 0.0134\n",
      "Epoch: 329/500... Training loss: 0.0311\n",
      "Epoch: 329/500... Training loss: 0.0040\n",
      "Epoch: 329/500... Training loss: 0.0072\n",
      "Epoch: 329/500... Training loss: 0.0497\n",
      "Epoch: 329/500... Training loss: 0.0065\n",
      "Epoch: 329/500... Training loss: 0.0487\n",
      "Epoch: 329/500... Training loss: 0.0094\n",
      "Epoch: 329/500... Training loss: 0.0106\n",
      "Epoch: 329/500... Training loss: 0.0054\n",
      "Epoch: 329/500... Training loss: 0.0032\n",
      "Epoch: 329/500... Training loss: 0.0017\n",
      "Epoch: 329/500... Training loss: 0.0086\n",
      "Epoch: 329/500... Training loss: 0.0069\n",
      "Epoch: 329/500... Training loss: 0.0052\n",
      "Epoch: 329/500... Training loss: 0.0092\n",
      "Epoch: 329/500... Training loss: 0.0118\n",
      "Epoch: 329/500... Training loss: 0.0038\n",
      "Epoch: 329/500... Training loss: 0.0040\n",
      "Epoch: 329/500... Training loss: 0.0516\n",
      "Epoch: 329/500... Training loss: 0.0181\n",
      "Epoch: 329/500... Training loss: 0.0111\n",
      "Epoch: 329/500... Training loss: 0.0160\n",
      "Epoch: 329/500... Training loss: 0.1114\n",
      "Epoch: 329/500... Training loss: 0.0078\n",
      "Epoch: 329/500... Training loss: 0.0084\n",
      "Epoch: 329/500... Training loss: 0.0038\n",
      "Epoch: 329/500... Training loss: 0.0043\n",
      "Epoch: 329/500... Training loss: 0.0104\n",
      "Epoch: 330/500... Training loss: 0.0110\n",
      "Epoch: 330/500... Training loss: 0.0017\n",
      "Epoch: 330/500... Training loss: 0.0040\n",
      "Epoch: 330/500... Training loss: 0.0051\n",
      "Epoch: 330/500... Training loss: 0.0295\n",
      "Epoch: 330/500... Training loss: 0.0502\n",
      "Epoch: 330/500... Training loss: 0.0789\n",
      "Epoch: 330/500... Training loss: 0.0021\n",
      "Epoch: 330/500... Training loss: 0.0039\n",
      "Epoch: 330/500... Training loss: 0.0054\n",
      "Epoch: 330/500... Training loss: 0.0368\n",
      "Epoch: 330/500... Training loss: 0.0032\n",
      "Epoch: 330/500... Training loss: 0.0157\n",
      "Epoch: 330/500... Training loss: 0.0022\n",
      "Epoch: 330/500... Training loss: 0.0024\n",
      "Epoch: 330/500... Training loss: 0.0056\n",
      "Epoch: 330/500... Training loss: 0.0300\n",
      "Epoch: 330/500... Training loss: 0.0465\n",
      "Epoch: 330/500... Training loss: 0.0036\n",
      "Epoch: 330/500... Training loss: 0.0030\n",
      "Epoch: 330/500... Training loss: 0.0699\n",
      "Epoch: 330/500... Training loss: 0.0101\n",
      "Epoch: 330/500... Training loss: 0.0097\n",
      "Epoch: 330/500... Training loss: 0.0018\n",
      "Epoch: 330/500... Training loss: 0.0230\n",
      "Epoch: 330/500... Training loss: 0.0151\n",
      "Epoch: 330/500... Training loss: 0.0024\n",
      "Epoch: 330/500... Training loss: 0.1041\n",
      "Epoch: 330/500... Training loss: 0.0048\n",
      "Epoch: 330/500... Training loss: 0.0055\n",
      "Epoch: 330/500... Training loss: 0.0053\n",
      "Epoch: 331/500... Training loss: 0.0337\n",
      "Epoch: 331/500... Training loss: 0.0068\n",
      "Epoch: 331/500... Training loss: 0.0028\n",
      "Epoch: 331/500... Training loss: 0.0080\n",
      "Epoch: 331/500... Training loss: 0.0245\n",
      "Epoch: 331/500... Training loss: 0.0115\n",
      "Epoch: 331/500... Training loss: 0.0033\n",
      "Epoch: 331/500... Training loss: 0.0242\n",
      "Epoch: 331/500... Training loss: 0.0090\n",
      "Epoch: 331/500... Training loss: 0.0074\n",
      "Epoch: 331/500... Training loss: 0.0117\n",
      "Epoch: 331/500... Training loss: 0.0028\n",
      "Epoch: 331/500... Training loss: 0.0056\n",
      "Epoch: 331/500... Training loss: 0.0016\n",
      "Epoch: 331/500... Training loss: 0.0047\n",
      "Epoch: 331/500... Training loss: 0.0219\n",
      "Epoch: 331/500... Training loss: 0.0027\n",
      "Epoch: 331/500... Training loss: 0.0065\n",
      "Epoch: 331/500... Training loss: 0.0370\n",
      "Epoch: 331/500... Training loss: 0.0906\n",
      "Epoch: 331/500... Training loss: 0.0029\n",
      "Epoch: 331/500... Training loss: 0.0030\n",
      "Epoch: 331/500... Training loss: 0.0051\n",
      "Epoch: 331/500... Training loss: 0.0064\n",
      "Epoch: 331/500... Training loss: 0.0023\n",
      "Epoch: 331/500... Training loss: 0.0020\n",
      "Epoch: 331/500... Training loss: 0.0046\n",
      "Epoch: 331/500... Training loss: 0.0815\n",
      "Epoch: 331/500... Training loss: 0.0037\n",
      "Epoch: 331/500... Training loss: 0.0015\n",
      "Epoch: 331/500... Training loss: 0.0015\n",
      "Epoch: 332/500... Training loss: 0.0161\n",
      "Epoch: 332/500... Training loss: 0.0014\n",
      "Epoch: 332/500... Training loss: 0.0109\n",
      "Epoch: 332/500... Training loss: 0.0643\n",
      "Epoch: 332/500... Training loss: 0.0696\n",
      "Epoch: 332/500... Training loss: 0.0391\n",
      "Epoch: 332/500... Training loss: 0.0018\n",
      "Epoch: 332/500... Training loss: 0.0036\n",
      "Epoch: 332/500... Training loss: 0.0506\n",
      "Epoch: 332/500... Training loss: 0.0008\n",
      "Epoch: 332/500... Training loss: 0.0297\n",
      "Epoch: 332/500... Training loss: 0.0079\n",
      "Epoch: 332/500... Training loss: 0.0039\n",
      "Epoch: 332/500... Training loss: 0.0414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 332/500... Training loss: 0.0118\n",
      "Epoch: 332/500... Training loss: 0.0024\n",
      "Epoch: 332/500... Training loss: 0.0111\n",
      "Epoch: 332/500... Training loss: 0.0061\n",
      "Epoch: 332/500... Training loss: 0.0067\n",
      "Epoch: 332/500... Training loss: 0.0015\n",
      "Epoch: 332/500... Training loss: 0.0033\n",
      "Epoch: 332/500... Training loss: 0.0051\n",
      "Epoch: 332/500... Training loss: 0.0182\n",
      "Epoch: 332/500... Training loss: 0.0014\n",
      "Epoch: 332/500... Training loss: 0.0146\n",
      "Epoch: 332/500... Training loss: 0.0064\n",
      "Epoch: 332/500... Training loss: 0.0079\n",
      "Epoch: 332/500... Training loss: 0.0028\n",
      "Epoch: 332/500... Training loss: 0.0101\n",
      "Epoch: 332/500... Training loss: 0.0024\n",
      "Epoch: 332/500... Training loss: 0.0022\n",
      "Epoch: 333/500... Training loss: 0.0035\n",
      "Epoch: 333/500... Training loss: 0.0758\n",
      "Epoch: 333/500... Training loss: 0.0073\n",
      "Epoch: 333/500... Training loss: 0.0186\n",
      "Epoch: 333/500... Training loss: 0.0176\n",
      "Epoch: 333/500... Training loss: 0.0147\n",
      "Epoch: 333/500... Training loss: 0.0172\n",
      "Epoch: 333/500... Training loss: 0.0186\n",
      "Epoch: 333/500... Training loss: 0.0052\n",
      "Epoch: 333/500... Training loss: 0.0035\n",
      "Epoch: 333/500... Training loss: 0.0098\n",
      "Epoch: 333/500... Training loss: 0.0255\n",
      "Epoch: 333/500... Training loss: 0.0124\n",
      "Epoch: 333/500... Training loss: 0.0027\n",
      "Epoch: 333/500... Training loss: 0.0034\n",
      "Epoch: 333/500... Training loss: 0.0138\n",
      "Epoch: 333/500... Training loss: 0.0059\n",
      "Epoch: 333/500... Training loss: 0.0192\n",
      "Epoch: 333/500... Training loss: 0.0331\n",
      "Epoch: 333/500... Training loss: 0.0078\n",
      "Epoch: 333/500... Training loss: 0.0202\n",
      "Epoch: 333/500... Training loss: 0.0361\n",
      "Epoch: 333/500... Training loss: 0.0059\n",
      "Epoch: 333/500... Training loss: 0.0144\n",
      "Epoch: 333/500... Training loss: 0.0326\n",
      "Epoch: 333/500... Training loss: 0.0032\n",
      "Epoch: 333/500... Training loss: 0.0053\n",
      "Epoch: 333/500... Training loss: 0.0034\n",
      "Epoch: 333/500... Training loss: 0.0045\n",
      "Epoch: 333/500... Training loss: 0.0815\n",
      "Epoch: 333/500... Training loss: 0.0393\n",
      "Epoch: 334/500... Training loss: 0.0111\n",
      "Epoch: 334/500... Training loss: 0.0058\n",
      "Epoch: 334/500... Training loss: 0.0048\n",
      "Epoch: 334/500... Training loss: 0.0023\n",
      "Epoch: 334/500... Training loss: 0.0057\n",
      "Epoch: 334/500... Training loss: 0.0097\n",
      "Epoch: 334/500... Training loss: 0.0245\n",
      "Epoch: 334/500... Training loss: 0.0036\n",
      "Epoch: 334/500... Training loss: 0.0109\n",
      "Epoch: 334/500... Training loss: 0.0258\n",
      "Epoch: 334/500... Training loss: 0.0183\n",
      "Epoch: 334/500... Training loss: 0.0060\n",
      "Epoch: 334/500... Training loss: 0.0060\n",
      "Epoch: 334/500... Training loss: 0.0258\n",
      "Epoch: 334/500... Training loss: 0.0026\n",
      "Epoch: 334/500... Training loss: 0.0017\n",
      "Epoch: 334/500... Training loss: 0.0157\n",
      "Epoch: 334/500... Training loss: 0.0427\n",
      "Epoch: 334/500... Training loss: 0.0221\n",
      "Epoch: 334/500... Training loss: 0.0013\n",
      "Epoch: 334/500... Training loss: 0.0415\n",
      "Epoch: 334/500... Training loss: 0.0136\n",
      "Epoch: 334/500... Training loss: 0.0357\n",
      "Epoch: 334/500... Training loss: 0.0528\n",
      "Epoch: 334/500... Training loss: 0.0067\n",
      "Epoch: 334/500... Training loss: 0.0385\n",
      "Epoch: 334/500... Training loss: 0.0031\n",
      "Epoch: 334/500... Training loss: 0.0400\n",
      "Epoch: 334/500... Training loss: 0.0084\n",
      "Epoch: 334/500... Training loss: 0.0101\n",
      "Epoch: 334/500... Training loss: 0.0016\n",
      "Epoch: 335/500... Training loss: 0.0166\n",
      "Epoch: 335/500... Training loss: 0.0033\n",
      "Epoch: 335/500... Training loss: 0.0256\n",
      "Epoch: 335/500... Training loss: 0.0037\n",
      "Epoch: 335/500... Training loss: 0.0076\n",
      "Epoch: 335/500... Training loss: 0.0254\n",
      "Epoch: 335/500... Training loss: 0.0059\n",
      "Epoch: 335/500... Training loss: 0.0024\n",
      "Epoch: 335/500... Training loss: 0.0037\n",
      "Epoch: 335/500... Training loss: 0.0029\n",
      "Epoch: 335/500... Training loss: 0.0081\n",
      "Epoch: 335/500... Training loss: 0.0438\n",
      "Epoch: 335/500... Training loss: 0.0010\n",
      "Epoch: 335/500... Training loss: 0.0058\n",
      "Epoch: 335/500... Training loss: 0.0228\n",
      "Epoch: 335/500... Training loss: 0.0133\n",
      "Epoch: 335/500... Training loss: 0.0369\n",
      "Epoch: 335/500... Training loss: 0.0011\n",
      "Epoch: 335/500... Training loss: 0.0034\n",
      "Epoch: 335/500... Training loss: 0.1476\n",
      "Epoch: 335/500... Training loss: 0.0023\n",
      "Epoch: 335/500... Training loss: 0.0214\n",
      "Epoch: 335/500... Training loss: 0.0034\n",
      "Epoch: 335/500... Training loss: 0.1238\n",
      "Epoch: 335/500... Training loss: 0.0205\n",
      "Epoch: 335/500... Training loss: 0.0030\n",
      "Epoch: 335/500... Training loss: 0.0092\n",
      "Epoch: 335/500... Training loss: 0.0047\n",
      "Epoch: 335/500... Training loss: 0.0118\n",
      "Epoch: 335/500... Training loss: 0.0032\n",
      "Epoch: 335/500... Training loss: 0.0013\n",
      "Epoch: 336/500... Training loss: 0.0083\n",
      "Epoch: 336/500... Training loss: 0.0013\n",
      "Epoch: 336/500... Training loss: 0.0974\n",
      "Epoch: 336/500... Training loss: 0.0311\n",
      "Epoch: 336/500... Training loss: 0.0066\n",
      "Epoch: 336/500... Training loss: 0.0048\n",
      "Epoch: 336/500... Training loss: 0.0220\n",
      "Epoch: 336/500... Training loss: 0.0019\n",
      "Epoch: 336/500... Training loss: 0.0034\n",
      "Epoch: 336/500... Training loss: 0.0030\n",
      "Epoch: 336/500... Training loss: 0.0066\n",
      "Epoch: 336/500... Training loss: 0.0116\n",
      "Epoch: 336/500... Training loss: 0.0052\n",
      "Epoch: 336/500... Training loss: 0.0158\n",
      "Epoch: 336/500... Training loss: 0.0020\n",
      "Epoch: 336/500... Training loss: 0.0020\n",
      "Epoch: 336/500... Training loss: 0.0528\n",
      "Epoch: 336/500... Training loss: 0.0095\n",
      "Epoch: 336/500... Training loss: 0.0896\n",
      "Epoch: 336/500... Training loss: 0.0228\n",
      "Epoch: 336/500... Training loss: 0.0295\n",
      "Epoch: 336/500... Training loss: 0.0118\n",
      "Epoch: 336/500... Training loss: 0.0554\n",
      "Epoch: 336/500... Training loss: 0.0009\n",
      "Epoch: 336/500... Training loss: 0.0021\n",
      "Epoch: 336/500... Training loss: 0.0019\n",
      "Epoch: 336/500... Training loss: 0.0976\n",
      "Epoch: 336/500... Training loss: 0.0055\n",
      "Epoch: 336/500... Training loss: 0.0012\n",
      "Epoch: 336/500... Training loss: 0.0025\n",
      "Epoch: 336/500... Training loss: 0.0827\n",
      "Epoch: 337/500... Training loss: 0.0097\n",
      "Epoch: 337/500... Training loss: 0.0188\n",
      "Epoch: 337/500... Training loss: 0.1236\n",
      "Epoch: 337/500... Training loss: 0.0067\n",
      "Epoch: 337/500... Training loss: 0.0047\n",
      "Epoch: 337/500... Training loss: 0.0037\n",
      "Epoch: 337/500... Training loss: 0.0609\n",
      "Epoch: 337/500... Training loss: 0.0029\n",
      "Epoch: 337/500... Training loss: 0.0477\n",
      "Epoch: 337/500... Training loss: 0.0041\n",
      "Epoch: 337/500... Training loss: 0.0534\n",
      "Epoch: 337/500... Training loss: 0.0110\n",
      "Epoch: 337/500... Training loss: 0.0047\n",
      "Epoch: 337/500... Training loss: 0.0011\n",
      "Epoch: 337/500... Training loss: 0.0068\n",
      "Epoch: 337/500... Training loss: 0.0021\n",
      "Epoch: 337/500... Training loss: 0.0088\n",
      "Epoch: 337/500... Training loss: 0.0118\n",
      "Epoch: 337/500... Training loss: 0.0058\n",
      "Epoch: 337/500... Training loss: 0.0193\n",
      "Epoch: 337/500... Training loss: 0.0135\n",
      "Epoch: 337/500... Training loss: 0.0250\n",
      "Epoch: 337/500... Training loss: 0.1055\n",
      "Epoch: 337/500... Training loss: 0.0143\n",
      "Epoch: 337/500... Training loss: 0.0023\n",
      "Epoch: 337/500... Training loss: 0.0021\n",
      "Epoch: 337/500... Training loss: 0.0876\n",
      "Epoch: 337/500... Training loss: 0.0470\n",
      "Epoch: 337/500... Training loss: 0.0035\n",
      "Epoch: 337/500... Training loss: 0.0033\n",
      "Epoch: 337/500... Training loss: 0.0034\n",
      "Epoch: 338/500... Training loss: 0.0061\n",
      "Epoch: 338/500... Training loss: 0.0019\n",
      "Epoch: 338/500... Training loss: 0.0117\n",
      "Epoch: 338/500... Training loss: 0.0028\n",
      "Epoch: 338/500... Training loss: 0.0576\n",
      "Epoch: 338/500... Training loss: 0.0345\n",
      "Epoch: 338/500... Training loss: 0.0179\n",
      "Epoch: 338/500... Training loss: 0.0024\n",
      "Epoch: 338/500... Training loss: 0.0184\n",
      "Epoch: 338/500... Training loss: 0.0030\n",
      "Epoch: 338/500... Training loss: 0.0325\n",
      "Epoch: 338/500... Training loss: 0.0136\n",
      "Epoch: 338/500... Training loss: 0.0029\n",
      "Epoch: 338/500... Training loss: 0.0049\n",
      "Epoch: 338/500... Training loss: 0.0152\n",
      "Epoch: 338/500... Training loss: 0.0062\n",
      "Epoch: 338/500... Training loss: 0.0032\n",
      "Epoch: 338/500... Training loss: 0.0017\n",
      "Epoch: 338/500... Training loss: 0.0132\n",
      "Epoch: 338/500... Training loss: 0.0049\n",
      "Epoch: 338/500... Training loss: 0.0084\n",
      "Epoch: 338/500... Training loss: 0.0110\n",
      "Epoch: 338/500... Training loss: 0.1344\n",
      "Epoch: 338/500... Training loss: 0.0159\n",
      "Epoch: 338/500... Training loss: 0.0109\n",
      "Epoch: 338/500... Training loss: 0.0043\n",
      "Epoch: 338/500... Training loss: 0.0042\n",
      "Epoch: 338/500... Training loss: 0.0100\n",
      "Epoch: 338/500... Training loss: 0.0404\n",
      "Epoch: 338/500... Training loss: 0.0069\n",
      "Epoch: 338/500... Training loss: 0.0076\n",
      "Epoch: 339/500... Training loss: 0.0027\n",
      "Epoch: 339/500... Training loss: 0.0866\n",
      "Epoch: 339/500... Training loss: 0.0064\n",
      "Epoch: 339/500... Training loss: 0.0329\n",
      "Epoch: 339/500... Training loss: 0.0083\n",
      "Epoch: 339/500... Training loss: 0.0105\n",
      "Epoch: 339/500... Training loss: 0.0107\n",
      "Epoch: 339/500... Training loss: 0.0125\n",
      "Epoch: 339/500... Training loss: 0.0468\n",
      "Epoch: 339/500... Training loss: 0.0058\n",
      "Epoch: 339/500... Training loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/500... Training loss: 0.0417\n",
      "Epoch: 339/500... Training loss: 0.1056\n",
      "Epoch: 339/500... Training loss: 0.0019\n",
      "Epoch: 339/500... Training loss: 0.0027\n",
      "Epoch: 339/500... Training loss: 0.0286\n",
      "Epoch: 339/500... Training loss: 0.0015\n",
      "Epoch: 339/500... Training loss: 0.0058\n",
      "Epoch: 339/500... Training loss: 0.0055\n",
      "Epoch: 339/500... Training loss: 0.0172\n",
      "Epoch: 339/500... Training loss: 0.0041\n",
      "Epoch: 339/500... Training loss: 0.1596\n",
      "Epoch: 339/500... Training loss: 0.0028\n",
      "Epoch: 339/500... Training loss: 0.0091\n",
      "Epoch: 339/500... Training loss: 0.0017\n",
      "Epoch: 339/500... Training loss: 0.0048\n",
      "Epoch: 339/500... Training loss: 0.0432\n",
      "Epoch: 339/500... Training loss: 0.0232\n",
      "Epoch: 339/500... Training loss: 0.0425\n",
      "Epoch: 339/500... Training loss: 0.0774\n",
      "Epoch: 339/500... Training loss: 0.0149\n",
      "Epoch: 340/500... Training loss: 0.0164\n",
      "Epoch: 340/500... Training loss: 0.0145\n",
      "Epoch: 340/500... Training loss: 0.0951\n",
      "Epoch: 340/500... Training loss: 0.0021\n",
      "Epoch: 340/500... Training loss: 0.0103\n",
      "Epoch: 340/500... Training loss: 0.0464\n",
      "Epoch: 340/500... Training loss: 0.0713\n",
      "Epoch: 340/500... Training loss: 0.1062\n",
      "Epoch: 340/500... Training loss: 0.0330\n",
      "Epoch: 340/500... Training loss: 0.0036\n",
      "Epoch: 340/500... Training loss: 0.0116\n",
      "Epoch: 340/500... Training loss: 0.0220\n",
      "Epoch: 340/500... Training loss: 0.0404\n",
      "Epoch: 340/500... Training loss: 0.0172\n",
      "Epoch: 340/500... Training loss: 0.0046\n",
      "Epoch: 340/500... Training loss: 0.0016\n",
      "Epoch: 340/500... Training loss: 0.0063\n",
      "Epoch: 340/500... Training loss: 0.0819\n",
      "Epoch: 340/500... Training loss: 0.0025\n",
      "Epoch: 340/500... Training loss: 0.0223\n",
      "Epoch: 340/500... Training loss: 0.0464\n",
      "Epoch: 340/500... Training loss: 0.0471\n",
      "Epoch: 340/500... Training loss: 0.0462\n",
      "Epoch: 340/500... Training loss: 0.0037\n",
      "Epoch: 340/500... Training loss: 0.0056\n",
      "Epoch: 340/500... Training loss: 0.0010\n",
      "Epoch: 340/500... Training loss: 0.0060\n",
      "Epoch: 340/500... Training loss: 0.0026\n",
      "Epoch: 340/500... Training loss: 0.0553\n",
      "Epoch: 340/500... Training loss: 0.0107\n",
      "Epoch: 340/500... Training loss: 0.0285\n",
      "Epoch: 341/500... Training loss: 0.0510\n",
      "Epoch: 341/500... Training loss: 0.0019\n",
      "Epoch: 341/500... Training loss: 0.0050\n",
      "Epoch: 341/500... Training loss: 0.0054\n",
      "Epoch: 341/500... Training loss: 0.0025\n",
      "Epoch: 341/500... Training loss: 0.0135\n",
      "Epoch: 341/500... Training loss: 0.0367\n",
      "Epoch: 341/500... Training loss: 0.0033\n",
      "Epoch: 341/500... Training loss: 0.0053\n",
      "Epoch: 341/500... Training loss: 0.0123\n",
      "Epoch: 341/500... Training loss: 0.0060\n",
      "Epoch: 341/500... Training loss: 0.0165\n",
      "Epoch: 341/500... Training loss: 0.0074\n",
      "Epoch: 341/500... Training loss: 0.1021\n",
      "Epoch: 341/500... Training loss: 0.0259\n",
      "Epoch: 341/500... Training loss: 0.0192\n",
      "Epoch: 341/500... Training loss: 0.0107\n",
      "Epoch: 341/500... Training loss: 0.0014\n",
      "Epoch: 341/500... Training loss: 0.0033\n",
      "Epoch: 341/500... Training loss: 0.0035\n",
      "Epoch: 341/500... Training loss: 0.0111\n",
      "Epoch: 341/500... Training loss: 0.0070\n",
      "Epoch: 341/500... Training loss: 0.0090\n",
      "Epoch: 341/500... Training loss: 0.0012\n",
      "Epoch: 341/500... Training loss: 0.0286\n",
      "Epoch: 341/500... Training loss: 0.0889\n",
      "Epoch: 341/500... Training loss: 0.0062\n",
      "Epoch: 341/500... Training loss: 0.0660\n",
      "Epoch: 341/500... Training loss: 0.0335\n",
      "Epoch: 341/500... Training loss: 0.0011\n",
      "Epoch: 341/500... Training loss: 0.0026\n",
      "Epoch: 342/500... Training loss: 0.0075\n",
      "Epoch: 342/500... Training loss: 0.0166\n",
      "Epoch: 342/500... Training loss: 0.0041\n",
      "Epoch: 342/500... Training loss: 0.0018\n",
      "Epoch: 342/500... Training loss: 0.0036\n",
      "Epoch: 342/500... Training loss: 0.0022\n",
      "Epoch: 342/500... Training loss: 0.0092\n",
      "Epoch: 342/500... Training loss: 0.0028\n",
      "Epoch: 342/500... Training loss: 0.0146\n",
      "Epoch: 342/500... Training loss: 0.0312\n",
      "Epoch: 342/500... Training loss: 0.1023\n",
      "Epoch: 342/500... Training loss: 0.0285\n",
      "Epoch: 342/500... Training loss: 0.0602\n",
      "Epoch: 342/500... Training loss: 0.0094\n",
      "Epoch: 342/500... Training loss: 0.0283\n",
      "Epoch: 342/500... Training loss: 0.0089\n",
      "Epoch: 342/500... Training loss: 0.0037\n",
      "Epoch: 342/500... Training loss: 0.0046\n",
      "Epoch: 342/500... Training loss: 0.0102\n",
      "Epoch: 342/500... Training loss: 0.0025\n",
      "Epoch: 342/500... Training loss: 0.0032\n",
      "Epoch: 342/500... Training loss: 0.0350\n",
      "Epoch: 342/500... Training loss: 0.0353\n",
      "Epoch: 342/500... Training loss: 0.0032\n",
      "Epoch: 342/500... Training loss: 0.0036\n",
      "Epoch: 342/500... Training loss: 0.0042\n",
      "Epoch: 342/500... Training loss: 0.0039\n",
      "Epoch: 342/500... Training loss: 0.0073\n",
      "Epoch: 342/500... Training loss: 0.0019\n",
      "Epoch: 342/500... Training loss: 0.0072\n",
      "Epoch: 342/500... Training loss: 0.0259\n",
      "Epoch: 343/500... Training loss: 0.0411\n",
      "Epoch: 343/500... Training loss: 0.0030\n",
      "Epoch: 343/500... Training loss: 0.0077\n",
      "Epoch: 343/500... Training loss: 0.0138\n",
      "Epoch: 343/500... Training loss: 0.0093\n",
      "Epoch: 343/500... Training loss: 0.0300\n",
      "Epoch: 343/500... Training loss: 0.0024\n",
      "Epoch: 343/500... Training loss: 0.0667\n",
      "Epoch: 343/500... Training loss: 0.0760\n",
      "Epoch: 343/500... Training loss: 0.0031\n",
      "Epoch: 343/500... Training loss: 0.0372\n",
      "Epoch: 343/500... Training loss: 0.0067\n",
      "Epoch: 343/500... Training loss: 0.0024\n",
      "Epoch: 343/500... Training loss: 0.0390\n",
      "Epoch: 343/500... Training loss: 0.0030\n",
      "Epoch: 343/500... Training loss: 0.0474\n",
      "Epoch: 343/500... Training loss: 0.0708\n",
      "Epoch: 343/500... Training loss: 0.0062\n",
      "Epoch: 343/500... Training loss: 0.0155\n",
      "Epoch: 343/500... Training loss: 0.0056\n",
      "Epoch: 343/500... Training loss: 0.0028\n",
      "Epoch: 343/500... Training loss: 0.0084\n",
      "Epoch: 343/500... Training loss: 0.0581\n",
      "Epoch: 343/500... Training loss: 0.0033\n",
      "Epoch: 343/500... Training loss: 0.0056\n",
      "Epoch: 343/500... Training loss: 0.0180\n",
      "Epoch: 343/500... Training loss: 0.0018\n",
      "Epoch: 343/500... Training loss: 0.0175\n",
      "Epoch: 343/500... Training loss: 0.0069\n",
      "Epoch: 343/500... Training loss: 0.0371\n",
      "Epoch: 343/500... Training loss: 0.0091\n",
      "Epoch: 344/500... Training loss: 0.1458\n",
      "Epoch: 344/500... Training loss: 0.0041\n",
      "Epoch: 344/500... Training loss: 0.0413\n",
      "Epoch: 344/500... Training loss: 0.0015\n",
      "Epoch: 344/500... Training loss: 0.0052\n",
      "Epoch: 344/500... Training loss: 0.0363\n",
      "Epoch: 344/500... Training loss: 0.0112\n",
      "Epoch: 344/500... Training loss: 0.0276\n",
      "Epoch: 344/500... Training loss: 0.0126\n",
      "Epoch: 344/500... Training loss: 0.0120\n",
      "Epoch: 344/500... Training loss: 0.0351\n",
      "Epoch: 344/500... Training loss: 0.0078\n",
      "Epoch: 344/500... Training loss: 0.0022\n",
      "Epoch: 344/500... Training loss: 0.0022\n",
      "Epoch: 344/500... Training loss: 0.0199\n",
      "Epoch: 344/500... Training loss: 0.0285\n",
      "Epoch: 344/500... Training loss: 0.0018\n",
      "Epoch: 344/500... Training loss: 0.0283\n",
      "Epoch: 344/500... Training loss: 0.0361\n",
      "Epoch: 344/500... Training loss: 0.0045\n",
      "Epoch: 344/500... Training loss: 0.0140\n",
      "Epoch: 344/500... Training loss: 0.0208\n",
      "Epoch: 344/500... Training loss: 0.0245\n",
      "Epoch: 344/500... Training loss: 0.0046\n",
      "Epoch: 344/500... Training loss: 0.0037\n",
      "Epoch: 344/500... Training loss: 0.0206\n",
      "Epoch: 344/500... Training loss: 0.0423\n",
      "Epoch: 344/500... Training loss: 0.0043\n",
      "Epoch: 344/500... Training loss: 0.0115\n",
      "Epoch: 344/500... Training loss: 0.0036\n",
      "Epoch: 344/500... Training loss: 0.0785\n",
      "Epoch: 345/500... Training loss: 0.0212\n",
      "Epoch: 345/500... Training loss: 0.0381\n",
      "Epoch: 345/500... Training loss: 0.0272\n",
      "Epoch: 345/500... Training loss: 0.0042\n",
      "Epoch: 345/500... Training loss: 0.0450\n",
      "Epoch: 345/500... Training loss: 0.0135\n",
      "Epoch: 345/500... Training loss: 0.0049\n",
      "Epoch: 345/500... Training loss: 0.0032\n",
      "Epoch: 345/500... Training loss: 0.0169\n",
      "Epoch: 345/500... Training loss: 0.0249\n",
      "Epoch: 345/500... Training loss: 0.0120\n",
      "Epoch: 345/500... Training loss: 0.0041\n",
      "Epoch: 345/500... Training loss: 0.0842\n",
      "Epoch: 345/500... Training loss: 0.0105\n",
      "Epoch: 345/500... Training loss: 0.0023\n",
      "Epoch: 345/500... Training loss: 0.0041\n",
      "Epoch: 345/500... Training loss: 0.0040\n",
      "Epoch: 345/500... Training loss: 0.0266\n",
      "Epoch: 345/500... Training loss: 0.0740\n",
      "Epoch: 345/500... Training loss: 0.0020\n",
      "Epoch: 345/500... Training loss: 0.0029\n",
      "Epoch: 345/500... Training loss: 0.0114\n",
      "Epoch: 345/500... Training loss: 0.0361\n",
      "Epoch: 345/500... Training loss: 0.0021\n",
      "Epoch: 345/500... Training loss: 0.0058\n",
      "Epoch: 345/500... Training loss: 0.0060\n",
      "Epoch: 345/500... Training loss: 0.0053\n",
      "Epoch: 345/500... Training loss: 0.0148\n",
      "Epoch: 345/500... Training loss: 0.0115\n",
      "Epoch: 345/500... Training loss: 0.0126\n",
      "Epoch: 345/500... Training loss: 0.0169\n",
      "Epoch: 346/500... Training loss: 0.0021\n",
      "Epoch: 346/500... Training loss: 0.0140\n",
      "Epoch: 346/500... Training loss: 0.0377\n",
      "Epoch: 346/500... Training loss: 0.0089\n",
      "Epoch: 346/500... Training loss: 0.0890\n",
      "Epoch: 346/500... Training loss: 0.0303\n",
      "Epoch: 346/500... Training loss: 0.0062\n",
      "Epoch: 346/500... Training loss: 0.0191\n",
      "Epoch: 346/500... Training loss: 0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 346/500... Training loss: 0.0067\n",
      "Epoch: 346/500... Training loss: 0.0024\n",
      "Epoch: 346/500... Training loss: 0.0245\n",
      "Epoch: 346/500... Training loss: 0.0466\n",
      "Epoch: 346/500... Training loss: 0.0215\n",
      "Epoch: 346/500... Training loss: 0.0018\n",
      "Epoch: 346/500... Training loss: 0.0302\n",
      "Epoch: 346/500... Training loss: 0.0104\n",
      "Epoch: 346/500... Training loss: 0.0083\n",
      "Epoch: 346/500... Training loss: 0.0761\n",
      "Epoch: 346/500... Training loss: 0.0060\n",
      "Epoch: 346/500... Training loss: 0.0620\n",
      "Epoch: 346/500... Training loss: 0.0206\n",
      "Epoch: 346/500... Training loss: 0.0144\n",
      "Epoch: 346/500... Training loss: 0.0028\n",
      "Epoch: 346/500... Training loss: 0.0082\n",
      "Epoch: 346/500... Training loss: 0.0132\n",
      "Epoch: 346/500... Training loss: 0.0010\n",
      "Epoch: 346/500... Training loss: 0.0123\n",
      "Epoch: 346/500... Training loss: 0.0067\n",
      "Epoch: 346/500... Training loss: 0.1144\n",
      "Epoch: 346/500... Training loss: 0.0345\n",
      "Epoch: 347/500... Training loss: 0.0008\n",
      "Epoch: 347/500... Training loss: 0.0078\n",
      "Epoch: 347/500... Training loss: 0.0077\n",
      "Epoch: 347/500... Training loss: 0.0168\n",
      "Epoch: 347/500... Training loss: 0.0017\n",
      "Epoch: 347/500... Training loss: 0.0069\n",
      "Epoch: 347/500... Training loss: 0.0061\n",
      "Epoch: 347/500... Training loss: 0.0055\n",
      "Epoch: 347/500... Training loss: 0.0029\n",
      "Epoch: 347/500... Training loss: 0.1247\n",
      "Epoch: 347/500... Training loss: 0.0714\n",
      "Epoch: 347/500... Training loss: 0.0028\n",
      "Epoch: 347/500... Training loss: 0.0023\n",
      "Epoch: 347/500... Training loss: 0.0086\n",
      "Epoch: 347/500... Training loss: 0.0062\n",
      "Epoch: 347/500... Training loss: 0.0044\n",
      "Epoch: 347/500... Training loss: 0.0377\n",
      "Epoch: 347/500... Training loss: 0.0536\n",
      "Epoch: 347/500... Training loss: 0.0472\n",
      "Epoch: 347/500... Training loss: 0.0033\n",
      "Epoch: 347/500... Training loss: 0.0342\n",
      "Epoch: 347/500... Training loss: 0.0020\n",
      "Epoch: 347/500... Training loss: 0.0757\n",
      "Epoch: 347/500... Training loss: 0.0052\n",
      "Epoch: 347/500... Training loss: 0.0356\n",
      "Epoch: 347/500... Training loss: 0.0169\n",
      "Epoch: 347/500... Training loss: 0.0016\n",
      "Epoch: 347/500... Training loss: 0.0540\n",
      "Epoch: 347/500... Training loss: 0.0045\n",
      "Epoch: 347/500... Training loss: 0.0100\n",
      "Epoch: 347/500... Training loss: 0.0012\n",
      "Epoch: 348/500... Training loss: 0.0033\n",
      "Epoch: 348/500... Training loss: 0.0878\n",
      "Epoch: 348/500... Training loss: 0.0082\n",
      "Epoch: 348/500... Training loss: 0.0082\n",
      "Epoch: 348/500... Training loss: 0.0126\n",
      "Epoch: 348/500... Training loss: 0.1232\n",
      "Epoch: 348/500... Training loss: 0.0039\n",
      "Epoch: 348/500... Training loss: 0.0612\n",
      "Epoch: 348/500... Training loss: 0.0253\n",
      "Epoch: 348/500... Training loss: 0.0017\n",
      "Epoch: 348/500... Training loss: 0.0261\n",
      "Epoch: 348/500... Training loss: 0.0051\n",
      "Epoch: 348/500... Training loss: 0.0042\n",
      "Epoch: 348/500... Training loss: 0.0113\n",
      "Epoch: 348/500... Training loss: 0.0052\n",
      "Epoch: 348/500... Training loss: 0.0352\n",
      "Epoch: 348/500... Training loss: 0.0569\n",
      "Epoch: 348/500... Training loss: 0.0173\n",
      "Epoch: 348/500... Training loss: 0.0057\n",
      "Epoch: 348/500... Training loss: 0.0152\n",
      "Epoch: 348/500... Training loss: 0.0051\n",
      "Epoch: 348/500... Training loss: 0.0037\n",
      "Epoch: 348/500... Training loss: 0.0768\n",
      "Epoch: 348/500... Training loss: 0.0652\n",
      "Epoch: 348/500... Training loss: 0.0792\n",
      "Epoch: 348/500... Training loss: 0.0690\n",
      "Epoch: 348/500... Training loss: 0.0323\n",
      "Epoch: 348/500... Training loss: 0.0180\n",
      "Epoch: 348/500... Training loss: 0.0109\n",
      "Epoch: 348/500... Training loss: 0.0791\n",
      "Epoch: 348/500... Training loss: 0.0207\n",
      "Epoch: 349/500... Training loss: 0.0102\n",
      "Epoch: 349/500... Training loss: 0.0050\n",
      "Epoch: 349/500... Training loss: 0.0210\n",
      "Epoch: 349/500... Training loss: 0.0057\n",
      "Epoch: 349/500... Training loss: 0.0281\n",
      "Epoch: 349/500... Training loss: 0.0099\n",
      "Epoch: 349/500... Training loss: 0.0015\n",
      "Epoch: 349/500... Training loss: 0.0048\n",
      "Epoch: 349/500... Training loss: 0.0029\n",
      "Epoch: 349/500... Training loss: 0.0038\n",
      "Epoch: 349/500... Training loss: 0.0046\n",
      "Epoch: 349/500... Training loss: 0.0056\n",
      "Epoch: 349/500... Training loss: 0.0122\n",
      "Epoch: 349/500... Training loss: 0.0166\n",
      "Epoch: 349/500... Training loss: 0.0646\n",
      "Epoch: 349/500... Training loss: 0.0154\n",
      "Epoch: 349/500... Training loss: 0.0138\n",
      "Epoch: 349/500... Training loss: 0.0098\n",
      "Epoch: 349/500... Training loss: 0.0370\n",
      "Epoch: 349/500... Training loss: 0.0077\n",
      "Epoch: 349/500... Training loss: 0.0019\n",
      "Epoch: 349/500... Training loss: 0.0032\n",
      "Epoch: 349/500... Training loss: 0.0843\n",
      "Epoch: 349/500... Training loss: 0.0111\n",
      "Epoch: 349/500... Training loss: 0.0040\n",
      "Epoch: 349/500... Training loss: 0.0256\n",
      "Epoch: 349/500... Training loss: 0.0082\n",
      "Epoch: 349/500... Training loss: 0.0247\n",
      "Epoch: 349/500... Training loss: 0.0076\n",
      "Epoch: 349/500... Training loss: 0.0374\n",
      "Epoch: 349/500... Training loss: 0.0232\n",
      "Epoch: 350/500... Training loss: 0.0900\n",
      "Epoch: 350/500... Training loss: 0.0036\n",
      "Epoch: 350/500... Training loss: 0.0027\n",
      "Epoch: 350/500... Training loss: 0.0143\n",
      "Epoch: 350/500... Training loss: 0.0552\n",
      "Epoch: 350/500... Training loss: 0.0321\n",
      "Epoch: 350/500... Training loss: 0.0026\n",
      "Epoch: 350/500... Training loss: 0.0080\n",
      "Epoch: 350/500... Training loss: 0.0060\n",
      "Epoch: 350/500... Training loss: 0.0210\n",
      "Epoch: 350/500... Training loss: 0.0191\n",
      "Epoch: 350/500... Training loss: 0.0291\n",
      "Epoch: 350/500... Training loss: 0.0023\n",
      "Epoch: 350/500... Training loss: 0.0023\n",
      "Epoch: 350/500... Training loss: 0.0062\n",
      "Epoch: 350/500... Training loss: 0.0232\n",
      "Epoch: 350/500... Training loss: 0.0084\n",
      "Epoch: 350/500... Training loss: 0.0032\n",
      "Epoch: 350/500... Training loss: 0.0864\n",
      "Epoch: 350/500... Training loss: 0.0102\n",
      "Epoch: 350/500... Training loss: 0.0028\n",
      "Epoch: 350/500... Training loss: 0.0389\n",
      "Epoch: 350/500... Training loss: 0.0077\n",
      "Epoch: 350/500... Training loss: 0.0092\n",
      "Epoch: 350/500... Training loss: 0.0022\n",
      "Epoch: 350/500... Training loss: 0.1173\n",
      "Epoch: 350/500... Training loss: 0.0217\n",
      "Epoch: 350/500... Training loss: 0.0069\n",
      "Epoch: 350/500... Training loss: 0.0067\n",
      "Epoch: 350/500... Training loss: 0.0083\n",
      "Epoch: 350/500... Training loss: 0.0013\n",
      "Epoch: 351/500... Training loss: 0.0022\n",
      "Epoch: 351/500... Training loss: 0.0959\n",
      "Epoch: 351/500... Training loss: 0.0041\n",
      "Epoch: 351/500... Training loss: 0.0120\n",
      "Epoch: 351/500... Training loss: 0.0762\n",
      "Epoch: 351/500... Training loss: 0.0096\n",
      "Epoch: 351/500... Training loss: 0.0043\n",
      "Epoch: 351/500... Training loss: 0.0058\n",
      "Epoch: 351/500... Training loss: 0.0016\n",
      "Epoch: 351/500... Training loss: 0.0187\n",
      "Epoch: 351/500... Training loss: 0.1806\n",
      "Epoch: 351/500... Training loss: 0.0093\n",
      "Epoch: 351/500... Training loss: 0.0141\n",
      "Epoch: 351/500... Training loss: 0.0015\n",
      "Epoch: 351/500... Training loss: 0.0027\n",
      "Epoch: 351/500... Training loss: 0.0025\n",
      "Epoch: 351/500... Training loss: 0.0323\n",
      "Epoch: 351/500... Training loss: 0.0037\n",
      "Epoch: 351/500... Training loss: 0.0073\n",
      "Epoch: 351/500... Training loss: 0.0105\n",
      "Epoch: 351/500... Training loss: 0.0026\n",
      "Epoch: 351/500... Training loss: 0.0173\n",
      "Epoch: 351/500... Training loss: 0.0128\n",
      "Epoch: 351/500... Training loss: 0.0012\n",
      "Epoch: 351/500... Training loss: 0.0068\n",
      "Epoch: 351/500... Training loss: 0.0124\n",
      "Epoch: 351/500... Training loss: 0.0051\n",
      "Epoch: 351/500... Training loss: 0.0051\n",
      "Epoch: 351/500... Training loss: 0.0087\n",
      "Epoch: 351/500... Training loss: 0.0052\n",
      "Epoch: 351/500... Training loss: 0.0065\n",
      "Epoch: 352/500... Training loss: 0.0070\n",
      "Epoch: 352/500... Training loss: 0.0085\n",
      "Epoch: 352/500... Training loss: 0.0075\n",
      "Epoch: 352/500... Training loss: 0.0085\n",
      "Epoch: 352/500... Training loss: 0.0218\n",
      "Epoch: 352/500... Training loss: 0.0304\n",
      "Epoch: 352/500... Training loss: 0.0061\n",
      "Epoch: 352/500... Training loss: 0.0033\n",
      "Epoch: 352/500... Training loss: 0.0037\n",
      "Epoch: 352/500... Training loss: 0.0033\n",
      "Epoch: 352/500... Training loss: 0.0067\n",
      "Epoch: 352/500... Training loss: 0.0042\n",
      "Epoch: 352/500... Training loss: 0.0056\n",
      "Epoch: 352/500... Training loss: 0.0012\n",
      "Epoch: 352/500... Training loss: 0.0180\n",
      "Epoch: 352/500... Training loss: 0.0064\n",
      "Epoch: 352/500... Training loss: 0.0038\n",
      "Epoch: 352/500... Training loss: 0.0230\n",
      "Epoch: 352/500... Training loss: 0.0014\n",
      "Epoch: 352/500... Training loss: 0.0023\n",
      "Epoch: 352/500... Training loss: 0.0485\n",
      "Epoch: 352/500... Training loss: 0.0036\n",
      "Epoch: 352/500... Training loss: 0.0506\n",
      "Epoch: 352/500... Training loss: 0.0148\n",
      "Epoch: 352/500... Training loss: 0.0088\n",
      "Epoch: 352/500... Training loss: 0.0293\n",
      "Epoch: 352/500... Training loss: 0.0063\n",
      "Epoch: 352/500... Training loss: 0.0270\n",
      "Epoch: 352/500... Training loss: 0.0169\n",
      "Epoch: 352/500... Training loss: 0.0077\n",
      "Epoch: 352/500... Training loss: 0.0235\n",
      "Epoch: 353/500... Training loss: 0.0291\n",
      "Epoch: 353/500... Training loss: 0.0155\n",
      "Epoch: 353/500... Training loss: 0.0243\n",
      "Epoch: 353/500... Training loss: 0.0078\n",
      "Epoch: 353/500... Training loss: 0.0072\n",
      "Epoch: 353/500... Training loss: 0.0811\n",
      "Epoch: 353/500... Training loss: 0.0199\n",
      "Epoch: 353/500... Training loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 353/500... Training loss: 0.0445\n",
      "Epoch: 353/500... Training loss: 0.0032\n",
      "Epoch: 353/500... Training loss: 0.0556\n",
      "Epoch: 353/500... Training loss: 0.0020\n",
      "Epoch: 353/500... Training loss: 0.0053\n",
      "Epoch: 353/500... Training loss: 0.0105\n",
      "Epoch: 353/500... Training loss: 0.0287\n",
      "Epoch: 353/500... Training loss: 0.0204\n",
      "Epoch: 353/500... Training loss: 0.0177\n",
      "Epoch: 353/500... Training loss: 0.0010\n",
      "Epoch: 353/500... Training loss: 0.0019\n",
      "Epoch: 353/500... Training loss: 0.0014\n",
      "Epoch: 353/500... Training loss: 0.0044\n",
      "Epoch: 353/500... Training loss: 0.1868\n",
      "Epoch: 353/500... Training loss: 0.0771\n",
      "Epoch: 353/500... Training loss: 0.0129\n",
      "Epoch: 353/500... Training loss: 0.0043\n",
      "Epoch: 353/500... Training loss: 0.0369\n",
      "Epoch: 353/500... Training loss: 0.0373\n",
      "Epoch: 353/500... Training loss: 0.0151\n",
      "Epoch: 353/500... Training loss: 0.0192\n",
      "Epoch: 353/500... Training loss: 0.0072\n",
      "Epoch: 353/500... Training loss: 0.0144\n",
      "Epoch: 354/500... Training loss: 0.0889\n",
      "Epoch: 354/500... Training loss: 0.0543\n",
      "Epoch: 354/500... Training loss: 0.0323\n",
      "Epoch: 354/500... Training loss: 0.0504\n",
      "Epoch: 354/500... Training loss: 0.0197\n",
      "Epoch: 354/500... Training loss: 0.0746\n",
      "Epoch: 354/500... Training loss: 0.0020\n",
      "Epoch: 354/500... Training loss: 0.0841\n",
      "Epoch: 354/500... Training loss: 0.0030\n",
      "Epoch: 354/500... Training loss: 0.0144\n",
      "Epoch: 354/500... Training loss: 0.0092\n",
      "Epoch: 354/500... Training loss: 0.0114\n",
      "Epoch: 354/500... Training loss: 0.0019\n",
      "Epoch: 354/500... Training loss: 0.0025\n",
      "Epoch: 354/500... Training loss: 0.0021\n",
      "Epoch: 354/500... Training loss: 0.0096\n",
      "Epoch: 354/500... Training loss: 0.0300\n",
      "Epoch: 354/500... Training loss: 0.0265\n",
      "Epoch: 354/500... Training loss: 0.0216\n",
      "Epoch: 354/500... Training loss: 0.0350\n",
      "Epoch: 354/500... Training loss: 0.0056\n",
      "Epoch: 354/500... Training loss: 0.0372\n",
      "Epoch: 354/500... Training loss: 0.0276\n",
      "Epoch: 354/500... Training loss: 0.0114\n",
      "Epoch: 354/500... Training loss: 0.0078\n",
      "Epoch: 354/500... Training loss: 0.0269\n",
      "Epoch: 354/500... Training loss: 0.0129\n",
      "Epoch: 354/500... Training loss: 0.0174\n",
      "Epoch: 354/500... Training loss: 0.0042\n",
      "Epoch: 354/500... Training loss: 0.0029\n",
      "Epoch: 354/500... Training loss: 0.0182\n",
      "Epoch: 355/500... Training loss: 0.1243\n",
      "Epoch: 355/500... Training loss: 0.0223\n",
      "Epoch: 355/500... Training loss: 0.0922\n",
      "Epoch: 355/500... Training loss: 0.0151\n",
      "Epoch: 355/500... Training loss: 0.1036\n",
      "Epoch: 355/500... Training loss: 0.0099\n",
      "Epoch: 355/500... Training loss: 0.0029\n",
      "Epoch: 355/500... Training loss: 0.0060\n",
      "Epoch: 355/500... Training loss: 0.0223\n",
      "Epoch: 355/500... Training loss: 0.0835\n",
      "Epoch: 355/500... Training loss: 0.0259\n",
      "Epoch: 355/500... Training loss: 0.0509\n",
      "Epoch: 355/500... Training loss: 0.0036\n",
      "Epoch: 355/500... Training loss: 0.0400\n",
      "Epoch: 355/500... Training loss: 0.0210\n",
      "Epoch: 355/500... Training loss: 0.0150\n",
      "Epoch: 355/500... Training loss: 0.0880\n",
      "Epoch: 355/500... Training loss: 0.0019\n",
      "Epoch: 355/500... Training loss: 0.0130\n",
      "Epoch: 355/500... Training loss: 0.0096\n",
      "Epoch: 355/500... Training loss: 0.0291\n",
      "Epoch: 355/500... Training loss: 0.0018\n",
      "Epoch: 355/500... Training loss: 0.0874\n",
      "Epoch: 355/500... Training loss: 0.0031\n",
      "Epoch: 355/500... Training loss: 0.0472\n",
      "Epoch: 355/500... Training loss: 0.0151\n",
      "Epoch: 355/500... Training loss: 0.0900\n",
      "Epoch: 355/500... Training loss: 0.0060\n",
      "Epoch: 355/500... Training loss: 0.0066\n",
      "Epoch: 355/500... Training loss: 0.0609\n",
      "Epoch: 355/500... Training loss: 0.0040\n",
      "Epoch: 356/500... Training loss: 0.0834\n",
      "Epoch: 356/500... Training loss: 0.0889\n",
      "Epoch: 356/500... Training loss: 0.0136\n",
      "Epoch: 356/500... Training loss: 0.0165\n",
      "Epoch: 356/500... Training loss: 0.0066\n",
      "Epoch: 356/500... Training loss: 0.0513\n",
      "Epoch: 356/500... Training loss: 0.0171\n",
      "Epoch: 356/500... Training loss: 0.0047\n",
      "Epoch: 356/500... Training loss: 0.0092\n",
      "Epoch: 356/500... Training loss: 0.0111\n",
      "Epoch: 356/500... Training loss: 0.0080\n",
      "Epoch: 356/500... Training loss: 0.0270\n",
      "Epoch: 356/500... Training loss: 0.0021\n",
      "Epoch: 356/500... Training loss: 0.0125\n",
      "Epoch: 356/500... Training loss: 0.0198\n",
      "Epoch: 356/500... Training loss: 0.0734\n",
      "Epoch: 356/500... Training loss: 0.0090\n",
      "Epoch: 356/500... Training loss: 0.0137\n",
      "Epoch: 356/500... Training loss: 0.0500\n",
      "Epoch: 356/500... Training loss: 0.0047\n",
      "Epoch: 356/500... Training loss: 0.0322\n",
      "Epoch: 356/500... Training loss: 0.0253\n",
      "Epoch: 356/500... Training loss: 0.0914\n",
      "Epoch: 356/500... Training loss: 0.0097\n",
      "Epoch: 356/500... Training loss: 0.0008\n",
      "Epoch: 356/500... Training loss: 0.1079\n",
      "Epoch: 356/500... Training loss: 0.0030\n",
      "Epoch: 356/500... Training loss: 0.0062\n",
      "Epoch: 356/500... Training loss: 0.0229\n",
      "Epoch: 356/500... Training loss: 0.0026\n",
      "Epoch: 356/500... Training loss: 0.0138\n",
      "Epoch: 357/500... Training loss: 0.1320\n",
      "Epoch: 357/500... Training loss: 0.0103\n",
      "Epoch: 357/500... Training loss: 0.0066\n",
      "Epoch: 357/500... Training loss: 0.0304\n",
      "Epoch: 357/500... Training loss: 0.1094\n",
      "Epoch: 357/500... Training loss: 0.0217\n",
      "Epoch: 357/500... Training loss: 0.0067\n",
      "Epoch: 357/500... Training loss: 0.0037\n",
      "Epoch: 357/500... Training loss: 0.0254\n",
      "Epoch: 357/500... Training loss: 0.0365\n",
      "Epoch: 357/500... Training loss: 0.0154\n",
      "Epoch: 357/500... Training loss: 0.0038\n",
      "Epoch: 357/500... Training loss: 0.0161\n",
      "Epoch: 357/500... Training loss: 0.0047\n",
      "Epoch: 357/500... Training loss: 0.0108\n",
      "Epoch: 357/500... Training loss: 0.0042\n",
      "Epoch: 357/500... Training loss: 0.0160\n",
      "Epoch: 357/500... Training loss: 0.0422\n",
      "Epoch: 357/500... Training loss: 0.0036\n",
      "Epoch: 357/500... Training loss: 0.0886\n",
      "Epoch: 357/500... Training loss: 0.0318\n",
      "Epoch: 357/500... Training loss: 0.0072\n",
      "Epoch: 357/500... Training loss: 0.0531\n",
      "Epoch: 357/500... Training loss: 0.0151\n",
      "Epoch: 357/500... Training loss: 0.0043\n",
      "Epoch: 357/500... Training loss: 0.0488\n",
      "Epoch: 357/500... Training loss: 0.0251\n",
      "Epoch: 357/500... Training loss: 0.0320\n",
      "Epoch: 357/500... Training loss: 0.0087\n",
      "Epoch: 357/500... Training loss: 0.0020\n",
      "Epoch: 357/500... Training loss: 0.0048\n",
      "Epoch: 358/500... Training loss: 0.0482\n",
      "Epoch: 358/500... Training loss: 0.0017\n",
      "Epoch: 358/500... Training loss: 0.0119\n",
      "Epoch: 358/500... Training loss: 0.0106\n",
      "Epoch: 358/500... Training loss: 0.0986\n",
      "Epoch: 358/500... Training loss: 0.1057\n",
      "Epoch: 358/500... Training loss: 0.0079\n",
      "Epoch: 358/500... Training loss: 0.0201\n",
      "Epoch: 358/500... Training loss: 0.1066\n",
      "Epoch: 358/500... Training loss: 0.0036\n",
      "Epoch: 358/500... Training loss: 0.0211\n",
      "Epoch: 358/500... Training loss: 0.0255\n",
      "Epoch: 358/500... Training loss: 0.0052\n",
      "Epoch: 358/500... Training loss: 0.0082\n",
      "Epoch: 358/500... Training loss: 0.0567\n",
      "Epoch: 358/500... Training loss: 0.0242\n",
      "Epoch: 358/500... Training loss: 0.0039\n",
      "Epoch: 358/500... Training loss: 0.0161\n",
      "Epoch: 358/500... Training loss: 0.0250\n",
      "Epoch: 358/500... Training loss: 0.0106\n",
      "Epoch: 358/500... Training loss: 0.0160\n",
      "Epoch: 358/500... Training loss: 0.0651\n",
      "Epoch: 358/500... Training loss: 0.0951\n",
      "Epoch: 358/500... Training loss: 0.0822\n",
      "Epoch: 358/500... Training loss: 0.0228\n",
      "Epoch: 358/500... Training loss: 0.0069\n",
      "Epoch: 358/500... Training loss: 0.0126\n",
      "Epoch: 358/500... Training loss: 0.0456\n",
      "Epoch: 358/500... Training loss: 0.0150\n",
      "Epoch: 358/500... Training loss: 0.0306\n",
      "Epoch: 358/500... Training loss: 0.0472\n",
      "Epoch: 359/500... Training loss: 0.0054\n",
      "Epoch: 359/500... Training loss: 0.0027\n",
      "Epoch: 359/500... Training loss: 0.0032\n",
      "Epoch: 359/500... Training loss: 0.0320\n",
      "Epoch: 359/500... Training loss: 0.0118\n",
      "Epoch: 359/500... Training loss: 0.0574\n",
      "Epoch: 359/500... Training loss: 0.0062\n",
      "Epoch: 359/500... Training loss: 0.0038\n",
      "Epoch: 359/500... Training loss: 0.0126\n",
      "Epoch: 359/500... Training loss: 0.0152\n",
      "Epoch: 359/500... Training loss: 0.0134\n",
      "Epoch: 359/500... Training loss: 0.0065\n",
      "Epoch: 359/500... Training loss: 0.0993\n",
      "Epoch: 359/500... Training loss: 0.0040\n",
      "Epoch: 359/500... Training loss: 0.0128\n",
      "Epoch: 359/500... Training loss: 0.0376\n",
      "Epoch: 359/500... Training loss: 0.0737\n",
      "Epoch: 359/500... Training loss: 0.0103\n",
      "Epoch: 359/500... Training loss: 0.0098\n",
      "Epoch: 359/500... Training loss: 0.0016\n",
      "Epoch: 359/500... Training loss: 0.0065\n",
      "Epoch: 359/500... Training loss: 0.0659\n",
      "Epoch: 359/500... Training loss: 0.0722\n",
      "Epoch: 359/500... Training loss: 0.0104\n",
      "Epoch: 359/500... Training loss: 0.0053\n",
      "Epoch: 359/500... Training loss: 0.0736\n",
      "Epoch: 359/500... Training loss: 0.0023\n",
      "Epoch: 359/500... Training loss: 0.0026\n",
      "Epoch: 359/500... Training loss: 0.0086\n",
      "Epoch: 359/500... Training loss: 0.0243\n",
      "Epoch: 359/500... Training loss: 0.0083\n",
      "Epoch: 360/500... Training loss: 0.0018\n",
      "Epoch: 360/500... Training loss: 0.0045\n",
      "Epoch: 360/500... Training loss: 0.0254\n",
      "Epoch: 360/500... Training loss: 0.0040\n",
      "Epoch: 360/500... Training loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/500... Training loss: 0.0044\n",
      "Epoch: 360/500... Training loss: 0.0200\n",
      "Epoch: 360/500... Training loss: 0.0943\n",
      "Epoch: 360/500... Training loss: 0.0374\n",
      "Epoch: 360/500... Training loss: 0.0047\n",
      "Epoch: 360/500... Training loss: 0.0026\n",
      "Epoch: 360/500... Training loss: 0.0701\n",
      "Epoch: 360/500... Training loss: 0.0018\n",
      "Epoch: 360/500... Training loss: 0.0044\n",
      "Epoch: 360/500... Training loss: 0.0425\n",
      "Epoch: 360/500... Training loss: 0.0032\n",
      "Epoch: 360/500... Training loss: 0.0364\n",
      "Epoch: 360/500... Training loss: 0.1124\n",
      "Epoch: 360/500... Training loss: 0.0214\n",
      "Epoch: 360/500... Training loss: 0.0026\n",
      "Epoch: 360/500... Training loss: 0.0073\n",
      "Epoch: 360/500... Training loss: 0.0050\n",
      "Epoch: 360/500... Training loss: 0.0446\n",
      "Epoch: 360/500... Training loss: 0.0049\n",
      "Epoch: 360/500... Training loss: 0.0731\n",
      "Epoch: 360/500... Training loss: 0.0103\n",
      "Epoch: 360/500... Training loss: 0.0038\n",
      "Epoch: 360/500... Training loss: 0.0059\n",
      "Epoch: 360/500... Training loss: 0.0227\n",
      "Epoch: 360/500... Training loss: 0.0013\n",
      "Epoch: 360/500... Training loss: 0.0512\n",
      "Epoch: 361/500... Training loss: 0.0024\n",
      "Epoch: 361/500... Training loss: 0.0118\n",
      "Epoch: 361/500... Training loss: 0.0108\n",
      "Epoch: 361/500... Training loss: 0.0512\n",
      "Epoch: 361/500... Training loss: 0.0029\n",
      "Epoch: 361/500... Training loss: 0.0101\n",
      "Epoch: 361/500... Training loss: 0.0210\n",
      "Epoch: 361/500... Training loss: 0.0259\n",
      "Epoch: 361/500... Training loss: 0.0030\n",
      "Epoch: 361/500... Training loss: 0.0075\n",
      "Epoch: 361/500... Training loss: 0.0180\n",
      "Epoch: 361/500... Training loss: 0.0042\n",
      "Epoch: 361/500... Training loss: 0.0080\n",
      "Epoch: 361/500... Training loss: 0.0024\n",
      "Epoch: 361/500... Training loss: 0.0052\n",
      "Epoch: 361/500... Training loss: 0.0040\n",
      "Epoch: 361/500... Training loss: 0.0062\n",
      "Epoch: 361/500... Training loss: 0.0243\n",
      "Epoch: 361/500... Training loss: 0.0016\n",
      "Epoch: 361/500... Training loss: 0.0157\n",
      "Epoch: 361/500... Training loss: 0.0417\n",
      "Epoch: 361/500... Training loss: 0.0234\n",
      "Epoch: 361/500... Training loss: 0.0399\n",
      "Epoch: 361/500... Training loss: 0.0071\n",
      "Epoch: 361/500... Training loss: 0.0036\n",
      "Epoch: 361/500... Training loss: 0.0067\n",
      "Epoch: 361/500... Training loss: 0.0095\n",
      "Epoch: 361/500... Training loss: 0.0095\n",
      "Epoch: 361/500... Training loss: 0.0023\n",
      "Epoch: 361/500... Training loss: 0.0221\n",
      "Epoch: 361/500... Training loss: 0.0047\n",
      "Epoch: 362/500... Training loss: 0.0092\n",
      "Epoch: 362/500... Training loss: 0.0038\n",
      "Epoch: 362/500... Training loss: 0.0049\n",
      "Epoch: 362/500... Training loss: 0.0567\n",
      "Epoch: 362/500... Training loss: 0.0050\n",
      "Epoch: 362/500... Training loss: 0.0130\n",
      "Epoch: 362/500... Training loss: 0.0073\n",
      "Epoch: 362/500... Training loss: 0.0164\n",
      "Epoch: 362/500... Training loss: 0.0021\n",
      "Epoch: 362/500... Training loss: 0.0201\n",
      "Epoch: 362/500... Training loss: 0.0816\n",
      "Epoch: 362/500... Training loss: 0.0335\n",
      "Epoch: 362/500... Training loss: 0.0032\n",
      "Epoch: 362/500... Training loss: 0.0051\n",
      "Epoch: 362/500... Training loss: 0.0155\n",
      "Epoch: 362/500... Training loss: 0.0068\n",
      "Epoch: 362/500... Training loss: 0.0514\n",
      "Epoch: 362/500... Training loss: 0.0016\n",
      "Epoch: 362/500... Training loss: 0.0614\n",
      "Epoch: 362/500... Training loss: 0.0091\n",
      "Epoch: 362/500... Training loss: 0.0083\n",
      "Epoch: 362/500... Training loss: 0.0053\n",
      "Epoch: 362/500... Training loss: 0.0216\n",
      "Epoch: 362/500... Training loss: 0.0015\n",
      "Epoch: 362/500... Training loss: 0.0247\n",
      "Epoch: 362/500... Training loss: 0.0080\n",
      "Epoch: 362/500... Training loss: 0.0016\n",
      "Epoch: 362/500... Training loss: 0.0057\n",
      "Epoch: 362/500... Training loss: 0.0027\n",
      "Epoch: 362/500... Training loss: 0.0055\n",
      "Epoch: 362/500... Training loss: 0.0925\n",
      "Epoch: 363/500... Training loss: 0.0073\n",
      "Epoch: 363/500... Training loss: 0.0149\n",
      "Epoch: 363/500... Training loss: 0.0149\n",
      "Epoch: 363/500... Training loss: 0.0016\n",
      "Epoch: 363/500... Training loss: 0.0163\n",
      "Epoch: 363/500... Training loss: 0.0367\n",
      "Epoch: 363/500... Training loss: 0.0017\n",
      "Epoch: 363/500... Training loss: 0.0187\n",
      "Epoch: 363/500... Training loss: 0.0018\n",
      "Epoch: 363/500... Training loss: 0.0013\n",
      "Epoch: 363/500... Training loss: 0.0023\n",
      "Epoch: 363/500... Training loss: 0.0018\n",
      "Epoch: 363/500... Training loss: 0.0035\n",
      "Epoch: 363/500... Training loss: 0.0023\n",
      "Epoch: 363/500... Training loss: 0.0132\n",
      "Epoch: 363/500... Training loss: 0.0230\n",
      "Epoch: 363/500... Training loss: 0.0047\n",
      "Epoch: 363/500... Training loss: 0.0022\n",
      "Epoch: 363/500... Training loss: 0.0084\n",
      "Epoch: 363/500... Training loss: 0.0216\n",
      "Epoch: 363/500... Training loss: 0.0450\n",
      "Epoch: 363/500... Training loss: 0.0039\n",
      "Epoch: 363/500... Training loss: 0.0368\n",
      "Epoch: 363/500... Training loss: 0.0024\n",
      "Epoch: 363/500... Training loss: 0.0022\n",
      "Epoch: 363/500... Training loss: 0.1102\n",
      "Epoch: 363/500... Training loss: 0.0016\n",
      "Epoch: 363/500... Training loss: 0.0060\n",
      "Epoch: 363/500... Training loss: 0.0018\n",
      "Epoch: 363/500... Training loss: 0.0102\n",
      "Epoch: 363/500... Training loss: 0.0040\n",
      "Epoch: 364/500... Training loss: 0.0028\n",
      "Epoch: 364/500... Training loss: 0.0017\n",
      "Epoch: 364/500... Training loss: 0.0032\n",
      "Epoch: 364/500... Training loss: 0.0076\n",
      "Epoch: 364/500... Training loss: 0.0077\n",
      "Epoch: 364/500... Training loss: 0.0023\n",
      "Epoch: 364/500... Training loss: 0.0006\n",
      "Epoch: 364/500... Training loss: 0.0579\n",
      "Epoch: 364/500... Training loss: 0.0321\n",
      "Epoch: 364/500... Training loss: 0.0014\n",
      "Epoch: 364/500... Training loss: 0.0101\n",
      "Epoch: 364/500... Training loss: 0.0080\n",
      "Epoch: 364/500... Training loss: 0.0101\n",
      "Epoch: 364/500... Training loss: 0.0052\n",
      "Epoch: 364/500... Training loss: 0.0127\n",
      "Epoch: 364/500... Training loss: 0.0039\n",
      "Epoch: 364/500... Training loss: 0.0077\n",
      "Epoch: 364/500... Training loss: 0.0017\n",
      "Epoch: 364/500... Training loss: 0.0337\n",
      "Epoch: 364/500... Training loss: 0.0164\n",
      "Epoch: 364/500... Training loss: 0.0019\n",
      "Epoch: 364/500... Training loss: 0.0125\n",
      "Epoch: 364/500... Training loss: 0.0345\n",
      "Epoch: 364/500... Training loss: 0.0637\n",
      "Epoch: 364/500... Training loss: 0.0027\n",
      "Epoch: 364/500... Training loss: 0.0075\n",
      "Epoch: 364/500... Training loss: 0.0066\n",
      "Epoch: 364/500... Training loss: 0.0035\n",
      "Epoch: 364/500... Training loss: 0.0045\n",
      "Epoch: 364/500... Training loss: 0.0201\n",
      "Epoch: 364/500... Training loss: 0.0176\n",
      "Epoch: 365/500... Training loss: 0.0367\n",
      "Epoch: 365/500... Training loss: 0.0029\n",
      "Epoch: 365/500... Training loss: 0.0631\n",
      "Epoch: 365/500... Training loss: 0.0026\n",
      "Epoch: 365/500... Training loss: 0.0089\n",
      "Epoch: 365/500... Training loss: 0.0246\n",
      "Epoch: 365/500... Training loss: 0.0018\n",
      "Epoch: 365/500... Training loss: 0.0140\n",
      "Epoch: 365/500... Training loss: 0.0022\n",
      "Epoch: 365/500... Training loss: 0.0010\n",
      "Epoch: 365/500... Training loss: 0.0108\n",
      "Epoch: 365/500... Training loss: 0.0022\n",
      "Epoch: 365/500... Training loss: 0.0216\n",
      "Epoch: 365/500... Training loss: 0.0119\n",
      "Epoch: 365/500... Training loss: 0.0044\n",
      "Epoch: 365/500... Training loss: 0.0015\n",
      "Epoch: 365/500... Training loss: 0.0645\n",
      "Epoch: 365/500... Training loss: 0.0042\n",
      "Epoch: 365/500... Training loss: 0.0082\n",
      "Epoch: 365/500... Training loss: 0.0008\n",
      "Epoch: 365/500... Training loss: 0.0123\n",
      "Epoch: 365/500... Training loss: 0.0022\n",
      "Epoch: 365/500... Training loss: 0.0568\n",
      "Epoch: 365/500... Training loss: 0.0099\n",
      "Epoch: 365/500... Training loss: 0.0241\n",
      "Epoch: 365/500... Training loss: 0.0025\n",
      "Epoch: 365/500... Training loss: 0.0023\n",
      "Epoch: 365/500... Training loss: 0.0023\n",
      "Epoch: 365/500... Training loss: 0.0154\n",
      "Epoch: 365/500... Training loss: 0.0019\n",
      "Epoch: 365/500... Training loss: 0.0095\n",
      "Epoch: 366/500... Training loss: 0.0100\n",
      "Epoch: 366/500... Training loss: 0.0050\n",
      "Epoch: 366/500... Training loss: 0.0019\n",
      "Epoch: 366/500... Training loss: 0.0039\n",
      "Epoch: 366/500... Training loss: 0.0159\n",
      "Epoch: 366/500... Training loss: 0.0486\n",
      "Epoch: 366/500... Training loss: 0.0142\n",
      "Epoch: 366/500... Training loss: 0.0039\n",
      "Epoch: 366/500... Training loss: 0.0067\n",
      "Epoch: 366/500... Training loss: 0.0048\n",
      "Epoch: 366/500... Training loss: 0.0117\n",
      "Epoch: 366/500... Training loss: 0.0142\n",
      "Epoch: 366/500... Training loss: 0.0243\n",
      "Epoch: 366/500... Training loss: 0.0290\n",
      "Epoch: 366/500... Training loss: 0.0068\n",
      "Epoch: 366/500... Training loss: 0.0884\n",
      "Epoch: 366/500... Training loss: 0.0127\n",
      "Epoch: 366/500... Training loss: 0.0013\n",
      "Epoch: 366/500... Training loss: 0.0011\n",
      "Epoch: 366/500... Training loss: 0.0008\n",
      "Epoch: 366/500... Training loss: 0.0027\n",
      "Epoch: 366/500... Training loss: 0.0012\n",
      "Epoch: 366/500... Training loss: 0.0451\n",
      "Epoch: 366/500... Training loss: 0.0019\n",
      "Epoch: 366/500... Training loss: 0.0259\n",
      "Epoch: 366/500... Training loss: 0.0360\n",
      "Epoch: 366/500... Training loss: 0.0008\n",
      "Epoch: 366/500... Training loss: 0.0011\n",
      "Epoch: 366/500... Training loss: 0.0035\n",
      "Epoch: 366/500... Training loss: 0.0013\n",
      "Epoch: 366/500... Training loss: 0.0065\n",
      "Epoch: 367/500... Training loss: 0.0164\n",
      "Epoch: 367/500... Training loss: 0.0312\n",
      "Epoch: 367/500... Training loss: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 367/500... Training loss: 0.0033\n",
      "Epoch: 367/500... Training loss: 0.0020\n",
      "Epoch: 367/500... Training loss: 0.0146\n",
      "Epoch: 367/500... Training loss: 0.0017\n",
      "Epoch: 367/500... Training loss: 0.0278\n",
      "Epoch: 367/500... Training loss: 0.0041\n",
      "Epoch: 367/500... Training loss: 0.0014\n",
      "Epoch: 367/500... Training loss: 0.0625\n",
      "Epoch: 367/500... Training loss: 0.0047\n",
      "Epoch: 367/500... Training loss: 0.0459\n",
      "Epoch: 367/500... Training loss: 0.0081\n",
      "Epoch: 367/500... Training loss: 0.0154\n",
      "Epoch: 367/500... Training loss: 0.0145\n",
      "Epoch: 367/500... Training loss: 0.0084\n",
      "Epoch: 367/500... Training loss: 0.0026\n",
      "Epoch: 367/500... Training loss: 0.0269\n",
      "Epoch: 367/500... Training loss: 0.0027\n",
      "Epoch: 367/500... Training loss: 0.0253\n",
      "Epoch: 367/500... Training loss: 0.0040\n",
      "Epoch: 367/500... Training loss: 0.0774\n",
      "Epoch: 367/500... Training loss: 0.0086\n",
      "Epoch: 367/500... Training loss: 0.0225\n",
      "Epoch: 367/500... Training loss: 0.0233\n",
      "Epoch: 367/500... Training loss: 0.0219\n",
      "Epoch: 367/500... Training loss: 0.0095\n",
      "Epoch: 367/500... Training loss: 0.0352\n",
      "Epoch: 367/500... Training loss: 0.0032\n",
      "Epoch: 367/500... Training loss: 0.0025\n",
      "Epoch: 368/500... Training loss: 0.0486\n",
      "Epoch: 368/500... Training loss: 0.0543\n",
      "Epoch: 368/500... Training loss: 0.0106\n",
      "Epoch: 368/500... Training loss: 0.0354\n",
      "Epoch: 368/500... Training loss: 0.0018\n",
      "Epoch: 368/500... Training loss: 0.0319\n",
      "Epoch: 368/500... Training loss: 0.0030\n",
      "Epoch: 368/500... Training loss: 0.0071\n",
      "Epoch: 368/500... Training loss: 0.0012\n",
      "Epoch: 368/500... Training loss: 0.0665\n",
      "Epoch: 368/500... Training loss: 0.1632\n",
      "Epoch: 368/500... Training loss: 0.0047\n",
      "Epoch: 368/500... Training loss: 0.0170\n",
      "Epoch: 368/500... Training loss: 0.0303\n",
      "Epoch: 368/500... Training loss: 0.0108\n",
      "Epoch: 368/500... Training loss: 0.0126\n",
      "Epoch: 368/500... Training loss: 0.0987\n",
      "Epoch: 368/500... Training loss: 0.0080\n",
      "Epoch: 368/500... Training loss: 0.0073\n",
      "Epoch: 368/500... Training loss: 0.0025\n",
      "Epoch: 368/500... Training loss: 0.0049\n",
      "Epoch: 368/500... Training loss: 0.0046\n",
      "Epoch: 368/500... Training loss: 0.0074\n",
      "Epoch: 368/500... Training loss: 0.0617\n",
      "Epoch: 368/500... Training loss: 0.0075\n",
      "Epoch: 368/500... Training loss: 0.0704\n",
      "Epoch: 368/500... Training loss: 0.0107\n",
      "Epoch: 368/500... Training loss: 0.0282\n",
      "Epoch: 368/500... Training loss: 0.0548\n",
      "Epoch: 368/500... Training loss: 0.0039\n",
      "Epoch: 368/500... Training loss: 0.0048\n",
      "Epoch: 369/500... Training loss: 0.0177\n",
      "Epoch: 369/500... Training loss: 0.0024\n",
      "Epoch: 369/500... Training loss: 0.0148\n",
      "Epoch: 369/500... Training loss: 0.0199\n",
      "Epoch: 369/500... Training loss: 0.0017\n",
      "Epoch: 369/500... Training loss: 0.0018\n",
      "Epoch: 369/500... Training loss: 0.0017\n",
      "Epoch: 369/500... Training loss: 0.0622\n",
      "Epoch: 369/500... Training loss: 0.0033\n",
      "Epoch: 369/500... Training loss: 0.0081\n",
      "Epoch: 369/500... Training loss: 0.0932\n",
      "Epoch: 369/500... Training loss: 0.0054\n",
      "Epoch: 369/500... Training loss: 0.0128\n",
      "Epoch: 369/500... Training loss: 0.0017\n",
      "Epoch: 369/500... Training loss: 0.0185\n",
      "Epoch: 369/500... Training loss: 0.0997\n",
      "Epoch: 369/500... Training loss: 0.0034\n",
      "Epoch: 369/500... Training loss: 0.0025\n",
      "Epoch: 369/500... Training loss: 0.0213\n",
      "Epoch: 369/500... Training loss: 0.0237\n",
      "Epoch: 369/500... Training loss: 0.0008\n",
      "Epoch: 369/500... Training loss: 0.0222\n",
      "Epoch: 369/500... Training loss: 0.0183\n",
      "Epoch: 369/500... Training loss: 0.0193\n",
      "Epoch: 369/500... Training loss: 0.0037\n",
      "Epoch: 369/500... Training loss: 0.0260\n",
      "Epoch: 369/500... Training loss: 0.0012\n",
      "Epoch: 369/500... Training loss: 0.0199\n",
      "Epoch: 369/500... Training loss: 0.0233\n",
      "Epoch: 369/500... Training loss: 0.0060\n",
      "Epoch: 369/500... Training loss: 0.0078\n",
      "Epoch: 370/500... Training loss: 0.0026\n",
      "Epoch: 370/500... Training loss: 0.0549\n",
      "Epoch: 370/500... Training loss: 0.0065\n",
      "Epoch: 370/500... Training loss: 0.0096\n",
      "Epoch: 370/500... Training loss: 0.0464\n",
      "Epoch: 370/500... Training loss: 0.0312\n",
      "Epoch: 370/500... Training loss: 0.0521\n",
      "Epoch: 370/500... Training loss: 0.0013\n",
      "Epoch: 370/500... Training loss: 0.0033\n",
      "Epoch: 370/500... Training loss: 0.0109\n",
      "Epoch: 370/500... Training loss: 0.0734\n",
      "Epoch: 370/500... Training loss: 0.0224\n",
      "Epoch: 370/500... Training loss: 0.0029\n",
      "Epoch: 370/500... Training loss: 0.0279\n",
      "Epoch: 370/500... Training loss: 0.0650\n",
      "Epoch: 370/500... Training loss: 0.0020\n",
      "Epoch: 370/500... Training loss: 0.0078\n",
      "Epoch: 370/500... Training loss: 0.0227\n",
      "Epoch: 370/500... Training loss: 0.0076\n",
      "Epoch: 370/500... Training loss: 0.0180\n",
      "Epoch: 370/500... Training loss: 0.0149\n",
      "Epoch: 370/500... Training loss: 0.0298\n",
      "Epoch: 370/500... Training loss: 0.0282\n",
      "Epoch: 370/500... Training loss: 0.0266\n",
      "Epoch: 370/500... Training loss: 0.0060\n",
      "Epoch: 370/500... Training loss: 0.0008\n",
      "Epoch: 370/500... Training loss: 0.0659\n",
      "Epoch: 370/500... Training loss: 0.0020\n",
      "Epoch: 370/500... Training loss: 0.1564\n",
      "Epoch: 370/500... Training loss: 0.0158\n",
      "Epoch: 370/500... Training loss: 0.0019\n",
      "Epoch: 371/500... Training loss: 0.0032\n",
      "Epoch: 371/500... Training loss: 0.0094\n",
      "Epoch: 371/500... Training loss: 0.0034\n",
      "Epoch: 371/500... Training loss: 0.0060\n",
      "Epoch: 371/500... Training loss: 0.0008\n",
      "Epoch: 371/500... Training loss: 0.0267\n",
      "Epoch: 371/500... Training loss: 0.0034\n",
      "Epoch: 371/500... Training loss: 0.0031\n",
      "Epoch: 371/500... Training loss: 0.0023\n",
      "Epoch: 371/500... Training loss: 0.0087\n",
      "Epoch: 371/500... Training loss: 0.0125\n",
      "Epoch: 371/500... Training loss: 0.0093\n",
      "Epoch: 371/500... Training loss: 0.0029\n",
      "Epoch: 371/500... Training loss: 0.0945\n",
      "Epoch: 371/500... Training loss: 0.0029\n",
      "Epoch: 371/500... Training loss: 0.0069\n",
      "Epoch: 371/500... Training loss: 0.0238\n",
      "Epoch: 371/500... Training loss: 0.0024\n",
      "Epoch: 371/500... Training loss: 0.0010\n",
      "Epoch: 371/500... Training loss: 0.0025\n",
      "Epoch: 371/500... Training loss: 0.0057\n",
      "Epoch: 371/500... Training loss: 0.0041\n",
      "Epoch: 371/500... Training loss: 0.0970\n",
      "Epoch: 371/500... Training loss: 0.0052\n",
      "Epoch: 371/500... Training loss: 0.0248\n",
      "Epoch: 371/500... Training loss: 0.0997\n",
      "Epoch: 371/500... Training loss: 0.0471\n",
      "Epoch: 371/500... Training loss: 0.0929\n",
      "Epoch: 371/500... Training loss: 0.0012\n",
      "Epoch: 371/500... Training loss: 0.0106\n",
      "Epoch: 371/500... Training loss: 0.0301\n",
      "Epoch: 372/500... Training loss: 0.0032\n",
      "Epoch: 372/500... Training loss: 0.0950\n",
      "Epoch: 372/500... Training loss: 0.0107\n",
      "Epoch: 372/500... Training loss: 0.0169\n",
      "Epoch: 372/500... Training loss: 0.0034\n",
      "Epoch: 372/500... Training loss: 0.0030\n",
      "Epoch: 372/500... Training loss: 0.0026\n",
      "Epoch: 372/500... Training loss: 0.0607\n",
      "Epoch: 372/500... Training loss: 0.0032\n",
      "Epoch: 372/500... Training loss: 0.0116\n",
      "Epoch: 372/500... Training loss: 0.0096\n",
      "Epoch: 372/500... Training loss: 0.0008\n",
      "Epoch: 372/500... Training loss: 0.0043\n",
      "Epoch: 372/500... Training loss: 0.0012\n",
      "Epoch: 372/500... Training loss: 0.0108\n",
      "Epoch: 372/500... Training loss: 0.0039\n",
      "Epoch: 372/500... Training loss: 0.0031\n",
      "Epoch: 372/500... Training loss: 0.0021\n",
      "Epoch: 372/500... Training loss: 0.0278\n",
      "Epoch: 372/500... Training loss: 0.0274\n",
      "Epoch: 372/500... Training loss: 0.0047\n",
      "Epoch: 372/500... Training loss: 0.0298\n",
      "Epoch: 372/500... Training loss: 0.0237\n",
      "Epoch: 372/500... Training loss: 0.0087\n",
      "Epoch: 372/500... Training loss: 0.0038\n",
      "Epoch: 372/500... Training loss: 0.0037\n",
      "Epoch: 372/500... Training loss: 0.0034\n",
      "Epoch: 372/500... Training loss: 0.0023\n",
      "Epoch: 372/500... Training loss: 0.0027\n",
      "Epoch: 372/500... Training loss: 0.0599\n",
      "Epoch: 372/500... Training loss: 0.0040\n",
      "Epoch: 373/500... Training loss: 0.0127\n",
      "Epoch: 373/500... Training loss: 0.0170\n",
      "Epoch: 373/500... Training loss: 0.0022\n",
      "Epoch: 373/500... Training loss: 0.0015\n",
      "Epoch: 373/500... Training loss: 0.0024\n",
      "Epoch: 373/500... Training loss: 0.0667\n",
      "Epoch: 373/500... Training loss: 0.0020\n",
      "Epoch: 373/500... Training loss: 0.0028\n",
      "Epoch: 373/500... Training loss: 0.0045\n",
      "Epoch: 373/500... Training loss: 0.0454\n",
      "Epoch: 373/500... Training loss: 0.0099\n",
      "Epoch: 373/500... Training loss: 0.0092\n",
      "Epoch: 373/500... Training loss: 0.0286\n",
      "Epoch: 373/500... Training loss: 0.0086\n",
      "Epoch: 373/500... Training loss: 0.0058\n",
      "Epoch: 373/500... Training loss: 0.0417\n",
      "Epoch: 373/500... Training loss: 0.0399\n",
      "Epoch: 373/500... Training loss: 0.0027\n",
      "Epoch: 373/500... Training loss: 0.0175\n",
      "Epoch: 373/500... Training loss: 0.0015\n",
      "Epoch: 373/500... Training loss: 0.0489\n",
      "Epoch: 373/500... Training loss: 0.0014\n",
      "Epoch: 373/500... Training loss: 0.0460\n",
      "Epoch: 373/500... Training loss: 0.0073\n",
      "Epoch: 373/500... Training loss: 0.0024\n",
      "Epoch: 373/500... Training loss: 0.0045\n",
      "Epoch: 373/500... Training loss: 0.0101\n",
      "Epoch: 373/500... Training loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 373/500... Training loss: 0.0060\n",
      "Epoch: 373/500... Training loss: 0.0399\n",
      "Epoch: 373/500... Training loss: 0.0022\n",
      "Epoch: 374/500... Training loss: 0.0019\n",
      "Epoch: 374/500... Training loss: 0.0021\n",
      "Epoch: 374/500... Training loss: 0.0042\n",
      "Epoch: 374/500... Training loss: 0.0070\n",
      "Epoch: 374/500... Training loss: 0.0644\n",
      "Epoch: 374/500... Training loss: 0.0038\n",
      "Epoch: 374/500... Training loss: 0.0115\n",
      "Epoch: 374/500... Training loss: 0.0190\n",
      "Epoch: 374/500... Training loss: 0.0149\n",
      "Epoch: 374/500... Training loss: 0.0181\n",
      "Epoch: 374/500... Training loss: 0.0277\n",
      "Epoch: 374/500... Training loss: 0.0183\n",
      "Epoch: 374/500... Training loss: 0.1243\n",
      "Epoch: 374/500... Training loss: 0.0043\n",
      "Epoch: 374/500... Training loss: 0.0109\n",
      "Epoch: 374/500... Training loss: 0.0043\n",
      "Epoch: 374/500... Training loss: 0.0046\n",
      "Epoch: 374/500... Training loss: 0.0227\n",
      "Epoch: 374/500... Training loss: 0.0058\n",
      "Epoch: 374/500... Training loss: 0.0316\n",
      "Epoch: 374/500... Training loss: 0.0033\n",
      "Epoch: 374/500... Training loss: 0.0011\n",
      "Epoch: 374/500... Training loss: 0.0201\n",
      "Epoch: 374/500... Training loss: 0.0534\n",
      "Epoch: 374/500... Training loss: 0.0056\n",
      "Epoch: 374/500... Training loss: 0.0629\n",
      "Epoch: 374/500... Training loss: 0.0034\n",
      "Epoch: 374/500... Training loss: 0.0028\n",
      "Epoch: 374/500... Training loss: 0.0063\n",
      "Epoch: 374/500... Training loss: 0.0370\n",
      "Epoch: 374/500... Training loss: 0.0015\n",
      "Epoch: 375/500... Training loss: 0.0047\n",
      "Epoch: 375/500... Training loss: 0.0063\n",
      "Epoch: 375/500... Training loss: 0.0046\n",
      "Epoch: 375/500... Training loss: 0.0144\n",
      "Epoch: 375/500... Training loss: 0.0032\n",
      "Epoch: 375/500... Training loss: 0.0478\n",
      "Epoch: 375/500... Training loss: 0.0463\n",
      "Epoch: 375/500... Training loss: 0.0032\n",
      "Epoch: 375/500... Training loss: 0.0057\n",
      "Epoch: 375/500... Training loss: 0.0021\n",
      "Epoch: 375/500... Training loss: 0.0050\n",
      "Epoch: 375/500... Training loss: 0.0038\n",
      "Epoch: 375/500... Training loss: 0.0767\n",
      "Epoch: 375/500... Training loss: 0.1391\n",
      "Epoch: 375/500... Training loss: 0.1385\n",
      "Epoch: 375/500... Training loss: 0.0016\n",
      "Epoch: 375/500... Training loss: 0.0008\n",
      "Epoch: 375/500... Training loss: 0.0085\n",
      "Epoch: 375/500... Training loss: 0.0013\n",
      "Epoch: 375/500... Training loss: 0.0027\n",
      "Epoch: 375/500... Training loss: 0.0081\n",
      "Epoch: 375/500... Training loss: 0.0092\n",
      "Epoch: 375/500... Training loss: 0.0013\n",
      "Epoch: 375/500... Training loss: 0.0004\n",
      "Epoch: 375/500... Training loss: 0.0181\n",
      "Epoch: 375/500... Training loss: 0.0011\n",
      "Epoch: 375/500... Training loss: 0.0130\n",
      "Epoch: 375/500... Training loss: 0.0057\n",
      "Epoch: 375/500... Training loss: 0.0042\n",
      "Epoch: 375/500... Training loss: 0.0459\n",
      "Epoch: 375/500... Training loss: 0.0172\n",
      "Epoch: 376/500... Training loss: 0.0037\n",
      "Epoch: 376/500... Training loss: 0.0104\n",
      "Epoch: 376/500... Training loss: 0.0037\n",
      "Epoch: 376/500... Training loss: 0.0188\n",
      "Epoch: 376/500... Training loss: 0.0030\n",
      "Epoch: 376/500... Training loss: 0.0013\n",
      "Epoch: 376/500... Training loss: 0.0105\n",
      "Epoch: 376/500... Training loss: 0.0104\n",
      "Epoch: 376/500... Training loss: 0.0098\n",
      "Epoch: 376/500... Training loss: 0.0192\n",
      "Epoch: 376/500... Training loss: 0.0061\n",
      "Epoch: 376/500... Training loss: 0.0103\n",
      "Epoch: 376/500... Training loss: 0.0217\n",
      "Epoch: 376/500... Training loss: 0.0225\n",
      "Epoch: 376/500... Training loss: 0.0009\n",
      "Epoch: 376/500... Training loss: 0.0033\n",
      "Epoch: 376/500... Training loss: 0.0073\n",
      "Epoch: 376/500... Training loss: 0.0033\n",
      "Epoch: 376/500... Training loss: 0.0781\n",
      "Epoch: 376/500... Training loss: 0.0021\n",
      "Epoch: 376/500... Training loss: 0.0110\n",
      "Epoch: 376/500... Training loss: 0.0468\n",
      "Epoch: 376/500... Training loss: 0.0031\n",
      "Epoch: 376/500... Training loss: 0.0052\n",
      "Epoch: 376/500... Training loss: 0.0708\n",
      "Epoch: 376/500... Training loss: 0.0029\n",
      "Epoch: 376/500... Training loss: 0.0134\n",
      "Epoch: 376/500... Training loss: 0.0062\n",
      "Epoch: 376/500... Training loss: 0.0647\n",
      "Epoch: 376/500... Training loss: 0.0564\n",
      "Epoch: 376/500... Training loss: 0.0336\n",
      "Epoch: 377/500... Training loss: 0.0024\n",
      "Epoch: 377/500... Training loss: 0.0366\n",
      "Epoch: 377/500... Training loss: 0.0028\n",
      "Epoch: 377/500... Training loss: 0.1286\n",
      "Epoch: 377/500... Training loss: 0.0024\n",
      "Epoch: 377/500... Training loss: 0.0060\n",
      "Epoch: 377/500... Training loss: 0.0078\n",
      "Epoch: 377/500... Training loss: 0.0271\n",
      "Epoch: 377/500... Training loss: 0.0090\n",
      "Epoch: 377/500... Training loss: 0.0037\n",
      "Epoch: 377/500... Training loss: 0.0022\n",
      "Epoch: 377/500... Training loss: 0.0371\n",
      "Epoch: 377/500... Training loss: 0.0111\n",
      "Epoch: 377/500... Training loss: 0.0621\n",
      "Epoch: 377/500... Training loss: 0.0030\n",
      "Epoch: 377/500... Training loss: 0.0206\n",
      "Epoch: 377/500... Training loss: 0.0044\n",
      "Epoch: 377/500... Training loss: 0.0013\n",
      "Epoch: 377/500... Training loss: 0.0024\n",
      "Epoch: 377/500... Training loss: 0.0052\n",
      "Epoch: 377/500... Training loss: 0.0099\n",
      "Epoch: 377/500... Training loss: 0.0318\n",
      "Epoch: 377/500... Training loss: 0.0503\n",
      "Epoch: 377/500... Training loss: 0.0046\n",
      "Epoch: 377/500... Training loss: 0.0056\n",
      "Epoch: 377/500... Training loss: 0.0065\n",
      "Epoch: 377/500... Training loss: 0.1078\n",
      "Epoch: 377/500... Training loss: 0.0017\n",
      "Epoch: 377/500... Training loss: 0.0405\n",
      "Epoch: 377/500... Training loss: 0.0104\n",
      "Epoch: 377/500... Training loss: 0.0067\n",
      "Epoch: 378/500... Training loss: 0.0020\n",
      "Epoch: 378/500... Training loss: 0.0024\n",
      "Epoch: 378/500... Training loss: 0.0029\n",
      "Epoch: 378/500... Training loss: 0.0075\n",
      "Epoch: 378/500... Training loss: 0.0056\n",
      "Epoch: 378/500... Training loss: 0.0075\n",
      "Epoch: 378/500... Training loss: 0.0050\n",
      "Epoch: 378/500... Training loss: 0.0010\n",
      "Epoch: 378/500... Training loss: 0.0027\n",
      "Epoch: 378/500... Training loss: 0.0012\n",
      "Epoch: 378/500... Training loss: 0.0040\n",
      "Epoch: 378/500... Training loss: 0.0328\n",
      "Epoch: 378/500... Training loss: 0.0027\n",
      "Epoch: 378/500... Training loss: 0.0026\n",
      "Epoch: 378/500... Training loss: 0.0029\n",
      "Epoch: 378/500... Training loss: 0.0067\n",
      "Epoch: 378/500... Training loss: 0.0025\n",
      "Epoch: 378/500... Training loss: 0.0326\n",
      "Epoch: 378/500... Training loss: 0.0049\n",
      "Epoch: 378/500... Training loss: 0.0029\n",
      "Epoch: 378/500... Training loss: 0.0028\n",
      "Epoch: 378/500... Training loss: 0.0064\n",
      "Epoch: 378/500... Training loss: 0.0606\n",
      "Epoch: 378/500... Training loss: 0.0047\n",
      "Epoch: 378/500... Training loss: 0.0114\n",
      "Epoch: 378/500... Training loss: 0.0086\n",
      "Epoch: 378/500... Training loss: 0.0039\n",
      "Epoch: 378/500... Training loss: 0.0033\n",
      "Epoch: 378/500... Training loss: 0.0316\n",
      "Epoch: 378/500... Training loss: 0.0147\n",
      "Epoch: 378/500... Training loss: 0.0015\n",
      "Epoch: 379/500... Training loss: 0.0057\n",
      "Epoch: 379/500... Training loss: 0.0016\n",
      "Epoch: 379/500... Training loss: 0.0032\n",
      "Epoch: 379/500... Training loss: 0.0053\n",
      "Epoch: 379/500... Training loss: 0.0047\n",
      "Epoch: 379/500... Training loss: 0.0060\n",
      "Epoch: 379/500... Training loss: 0.0239\n",
      "Epoch: 379/500... Training loss: 0.0026\n",
      "Epoch: 379/500... Training loss: 0.0612\n",
      "Epoch: 379/500... Training loss: 0.0024\n",
      "Epoch: 379/500... Training loss: 0.0029\n",
      "Epoch: 379/500... Training loss: 0.0013\n",
      "Epoch: 379/500... Training loss: 0.0101\n",
      "Epoch: 379/500... Training loss: 0.0045\n",
      "Epoch: 379/500... Training loss: 0.0292\n",
      "Epoch: 379/500... Training loss: 0.0229\n",
      "Epoch: 379/500... Training loss: 0.0668\n",
      "Epoch: 379/500... Training loss: 0.0104\n",
      "Epoch: 379/500... Training loss: 0.0090\n",
      "Epoch: 379/500... Training loss: 0.0044\n",
      "Epoch: 379/500... Training loss: 0.0058\n",
      "Epoch: 379/500... Training loss: 0.0334\n",
      "Epoch: 379/500... Training loss: 0.0011\n",
      "Epoch: 379/500... Training loss: 0.0087\n",
      "Epoch: 379/500... Training loss: 0.0008\n",
      "Epoch: 379/500... Training loss: 0.0012\n",
      "Epoch: 379/500... Training loss: 0.0049\n",
      "Epoch: 379/500... Training loss: 0.0146\n",
      "Epoch: 379/500... Training loss: 0.0008\n",
      "Epoch: 379/500... Training loss: 0.0437\n",
      "Epoch: 379/500... Training loss: 0.0056\n",
      "Epoch: 380/500... Training loss: 0.0175\n",
      "Epoch: 380/500... Training loss: 0.0578\n",
      "Epoch: 380/500... Training loss: 0.0062\n",
      "Epoch: 380/500... Training loss: 0.0102\n",
      "Epoch: 380/500... Training loss: 0.0123\n",
      "Epoch: 380/500... Training loss: 0.0312\n",
      "Epoch: 380/500... Training loss: 0.0017\n",
      "Epoch: 380/500... Training loss: 0.0219\n",
      "Epoch: 380/500... Training loss: 0.0037\n",
      "Epoch: 380/500... Training loss: 0.0394\n",
      "Epoch: 380/500... Training loss: 0.0111\n",
      "Epoch: 380/500... Training loss: 0.0103\n",
      "Epoch: 380/500... Training loss: 0.0039\n",
      "Epoch: 380/500... Training loss: 0.0020\n",
      "Epoch: 380/500... Training loss: 0.0023\n",
      "Epoch: 380/500... Training loss: 0.0027\n",
      "Epoch: 380/500... Training loss: 0.0004\n",
      "Epoch: 380/500... Training loss: 0.0085\n",
      "Epoch: 380/500... Training loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380/500... Training loss: 0.0051\n",
      "Epoch: 380/500... Training loss: 0.0228\n",
      "Epoch: 380/500... Training loss: 0.0009\n",
      "Epoch: 380/500... Training loss: 0.0018\n",
      "Epoch: 380/500... Training loss: 0.0091\n",
      "Epoch: 380/500... Training loss: 0.0460\n",
      "Epoch: 380/500... Training loss: 0.0013\n",
      "Epoch: 380/500... Training loss: 0.0020\n",
      "Epoch: 380/500... Training loss: 0.0021\n",
      "Epoch: 380/500... Training loss: 0.0151\n",
      "Epoch: 380/500... Training loss: 0.0712\n",
      "Epoch: 380/500... Training loss: 0.0071\n",
      "Epoch: 381/500... Training loss: 0.0027\n",
      "Epoch: 381/500... Training loss: 0.0137\n",
      "Epoch: 381/500... Training loss: 0.0049\n",
      "Epoch: 381/500... Training loss: 0.0030\n",
      "Epoch: 381/500... Training loss: 0.0111\n",
      "Epoch: 381/500... Training loss: 0.0064\n",
      "Epoch: 381/500... Training loss: 0.0284\n",
      "Epoch: 381/500... Training loss: 0.0195\n",
      "Epoch: 381/500... Training loss: 0.0043\n",
      "Epoch: 381/500... Training loss: 0.0018\n",
      "Epoch: 381/500... Training loss: 0.0012\n",
      "Epoch: 381/500... Training loss: 0.0013\n",
      "Epoch: 381/500... Training loss: 0.0087\n",
      "Epoch: 381/500... Training loss: 0.0084\n",
      "Epoch: 381/500... Training loss: 0.0455\n",
      "Epoch: 381/500... Training loss: 0.0026\n",
      "Epoch: 381/500... Training loss: 0.0066\n",
      "Epoch: 381/500... Training loss: 0.0258\n",
      "Epoch: 381/500... Training loss: 0.0686\n",
      "Epoch: 381/500... Training loss: 0.0345\n",
      "Epoch: 381/500... Training loss: 0.0012\n",
      "Epoch: 381/500... Training loss: 0.0293\n",
      "Epoch: 381/500... Training loss: 0.0192\n",
      "Epoch: 381/500... Training loss: 0.0046\n",
      "Epoch: 381/500... Training loss: 0.0050\n",
      "Epoch: 381/500... Training loss: 0.0056\n",
      "Epoch: 381/500... Training loss: 0.0018\n",
      "Epoch: 381/500... Training loss: 0.0006\n",
      "Epoch: 381/500... Training loss: 0.0017\n",
      "Epoch: 381/500... Training loss: 0.0011\n",
      "Epoch: 381/500... Training loss: 0.0128\n",
      "Epoch: 382/500... Training loss: 0.0023\n",
      "Epoch: 382/500... Training loss: 0.0192\n",
      "Epoch: 382/500... Training loss: 0.0089\n",
      "Epoch: 382/500... Training loss: 0.0430\n",
      "Epoch: 382/500... Training loss: 0.0377\n",
      "Epoch: 382/500... Training loss: 0.0238\n",
      "Epoch: 382/500... Training loss: 0.0138\n",
      "Epoch: 382/500... Training loss: 0.0119\n",
      "Epoch: 382/500... Training loss: 0.0034\n",
      "Epoch: 382/500... Training loss: 0.0293\n",
      "Epoch: 382/500... Training loss: 0.0026\n",
      "Epoch: 382/500... Training loss: 0.0069\n",
      "Epoch: 382/500... Training loss: 0.2208\n",
      "Epoch: 382/500... Training loss: 0.0032\n",
      "Epoch: 382/500... Training loss: 0.0294\n",
      "Epoch: 382/500... Training loss: 0.0008\n",
      "Epoch: 382/500... Training loss: 0.0135\n",
      "Epoch: 382/500... Training loss: 0.0098\n",
      "Epoch: 382/500... Training loss: 0.0177\n",
      "Epoch: 382/500... Training loss: 0.1022\n",
      "Epoch: 382/500... Training loss: 0.0280\n",
      "Epoch: 382/500... Training loss: 0.0564\n",
      "Epoch: 382/500... Training loss: 0.0359\n",
      "Epoch: 382/500... Training loss: 0.0225\n",
      "Epoch: 382/500... Training loss: 0.0027\n",
      "Epoch: 382/500... Training loss: 0.0026\n",
      "Epoch: 382/500... Training loss: 0.0014\n",
      "Epoch: 382/500... Training loss: 0.0019\n",
      "Epoch: 382/500... Training loss: 0.0018\n",
      "Epoch: 382/500... Training loss: 0.0235\n",
      "Epoch: 382/500... Training loss: 0.0403\n",
      "Epoch: 383/500... Training loss: 0.0055\n",
      "Epoch: 383/500... Training loss: 0.0164\n",
      "Epoch: 383/500... Training loss: 0.0044\n",
      "Epoch: 383/500... Training loss: 0.0194\n",
      "Epoch: 383/500... Training loss: 0.0103\n",
      "Epoch: 383/500... Training loss: 0.0037\n",
      "Epoch: 383/500... Training loss: 0.0060\n",
      "Epoch: 383/500... Training loss: 0.0098\n",
      "Epoch: 383/500... Training loss: 0.0024\n",
      "Epoch: 383/500... Training loss: 0.0022\n",
      "Epoch: 383/500... Training loss: 0.0133\n",
      "Epoch: 383/500... Training loss: 0.0126\n",
      "Epoch: 383/500... Training loss: 0.0212\n",
      "Epoch: 383/500... Training loss: 0.0373\n",
      "Epoch: 383/500... Training loss: 0.0068\n",
      "Epoch: 383/500... Training loss: 0.0094\n",
      "Epoch: 383/500... Training loss: 0.0077\n",
      "Epoch: 383/500... Training loss: 0.0029\n",
      "Epoch: 383/500... Training loss: 0.0183\n",
      "Epoch: 383/500... Training loss: 0.0099\n",
      "Epoch: 383/500... Training loss: 0.0007\n",
      "Epoch: 383/500... Training loss: 0.0133\n",
      "Epoch: 383/500... Training loss: 0.0525\n",
      "Epoch: 383/500... Training loss: 0.0166\n",
      "Epoch: 383/500... Training loss: 0.0022\n",
      "Epoch: 383/500... Training loss: 0.0020\n",
      "Epoch: 383/500... Training loss: 0.0036\n",
      "Epoch: 383/500... Training loss: 0.0009\n",
      "Epoch: 383/500... Training loss: 0.0112\n",
      "Epoch: 383/500... Training loss: 0.0064\n",
      "Epoch: 383/500... Training loss: 0.0013\n",
      "Epoch: 384/500... Training loss: 0.0345\n",
      "Epoch: 384/500... Training loss: 0.0034\n",
      "Epoch: 384/500... Training loss: 0.0058\n",
      "Epoch: 384/500... Training loss: 0.1141\n",
      "Epoch: 384/500... Training loss: 0.0098\n",
      "Epoch: 384/500... Training loss: 0.0052\n",
      "Epoch: 384/500... Training loss: 0.0091\n",
      "Epoch: 384/500... Training loss: 0.0050\n",
      "Epoch: 384/500... Training loss: 0.0416\n",
      "Epoch: 384/500... Training loss: 0.0317\n",
      "Epoch: 384/500... Training loss: 0.0688\n",
      "Epoch: 384/500... Training loss: 0.0316\n",
      "Epoch: 384/500... Training loss: 0.0030\n",
      "Epoch: 384/500... Training loss: 0.0015\n",
      "Epoch: 384/500... Training loss: 0.0149\n",
      "Epoch: 384/500... Training loss: 0.0030\n",
      "Epoch: 384/500... Training loss: 0.0162\n",
      "Epoch: 384/500... Training loss: 0.0554\n",
      "Epoch: 384/500... Training loss: 0.0020\n",
      "Epoch: 384/500... Training loss: 0.0014\n",
      "Epoch: 384/500... Training loss: 0.0026\n",
      "Epoch: 384/500... Training loss: 0.0018\n",
      "Epoch: 384/500... Training loss: 0.1007\n",
      "Epoch: 384/500... Training loss: 0.0010\n",
      "Epoch: 384/500... Training loss: 0.0157\n",
      "Epoch: 384/500... Training loss: 0.0052\n",
      "Epoch: 384/500... Training loss: 0.0017\n",
      "Epoch: 384/500... Training loss: 0.0024\n",
      "Epoch: 384/500... Training loss: 0.0054\n",
      "Epoch: 384/500... Training loss: 0.0050\n",
      "Epoch: 384/500... Training loss: 0.0672\n",
      "Epoch: 385/500... Training loss: 0.0080\n",
      "Epoch: 385/500... Training loss: 0.0013\n",
      "Epoch: 385/500... Training loss: 0.0522\n",
      "Epoch: 385/500... Training loss: 0.0086\n",
      "Epoch: 385/500... Training loss: 0.0021\n",
      "Epoch: 385/500... Training loss: 0.0125\n",
      "Epoch: 385/500... Training loss: 0.0061\n",
      "Epoch: 385/500... Training loss: 0.0040\n",
      "Epoch: 385/500... Training loss: 0.0284\n",
      "Epoch: 385/500... Training loss: 0.0389\n",
      "Epoch: 385/500... Training loss: 0.0131\n",
      "Epoch: 385/500... Training loss: 0.0019\n",
      "Epoch: 385/500... Training loss: 0.0041\n",
      "Epoch: 385/500... Training loss: 0.0134\n",
      "Epoch: 385/500... Training loss: 0.0039\n",
      "Epoch: 385/500... Training loss: 0.0069\n",
      "Epoch: 385/500... Training loss: 0.0667\n",
      "Epoch: 385/500... Training loss: 0.0281\n",
      "Epoch: 385/500... Training loss: 0.0126\n",
      "Epoch: 385/500... Training loss: 0.0029\n",
      "Epoch: 385/500... Training loss: 0.0021\n",
      "Epoch: 385/500... Training loss: 0.0019\n",
      "Epoch: 385/500... Training loss: 0.0007\n",
      "Epoch: 385/500... Training loss: 0.0061\n",
      "Epoch: 385/500... Training loss: 0.1061\n",
      "Epoch: 385/500... Training loss: 0.0132\n",
      "Epoch: 385/500... Training loss: 0.0242\n",
      "Epoch: 385/500... Training loss: 0.0124\n",
      "Epoch: 385/500... Training loss: 0.0332\n",
      "Epoch: 385/500... Training loss: 0.0034\n",
      "Epoch: 385/500... Training loss: 0.0200\n",
      "Epoch: 386/500... Training loss: 0.0354\n",
      "Epoch: 386/500... Training loss: 0.0044\n",
      "Epoch: 386/500... Training loss: 0.0352\n",
      "Epoch: 386/500... Training loss: 0.0477\n",
      "Epoch: 386/500... Training loss: 0.0038\n",
      "Epoch: 386/500... Training loss: 0.0453\n",
      "Epoch: 386/500... Training loss: 0.0077\n",
      "Epoch: 386/500... Training loss: 0.0025\n",
      "Epoch: 386/500... Training loss: 0.0295\n",
      "Epoch: 386/500... Training loss: 0.0043\n",
      "Epoch: 386/500... Training loss: 0.0026\n",
      "Epoch: 386/500... Training loss: 0.0024\n",
      "Epoch: 386/500... Training loss: 0.0052\n",
      "Epoch: 386/500... Training loss: 0.0111\n",
      "Epoch: 386/500... Training loss: 0.0046\n",
      "Epoch: 386/500... Training loss: 0.0127\n",
      "Epoch: 386/500... Training loss: 0.0158\n",
      "Epoch: 386/500... Training loss: 0.0379\n",
      "Epoch: 386/500... Training loss: 0.0076\n",
      "Epoch: 386/500... Training loss: 0.0371\n",
      "Epoch: 386/500... Training loss: 0.0358\n",
      "Epoch: 386/500... Training loss: 0.0017\n",
      "Epoch: 386/500... Training loss: 0.0488\n",
      "Epoch: 386/500... Training loss: 0.0028\n",
      "Epoch: 386/500... Training loss: 0.0268\n",
      "Epoch: 386/500... Training loss: 0.0210\n",
      "Epoch: 386/500... Training loss: 0.0187\n",
      "Epoch: 386/500... Training loss: 0.0012\n",
      "Epoch: 386/500... Training loss: 0.0350\n",
      "Epoch: 386/500... Training loss: 0.0077\n",
      "Epoch: 386/500... Training loss: 0.0089\n",
      "Epoch: 387/500... Training loss: 0.1876\n",
      "Epoch: 387/500... Training loss: 0.0058\n",
      "Epoch: 387/500... Training loss: 0.0040\n",
      "Epoch: 387/500... Training loss: 0.0444\n",
      "Epoch: 387/500... Training loss: 0.0036\n",
      "Epoch: 387/500... Training loss: 0.0799\n",
      "Epoch: 387/500... Training loss: 0.0149\n",
      "Epoch: 387/500... Training loss: 0.0399\n",
      "Epoch: 387/500... Training loss: 0.0349\n",
      "Epoch: 387/500... Training loss: 0.0076\n",
      "Epoch: 387/500... Training loss: 0.0297\n",
      "Epoch: 387/500... Training loss: 0.0675\n",
      "Epoch: 387/500... Training loss: 0.0438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387/500... Training loss: 0.0036\n",
      "Epoch: 387/500... Training loss: 0.0056\n",
      "Epoch: 387/500... Training loss: 0.0026\n",
      "Epoch: 387/500... Training loss: 0.0096\n",
      "Epoch: 387/500... Training loss: 0.0021\n",
      "Epoch: 387/500... Training loss: 0.0613\n",
      "Epoch: 387/500... Training loss: 0.0051\n",
      "Epoch: 387/500... Training loss: 0.0210\n",
      "Epoch: 387/500... Training loss: 0.0028\n",
      "Epoch: 387/500... Training loss: 0.0088\n",
      "Epoch: 387/500... Training loss: 0.0015\n",
      "Epoch: 387/500... Training loss: 0.0102\n",
      "Epoch: 387/500... Training loss: 0.0022\n",
      "Epoch: 387/500... Training loss: 0.0231\n",
      "Epoch: 387/500... Training loss: 0.0060\n",
      "Epoch: 387/500... Training loss: 0.0009\n",
      "Epoch: 387/500... Training loss: 0.0041\n",
      "Epoch: 387/500... Training loss: 0.0362\n",
      "Epoch: 388/500... Training loss: 0.0403\n",
      "Epoch: 388/500... Training loss: 0.0493\n",
      "Epoch: 388/500... Training loss: 0.0246\n",
      "Epoch: 388/500... Training loss: 0.0115\n",
      "Epoch: 388/500... Training loss: 0.0021\n",
      "Epoch: 388/500... Training loss: 0.0104\n",
      "Epoch: 388/500... Training loss: 0.0055\n",
      "Epoch: 388/500... Training loss: 0.0189\n",
      "Epoch: 388/500... Training loss: 0.0935\n",
      "Epoch: 388/500... Training loss: 0.0738\n",
      "Epoch: 388/500... Training loss: 0.0985\n",
      "Epoch: 388/500... Training loss: 0.0087\n",
      "Epoch: 388/500... Training loss: 0.1143\n",
      "Epoch: 388/500... Training loss: 0.0062\n",
      "Epoch: 388/500... Training loss: 0.0144\n",
      "Epoch: 388/500... Training loss: 0.0066\n",
      "Epoch: 388/500... Training loss: 0.0191\n",
      "Epoch: 388/500... Training loss: 0.0210\n",
      "Epoch: 388/500... Training loss: 0.0869\n",
      "Epoch: 388/500... Training loss: 0.0775\n",
      "Epoch: 388/500... Training loss: 0.0154\n",
      "Epoch: 388/500... Training loss: 0.0018\n",
      "Epoch: 388/500... Training loss: 0.0455\n",
      "Epoch: 388/500... Training loss: 0.0061\n",
      "Epoch: 388/500... Training loss: 0.0111\n",
      "Epoch: 388/500... Training loss: 0.0329\n",
      "Epoch: 388/500... Training loss: 0.0070\n",
      "Epoch: 388/500... Training loss: 0.0120\n",
      "Epoch: 388/500... Training loss: 0.0030\n",
      "Epoch: 388/500... Training loss: 0.0093\n",
      "Epoch: 388/500... Training loss: 0.0367\n",
      "Epoch: 389/500... Training loss: 0.0654\n",
      "Epoch: 389/500... Training loss: 0.0178\n",
      "Epoch: 389/500... Training loss: 0.0026\n",
      "Epoch: 389/500... Training loss: 0.0149\n",
      "Epoch: 389/500... Training loss: 0.0047\n",
      "Epoch: 389/500... Training loss: 0.0327\n",
      "Epoch: 389/500... Training loss: 0.0173\n",
      "Epoch: 389/500... Training loss: 0.0521\n",
      "Epoch: 389/500... Training loss: 0.0292\n",
      "Epoch: 389/500... Training loss: 0.0013\n",
      "Epoch: 389/500... Training loss: 0.0755\n",
      "Epoch: 389/500... Training loss: 0.1755\n",
      "Epoch: 389/500... Training loss: 0.0065\n",
      "Epoch: 389/500... Training loss: 0.0078\n",
      "Epoch: 389/500... Training loss: 0.0140\n",
      "Epoch: 389/500... Training loss: 0.0083\n",
      "Epoch: 389/500... Training loss: 0.0043\n",
      "Epoch: 389/500... Training loss: 0.0055\n",
      "Epoch: 389/500... Training loss: 0.0015\n",
      "Epoch: 389/500... Training loss: 0.0448\n",
      "Epoch: 389/500... Training loss: 0.0024\n",
      "Epoch: 389/500... Training loss: 0.0530\n",
      "Epoch: 389/500... Training loss: 0.0026\n",
      "Epoch: 389/500... Training loss: 0.0020\n",
      "Epoch: 389/500... Training loss: 0.0499\n",
      "Epoch: 389/500... Training loss: 0.0025\n",
      "Epoch: 389/500... Training loss: 0.0011\n",
      "Epoch: 389/500... Training loss: 0.0023\n",
      "Epoch: 389/500... Training loss: 0.0180\n",
      "Epoch: 389/500... Training loss: 0.0709\n",
      "Epoch: 389/500... Training loss: 0.0107\n",
      "Epoch: 390/500... Training loss: 0.0038\n",
      "Epoch: 390/500... Training loss: 0.0112\n",
      "Epoch: 390/500... Training loss: 0.0031\n",
      "Epoch: 390/500... Training loss: 0.0236\n",
      "Epoch: 390/500... Training loss: 0.0073\n",
      "Epoch: 390/500... Training loss: 0.0543\n",
      "Epoch: 390/500... Training loss: 0.0019\n",
      "Epoch: 390/500... Training loss: 0.0184\n",
      "Epoch: 390/500... Training loss: 0.0112\n",
      "Epoch: 390/500... Training loss: 0.0463\n",
      "Epoch: 390/500... Training loss: 0.0040\n",
      "Epoch: 390/500... Training loss: 0.0021\n",
      "Epoch: 390/500... Training loss: 0.0022\n",
      "Epoch: 390/500... Training loss: 0.0018\n",
      "Epoch: 390/500... Training loss: 0.0051\n",
      "Epoch: 390/500... Training loss: 0.0049\n",
      "Epoch: 390/500... Training loss: 0.0071\n",
      "Epoch: 390/500... Training loss: 0.0185\n",
      "Epoch: 390/500... Training loss: 0.0062\n",
      "Epoch: 390/500... Training loss: 0.0029\n",
      "Epoch: 390/500... Training loss: 0.0024\n",
      "Epoch: 390/500... Training loss: 0.0671\n",
      "Epoch: 390/500... Training loss: 0.0020\n",
      "Epoch: 390/500... Training loss: 0.0058\n",
      "Epoch: 390/500... Training loss: 0.0037\n",
      "Epoch: 390/500... Training loss: 0.0282\n",
      "Epoch: 390/500... Training loss: 0.0009\n",
      "Epoch: 390/500... Training loss: 0.0048\n",
      "Epoch: 390/500... Training loss: 0.0052\n",
      "Epoch: 390/500... Training loss: 0.0075\n",
      "Epoch: 390/500... Training loss: 0.0072\n",
      "Epoch: 391/500... Training loss: 0.0036\n",
      "Epoch: 391/500... Training loss: 0.0073\n",
      "Epoch: 391/500... Training loss: 0.0175\n",
      "Epoch: 391/500... Training loss: 0.0151\n",
      "Epoch: 391/500... Training loss: 0.0022\n",
      "Epoch: 391/500... Training loss: 0.0219\n",
      "Epoch: 391/500... Training loss: 0.0062\n",
      "Epoch: 391/500... Training loss: 0.0103\n",
      "Epoch: 391/500... Training loss: 0.0602\n",
      "Epoch: 391/500... Training loss: 0.0015\n",
      "Epoch: 391/500... Training loss: 0.0040\n",
      "Epoch: 391/500... Training loss: 0.0075\n",
      "Epoch: 391/500... Training loss: 0.0164\n",
      "Epoch: 391/500... Training loss: 0.0034\n",
      "Epoch: 391/500... Training loss: 0.0488\n",
      "Epoch: 391/500... Training loss: 0.0023\n",
      "Epoch: 391/500... Training loss: 0.0043\n",
      "Epoch: 391/500... Training loss: 0.0509\n",
      "Epoch: 391/500... Training loss: 0.0040\n",
      "Epoch: 391/500... Training loss: 0.0171\n",
      "Epoch: 391/500... Training loss: 0.0017\n",
      "Epoch: 391/500... Training loss: 0.0081\n",
      "Epoch: 391/500... Training loss: 0.0060\n",
      "Epoch: 391/500... Training loss: 0.0048\n",
      "Epoch: 391/500... Training loss: 0.0102\n",
      "Epoch: 391/500... Training loss: 0.0031\n",
      "Epoch: 391/500... Training loss: 0.0182\n",
      "Epoch: 391/500... Training loss: 0.0115\n",
      "Epoch: 391/500... Training loss: 0.0057\n",
      "Epoch: 391/500... Training loss: 0.0013\n",
      "Epoch: 391/500... Training loss: 0.0006\n",
      "Epoch: 392/500... Training loss: 0.0064\n",
      "Epoch: 392/500... Training loss: 0.0522\n",
      "Epoch: 392/500... Training loss: 0.0080\n",
      "Epoch: 392/500... Training loss: 0.1131\n",
      "Epoch: 392/500... Training loss: 0.0371\n",
      "Epoch: 392/500... Training loss: 0.0027\n",
      "Epoch: 392/500... Training loss: 0.0041\n",
      "Epoch: 392/500... Training loss: 0.0051\n",
      "Epoch: 392/500... Training loss: 0.2007\n",
      "Epoch: 392/500... Training loss: 0.0051\n",
      "Epoch: 392/500... Training loss: 0.0119\n",
      "Epoch: 392/500... Training loss: 0.0149\n",
      "Epoch: 392/500... Training loss: 0.0075\n",
      "Epoch: 392/500... Training loss: 0.0096\n",
      "Epoch: 392/500... Training loss: 0.0081\n",
      "Epoch: 392/500... Training loss: 0.0633\n",
      "Epoch: 392/500... Training loss: 0.0011\n",
      "Epoch: 392/500... Training loss: 0.0105\n",
      "Epoch: 392/500... Training loss: 0.0016\n",
      "Epoch: 392/500... Training loss: 0.0011\n",
      "Epoch: 392/500... Training loss: 0.0109\n",
      "Epoch: 392/500... Training loss: 0.0025\n",
      "Epoch: 392/500... Training loss: 0.0116\n",
      "Epoch: 392/500... Training loss: 0.0034\n",
      "Epoch: 392/500... Training loss: 0.0016\n",
      "Epoch: 392/500... Training loss: 0.0030\n",
      "Epoch: 392/500... Training loss: 0.0136\n",
      "Epoch: 392/500... Training loss: 0.0037\n",
      "Epoch: 392/500... Training loss: 0.0078\n",
      "Epoch: 392/500... Training loss: 0.0530\n",
      "Epoch: 392/500... Training loss: 0.0057\n",
      "Epoch: 393/500... Training loss: 0.0207\n",
      "Epoch: 393/500... Training loss: 0.0069\n",
      "Epoch: 393/500... Training loss: 0.0475\n",
      "Epoch: 393/500... Training loss: 0.0051\n",
      "Epoch: 393/500... Training loss: 0.0018\n",
      "Epoch: 393/500... Training loss: 0.0058\n",
      "Epoch: 393/500... Training loss: 0.0063\n",
      "Epoch: 393/500... Training loss: 0.0238\n",
      "Epoch: 393/500... Training loss: 0.0310\n",
      "Epoch: 393/500... Training loss: 0.0019\n",
      "Epoch: 393/500... Training loss: 0.0014\n",
      "Epoch: 393/500... Training loss: 0.0084\n",
      "Epoch: 393/500... Training loss: 0.1531\n",
      "Epoch: 393/500... Training loss: 0.0357\n",
      "Epoch: 393/500... Training loss: 0.0072\n",
      "Epoch: 393/500... Training loss: 0.0071\n",
      "Epoch: 393/500... Training loss: 0.0103\n",
      "Epoch: 393/500... Training loss: 0.0063\n",
      "Epoch: 393/500... Training loss: 0.0330\n",
      "Epoch: 393/500... Training loss: 0.0027\n",
      "Epoch: 393/500... Training loss: 0.0052\n",
      "Epoch: 393/500... Training loss: 0.0009\n",
      "Epoch: 393/500... Training loss: 0.1017\n",
      "Epoch: 393/500... Training loss: 0.0096\n",
      "Epoch: 393/500... Training loss: 0.0015\n",
      "Epoch: 393/500... Training loss: 0.0054\n",
      "Epoch: 393/500... Training loss: 0.0026\n",
      "Epoch: 393/500... Training loss: 0.0484\n",
      "Epoch: 393/500... Training loss: 0.0014\n",
      "Epoch: 393/500... Training loss: 0.0025\n",
      "Epoch: 393/500... Training loss: 0.0099\n",
      "Epoch: 394/500... Training loss: 0.0042\n",
      "Epoch: 394/500... Training loss: 0.0207\n",
      "Epoch: 394/500... Training loss: 0.0037\n",
      "Epoch: 394/500... Training loss: 0.0424\n",
      "Epoch: 394/500... Training loss: 0.0169\n",
      "Epoch: 394/500... Training loss: 0.0282\n",
      "Epoch: 394/500... Training loss: 0.0026\n",
      "Epoch: 394/500... Training loss: 0.0056\n",
      "Epoch: 394/500... Training loss: 0.0304\n",
      "Epoch: 394/500... Training loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394/500... Training loss: 0.0084\n",
      "Epoch: 394/500... Training loss: 0.0105\n",
      "Epoch: 394/500... Training loss: 0.1211\n",
      "Epoch: 394/500... Training loss: 0.0492\n",
      "Epoch: 394/500... Training loss: 0.0365\n",
      "Epoch: 394/500... Training loss: 0.0284\n",
      "Epoch: 394/500... Training loss: 0.0094\n",
      "Epoch: 394/500... Training loss: 0.0026\n",
      "Epoch: 394/500... Training loss: 0.0064\n",
      "Epoch: 394/500... Training loss: 0.0183\n",
      "Epoch: 394/500... Training loss: 0.0015\n",
      "Epoch: 394/500... Training loss: 0.0476\n",
      "Epoch: 394/500... Training loss: 0.0873\n",
      "Epoch: 394/500... Training loss: 0.0022\n",
      "Epoch: 394/500... Training loss: 0.0097\n",
      "Epoch: 394/500... Training loss: 0.0139\n",
      "Epoch: 394/500... Training loss: 0.0304\n",
      "Epoch: 394/500... Training loss: 0.0055\n",
      "Epoch: 394/500... Training loss: 0.0078\n",
      "Epoch: 394/500... Training loss: 0.0215\n",
      "Epoch: 394/500... Training loss: 0.0046\n",
      "Epoch: 395/500... Training loss: 0.0129\n",
      "Epoch: 395/500... Training loss: 0.0083\n",
      "Epoch: 395/500... Training loss: 0.0031\n",
      "Epoch: 395/500... Training loss: 0.0045\n",
      "Epoch: 395/500... Training loss: 0.0419\n",
      "Epoch: 395/500... Training loss: 0.0304\n",
      "Epoch: 395/500... Training loss: 0.0606\n",
      "Epoch: 395/500... Training loss: 0.0315\n",
      "Epoch: 395/500... Training loss: 0.0537\n",
      "Epoch: 395/500... Training loss: 0.0021\n",
      "Epoch: 395/500... Training loss: 0.0342\n",
      "Epoch: 395/500... Training loss: 0.0723\n",
      "Epoch: 395/500... Training loss: 0.1526\n",
      "Epoch: 395/500... Training loss: 0.0425\n",
      "Epoch: 395/500... Training loss: 0.0027\n",
      "Epoch: 395/500... Training loss: 0.0625\n",
      "Epoch: 395/500... Training loss: 0.0029\n",
      "Epoch: 395/500... Training loss: 0.0116\n",
      "Epoch: 395/500... Training loss: 0.0097\n",
      "Epoch: 395/500... Training loss: 0.0729\n",
      "Epoch: 395/500... Training loss: 0.0072\n",
      "Epoch: 395/500... Training loss: 0.0052\n",
      "Epoch: 395/500... Training loss: 0.0979\n",
      "Epoch: 395/500... Training loss: 0.0172\n",
      "Epoch: 395/500... Training loss: 0.0514\n",
      "Epoch: 395/500... Training loss: 0.0218\n",
      "Epoch: 395/500... Training loss: 0.0010\n",
      "Epoch: 395/500... Training loss: 0.0322\n",
      "Epoch: 395/500... Training loss: 0.0126\n",
      "Epoch: 395/500... Training loss: 0.0066\n",
      "Epoch: 395/500... Training loss: 0.0013\n",
      "Epoch: 396/500... Training loss: 0.0242\n",
      "Epoch: 396/500... Training loss: 0.0235\n",
      "Epoch: 396/500... Training loss: 0.0211\n",
      "Epoch: 396/500... Training loss: 0.0289\n",
      "Epoch: 396/500... Training loss: 0.0369\n",
      "Epoch: 396/500... Training loss: 0.0225\n",
      "Epoch: 396/500... Training loss: 0.0032\n",
      "Epoch: 396/500... Training loss: 0.0452\n",
      "Epoch: 396/500... Training loss: 0.0158\n",
      "Epoch: 396/500... Training loss: 0.0037\n",
      "Epoch: 396/500... Training loss: 0.0563\n",
      "Epoch: 396/500... Training loss: 0.0032\n",
      "Epoch: 396/500... Training loss: 0.0608\n",
      "Epoch: 396/500... Training loss: 0.0078\n",
      "Epoch: 396/500... Training loss: 0.0115\n",
      "Epoch: 396/500... Training loss: 0.0210\n",
      "Epoch: 396/500... Training loss: 0.0656\n",
      "Epoch: 396/500... Training loss: 0.0097\n",
      "Epoch: 396/500... Training loss: 0.0315\n",
      "Epoch: 396/500... Training loss: 0.1186\n",
      "Epoch: 396/500... Training loss: 0.0038\n",
      "Epoch: 396/500... Training loss: 0.0024\n",
      "Epoch: 396/500... Training loss: 0.0548\n",
      "Epoch: 396/500... Training loss: 0.0063\n",
      "Epoch: 396/500... Training loss: 0.0164\n",
      "Epoch: 396/500... Training loss: 0.0123\n",
      "Epoch: 396/500... Training loss: 0.0011\n",
      "Epoch: 396/500... Training loss: 0.0134\n",
      "Epoch: 396/500... Training loss: 0.0068\n",
      "Epoch: 396/500... Training loss: 0.0109\n",
      "Epoch: 396/500... Training loss: 0.0121\n",
      "Epoch: 397/500... Training loss: 0.0101\n",
      "Epoch: 397/500... Training loss: 0.0220\n",
      "Epoch: 397/500... Training loss: 0.0072\n",
      "Epoch: 397/500... Training loss: 0.0709\n",
      "Epoch: 397/500... Training loss: 0.0437\n",
      "Epoch: 397/500... Training loss: 0.0780\n",
      "Epoch: 397/500... Training loss: 0.0157\n",
      "Epoch: 397/500... Training loss: 0.0018\n",
      "Epoch: 397/500... Training loss: 0.0562\n",
      "Epoch: 397/500... Training loss: 0.0039\n",
      "Epoch: 397/500... Training loss: 0.0509\n",
      "Epoch: 397/500... Training loss: 0.0091\n",
      "Epoch: 397/500... Training loss: 0.0038\n",
      "Epoch: 397/500... Training loss: 0.0052\n",
      "Epoch: 397/500... Training loss: 0.0034\n",
      "Epoch: 397/500... Training loss: 0.0087\n",
      "Epoch: 397/500... Training loss: 0.0019\n",
      "Epoch: 397/500... Training loss: 0.0019\n",
      "Epoch: 397/500... Training loss: 0.0023\n",
      "Epoch: 397/500... Training loss: 0.0040\n",
      "Epoch: 397/500... Training loss: 0.0020\n",
      "Epoch: 397/500... Training loss: 0.0039\n",
      "Epoch: 397/500... Training loss: 0.0395\n",
      "Epoch: 397/500... Training loss: 0.0045\n",
      "Epoch: 397/500... Training loss: 0.0113\n",
      "Epoch: 397/500... Training loss: 0.0053\n",
      "Epoch: 397/500... Training loss: 0.0021\n",
      "Epoch: 397/500... Training loss: 0.0297\n",
      "Epoch: 397/500... Training loss: 0.0014\n",
      "Epoch: 397/500... Training loss: 0.0048\n",
      "Epoch: 397/500... Training loss: 0.0048\n",
      "Epoch: 398/500... Training loss: 0.0040\n",
      "Epoch: 398/500... Training loss: 0.0027\n",
      "Epoch: 398/500... Training loss: 0.0061\n",
      "Epoch: 398/500... Training loss: 0.0088\n",
      "Epoch: 398/500... Training loss: 0.0197\n",
      "Epoch: 398/500... Training loss: 0.1061\n",
      "Epoch: 398/500... Training loss: 0.0041\n",
      "Epoch: 398/500... Training loss: 0.0162\n",
      "Epoch: 398/500... Training loss: 0.0094\n",
      "Epoch: 398/500... Training loss: 0.0090\n",
      "Epoch: 398/500... Training loss: 0.0040\n",
      "Epoch: 398/500... Training loss: 0.0214\n",
      "Epoch: 398/500... Training loss: 0.0032\n",
      "Epoch: 398/500... Training loss: 0.0054\n",
      "Epoch: 398/500... Training loss: 0.0161\n",
      "Epoch: 398/500... Training loss: 0.0044\n",
      "Epoch: 398/500... Training loss: 0.0021\n",
      "Epoch: 398/500... Training loss: 0.0053\n",
      "Epoch: 398/500... Training loss: 0.0012\n",
      "Epoch: 398/500... Training loss: 0.0184\n",
      "Epoch: 398/500... Training loss: 0.0113\n",
      "Epoch: 398/500... Training loss: 0.0026\n",
      "Epoch: 398/500... Training loss: 0.0731\n",
      "Epoch: 398/500... Training loss: 0.0022\n",
      "Epoch: 398/500... Training loss: 0.0238\n",
      "Epoch: 398/500... Training loss: 0.0121\n",
      "Epoch: 398/500... Training loss: 0.0033\n",
      "Epoch: 398/500... Training loss: 0.0031\n",
      "Epoch: 398/500... Training loss: 0.0066\n",
      "Epoch: 398/500... Training loss: 0.0010\n",
      "Epoch: 398/500... Training loss: 0.0092\n",
      "Epoch: 399/500... Training loss: 0.0161\n",
      "Epoch: 399/500... Training loss: 0.0021\n",
      "Epoch: 399/500... Training loss: 0.0073\n",
      "Epoch: 399/500... Training loss: 0.0027\n",
      "Epoch: 399/500... Training loss: 0.0028\n",
      "Epoch: 399/500... Training loss: 0.0086\n",
      "Epoch: 399/500... Training loss: 0.0024\n",
      "Epoch: 399/500... Training loss: 0.0569\n",
      "Epoch: 399/500... Training loss: 0.0509\n",
      "Epoch: 399/500... Training loss: 0.0048\n",
      "Epoch: 399/500... Training loss: 0.0041\n",
      "Epoch: 399/500... Training loss: 0.0409\n",
      "Epoch: 399/500... Training loss: 0.0015\n",
      "Epoch: 399/500... Training loss: 0.0032\n",
      "Epoch: 399/500... Training loss: 0.0025\n",
      "Epoch: 399/500... Training loss: 0.0012\n",
      "Epoch: 399/500... Training loss: 0.0133\n",
      "Epoch: 399/500... Training loss: 0.0018\n",
      "Epoch: 399/500... Training loss: 0.0065\n",
      "Epoch: 399/500... Training loss: 0.0167\n",
      "Epoch: 399/500... Training loss: 0.0589\n",
      "Epoch: 399/500... Training loss: 0.0365\n",
      "Epoch: 399/500... Training loss: 0.0231\n",
      "Epoch: 399/500... Training loss: 0.0031\n",
      "Epoch: 399/500... Training loss: 0.1384\n",
      "Epoch: 399/500... Training loss: 0.0689\n",
      "Epoch: 399/500... Training loss: 0.0034\n",
      "Epoch: 399/500... Training loss: 0.0449\n",
      "Epoch: 399/500... Training loss: 0.0053\n",
      "Epoch: 399/500... Training loss: 0.0041\n",
      "Epoch: 399/500... Training loss: 0.0138\n",
      "Epoch: 400/500... Training loss: 0.0021\n",
      "Epoch: 400/500... Training loss: 0.0012\n",
      "Epoch: 400/500... Training loss: 0.0035\n",
      "Epoch: 400/500... Training loss: 0.0048\n",
      "Epoch: 400/500... Training loss: 0.0129\n",
      "Epoch: 400/500... Training loss: 0.0148\n",
      "Epoch: 400/500... Training loss: 0.0245\n",
      "Epoch: 400/500... Training loss: 0.0036\n",
      "Epoch: 400/500... Training loss: 0.0042\n",
      "Epoch: 400/500... Training loss: 0.0056\n",
      "Epoch: 400/500... Training loss: 0.0096\n",
      "Epoch: 400/500... Training loss: 0.0105\n",
      "Epoch: 400/500... Training loss: 0.0501\n",
      "Epoch: 400/500... Training loss: 0.0489\n",
      "Epoch: 400/500... Training loss: 0.0082\n",
      "Epoch: 400/500... Training loss: 0.0050\n",
      "Epoch: 400/500... Training loss: 0.0137\n",
      "Epoch: 400/500... Training loss: 0.0047\n",
      "Epoch: 400/500... Training loss: 0.0006\n",
      "Epoch: 400/500... Training loss: 0.0669\n",
      "Epoch: 400/500... Training loss: 0.0032\n",
      "Epoch: 400/500... Training loss: 0.0157\n",
      "Epoch: 400/500... Training loss: 0.1229\n",
      "Epoch: 400/500... Training loss: 0.0061\n",
      "Epoch: 400/500... Training loss: 0.0300\n",
      "Epoch: 400/500... Training loss: 0.0645\n",
      "Epoch: 400/500... Training loss: 0.0026\n",
      "Epoch: 400/500... Training loss: 0.0431\n",
      "Epoch: 400/500... Training loss: 0.0033\n",
      "Epoch: 400/500... Training loss: 0.0062\n",
      "Epoch: 400/500... Training loss: 0.0013\n",
      "Epoch: 401/500... Training loss: 0.0021\n",
      "Epoch: 401/500... Training loss: 0.0111\n",
      "Epoch: 401/500... Training loss: 0.0063\n",
      "Epoch: 401/500... Training loss: 0.0051\n",
      "Epoch: 401/500... Training loss: 0.0043\n",
      "Epoch: 401/500... Training loss: 0.0212\n",
      "Epoch: 401/500... Training loss: 0.0054\n",
      "Epoch: 401/500... Training loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401/500... Training loss: 0.0048\n",
      "Epoch: 401/500... Training loss: 0.0042\n",
      "Epoch: 401/500... Training loss: 0.0043\n",
      "Epoch: 401/500... Training loss: 0.0772\n",
      "Epoch: 401/500... Training loss: 0.0313\n",
      "Epoch: 401/500... Training loss: 0.0061\n",
      "Epoch: 401/500... Training loss: 0.0036\n",
      "Epoch: 401/500... Training loss: 0.0605\n",
      "Epoch: 401/500... Training loss: 0.0038\n",
      "Epoch: 401/500... Training loss: 0.0038\n",
      "Epoch: 401/500... Training loss: 0.0026\n",
      "Epoch: 401/500... Training loss: 0.0251\n",
      "Epoch: 401/500... Training loss: 0.0074\n",
      "Epoch: 401/500... Training loss: 0.0034\n",
      "Epoch: 401/500... Training loss: 0.0617\n",
      "Epoch: 401/500... Training loss: 0.0072\n",
      "Epoch: 401/500... Training loss: 0.0035\n",
      "Epoch: 401/500... Training loss: 0.0029\n",
      "Epoch: 401/500... Training loss: 0.0032\n",
      "Epoch: 401/500... Training loss: 0.0134\n",
      "Epoch: 401/500... Training loss: 0.0062\n",
      "Epoch: 401/500... Training loss: 0.0026\n",
      "Epoch: 401/500... Training loss: 0.0015\n",
      "Epoch: 402/500... Training loss: 0.0018\n",
      "Epoch: 402/500... Training loss: 0.0022\n",
      "Epoch: 402/500... Training loss: 0.0262\n",
      "Epoch: 402/500... Training loss: 0.1059\n",
      "Epoch: 402/500... Training loss: 0.0046\n",
      "Epoch: 402/500... Training loss: 0.0129\n",
      "Epoch: 402/500... Training loss: 0.0023\n",
      "Epoch: 402/500... Training loss: 0.0155\n",
      "Epoch: 402/500... Training loss: 0.0025\n",
      "Epoch: 402/500... Training loss: 0.1388\n",
      "Epoch: 402/500... Training loss: 0.0029\n",
      "Epoch: 402/500... Training loss: 0.0754\n",
      "Epoch: 402/500... Training loss: 0.0028\n",
      "Epoch: 402/500... Training loss: 0.0065\n",
      "Epoch: 402/500... Training loss: 0.0372\n",
      "Epoch: 402/500... Training loss: 0.0044\n",
      "Epoch: 402/500... Training loss: 0.0027\n",
      "Epoch: 402/500... Training loss: 0.0304\n",
      "Epoch: 402/500... Training loss: 0.0034\n",
      "Epoch: 402/500... Training loss: 0.0012\n",
      "Epoch: 402/500... Training loss: 0.0277\n",
      "Epoch: 402/500... Training loss: 0.0014\n",
      "Epoch: 402/500... Training loss: 0.0861\n",
      "Epoch: 402/500... Training loss: 0.0040\n",
      "Epoch: 402/500... Training loss: 0.0133\n",
      "Epoch: 402/500... Training loss: 0.0043\n",
      "Epoch: 402/500... Training loss: 0.0180\n",
      "Epoch: 402/500... Training loss: 0.0019\n",
      "Epoch: 402/500... Training loss: 0.0236\n",
      "Epoch: 402/500... Training loss: 0.0138\n",
      "Epoch: 402/500... Training loss: 0.0155\n",
      "Epoch: 403/500... Training loss: 0.0014\n",
      "Epoch: 403/500... Training loss: 0.0078\n",
      "Epoch: 403/500... Training loss: 0.0094\n",
      "Epoch: 403/500... Training loss: 0.0020\n",
      "Epoch: 403/500... Training loss: 0.0072\n",
      "Epoch: 403/500... Training loss: 0.0204\n",
      "Epoch: 403/500... Training loss: 0.0118\n",
      "Epoch: 403/500... Training loss: 0.0025\n",
      "Epoch: 403/500... Training loss: 0.0455\n",
      "Epoch: 403/500... Training loss: 0.0016\n",
      "Epoch: 403/500... Training loss: 0.0057\n",
      "Epoch: 403/500... Training loss: 0.0946\n",
      "Epoch: 403/500... Training loss: 0.0162\n",
      "Epoch: 403/500... Training loss: 0.0117\n",
      "Epoch: 403/500... Training loss: 0.0441\n",
      "Epoch: 403/500... Training loss: 0.0047\n",
      "Epoch: 403/500... Training loss: 0.0017\n",
      "Epoch: 403/500... Training loss: 0.0132\n",
      "Epoch: 403/500... Training loss: 0.0074\n",
      "Epoch: 403/500... Training loss: 0.0328\n",
      "Epoch: 403/500... Training loss: 0.0167\n",
      "Epoch: 403/500... Training loss: 0.0009\n",
      "Epoch: 403/500... Training loss: 0.0097\n",
      "Epoch: 403/500... Training loss: 0.1489\n",
      "Epoch: 403/500... Training loss: 0.0075\n",
      "Epoch: 403/500... Training loss: 0.0039\n",
      "Epoch: 403/500... Training loss: 0.0008\n",
      "Epoch: 403/500... Training loss: 0.1487\n",
      "Epoch: 403/500... Training loss: 0.0035\n",
      "Epoch: 403/500... Training loss: 0.0026\n",
      "Epoch: 403/500... Training loss: 0.0025\n",
      "Epoch: 404/500... Training loss: 0.0017\n",
      "Epoch: 404/500... Training loss: 0.0021\n",
      "Epoch: 404/500... Training loss: 0.0153\n",
      "Epoch: 404/500... Training loss: 0.0047\n",
      "Epoch: 404/500... Training loss: 0.0038\n",
      "Epoch: 404/500... Training loss: 0.0053\n",
      "Epoch: 404/500... Training loss: 0.0089\n",
      "Epoch: 404/500... Training loss: 0.0021\n",
      "Epoch: 404/500... Training loss: 0.0011\n",
      "Epoch: 404/500... Training loss: 0.0045\n",
      "Epoch: 404/500... Training loss: 0.0075\n",
      "Epoch: 404/500... Training loss: 0.0016\n",
      "Epoch: 404/500... Training loss: 0.0036\n",
      "Epoch: 404/500... Training loss: 0.0016\n",
      "Epoch: 404/500... Training loss: 0.0043\n",
      "Epoch: 404/500... Training loss: 0.0114\n",
      "Epoch: 404/500... Training loss: 0.0065\n",
      "Epoch: 404/500... Training loss: 0.0100\n",
      "Epoch: 404/500... Training loss: 0.0030\n",
      "Epoch: 404/500... Training loss: 0.0022\n",
      "Epoch: 404/500... Training loss: 0.0182\n",
      "Epoch: 404/500... Training loss: 0.0009\n",
      "Epoch: 404/500... Training loss: 0.0086\n",
      "Epoch: 404/500... Training loss: 0.0056\n",
      "Epoch: 404/500... Training loss: 0.0011\n",
      "Epoch: 404/500... Training loss: 0.0053\n",
      "Epoch: 404/500... Training loss: 0.0010\n",
      "Epoch: 404/500... Training loss: 0.0107\n",
      "Epoch: 404/500... Training loss: 0.0034\n",
      "Epoch: 404/500... Training loss: 0.0024\n",
      "Epoch: 404/500... Training loss: 0.0089\n",
      "Epoch: 405/500... Training loss: 0.0047\n",
      "Epoch: 405/500... Training loss: 0.0186\n",
      "Epoch: 405/500... Training loss: 0.0128\n",
      "Epoch: 405/500... Training loss: 0.0065\n",
      "Epoch: 405/500... Training loss: 0.0012\n",
      "Epoch: 405/500... Training loss: 0.0076\n",
      "Epoch: 405/500... Training loss: 0.0023\n",
      "Epoch: 405/500... Training loss: 0.0034\n",
      "Epoch: 405/500... Training loss: 0.0023\n",
      "Epoch: 405/500... Training loss: 0.0236\n",
      "Epoch: 405/500... Training loss: 0.0116\n",
      "Epoch: 405/500... Training loss: 0.0235\n",
      "Epoch: 405/500... Training loss: 0.0045\n",
      "Epoch: 405/500... Training loss: 0.0036\n",
      "Epoch: 405/500... Training loss: 0.0132\n",
      "Epoch: 405/500... Training loss: 0.0026\n",
      "Epoch: 405/500... Training loss: 0.0052\n",
      "Epoch: 405/500... Training loss: 0.0016\n",
      "Epoch: 405/500... Training loss: 0.0020\n",
      "Epoch: 405/500... Training loss: 0.0318\n",
      "Epoch: 405/500... Training loss: 0.0071\n",
      "Epoch: 405/500... Training loss: 0.0006\n",
      "Epoch: 405/500... Training loss: 0.0157\n",
      "Epoch: 405/500... Training loss: 0.0058\n",
      "Epoch: 405/500... Training loss: 0.0056\n",
      "Epoch: 405/500... Training loss: 0.0050\n",
      "Epoch: 405/500... Training loss: 0.0010\n",
      "Epoch: 405/500... Training loss: 0.0022\n",
      "Epoch: 405/500... Training loss: 0.0018\n",
      "Epoch: 405/500... Training loss: 0.0032\n",
      "Epoch: 405/500... Training loss: 0.0082\n",
      "Epoch: 406/500... Training loss: 0.0093\n",
      "Epoch: 406/500... Training loss: 0.0518\n",
      "Epoch: 406/500... Training loss: 0.0032\n",
      "Epoch: 406/500... Training loss: 0.0013\n",
      "Epoch: 406/500... Training loss: 0.0099\n",
      "Epoch: 406/500... Training loss: 0.0252\n",
      "Epoch: 406/500... Training loss: 0.0012\n",
      "Epoch: 406/500... Training loss: 0.0010\n",
      "Epoch: 406/500... Training loss: 0.0012\n",
      "Epoch: 406/500... Training loss: 0.0025\n",
      "Epoch: 406/500... Training loss: 0.0094\n",
      "Epoch: 406/500... Training loss: 0.0277\n",
      "Epoch: 406/500... Training loss: 0.0104\n",
      "Epoch: 406/500... Training loss: 0.0064\n",
      "Epoch: 406/500... Training loss: 0.0069\n",
      "Epoch: 406/500... Training loss: 0.0708\n",
      "Epoch: 406/500... Training loss: 0.0006\n",
      "Epoch: 406/500... Training loss: 0.0019\n",
      "Epoch: 406/500... Training loss: 0.0037\n",
      "Epoch: 406/500... Training loss: 0.0008\n",
      "Epoch: 406/500... Training loss: 0.0105\n",
      "Epoch: 406/500... Training loss: 0.0018\n",
      "Epoch: 406/500... Training loss: 0.0388\n",
      "Epoch: 406/500... Training loss: 0.0028\n",
      "Epoch: 406/500... Training loss: 0.0400\n",
      "Epoch: 406/500... Training loss: 0.0306\n",
      "Epoch: 406/500... Training loss: 0.0013\n",
      "Epoch: 406/500... Training loss: 0.0019\n",
      "Epoch: 406/500... Training loss: 0.0195\n",
      "Epoch: 406/500... Training loss: 0.0019\n",
      "Epoch: 406/500... Training loss: 0.0808\n",
      "Epoch: 407/500... Training loss: 0.0064\n",
      "Epoch: 407/500... Training loss: 0.0015\n",
      "Epoch: 407/500... Training loss: 0.0032\n",
      "Epoch: 407/500... Training loss: 0.0016\n",
      "Epoch: 407/500... Training loss: 0.0011\n",
      "Epoch: 407/500... Training loss: 0.0015\n",
      "Epoch: 407/500... Training loss: 0.0306\n",
      "Epoch: 407/500... Training loss: 0.0017\n",
      "Epoch: 407/500... Training loss: 0.0070\n",
      "Epoch: 407/500... Training loss: 0.0455\n",
      "Epoch: 407/500... Training loss: 0.0010\n",
      "Epoch: 407/500... Training loss: 0.0046\n",
      "Epoch: 407/500... Training loss: 0.0008\n",
      "Epoch: 407/500... Training loss: 0.0236\n",
      "Epoch: 407/500... Training loss: 0.0006\n",
      "Epoch: 407/500... Training loss: 0.0230\n",
      "Epoch: 407/500... Training loss: 0.0035\n",
      "Epoch: 407/500... Training loss: 0.0303\n",
      "Epoch: 407/500... Training loss: 0.0758\n",
      "Epoch: 407/500... Training loss: 0.0091\n",
      "Epoch: 407/500... Training loss: 0.0928\n",
      "Epoch: 407/500... Training loss: 0.0025\n",
      "Epoch: 407/500... Training loss: 0.0032\n",
      "Epoch: 407/500... Training loss: 0.0855\n",
      "Epoch: 407/500... Training loss: 0.0052\n",
      "Epoch: 407/500... Training loss: 0.0133\n",
      "Epoch: 407/500... Training loss: 0.0008\n",
      "Epoch: 407/500... Training loss: 0.0054\n",
      "Epoch: 407/500... Training loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407/500... Training loss: 0.0230\n",
      "Epoch: 407/500... Training loss: 0.0247\n",
      "Epoch: 408/500... Training loss: 0.0028\n",
      "Epoch: 408/500... Training loss: 0.0008\n",
      "Epoch: 408/500... Training loss: 0.0147\n",
      "Epoch: 408/500... Training loss: 0.0076\n",
      "Epoch: 408/500... Training loss: 0.0910\n",
      "Epoch: 408/500... Training loss: 0.0012\n",
      "Epoch: 408/500... Training loss: 0.0010\n",
      "Epoch: 408/500... Training loss: 0.0020\n",
      "Epoch: 408/500... Training loss: 0.0066\n",
      "Epoch: 408/500... Training loss: 0.0024\n",
      "Epoch: 408/500... Training loss: 0.0074\n",
      "Epoch: 408/500... Training loss: 0.0026\n",
      "Epoch: 408/500... Training loss: 0.0014\n",
      "Epoch: 408/500... Training loss: 0.0070\n",
      "Epoch: 408/500... Training loss: 0.0048\n",
      "Epoch: 408/500... Training loss: 0.0604\n",
      "Epoch: 408/500... Training loss: 0.0134\n",
      "Epoch: 408/500... Training loss: 0.0124\n",
      "Epoch: 408/500... Training loss: 0.0350\n",
      "Epoch: 408/500... Training loss: 0.0014\n",
      "Epoch: 408/500... Training loss: 0.0057\n",
      "Epoch: 408/500... Training loss: 0.0017\n",
      "Epoch: 408/500... Training loss: 0.0382\n",
      "Epoch: 408/500... Training loss: 0.0043\n",
      "Epoch: 408/500... Training loss: 0.0046\n",
      "Epoch: 408/500... Training loss: 0.0164\n",
      "Epoch: 408/500... Training loss: 0.0213\n",
      "Epoch: 408/500... Training loss: 0.0044\n",
      "Epoch: 408/500... Training loss: 0.0005\n",
      "Epoch: 408/500... Training loss: 0.0405\n",
      "Epoch: 408/500... Training loss: 0.0064\n",
      "Epoch: 409/500... Training loss: 0.0011\n",
      "Epoch: 409/500... Training loss: 0.0039\n",
      "Epoch: 409/500... Training loss: 0.0028\n",
      "Epoch: 409/500... Training loss: 0.0146\n",
      "Epoch: 409/500... Training loss: 0.0026\n",
      "Epoch: 409/500... Training loss: 0.0021\n",
      "Epoch: 409/500... Training loss: 0.0006\n",
      "Epoch: 409/500... Training loss: 0.0035\n",
      "Epoch: 409/500... Training loss: 0.0010\n",
      "Epoch: 409/500... Training loss: 0.0071\n",
      "Epoch: 409/500... Training loss: 0.0051\n",
      "Epoch: 409/500... Training loss: 0.0025\n",
      "Epoch: 409/500... Training loss: 0.0304\n",
      "Epoch: 409/500... Training loss: 0.0081\n",
      "Epoch: 409/500... Training loss: 0.0007\n",
      "Epoch: 409/500... Training loss: 0.0080\n",
      "Epoch: 409/500... Training loss: 0.0025\n",
      "Epoch: 409/500... Training loss: 0.0161\n",
      "Epoch: 409/500... Training loss: 0.0151\n",
      "Epoch: 409/500... Training loss: 0.0050\n",
      "Epoch: 409/500... Training loss: 0.0022\n",
      "Epoch: 409/500... Training loss: 0.0060\n",
      "Epoch: 409/500... Training loss: 0.0007\n",
      "Epoch: 409/500... Training loss: 0.0038\n",
      "Epoch: 409/500... Training loss: 0.0132\n",
      "Epoch: 409/500... Training loss: 0.0012\n",
      "Epoch: 409/500... Training loss: 0.0209\n",
      "Epoch: 409/500... Training loss: 0.0016\n",
      "Epoch: 409/500... Training loss: 0.0750\n",
      "Epoch: 409/500... Training loss: 0.0750\n",
      "Epoch: 409/500... Training loss: 0.0023\n",
      "Epoch: 410/500... Training loss: 0.0133\n",
      "Epoch: 410/500... Training loss: 0.0022\n",
      "Epoch: 410/500... Training loss: 0.0009\n",
      "Epoch: 410/500... Training loss: 0.0198\n",
      "Epoch: 410/500... Training loss: 0.0022\n",
      "Epoch: 410/500... Training loss: 0.0041\n",
      "Epoch: 410/500... Training loss: 0.0032\n",
      "Epoch: 410/500... Training loss: 0.0624\n",
      "Epoch: 410/500... Training loss: 0.0089\n",
      "Epoch: 410/500... Training loss: 0.0012\n",
      "Epoch: 410/500... Training loss: 0.0238\n",
      "Epoch: 410/500... Training loss: 0.0034\n",
      "Epoch: 410/500... Training loss: 0.0055\n",
      "Epoch: 410/500... Training loss: 0.0011\n",
      "Epoch: 410/500... Training loss: 0.0038\n",
      "Epoch: 410/500... Training loss: 0.0098\n",
      "Epoch: 410/500... Training loss: 0.0028\n",
      "Epoch: 410/500... Training loss: 0.0126\n",
      "Epoch: 410/500... Training loss: 0.0025\n",
      "Epoch: 410/500... Training loss: 0.0318\n",
      "Epoch: 410/500... Training loss: 0.0145\n",
      "Epoch: 410/500... Training loss: 0.0023\n",
      "Epoch: 410/500... Training loss: 0.0260\n",
      "Epoch: 410/500... Training loss: 0.0018\n",
      "Epoch: 410/500... Training loss: 0.0174\n",
      "Epoch: 410/500... Training loss: 0.0012\n",
      "Epoch: 410/500... Training loss: 0.0087\n",
      "Epoch: 410/500... Training loss: 0.0007\n",
      "Epoch: 410/500... Training loss: 0.0018\n",
      "Epoch: 410/500... Training loss: 0.0121\n",
      "Epoch: 410/500... Training loss: 0.0074\n",
      "Epoch: 411/500... Training loss: 0.0011\n",
      "Epoch: 411/500... Training loss: 0.0010\n",
      "Epoch: 411/500... Training loss: 0.0008\n",
      "Epoch: 411/500... Training loss: 0.0034\n",
      "Epoch: 411/500... Training loss: 0.0203\n",
      "Epoch: 411/500... Training loss: 0.0023\n",
      "Epoch: 411/500... Training loss: 0.0022\n",
      "Epoch: 411/500... Training loss: 0.0090\n",
      "Epoch: 411/500... Training loss: 0.0268\n",
      "Epoch: 411/500... Training loss: 0.0006\n",
      "Epoch: 411/500... Training loss: 0.0030\n",
      "Epoch: 411/500... Training loss: 0.0185\n",
      "Epoch: 411/500... Training loss: 0.0052\n",
      "Epoch: 411/500... Training loss: 0.0097\n",
      "Epoch: 411/500... Training loss: 0.0045\n",
      "Epoch: 411/500... Training loss: 0.0023\n",
      "Epoch: 411/500... Training loss: 0.0078\n",
      "Epoch: 411/500... Training loss: 0.0135\n",
      "Epoch: 411/500... Training loss: 0.0015\n",
      "Epoch: 411/500... Training loss: 0.0026\n",
      "Epoch: 411/500... Training loss: 0.0050\n",
      "Epoch: 411/500... Training loss: 0.0009\n",
      "Epoch: 411/500... Training loss: 0.0979\n",
      "Epoch: 411/500... Training loss: 0.0077\n",
      "Epoch: 411/500... Training loss: 0.0109\n",
      "Epoch: 411/500... Training loss: 0.0088\n",
      "Epoch: 411/500... Training loss: 0.0021\n",
      "Epoch: 411/500... Training loss: 0.0022\n",
      "Epoch: 411/500... Training loss: 0.0008\n",
      "Epoch: 411/500... Training loss: 0.0189\n",
      "Epoch: 411/500... Training loss: 0.0015\n",
      "Epoch: 412/500... Training loss: 0.0013\n",
      "Epoch: 412/500... Training loss: 0.0046\n",
      "Epoch: 412/500... Training loss: 0.0028\n",
      "Epoch: 412/500... Training loss: 0.0068\n",
      "Epoch: 412/500... Training loss: 0.0081\n",
      "Epoch: 412/500... Training loss: 0.0047\n",
      "Epoch: 412/500... Training loss: 0.0231\n",
      "Epoch: 412/500... Training loss: 0.0250\n",
      "Epoch: 412/500... Training loss: 0.0013\n",
      "Epoch: 412/500... Training loss: 0.0105\n",
      "Epoch: 412/500... Training loss: 0.0010\n",
      "Epoch: 412/500... Training loss: 0.0013\n",
      "Epoch: 412/500... Training loss: 0.0009\n",
      "Epoch: 412/500... Training loss: 0.0044\n",
      "Epoch: 412/500... Training loss: 0.0021\n",
      "Epoch: 412/500... Training loss: 0.0427\n",
      "Epoch: 412/500... Training loss: 0.0054\n",
      "Epoch: 412/500... Training loss: 0.0193\n",
      "Epoch: 412/500... Training loss: 0.0117\n",
      "Epoch: 412/500... Training loss: 0.0039\n",
      "Epoch: 412/500... Training loss: 0.0114\n",
      "Epoch: 412/500... Training loss: 0.0021\n",
      "Epoch: 412/500... Training loss: 0.0160\n",
      "Epoch: 412/500... Training loss: 0.0460\n",
      "Epoch: 412/500... Training loss: 0.0181\n",
      "Epoch: 412/500... Training loss: 0.0085\n",
      "Epoch: 412/500... Training loss: 0.0047\n",
      "Epoch: 412/500... Training loss: 0.0336\n",
      "Epoch: 412/500... Training loss: 0.0041\n",
      "Epoch: 412/500... Training loss: 0.0029\n",
      "Epoch: 412/500... Training loss: 0.0092\n",
      "Epoch: 413/500... Training loss: 0.0010\n",
      "Epoch: 413/500... Training loss: 0.0242\n",
      "Epoch: 413/500... Training loss: 0.0022\n",
      "Epoch: 413/500... Training loss: 0.0052\n",
      "Epoch: 413/500... Training loss: 0.0427\n",
      "Epoch: 413/500... Training loss: 0.0085\n",
      "Epoch: 413/500... Training loss: 0.0060\n",
      "Epoch: 413/500... Training loss: 0.0245\n",
      "Epoch: 413/500... Training loss: 0.0017\n",
      "Epoch: 413/500... Training loss: 0.0079\n",
      "Epoch: 413/500... Training loss: 0.0075\n",
      "Epoch: 413/500... Training loss: 0.0233\n",
      "Epoch: 413/500... Training loss: 0.0004\n",
      "Epoch: 413/500... Training loss: 0.0042\n",
      "Epoch: 413/500... Training loss: 0.0009\n",
      "Epoch: 413/500... Training loss: 0.0030\n",
      "Epoch: 413/500... Training loss: 0.0301\n",
      "Epoch: 413/500... Training loss: 0.0192\n",
      "Epoch: 413/500... Training loss: 0.0032\n",
      "Epoch: 413/500... Training loss: 0.0200\n",
      "Epoch: 413/500... Training loss: 0.0061\n",
      "Epoch: 413/500... Training loss: 0.0791\n",
      "Epoch: 413/500... Training loss: 0.0082\n",
      "Epoch: 413/500... Training loss: 0.0005\n",
      "Epoch: 413/500... Training loss: 0.0097\n",
      "Epoch: 413/500... Training loss: 0.0217\n",
      "Epoch: 413/500... Training loss: 0.0024\n",
      "Epoch: 413/500... Training loss: 0.0009\n",
      "Epoch: 413/500... Training loss: 0.0079\n",
      "Epoch: 413/500... Training loss: 0.0061\n",
      "Epoch: 413/500... Training loss: 0.0157\n",
      "Epoch: 414/500... Training loss: 0.0012\n",
      "Epoch: 414/500... Training loss: 0.0023\n",
      "Epoch: 414/500... Training loss: 0.0013\n",
      "Epoch: 414/500... Training loss: 0.0027\n",
      "Epoch: 414/500... Training loss: 0.0011\n",
      "Epoch: 414/500... Training loss: 0.0090\n",
      "Epoch: 414/500... Training loss: 0.0075\n",
      "Epoch: 414/500... Training loss: 0.0066\n",
      "Epoch: 414/500... Training loss: 0.0237\n",
      "Epoch: 414/500... Training loss: 0.0099\n",
      "Epoch: 414/500... Training loss: 0.0036\n",
      "Epoch: 414/500... Training loss: 0.0353\n",
      "Epoch: 414/500... Training loss: 0.0099\n",
      "Epoch: 414/500... Training loss: 0.0018\n",
      "Epoch: 414/500... Training loss: 0.0156\n",
      "Epoch: 414/500... Training loss: 0.0235\n",
      "Epoch: 414/500... Training loss: 0.0030\n",
      "Epoch: 414/500... Training loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 414/500... Training loss: 0.0040\n",
      "Epoch: 414/500... Training loss: 0.0379\n",
      "Epoch: 414/500... Training loss: 0.0080\n",
      "Epoch: 414/500... Training loss: 0.0472\n",
      "Epoch: 414/500... Training loss: 0.0649\n",
      "Epoch: 414/500... Training loss: 0.0037\n",
      "Epoch: 414/500... Training loss: 0.0019\n",
      "Epoch: 414/500... Training loss: 0.0046\n",
      "Epoch: 414/500... Training loss: 0.0044\n",
      "Epoch: 414/500... Training loss: 0.0137\n",
      "Epoch: 414/500... Training loss: 0.0089\n",
      "Epoch: 414/500... Training loss: 0.0118\n",
      "Epoch: 414/500... Training loss: 0.0424\n",
      "Epoch: 415/500... Training loss: 0.1726\n",
      "Epoch: 415/500... Training loss: 0.0025\n",
      "Epoch: 415/500... Training loss: 0.0831\n",
      "Epoch: 415/500... Training loss: 0.0303\n",
      "Epoch: 415/500... Training loss: 0.0079\n",
      "Epoch: 415/500... Training loss: 0.0023\n",
      "Epoch: 415/500... Training loss: 0.0499\n",
      "Epoch: 415/500... Training loss: 0.0090\n",
      "Epoch: 415/500... Training loss: 0.0009\n",
      "Epoch: 415/500... Training loss: 0.0066\n",
      "Epoch: 415/500... Training loss: 0.0016\n",
      "Epoch: 415/500... Training loss: 0.1133\n",
      "Epoch: 415/500... Training loss: 0.0014\n",
      "Epoch: 415/500... Training loss: 0.0116\n",
      "Epoch: 415/500... Training loss: 0.0860\n",
      "Epoch: 415/500... Training loss: 0.0057\n",
      "Epoch: 415/500... Training loss: 0.0015\n",
      "Epoch: 415/500... Training loss: 0.0912\n",
      "Epoch: 415/500... Training loss: 0.0395\n",
      "Epoch: 415/500... Training loss: 0.0061\n",
      "Epoch: 415/500... Training loss: 0.0204\n",
      "Epoch: 415/500... Training loss: 0.0010\n",
      "Epoch: 415/500... Training loss: 0.0124\n",
      "Epoch: 415/500... Training loss: 0.0014\n",
      "Epoch: 415/500... Training loss: 0.0014\n",
      "Epoch: 415/500... Training loss: 0.0127\n",
      "Epoch: 415/500... Training loss: 0.0014\n",
      "Epoch: 415/500... Training loss: 0.0042\n",
      "Epoch: 415/500... Training loss: 0.1231\n",
      "Epoch: 415/500... Training loss: 0.0424\n",
      "Epoch: 415/500... Training loss: 0.0140\n",
      "Epoch: 416/500... Training loss: 0.1039\n",
      "Epoch: 416/500... Training loss: 0.0293\n",
      "Epoch: 416/500... Training loss: 0.0022\n",
      "Epoch: 416/500... Training loss: 0.0026\n",
      "Epoch: 416/500... Training loss: 0.0020\n",
      "Epoch: 416/500... Training loss: 0.0196\n",
      "Epoch: 416/500... Training loss: 0.0041\n",
      "Epoch: 416/500... Training loss: 0.0059\n",
      "Epoch: 416/500... Training loss: 0.0021\n",
      "Epoch: 416/500... Training loss: 0.0023\n",
      "Epoch: 416/500... Training loss: 0.0270\n",
      "Epoch: 416/500... Training loss: 0.0038\n",
      "Epoch: 416/500... Training loss: 0.1268\n",
      "Epoch: 416/500... Training loss: 0.0060\n",
      "Epoch: 416/500... Training loss: 0.0046\n",
      "Epoch: 416/500... Training loss: 0.0066\n",
      "Epoch: 416/500... Training loss: 0.0041\n",
      "Epoch: 416/500... Training loss: 0.0077\n",
      "Epoch: 416/500... Training loss: 0.0407\n",
      "Epoch: 416/500... Training loss: 0.0035\n",
      "Epoch: 416/500... Training loss: 0.0015\n",
      "Epoch: 416/500... Training loss: 0.0157\n",
      "Epoch: 416/500... Training loss: 0.0124\n",
      "Epoch: 416/500... Training loss: 0.0007\n",
      "Epoch: 416/500... Training loss: 0.0015\n",
      "Epoch: 416/500... Training loss: 0.0528\n",
      "Epoch: 416/500... Training loss: 0.0020\n",
      "Epoch: 416/500... Training loss: 0.0200\n",
      "Epoch: 416/500... Training loss: 0.0431\n",
      "Epoch: 416/500... Training loss: 0.0022\n",
      "Epoch: 416/500... Training loss: 0.0023\n",
      "Epoch: 417/500... Training loss: 0.0304\n",
      "Epoch: 417/500... Training loss: 0.0043\n",
      "Epoch: 417/500... Training loss: 0.0032\n",
      "Epoch: 417/500... Training loss: 0.0027\n",
      "Epoch: 417/500... Training loss: 0.0127\n",
      "Epoch: 417/500... Training loss: 0.0072\n",
      "Epoch: 417/500... Training loss: 0.0212\n",
      "Epoch: 417/500... Training loss: 0.0019\n",
      "Epoch: 417/500... Training loss: 0.0022\n",
      "Epoch: 417/500... Training loss: 0.0014\n",
      "Epoch: 417/500... Training loss: 0.0020\n",
      "Epoch: 417/500... Training loss: 0.0060\n",
      "Epoch: 417/500... Training loss: 0.0005\n",
      "Epoch: 417/500... Training loss: 0.0035\n",
      "Epoch: 417/500... Training loss: 0.0524\n",
      "Epoch: 417/500... Training loss: 0.0273\n",
      "Epoch: 417/500... Training loss: 0.0026\n",
      "Epoch: 417/500... Training loss: 0.0119\n",
      "Epoch: 417/500... Training loss: 0.0097\n",
      "Epoch: 417/500... Training loss: 0.0008\n",
      "Epoch: 417/500... Training loss: 0.0046\n",
      "Epoch: 417/500... Training loss: 0.0189\n",
      "Epoch: 417/500... Training loss: 0.0021\n",
      "Epoch: 417/500... Training loss: 0.0048\n",
      "Epoch: 417/500... Training loss: 0.0189\n",
      "Epoch: 417/500... Training loss: 0.0018\n",
      "Epoch: 417/500... Training loss: 0.0293\n",
      "Epoch: 417/500... Training loss: 0.0017\n",
      "Epoch: 417/500... Training loss: 0.0111\n",
      "Epoch: 417/500... Training loss: 0.0061\n",
      "Epoch: 417/500... Training loss: 0.0016\n",
      "Epoch: 418/500... Training loss: 0.0024\n",
      "Epoch: 418/500... Training loss: 0.0013\n",
      "Epoch: 418/500... Training loss: 0.0121\n",
      "Epoch: 418/500... Training loss: 0.0983\n",
      "Epoch: 418/500... Training loss: 0.0077\n",
      "Epoch: 418/500... Training loss: 0.0148\n",
      "Epoch: 418/500... Training loss: 0.0412\n",
      "Epoch: 418/500... Training loss: 0.0009\n",
      "Epoch: 418/500... Training loss: 0.0081\n",
      "Epoch: 418/500... Training loss: 0.0122\n",
      "Epoch: 418/500... Training loss: 0.0037\n",
      "Epoch: 418/500... Training loss: 0.0050\n",
      "Epoch: 418/500... Training loss: 0.0116\n",
      "Epoch: 418/500... Training loss: 0.0166\n",
      "Epoch: 418/500... Training loss: 0.0175\n",
      "Epoch: 418/500... Training loss: 0.0038\n",
      "Epoch: 418/500... Training loss: 0.0084\n",
      "Epoch: 418/500... Training loss: 0.0572\n",
      "Epoch: 418/500... Training loss: 0.0018\n",
      "Epoch: 418/500... Training loss: 0.0109\n",
      "Epoch: 418/500... Training loss: 0.0090\n",
      "Epoch: 418/500... Training loss: 0.0032\n",
      "Epoch: 418/500... Training loss: 0.0623\n",
      "Epoch: 418/500... Training loss: 0.0155\n",
      "Epoch: 418/500... Training loss: 0.0012\n",
      "Epoch: 418/500... Training loss: 0.0087\n",
      "Epoch: 418/500... Training loss: 0.0038\n",
      "Epoch: 418/500... Training loss: 0.0305\n",
      "Epoch: 418/500... Training loss: 0.0010\n",
      "Epoch: 418/500... Training loss: 0.0012\n",
      "Epoch: 418/500... Training loss: 0.0158\n",
      "Epoch: 419/500... Training loss: 0.0060\n",
      "Epoch: 419/500... Training loss: 0.0179\n",
      "Epoch: 419/500... Training loss: 0.0041\n",
      "Epoch: 419/500... Training loss: 0.1018\n",
      "Epoch: 419/500... Training loss: 0.0108\n",
      "Epoch: 419/500... Training loss: 0.0531\n",
      "Epoch: 419/500... Training loss: 0.0013\n",
      "Epoch: 419/500... Training loss: 0.0028\n",
      "Epoch: 419/500... Training loss: 0.0022\n",
      "Epoch: 419/500... Training loss: 0.0033\n",
      "Epoch: 419/500... Training loss: 0.0038\n",
      "Epoch: 419/500... Training loss: 0.0102\n",
      "Epoch: 419/500... Training loss: 0.1063\n",
      "Epoch: 419/500... Training loss: 0.0097\n",
      "Epoch: 419/500... Training loss: 0.0450\n",
      "Epoch: 419/500... Training loss: 0.0018\n",
      "Epoch: 419/500... Training loss: 0.0033\n",
      "Epoch: 419/500... Training loss: 0.0045\n",
      "Epoch: 419/500... Training loss: 0.0017\n",
      "Epoch: 419/500... Training loss: 0.0247\n",
      "Epoch: 419/500... Training loss: 0.0005\n",
      "Epoch: 419/500... Training loss: 0.0024\n",
      "Epoch: 419/500... Training loss: 0.0220\n",
      "Epoch: 419/500... Training loss: 0.0493\n",
      "Epoch: 419/500... Training loss: 0.0684\n",
      "Epoch: 419/500... Training loss: 0.0037\n",
      "Epoch: 419/500... Training loss: 0.0009\n",
      "Epoch: 419/500... Training loss: 0.0019\n",
      "Epoch: 419/500... Training loss: 0.0137\n",
      "Epoch: 419/500... Training loss: 0.0054\n",
      "Epoch: 419/500... Training loss: 0.0116\n",
      "Epoch: 420/500... Training loss: 0.0054\n",
      "Epoch: 420/500... Training loss: 0.0254\n",
      "Epoch: 420/500... Training loss: 0.0052\n",
      "Epoch: 420/500... Training loss: 0.0040\n",
      "Epoch: 420/500... Training loss: 0.0049\n",
      "Epoch: 420/500... Training loss: 0.0056\n",
      "Epoch: 420/500... Training loss: 0.0191\n",
      "Epoch: 420/500... Training loss: 0.0169\n",
      "Epoch: 420/500... Training loss: 0.0020\n",
      "Epoch: 420/500... Training loss: 0.0019\n",
      "Epoch: 420/500... Training loss: 0.0058\n",
      "Epoch: 420/500... Training loss: 0.0031\n",
      "Epoch: 420/500... Training loss: 0.0017\n",
      "Epoch: 420/500... Training loss: 0.0023\n",
      "Epoch: 420/500... Training loss: 0.0081\n",
      "Epoch: 420/500... Training loss: 0.0225\n",
      "Epoch: 420/500... Training loss: 0.0019\n",
      "Epoch: 420/500... Training loss: 0.1292\n",
      "Epoch: 420/500... Training loss: 0.0191\n",
      "Epoch: 420/500... Training loss: 0.0874\n",
      "Epoch: 420/500... Training loss: 0.0020\n",
      "Epoch: 420/500... Training loss: 0.0033\n",
      "Epoch: 420/500... Training loss: 0.0412\n",
      "Epoch: 420/500... Training loss: 0.0027\n",
      "Epoch: 420/500... Training loss: 0.0052\n",
      "Epoch: 420/500... Training loss: 0.1070\n",
      "Epoch: 420/500... Training loss: 0.0012\n",
      "Epoch: 420/500... Training loss: 0.0324\n",
      "Epoch: 420/500... Training loss: 0.0044\n",
      "Epoch: 420/500... Training loss: 0.0021\n",
      "Epoch: 420/500... Training loss: 0.0013\n",
      "Epoch: 421/500... Training loss: 0.0205\n",
      "Epoch: 421/500... Training loss: 0.0031\n",
      "Epoch: 421/500... Training loss: 0.0171\n",
      "Epoch: 421/500... Training loss: 0.0014\n",
      "Epoch: 421/500... Training loss: 0.0031\n",
      "Epoch: 421/500... Training loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 421/500... Training loss: 0.0024\n",
      "Epoch: 421/500... Training loss: 0.0015\n",
      "Epoch: 421/500... Training loss: 0.0396\n",
      "Epoch: 421/500... Training loss: 0.0060\n",
      "Epoch: 421/500... Training loss: 0.0155\n",
      "Epoch: 421/500... Training loss: 0.0168\n",
      "Epoch: 421/500... Training loss: 0.0010\n",
      "Epoch: 421/500... Training loss: 0.0041\n",
      "Epoch: 421/500... Training loss: 0.0078\n",
      "Epoch: 421/500... Training loss: 0.0022\n",
      "Epoch: 421/500... Training loss: 0.0023\n",
      "Epoch: 421/500... Training loss: 0.0156\n",
      "Epoch: 421/500... Training loss: 0.1055\n",
      "Epoch: 421/500... Training loss: 0.0049\n",
      "Epoch: 421/500... Training loss: 0.0092\n",
      "Epoch: 421/500... Training loss: 0.0014\n",
      "Epoch: 421/500... Training loss: 0.0036\n",
      "Epoch: 421/500... Training loss: 0.0014\n",
      "Epoch: 421/500... Training loss: 0.0040\n",
      "Epoch: 421/500... Training loss: 0.0016\n",
      "Epoch: 421/500... Training loss: 0.0083\n",
      "Epoch: 421/500... Training loss: 0.0022\n",
      "Epoch: 421/500... Training loss: 0.0020\n",
      "Epoch: 421/500... Training loss: 0.0582\n",
      "Epoch: 421/500... Training loss: 0.0706\n",
      "Epoch: 422/500... Training loss: 0.0088\n",
      "Epoch: 422/500... Training loss: 0.0010\n",
      "Epoch: 422/500... Training loss: 0.0028\n",
      "Epoch: 422/500... Training loss: 0.0033\n",
      "Epoch: 422/500... Training loss: 0.0578\n",
      "Epoch: 422/500... Training loss: 0.0030\n",
      "Epoch: 422/500... Training loss: 0.0138\n",
      "Epoch: 422/500... Training loss: 0.0185\n",
      "Epoch: 422/500... Training loss: 0.0037\n",
      "Epoch: 422/500... Training loss: 0.0063\n",
      "Epoch: 422/500... Training loss: 0.0436\n",
      "Epoch: 422/500... Training loss: 0.0028\n",
      "Epoch: 422/500... Training loss: 0.0126\n",
      "Epoch: 422/500... Training loss: 0.0009\n",
      "Epoch: 422/500... Training loss: 0.0066\n",
      "Epoch: 422/500... Training loss: 0.0039\n",
      "Epoch: 422/500... Training loss: 0.0261\n",
      "Epoch: 422/500... Training loss: 0.0027\n",
      "Epoch: 422/500... Training loss: 0.0023\n",
      "Epoch: 422/500... Training loss: 0.0101\n",
      "Epoch: 422/500... Training loss: 0.0210\n",
      "Epoch: 422/500... Training loss: 0.0064\n",
      "Epoch: 422/500... Training loss: 0.0016\n",
      "Epoch: 422/500... Training loss: 0.0516\n",
      "Epoch: 422/500... Training loss: 0.0022\n",
      "Epoch: 422/500... Training loss: 0.0010\n",
      "Epoch: 422/500... Training loss: 0.0019\n",
      "Epoch: 422/500... Training loss: 0.0018\n",
      "Epoch: 422/500... Training loss: 0.0031\n",
      "Epoch: 422/500... Training loss: 0.0015\n",
      "Epoch: 422/500... Training loss: 0.0102\n",
      "Epoch: 423/500... Training loss: 0.0215\n",
      "Epoch: 423/500... Training loss: 0.0039\n",
      "Epoch: 423/500... Training loss: 0.0230\n",
      "Epoch: 423/500... Training loss: 0.0014\n",
      "Epoch: 423/500... Training loss: 0.0017\n",
      "Epoch: 423/500... Training loss: 0.0267\n",
      "Epoch: 423/500... Training loss: 0.0046\n",
      "Epoch: 423/500... Training loss: 0.0135\n",
      "Epoch: 423/500... Training loss: 0.0045\n",
      "Epoch: 423/500... Training loss: 0.0127\n",
      "Epoch: 423/500... Training loss: 0.0149\n",
      "Epoch: 423/500... Training loss: 0.0096\n",
      "Epoch: 423/500... Training loss: 0.0010\n",
      "Epoch: 423/500... Training loss: 0.0065\n",
      "Epoch: 423/500... Training loss: 0.0012\n",
      "Epoch: 423/500... Training loss: 0.0056\n",
      "Epoch: 423/500... Training loss: 0.0044\n",
      "Epoch: 423/500... Training loss: 0.0051\n",
      "Epoch: 423/500... Training loss: 0.0024\n",
      "Epoch: 423/500... Training loss: 0.0010\n",
      "Epoch: 423/500... Training loss: 0.0013\n",
      "Epoch: 423/500... Training loss: 0.0008\n",
      "Epoch: 423/500... Training loss: 0.0010\n",
      "Epoch: 423/500... Training loss: 0.0007\n",
      "Epoch: 423/500... Training loss: 0.0065\n",
      "Epoch: 423/500... Training loss: 0.0064\n",
      "Epoch: 423/500... Training loss: 0.0074\n",
      "Epoch: 423/500... Training loss: 0.0019\n",
      "Epoch: 423/500... Training loss: 0.0041\n",
      "Epoch: 423/500... Training loss: 0.0020\n",
      "Epoch: 423/500... Training loss: 0.0010\n",
      "Epoch: 424/500... Training loss: 0.0188\n",
      "Epoch: 424/500... Training loss: 0.0033\n",
      "Epoch: 424/500... Training loss: 0.0018\n",
      "Epoch: 424/500... Training loss: 0.0341\n",
      "Epoch: 424/500... Training loss: 0.0032\n",
      "Epoch: 424/500... Training loss: 0.0113\n",
      "Epoch: 424/500... Training loss: 0.0019\n",
      "Epoch: 424/500... Training loss: 0.0684\n",
      "Epoch: 424/500... Training loss: 0.0022\n",
      "Epoch: 424/500... Training loss: 0.0157\n",
      "Epoch: 424/500... Training loss: 0.0034\n",
      "Epoch: 424/500... Training loss: 0.0265\n",
      "Epoch: 424/500... Training loss: 0.0156\n",
      "Epoch: 424/500... Training loss: 0.0016\n",
      "Epoch: 424/500... Training loss: 0.0014\n",
      "Epoch: 424/500... Training loss: 0.0130\n",
      "Epoch: 424/500... Training loss: 0.0015\n",
      "Epoch: 424/500... Training loss: 0.0031\n",
      "Epoch: 424/500... Training loss: 0.0092\n",
      "Epoch: 424/500... Training loss: 0.0033\n",
      "Epoch: 424/500... Training loss: 0.0068\n",
      "Epoch: 424/500... Training loss: 0.0017\n",
      "Epoch: 424/500... Training loss: 0.0004\n",
      "Epoch: 424/500... Training loss: 0.0032\n",
      "Epoch: 424/500... Training loss: 0.0095\n",
      "Epoch: 424/500... Training loss: 0.0058\n",
      "Epoch: 424/500... Training loss: 0.0152\n",
      "Epoch: 424/500... Training loss: 0.0485\n",
      "Epoch: 424/500... Training loss: 0.0128\n",
      "Epoch: 424/500... Training loss: 0.0024\n",
      "Epoch: 424/500... Training loss: 0.0030\n",
      "Epoch: 425/500... Training loss: 0.0238\n",
      "Epoch: 425/500... Training loss: 0.0030\n",
      "Epoch: 425/500... Training loss: 0.0230\n",
      "Epoch: 425/500... Training loss: 0.0016\n",
      "Epoch: 425/500... Training loss: 0.0028\n",
      "Epoch: 425/500... Training loss: 0.0010\n",
      "Epoch: 425/500... Training loss: 0.0169\n",
      "Epoch: 425/500... Training loss: 0.0038\n",
      "Epoch: 425/500... Training loss: 0.0218\n",
      "Epoch: 425/500... Training loss: 0.0040\n",
      "Epoch: 425/500... Training loss: 0.0015\n",
      "Epoch: 425/500... Training loss: 0.0253\n",
      "Epoch: 425/500... Training loss: 0.0046\n",
      "Epoch: 425/500... Training loss: 0.0042\n",
      "Epoch: 425/500... Training loss: 0.0033\n",
      "Epoch: 425/500... Training loss: 0.0011\n",
      "Epoch: 425/500... Training loss: 0.0269\n",
      "Epoch: 425/500... Training loss: 0.0127\n",
      "Epoch: 425/500... Training loss: 0.0018\n",
      "Epoch: 425/500... Training loss: 0.0029\n",
      "Epoch: 425/500... Training loss: 0.0044\n",
      "Epoch: 425/500... Training loss: 0.0193\n",
      "Epoch: 425/500... Training loss: 0.0010\n",
      "Epoch: 425/500... Training loss: 0.0023\n",
      "Epoch: 425/500... Training loss: 0.0022\n",
      "Epoch: 425/500... Training loss: 0.0016\n",
      "Epoch: 425/500... Training loss: 0.0075\n",
      "Epoch: 425/500... Training loss: 0.0597\n",
      "Epoch: 425/500... Training loss: 0.0151\n",
      "Epoch: 425/500... Training loss: 0.0011\n",
      "Epoch: 425/500... Training loss: 0.0014\n",
      "Epoch: 426/500... Training loss: 0.0024\n",
      "Epoch: 426/500... Training loss: 0.0061\n",
      "Epoch: 426/500... Training loss: 0.0028\n",
      "Epoch: 426/500... Training loss: 0.0021\n",
      "Epoch: 426/500... Training loss: 0.0020\n",
      "Epoch: 426/500... Training loss: 0.0145\n",
      "Epoch: 426/500... Training loss: 0.0010\n",
      "Epoch: 426/500... Training loss: 0.0044\n",
      "Epoch: 426/500... Training loss: 0.0009\n",
      "Epoch: 426/500... Training loss: 0.0026\n",
      "Epoch: 426/500... Training loss: 0.0027\n",
      "Epoch: 426/500... Training loss: 0.0029\n",
      "Epoch: 426/500... Training loss: 0.0055\n",
      "Epoch: 426/500... Training loss: 0.0065\n",
      "Epoch: 426/500... Training loss: 0.0197\n",
      "Epoch: 426/500... Training loss: 0.0086\n",
      "Epoch: 426/500... Training loss: 0.0010\n",
      "Epoch: 426/500... Training loss: 0.0094\n",
      "Epoch: 426/500... Training loss: 0.0020\n",
      "Epoch: 426/500... Training loss: 0.0168\n",
      "Epoch: 426/500... Training loss: 0.0024\n",
      "Epoch: 426/500... Training loss: 0.0025\n",
      "Epoch: 426/500... Training loss: 0.0080\n",
      "Epoch: 426/500... Training loss: 0.0016\n",
      "Epoch: 426/500... Training loss: 0.0039\n",
      "Epoch: 426/500... Training loss: 0.0094\n",
      "Epoch: 426/500... Training loss: 0.0034\n",
      "Epoch: 426/500... Training loss: 0.0051\n",
      "Epoch: 426/500... Training loss: 0.0010\n",
      "Epoch: 426/500... Training loss: 0.0064\n",
      "Epoch: 426/500... Training loss: 0.0091\n",
      "Epoch: 427/500... Training loss: 0.0041\n",
      "Epoch: 427/500... Training loss: 0.0849\n",
      "Epoch: 427/500... Training loss: 0.0048\n",
      "Epoch: 427/500... Training loss: 0.0020\n",
      "Epoch: 427/500... Training loss: 0.0456\n",
      "Epoch: 427/500... Training loss: 0.0260\n",
      "Epoch: 427/500... Training loss: 0.0057\n",
      "Epoch: 427/500... Training loss: 0.0022\n",
      "Epoch: 427/500... Training loss: 0.0012\n",
      "Epoch: 427/500... Training loss: 0.0409\n",
      "Epoch: 427/500... Training loss: 0.0056\n",
      "Epoch: 427/500... Training loss: 0.0024\n",
      "Epoch: 427/500... Training loss: 0.0022\n",
      "Epoch: 427/500... Training loss: 0.0013\n",
      "Epoch: 427/500... Training loss: 0.0358\n",
      "Epoch: 427/500... Training loss: 0.0027\n",
      "Epoch: 427/500... Training loss: 0.0011\n",
      "Epoch: 427/500... Training loss: 0.0020\n",
      "Epoch: 427/500... Training loss: 0.0003\n",
      "Epoch: 427/500... Training loss: 0.0354\n",
      "Epoch: 427/500... Training loss: 0.0074\n",
      "Epoch: 427/500... Training loss: 0.0073\n",
      "Epoch: 427/500... Training loss: 0.0041\n",
      "Epoch: 427/500... Training loss: 0.0520\n",
      "Epoch: 427/500... Training loss: 0.0038\n",
      "Epoch: 427/500... Training loss: 0.0452\n",
      "Epoch: 427/500... Training loss: 0.0017\n",
      "Epoch: 427/500... Training loss: 0.0333\n",
      "Epoch: 427/500... Training loss: 0.0011\n",
      "Epoch: 427/500... Training loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 427/500... Training loss: 0.0042\n",
      "Epoch: 428/500... Training loss: 0.0025\n",
      "Epoch: 428/500... Training loss: 0.0101\n",
      "Epoch: 428/500... Training loss: 0.0027\n",
      "Epoch: 428/500... Training loss: 0.0074\n",
      "Epoch: 428/500... Training loss: 0.0009\n",
      "Epoch: 428/500... Training loss: 0.0110\n",
      "Epoch: 428/500... Training loss: 0.0182\n",
      "Epoch: 428/500... Training loss: 0.0005\n",
      "Epoch: 428/500... Training loss: 0.0041\n",
      "Epoch: 428/500... Training loss: 0.0160\n",
      "Epoch: 428/500... Training loss: 0.0045\n",
      "Epoch: 428/500... Training loss: 0.0191\n",
      "Epoch: 428/500... Training loss: 0.0031\n",
      "Epoch: 428/500... Training loss: 0.0346\n",
      "Epoch: 428/500... Training loss: 0.0149\n",
      "Epoch: 428/500... Training loss: 0.0095\n",
      "Epoch: 428/500... Training loss: 0.0114\n",
      "Epoch: 428/500... Training loss: 0.0023\n",
      "Epoch: 428/500... Training loss: 0.0007\n",
      "Epoch: 428/500... Training loss: 0.1304\n",
      "Epoch: 428/500... Training loss: 0.0043\n",
      "Epoch: 428/500... Training loss: 0.0008\n",
      "Epoch: 428/500... Training loss: 0.0081\n",
      "Epoch: 428/500... Training loss: 0.0023\n",
      "Epoch: 428/500... Training loss: 0.0009\n",
      "Epoch: 428/500... Training loss: 0.0008\n",
      "Epoch: 428/500... Training loss: 0.0026\n",
      "Epoch: 428/500... Training loss: 0.0016\n",
      "Epoch: 428/500... Training loss: 0.0328\n",
      "Epoch: 428/500... Training loss: 0.0484\n",
      "Epoch: 428/500... Training loss: 0.0031\n",
      "Epoch: 429/500... Training loss: 0.0022\n",
      "Epoch: 429/500... Training loss: 0.0018\n",
      "Epoch: 429/500... Training loss: 0.0011\n",
      "Epoch: 429/500... Training loss: 0.0043\n",
      "Epoch: 429/500... Training loss: 0.0059\n",
      "Epoch: 429/500... Training loss: 0.0273\n",
      "Epoch: 429/500... Training loss: 0.0443\n",
      "Epoch: 429/500... Training loss: 0.0032\n",
      "Epoch: 429/500... Training loss: 0.0011\n",
      "Epoch: 429/500... Training loss: 0.0031\n",
      "Epoch: 429/500... Training loss: 0.0049\n",
      "Epoch: 429/500... Training loss: 0.0138\n",
      "Epoch: 429/500... Training loss: 0.0013\n",
      "Epoch: 429/500... Training loss: 0.0502\n",
      "Epoch: 429/500... Training loss: 0.0045\n",
      "Epoch: 429/500... Training loss: 0.0005\n",
      "Epoch: 429/500... Training loss: 0.0005\n",
      "Epoch: 429/500... Training loss: 0.0492\n",
      "Epoch: 429/500... Training loss: 0.0013\n",
      "Epoch: 429/500... Training loss: 0.0312\n",
      "Epoch: 429/500... Training loss: 0.0018\n",
      "Epoch: 429/500... Training loss: 0.0010\n",
      "Epoch: 429/500... Training loss: 0.0040\n",
      "Epoch: 429/500... Training loss: 0.0186\n",
      "Epoch: 429/500... Training loss: 0.0122\n",
      "Epoch: 429/500... Training loss: 0.0038\n",
      "Epoch: 429/500... Training loss: 0.0636\n",
      "Epoch: 429/500... Training loss: 0.0033\n",
      "Epoch: 429/500... Training loss: 0.0049\n",
      "Epoch: 429/500... Training loss: 0.0101\n",
      "Epoch: 429/500... Training loss: 0.0017\n",
      "Epoch: 430/500... Training loss: 0.0014\n",
      "Epoch: 430/500... Training loss: 0.0010\n",
      "Epoch: 430/500... Training loss: 0.0186\n",
      "Epoch: 430/500... Training loss: 0.0063\n",
      "Epoch: 430/500... Training loss: 0.0072\n",
      "Epoch: 430/500... Training loss: 0.0312\n",
      "Epoch: 430/500... Training loss: 0.0051\n",
      "Epoch: 430/500... Training loss: 0.0017\n",
      "Epoch: 430/500... Training loss: 0.0010\n",
      "Epoch: 430/500... Training loss: 0.0009\n",
      "Epoch: 430/500... Training loss: 0.0246\n",
      "Epoch: 430/500... Training loss: 0.0048\n",
      "Epoch: 430/500... Training loss: 0.0002\n",
      "Epoch: 430/500... Training loss: 0.0094\n",
      "Epoch: 430/500... Training loss: 0.0006\n",
      "Epoch: 430/500... Training loss: 0.0014\n",
      "Epoch: 430/500... Training loss: 0.0458\n",
      "Epoch: 430/500... Training loss: 0.0121\n",
      "Epoch: 430/500... Training loss: 0.0009\n",
      "Epoch: 430/500... Training loss: 0.0921\n",
      "Epoch: 430/500... Training loss: 0.0004\n",
      "Epoch: 430/500... Training loss: 0.0161\n",
      "Epoch: 430/500... Training loss: 0.0278\n",
      "Epoch: 430/500... Training loss: 0.0191\n",
      "Epoch: 430/500... Training loss: 0.0082\n",
      "Epoch: 430/500... Training loss: 0.0048\n",
      "Epoch: 430/500... Training loss: 0.0013\n",
      "Epoch: 430/500... Training loss: 0.0080\n",
      "Epoch: 430/500... Training loss: 0.0010\n",
      "Epoch: 430/500... Training loss: 0.0045\n",
      "Epoch: 430/500... Training loss: 0.0016\n",
      "Epoch: 431/500... Training loss: 0.0015\n",
      "Epoch: 431/500... Training loss: 0.0009\n",
      "Epoch: 431/500... Training loss: 0.0097\n",
      "Epoch: 431/500... Training loss: 0.0080\n",
      "Epoch: 431/500... Training loss: 0.0009\n",
      "Epoch: 431/500... Training loss: 0.0050\n",
      "Epoch: 431/500... Training loss: 0.0019\n",
      "Epoch: 431/500... Training loss: 0.0430\n",
      "Epoch: 431/500... Training loss: 0.0016\n",
      "Epoch: 431/500... Training loss: 0.0588\n",
      "Epoch: 431/500... Training loss: 0.0021\n",
      "Epoch: 431/500... Training loss: 0.0205\n",
      "Epoch: 431/500... Training loss: 0.0005\n",
      "Epoch: 431/500... Training loss: 0.0120\n",
      "Epoch: 431/500... Training loss: 0.0060\n",
      "Epoch: 431/500... Training loss: 0.0013\n",
      "Epoch: 431/500... Training loss: 0.0012\n",
      "Epoch: 431/500... Training loss: 0.0106\n",
      "Epoch: 431/500... Training loss: 0.0051\n",
      "Epoch: 431/500... Training loss: 0.0008\n",
      "Epoch: 431/500... Training loss: 0.0009\n",
      "Epoch: 431/500... Training loss: 0.0025\n",
      "Epoch: 431/500... Training loss: 0.0049\n",
      "Epoch: 431/500... Training loss: 0.0016\n",
      "Epoch: 431/500... Training loss: 0.0669\n",
      "Epoch: 431/500... Training loss: 0.0044\n",
      "Epoch: 431/500... Training loss: 0.0031\n",
      "Epoch: 431/500... Training loss: 0.0208\n",
      "Epoch: 431/500... Training loss: 0.0019\n",
      "Epoch: 431/500... Training loss: 0.0396\n",
      "Epoch: 431/500... Training loss: 0.0449\n",
      "Epoch: 432/500... Training loss: 0.0059\n",
      "Epoch: 432/500... Training loss: 0.0059\n",
      "Epoch: 432/500... Training loss: 0.0161\n",
      "Epoch: 432/500... Training loss: 0.0770\n",
      "Epoch: 432/500... Training loss: 0.0017\n",
      "Epoch: 432/500... Training loss: 0.0070\n",
      "Epoch: 432/500... Training loss: 0.0113\n",
      "Epoch: 432/500... Training loss: 0.0010\n",
      "Epoch: 432/500... Training loss: 0.0007\n",
      "Epoch: 432/500... Training loss: 0.0183\n",
      "Epoch: 432/500... Training loss: 0.0274\n",
      "Epoch: 432/500... Training loss: 0.0253\n",
      "Epoch: 432/500... Training loss: 0.0010\n",
      "Epoch: 432/500... Training loss: 0.0031\n",
      "Epoch: 432/500... Training loss: 0.0054\n",
      "Epoch: 432/500... Training loss: 0.0009\n",
      "Epoch: 432/500... Training loss: 0.0314\n",
      "Epoch: 432/500... Training loss: 0.0071\n",
      "Epoch: 432/500... Training loss: 0.0132\n",
      "Epoch: 432/500... Training loss: 0.0005\n",
      "Epoch: 432/500... Training loss: 0.0074\n",
      "Epoch: 432/500... Training loss: 0.0119\n",
      "Epoch: 432/500... Training loss: 0.0269\n",
      "Epoch: 432/500... Training loss: 0.0025\n",
      "Epoch: 432/500... Training loss: 0.0190\n",
      "Epoch: 432/500... Training loss: 0.0018\n",
      "Epoch: 432/500... Training loss: 0.0017\n",
      "Epoch: 432/500... Training loss: 0.0077\n",
      "Epoch: 432/500... Training loss: 0.0051\n",
      "Epoch: 432/500... Training loss: 0.0042\n",
      "Epoch: 432/500... Training loss: 0.0696\n",
      "Epoch: 433/500... Training loss: 0.0199\n",
      "Epoch: 433/500... Training loss: 0.0047\n",
      "Epoch: 433/500... Training loss: 0.0065\n",
      "Epoch: 433/500... Training loss: 0.0012\n",
      "Epoch: 433/500... Training loss: 0.0012\n",
      "Epoch: 433/500... Training loss: 0.0340\n",
      "Epoch: 433/500... Training loss: 0.0013\n",
      "Epoch: 433/500... Training loss: 0.0113\n",
      "Epoch: 433/500... Training loss: 0.0051\n",
      "Epoch: 433/500... Training loss: 0.0339\n",
      "Epoch: 433/500... Training loss: 0.0069\n",
      "Epoch: 433/500... Training loss: 0.0049\n",
      "Epoch: 433/500... Training loss: 0.0017\n",
      "Epoch: 433/500... Training loss: 0.0013\n",
      "Epoch: 433/500... Training loss: 0.0187\n",
      "Epoch: 433/500... Training loss: 0.0004\n",
      "Epoch: 433/500... Training loss: 0.0007\n",
      "Epoch: 433/500... Training loss: 0.0690\n",
      "Epoch: 433/500... Training loss: 0.0027\n",
      "Epoch: 433/500... Training loss: 0.0045\n",
      "Epoch: 433/500... Training loss: 0.0020\n",
      "Epoch: 433/500... Training loss: 0.0008\n",
      "Epoch: 433/500... Training loss: 0.0050\n",
      "Epoch: 433/500... Training loss: 0.0064\n",
      "Epoch: 433/500... Training loss: 0.0007\n",
      "Epoch: 433/500... Training loss: 0.0028\n",
      "Epoch: 433/500... Training loss: 0.0625\n",
      "Epoch: 433/500... Training loss: 0.0045\n",
      "Epoch: 433/500... Training loss: 0.0060\n",
      "Epoch: 433/500... Training loss: 0.0044\n",
      "Epoch: 433/500... Training loss: 0.0016\n",
      "Epoch: 434/500... Training loss: 0.0143\n",
      "Epoch: 434/500... Training loss: 0.0286\n",
      "Epoch: 434/500... Training loss: 0.0153\n",
      "Epoch: 434/500... Training loss: 0.0376\n",
      "Epoch: 434/500... Training loss: 0.0006\n",
      "Epoch: 434/500... Training loss: 0.0018\n",
      "Epoch: 434/500... Training loss: 0.0020\n",
      "Epoch: 434/500... Training loss: 0.0069\n",
      "Epoch: 434/500... Training loss: 0.0084\n",
      "Epoch: 434/500... Training loss: 0.0022\n",
      "Epoch: 434/500... Training loss: 0.0034\n",
      "Epoch: 434/500... Training loss: 0.0241\n",
      "Epoch: 434/500... Training loss: 0.0005\n",
      "Epoch: 434/500... Training loss: 0.0131\n",
      "Epoch: 434/500... Training loss: 0.0327\n",
      "Epoch: 434/500... Training loss: 0.0133\n",
      "Epoch: 434/500... Training loss: 0.0018\n",
      "Epoch: 434/500... Training loss: 0.0294\n",
      "Epoch: 434/500... Training loss: 0.0007\n",
      "Epoch: 434/500... Training loss: 0.0092\n",
      "Epoch: 434/500... Training loss: 0.0012\n",
      "Epoch: 434/500... Training loss: 0.0232\n",
      "Epoch: 434/500... Training loss: 0.0258\n",
      "Epoch: 434/500... Training loss: 0.0062\n",
      "Epoch: 434/500... Training loss: 0.0056\n",
      "Epoch: 434/500... Training loss: 0.0164\n",
      "Epoch: 434/500... Training loss: 0.0023\n",
      "Epoch: 434/500... Training loss: 0.0027\n",
      "Epoch: 434/500... Training loss: 0.0030\n",
      "Epoch: 434/500... Training loss: 0.0037\n",
      "Epoch: 434/500... Training loss: 0.0039\n",
      "Epoch: 435/500... Training loss: 0.0139\n",
      "Epoch: 435/500... Training loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 435/500... Training loss: 0.0049\n",
      "Epoch: 435/500... Training loss: 0.0022\n",
      "Epoch: 435/500... Training loss: 0.0028\n",
      "Epoch: 435/500... Training loss: 0.0143\n",
      "Epoch: 435/500... Training loss: 0.1109\n",
      "Epoch: 435/500... Training loss: 0.0039\n",
      "Epoch: 435/500... Training loss: 0.0090\n",
      "Epoch: 435/500... Training loss: 0.0033\n",
      "Epoch: 435/500... Training loss: 0.0197\n",
      "Epoch: 435/500... Training loss: 0.0198\n",
      "Epoch: 435/500... Training loss: 0.0021\n",
      "Epoch: 435/500... Training loss: 0.0022\n",
      "Epoch: 435/500... Training loss: 0.0029\n",
      "Epoch: 435/500... Training loss: 0.0020\n",
      "Epoch: 435/500... Training loss: 0.0021\n",
      "Epoch: 435/500... Training loss: 0.0763\n",
      "Epoch: 435/500... Training loss: 0.0009\n",
      "Epoch: 435/500... Training loss: 0.0041\n",
      "Epoch: 435/500... Training loss: 0.0228\n",
      "Epoch: 435/500... Training loss: 0.0022\n",
      "Epoch: 435/500... Training loss: 0.0291\n",
      "Epoch: 435/500... Training loss: 0.0023\n",
      "Epoch: 435/500... Training loss: 0.0135\n",
      "Epoch: 435/500... Training loss: 0.0141\n",
      "Epoch: 435/500... Training loss: 0.0015\n",
      "Epoch: 435/500... Training loss: 0.0017\n",
      "Epoch: 435/500... Training loss: 0.0454\n",
      "Epoch: 435/500... Training loss: 0.0011\n",
      "Epoch: 435/500... Training loss: 0.0312\n",
      "Epoch: 436/500... Training loss: 0.0241\n",
      "Epoch: 436/500... Training loss: 0.0178\n",
      "Epoch: 436/500... Training loss: 0.0772\n",
      "Epoch: 436/500... Training loss: 0.0779\n",
      "Epoch: 436/500... Training loss: 0.0039\n",
      "Epoch: 436/500... Training loss: 0.0029\n",
      "Epoch: 436/500... Training loss: 0.0486\n",
      "Epoch: 436/500... Training loss: 0.0018\n",
      "Epoch: 436/500... Training loss: 0.0392\n",
      "Epoch: 436/500... Training loss: 0.0024\n",
      "Epoch: 436/500... Training loss: 0.0039\n",
      "Epoch: 436/500... Training loss: 0.0100\n",
      "Epoch: 436/500... Training loss: 0.0100\n",
      "Epoch: 436/500... Training loss: 0.0041\n",
      "Epoch: 436/500... Training loss: 0.0073\n",
      "Epoch: 436/500... Training loss: 0.0014\n",
      "Epoch: 436/500... Training loss: 0.0160\n",
      "Epoch: 436/500... Training loss: 0.0022\n",
      "Epoch: 436/500... Training loss: 0.0036\n",
      "Epoch: 436/500... Training loss: 0.0009\n",
      "Epoch: 436/500... Training loss: 0.1532\n",
      "Epoch: 436/500... Training loss: 0.0033\n",
      "Epoch: 436/500... Training loss: 0.0027\n",
      "Epoch: 436/500... Training loss: 0.0012\n",
      "Epoch: 436/500... Training loss: 0.0084\n",
      "Epoch: 436/500... Training loss: 0.0042\n",
      "Epoch: 436/500... Training loss: 0.0071\n",
      "Epoch: 436/500... Training loss: 0.0059\n",
      "Epoch: 436/500... Training loss: 0.0030\n",
      "Epoch: 436/500... Training loss: 0.0028\n",
      "Epoch: 436/500... Training loss: 0.0080\n",
      "Epoch: 437/500... Training loss: 0.0104\n",
      "Epoch: 437/500... Training loss: 0.0394\n",
      "Epoch: 437/500... Training loss: 0.0033\n",
      "Epoch: 437/500... Training loss: 0.0298\n",
      "Epoch: 437/500... Training loss: 0.0212\n",
      "Epoch: 437/500... Training loss: 0.0128\n",
      "Epoch: 437/500... Training loss: 0.0558\n",
      "Epoch: 437/500... Training loss: 0.0115\n",
      "Epoch: 437/500... Training loss: 0.0076\n",
      "Epoch: 437/500... Training loss: 0.0082\n",
      "Epoch: 437/500... Training loss: 0.0023\n",
      "Epoch: 437/500... Training loss: 0.0012\n",
      "Epoch: 437/500... Training loss: 0.0008\n",
      "Epoch: 437/500... Training loss: 0.0358\n",
      "Epoch: 437/500... Training loss: 0.0039\n",
      "Epoch: 437/500... Training loss: 0.0017\n",
      "Epoch: 437/500... Training loss: 0.0043\n",
      "Epoch: 437/500... Training loss: 0.0006\n",
      "Epoch: 437/500... Training loss: 0.0376\n",
      "Epoch: 437/500... Training loss: 0.0100\n",
      "Epoch: 437/500... Training loss: 0.0074\n",
      "Epoch: 437/500... Training loss: 0.0136\n",
      "Epoch: 437/500... Training loss: 0.1041\n",
      "Epoch: 437/500... Training loss: 0.0260\n",
      "Epoch: 437/500... Training loss: 0.0020\n",
      "Epoch: 437/500... Training loss: 0.0020\n",
      "Epoch: 437/500... Training loss: 0.0141\n",
      "Epoch: 437/500... Training loss: 0.0042\n",
      "Epoch: 437/500... Training loss: 0.0289\n",
      "Epoch: 437/500... Training loss: 0.0048\n",
      "Epoch: 437/500... Training loss: 0.0050\n",
      "Epoch: 438/500... Training loss: 0.0011\n",
      "Epoch: 438/500... Training loss: 0.0107\n",
      "Epoch: 438/500... Training loss: 0.0091\n",
      "Epoch: 438/500... Training loss: 0.0028\n",
      "Epoch: 438/500... Training loss: 0.0080\n",
      "Epoch: 438/500... Training loss: 0.0033\n",
      "Epoch: 438/500... Training loss: 0.0178\n",
      "Epoch: 438/500... Training loss: 0.0360\n",
      "Epoch: 438/500... Training loss: 0.0168\n",
      "Epoch: 438/500... Training loss: 0.0048\n",
      "Epoch: 438/500... Training loss: 0.0037\n",
      "Epoch: 438/500... Training loss: 0.0075\n",
      "Epoch: 438/500... Training loss: 0.0021\n",
      "Epoch: 438/500... Training loss: 0.0039\n",
      "Epoch: 438/500... Training loss: 0.0019\n",
      "Epoch: 438/500... Training loss: 0.0018\n",
      "Epoch: 438/500... Training loss: 0.0062\n",
      "Epoch: 438/500... Training loss: 0.0131\n",
      "Epoch: 438/500... Training loss: 0.0034\n",
      "Epoch: 438/500... Training loss: 0.0028\n",
      "Epoch: 438/500... Training loss: 0.0207\n",
      "Epoch: 438/500... Training loss: 0.0117\n",
      "Epoch: 438/500... Training loss: 0.0617\n",
      "Epoch: 438/500... Training loss: 0.0042\n",
      "Epoch: 438/500... Training loss: 0.0111\n",
      "Epoch: 438/500... Training loss: 0.0325\n",
      "Epoch: 438/500... Training loss: 0.0160\n",
      "Epoch: 438/500... Training loss: 0.0017\n",
      "Epoch: 438/500... Training loss: 0.0050\n",
      "Epoch: 438/500... Training loss: 0.0013\n",
      "Epoch: 438/500... Training loss: 0.0035\n",
      "Epoch: 439/500... Training loss: 0.0055\n",
      "Epoch: 439/500... Training loss: 0.0012\n",
      "Epoch: 439/500... Training loss: 0.0287\n",
      "Epoch: 439/500... Training loss: 0.0065\n",
      "Epoch: 439/500... Training loss: 0.0918\n",
      "Epoch: 439/500... Training loss: 0.1093\n",
      "Epoch: 439/500... Training loss: 0.0126\n",
      "Epoch: 439/500... Training loss: 0.0024\n",
      "Epoch: 439/500... Training loss: 0.0279\n",
      "Epoch: 439/500... Training loss: 0.0012\n",
      "Epoch: 439/500... Training loss: 0.0118\n",
      "Epoch: 439/500... Training loss: 0.0702\n",
      "Epoch: 439/500... Training loss: 0.0034\n",
      "Epoch: 439/500... Training loss: 0.0239\n",
      "Epoch: 439/500... Training loss: 0.0012\n",
      "Epoch: 439/500... Training loss: 0.0033\n",
      "Epoch: 439/500... Training loss: 0.0028\n",
      "Epoch: 439/500... Training loss: 0.0022\n",
      "Epoch: 439/500... Training loss: 0.0054\n",
      "Epoch: 439/500... Training loss: 0.0068\n",
      "Epoch: 439/500... Training loss: 0.0009\n",
      "Epoch: 439/500... Training loss: 0.0092\n",
      "Epoch: 439/500... Training loss: 0.0205\n",
      "Epoch: 439/500... Training loss: 0.0008\n",
      "Epoch: 439/500... Training loss: 0.0184\n",
      "Epoch: 439/500... Training loss: 0.0189\n",
      "Epoch: 439/500... Training loss: 0.0387\n",
      "Epoch: 439/500... Training loss: 0.0027\n",
      "Epoch: 439/500... Training loss: 0.0180\n",
      "Epoch: 439/500... Training loss: 0.0063\n",
      "Epoch: 439/500... Training loss: 0.0006\n",
      "Epoch: 440/500... Training loss: 0.0577\n",
      "Epoch: 440/500... Training loss: 0.0035\n",
      "Epoch: 440/500... Training loss: 0.0141\n",
      "Epoch: 440/500... Training loss: 0.0023\n",
      "Epoch: 440/500... Training loss: 0.0259\n",
      "Epoch: 440/500... Training loss: 0.0251\n",
      "Epoch: 440/500... Training loss: 0.0045\n",
      "Epoch: 440/500... Training loss: 0.0008\n",
      "Epoch: 440/500... Training loss: 0.0147\n",
      "Epoch: 440/500... Training loss: 0.0011\n",
      "Epoch: 440/500... Training loss: 0.0173\n",
      "Epoch: 440/500... Training loss: 0.0015\n",
      "Epoch: 440/500... Training loss: 0.0040\n",
      "Epoch: 440/500... Training loss: 0.0121\n",
      "Epoch: 440/500... Training loss: 0.0081\n",
      "Epoch: 440/500... Training loss: 0.0155\n",
      "Epoch: 440/500... Training loss: 0.0069\n",
      "Epoch: 440/500... Training loss: 0.0309\n",
      "Epoch: 440/500... Training loss: 0.0028\n",
      "Epoch: 440/500... Training loss: 0.0029\n",
      "Epoch: 440/500... Training loss: 0.0067\n",
      "Epoch: 440/500... Training loss: 0.0139\n",
      "Epoch: 440/500... Training loss: 0.0008\n",
      "Epoch: 440/500... Training loss: 0.0241\n",
      "Epoch: 440/500... Training loss: 0.0207\n",
      "Epoch: 440/500... Training loss: 0.0110\n",
      "Epoch: 440/500... Training loss: 0.0012\n",
      "Epoch: 440/500... Training loss: 0.0012\n",
      "Epoch: 440/500... Training loss: 0.0212\n",
      "Epoch: 440/500... Training loss: 0.0016\n",
      "Epoch: 440/500... Training loss: 0.0007\n",
      "Epoch: 441/500... Training loss: 0.0042\n",
      "Epoch: 441/500... Training loss: 0.0013\n",
      "Epoch: 441/500... Training loss: 0.0027\n",
      "Epoch: 441/500... Training loss: 0.0121\n",
      "Epoch: 441/500... Training loss: 0.0044\n",
      "Epoch: 441/500... Training loss: 0.0235\n",
      "Epoch: 441/500... Training loss: 0.0023\n",
      "Epoch: 441/500... Training loss: 0.0010\n",
      "Epoch: 441/500... Training loss: 0.0128\n",
      "Epoch: 441/500... Training loss: 0.0087\n",
      "Epoch: 441/500... Training loss: 0.0019\n",
      "Epoch: 441/500... Training loss: 0.0009\n",
      "Epoch: 441/500... Training loss: 0.1000\n",
      "Epoch: 441/500... Training loss: 0.0131\n",
      "Epoch: 441/500... Training loss: 0.0027\n",
      "Epoch: 441/500... Training loss: 0.0027\n",
      "Epoch: 441/500... Training loss: 0.0150\n",
      "Epoch: 441/500... Training loss: 0.0424\n",
      "Epoch: 441/500... Training loss: 0.0011\n",
      "Epoch: 441/500... Training loss: 0.0004\n",
      "Epoch: 441/500... Training loss: 0.0012\n",
      "Epoch: 441/500... Training loss: 0.0010\n",
      "Epoch: 441/500... Training loss: 0.0175\n",
      "Epoch: 441/500... Training loss: 0.0620\n",
      "Epoch: 441/500... Training loss: 0.0012\n",
      "Epoch: 441/500... Training loss: 0.0010\n",
      "Epoch: 441/500... Training loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 441/500... Training loss: 0.0477\n",
      "Epoch: 441/500... Training loss: 0.0089\n",
      "Epoch: 441/500... Training loss: 0.0012\n",
      "Epoch: 441/500... Training loss: 0.0108\n",
      "Epoch: 442/500... Training loss: 0.0016\n",
      "Epoch: 442/500... Training loss: 0.0010\n",
      "Epoch: 442/500... Training loss: 0.0056\n",
      "Epoch: 442/500... Training loss: 0.0104\n",
      "Epoch: 442/500... Training loss: 0.0014\n",
      "Epoch: 442/500... Training loss: 0.0111\n",
      "Epoch: 442/500... Training loss: 0.0237\n",
      "Epoch: 442/500... Training loss: 0.0023\n",
      "Epoch: 442/500... Training loss: 0.0184\n",
      "Epoch: 442/500... Training loss: 0.0162\n",
      "Epoch: 442/500... Training loss: 0.0381\n",
      "Epoch: 442/500... Training loss: 0.0126\n",
      "Epoch: 442/500... Training loss: 0.0142\n",
      "Epoch: 442/500... Training loss: 0.0004\n",
      "Epoch: 442/500... Training loss: 0.0026\n",
      "Epoch: 442/500... Training loss: 0.0009\n",
      "Epoch: 442/500... Training loss: 0.0176\n",
      "Epoch: 442/500... Training loss: 0.0047\n",
      "Epoch: 442/500... Training loss: 0.0008\n",
      "Epoch: 442/500... Training loss: 0.0016\n",
      "Epoch: 442/500... Training loss: 0.0120\n",
      "Epoch: 442/500... Training loss: 0.0017\n",
      "Epoch: 442/500... Training loss: 0.0112\n",
      "Epoch: 442/500... Training loss: 0.0022\n",
      "Epoch: 442/500... Training loss: 0.0018\n",
      "Epoch: 442/500... Training loss: 0.0033\n",
      "Epoch: 442/500... Training loss: 0.0009\n",
      "Epoch: 442/500... Training loss: 0.0189\n",
      "Epoch: 442/500... Training loss: 0.0023\n",
      "Epoch: 442/500... Training loss: 0.0006\n",
      "Epoch: 442/500... Training loss: 0.0062\n",
      "Epoch: 443/500... Training loss: 0.0050\n",
      "Epoch: 443/500... Training loss: 0.0577\n",
      "Epoch: 443/500... Training loss: 0.0048\n",
      "Epoch: 443/500... Training loss: 0.0034\n",
      "Epoch: 443/500... Training loss: 0.0072\n",
      "Epoch: 443/500... Training loss: 0.0189\n",
      "Epoch: 443/500... Training loss: 0.0216\n",
      "Epoch: 443/500... Training loss: 0.0014\n",
      "Epoch: 443/500... Training loss: 0.0213\n",
      "Epoch: 443/500... Training loss: 0.0078\n",
      "Epoch: 443/500... Training loss: 0.0012\n",
      "Epoch: 443/500... Training loss: 0.0015\n",
      "Epoch: 443/500... Training loss: 0.1115\n",
      "Epoch: 443/500... Training loss: 0.1009\n",
      "Epoch: 443/500... Training loss: 0.0021\n",
      "Epoch: 443/500... Training loss: 0.0028\n",
      "Epoch: 443/500... Training loss: 0.0031\n",
      "Epoch: 443/500... Training loss: 0.0418\n",
      "Epoch: 443/500... Training loss: 0.0090\n",
      "Epoch: 443/500... Training loss: 0.0008\n",
      "Epoch: 443/500... Training loss: 0.0008\n",
      "Epoch: 443/500... Training loss: 0.0089\n",
      "Epoch: 443/500... Training loss: 0.0013\n",
      "Epoch: 443/500... Training loss: 0.0066\n",
      "Epoch: 443/500... Training loss: 0.0230\n",
      "Epoch: 443/500... Training loss: 0.0030\n",
      "Epoch: 443/500... Training loss: 0.0007\n",
      "Epoch: 443/500... Training loss: 0.0014\n",
      "Epoch: 443/500... Training loss: 0.0047\n",
      "Epoch: 443/500... Training loss: 0.0147\n",
      "Epoch: 443/500... Training loss: 0.0025\n",
      "Epoch: 444/500... Training loss: 0.0031\n",
      "Epoch: 444/500... Training loss: 0.0525\n",
      "Epoch: 444/500... Training loss: 0.0115\n",
      "Epoch: 444/500... Training loss: 0.0567\n",
      "Epoch: 444/500... Training loss: 0.0015\n",
      "Epoch: 444/500... Training loss: 0.0041\n",
      "Epoch: 444/500... Training loss: 0.0129\n",
      "Epoch: 444/500... Training loss: 0.0010\n",
      "Epoch: 444/500... Training loss: 0.0267\n",
      "Epoch: 444/500... Training loss: 0.0011\n",
      "Epoch: 444/500... Training loss: 0.0235\n",
      "Epoch: 444/500... Training loss: 0.1115\n",
      "Epoch: 444/500... Training loss: 0.0234\n",
      "Epoch: 444/500... Training loss: 0.0264\n",
      "Epoch: 444/500... Training loss: 0.0010\n",
      "Epoch: 444/500... Training loss: 0.0010\n",
      "Epoch: 444/500... Training loss: 0.0020\n",
      "Epoch: 444/500... Training loss: 0.0038\n",
      "Epoch: 444/500... Training loss: 0.0073\n",
      "Epoch: 444/500... Training loss: 0.0020\n",
      "Epoch: 444/500... Training loss: 0.0015\n",
      "Epoch: 444/500... Training loss: 0.0268\n",
      "Epoch: 444/500... Training loss: 0.0392\n",
      "Epoch: 444/500... Training loss: 0.0029\n",
      "Epoch: 444/500... Training loss: 0.0036\n",
      "Epoch: 444/500... Training loss: 0.0034\n",
      "Epoch: 444/500... Training loss: 0.0006\n",
      "Epoch: 444/500... Training loss: 0.0191\n",
      "Epoch: 444/500... Training loss: 0.0037\n",
      "Epoch: 444/500... Training loss: 0.0041\n",
      "Epoch: 444/500... Training loss: 0.0528\n",
      "Epoch: 445/500... Training loss: 0.0172\n",
      "Epoch: 445/500... Training loss: 0.0018\n",
      "Epoch: 445/500... Training loss: 0.0038\n",
      "Epoch: 445/500... Training loss: 0.0010\n",
      "Epoch: 445/500... Training loss: 0.0237\n",
      "Epoch: 445/500... Training loss: 0.0042\n",
      "Epoch: 445/500... Training loss: 0.0374\n",
      "Epoch: 445/500... Training loss: 0.0118\n",
      "Epoch: 445/500... Training loss: 0.0017\n",
      "Epoch: 445/500... Training loss: 0.0038\n",
      "Epoch: 445/500... Training loss: 0.0028\n",
      "Epoch: 445/500... Training loss: 0.0017\n",
      "Epoch: 445/500... Training loss: 0.0064\n",
      "Epoch: 445/500... Training loss: 0.0012\n",
      "Epoch: 445/500... Training loss: 0.0257\n",
      "Epoch: 445/500... Training loss: 0.0007\n",
      "Epoch: 445/500... Training loss: 0.0103\n",
      "Epoch: 445/500... Training loss: 0.0205\n",
      "Epoch: 445/500... Training loss: 0.0283\n",
      "Epoch: 445/500... Training loss: 0.0012\n",
      "Epoch: 445/500... Training loss: 0.0012\n",
      "Epoch: 445/500... Training loss: 0.0040\n",
      "Epoch: 445/500... Training loss: 0.0009\n",
      "Epoch: 445/500... Training loss: 0.0024\n",
      "Epoch: 445/500... Training loss: 0.0045\n",
      "Epoch: 445/500... Training loss: 0.0145\n",
      "Epoch: 445/500... Training loss: 0.0027\n",
      "Epoch: 445/500... Training loss: 0.0117\n",
      "Epoch: 445/500... Training loss: 0.0076\n",
      "Epoch: 445/500... Training loss: 0.0399\n",
      "Epoch: 445/500... Training loss: 0.0209\n",
      "Epoch: 446/500... Training loss: 0.0541\n",
      "Epoch: 446/500... Training loss: 0.0081\n",
      "Epoch: 446/500... Training loss: 0.0006\n",
      "Epoch: 446/500... Training loss: 0.0040\n",
      "Epoch: 446/500... Training loss: 0.0036\n",
      "Epoch: 446/500... Training loss: 0.0207\n",
      "Epoch: 446/500... Training loss: 0.0034\n",
      "Epoch: 446/500... Training loss: 0.0040\n",
      "Epoch: 446/500... Training loss: 0.0035\n",
      "Epoch: 446/500... Training loss: 0.0048\n",
      "Epoch: 446/500... Training loss: 0.0007\n",
      "Epoch: 446/500... Training loss: 0.0021\n",
      "Epoch: 446/500... Training loss: 0.0110\n",
      "Epoch: 446/500... Training loss: 0.0075\n",
      "Epoch: 446/500... Training loss: 0.0050\n",
      "Epoch: 446/500... Training loss: 0.0026\n",
      "Epoch: 446/500... Training loss: 0.0015\n",
      "Epoch: 446/500... Training loss: 0.0040\n",
      "Epoch: 446/500... Training loss: 0.0018\n",
      "Epoch: 446/500... Training loss: 0.0010\n",
      "Epoch: 446/500... Training loss: 0.0075\n",
      "Epoch: 446/500... Training loss: 0.0081\n",
      "Epoch: 446/500... Training loss: 0.0057\n",
      "Epoch: 446/500... Training loss: 0.0008\n",
      "Epoch: 446/500... Training loss: 0.0075\n",
      "Epoch: 446/500... Training loss: 0.0057\n",
      "Epoch: 446/500... Training loss: 0.0004\n",
      "Epoch: 446/500... Training loss: 0.0053\n",
      "Epoch: 446/500... Training loss: 0.0752\n",
      "Epoch: 446/500... Training loss: 0.0467\n",
      "Epoch: 446/500... Training loss: 0.0045\n",
      "Epoch: 447/500... Training loss: 0.0026\n",
      "Epoch: 447/500... Training loss: 0.0033\n",
      "Epoch: 447/500... Training loss: 0.0073\n",
      "Epoch: 447/500... Training loss: 0.0036\n",
      "Epoch: 447/500... Training loss: 0.0234\n",
      "Epoch: 447/500... Training loss: 0.1272\n",
      "Epoch: 447/500... Training loss: 0.1915\n",
      "Epoch: 447/500... Training loss: 0.0172\n",
      "Epoch: 447/500... Training loss: 0.0094\n",
      "Epoch: 447/500... Training loss: 0.0022\n",
      "Epoch: 447/500... Training loss: 0.0032\n",
      "Epoch: 447/500... Training loss: 0.0185\n",
      "Epoch: 447/500... Training loss: 0.0022\n",
      "Epoch: 447/500... Training loss: 0.0045\n",
      "Epoch: 447/500... Training loss: 0.0141\n",
      "Epoch: 447/500... Training loss: 0.0053\n",
      "Epoch: 447/500... Training loss: 0.0048\n",
      "Epoch: 447/500... Training loss: 0.0017\n",
      "Epoch: 447/500... Training loss: 0.0040\n",
      "Epoch: 447/500... Training loss: 0.0015\n",
      "Epoch: 447/500... Training loss: 0.0456\n",
      "Epoch: 447/500... Training loss: 0.0018\n",
      "Epoch: 447/500... Training loss: 0.0768\n",
      "Epoch: 447/500... Training loss: 0.0034\n",
      "Epoch: 447/500... Training loss: 0.0021\n",
      "Epoch: 447/500... Training loss: 0.0026\n",
      "Epoch: 447/500... Training loss: 0.0042\n",
      "Epoch: 447/500... Training loss: 0.0016\n",
      "Epoch: 447/500... Training loss: 0.0072\n",
      "Epoch: 447/500... Training loss: 0.0441\n",
      "Epoch: 447/500... Training loss: 0.0205\n",
      "Epoch: 448/500... Training loss: 0.0005\n",
      "Epoch: 448/500... Training loss: 0.0012\n",
      "Epoch: 448/500... Training loss: 0.0049\n",
      "Epoch: 448/500... Training loss: 0.0421\n",
      "Epoch: 448/500... Training loss: 0.0579\n",
      "Epoch: 448/500... Training loss: 0.0740\n",
      "Epoch: 448/500... Training loss: 0.0034\n",
      "Epoch: 448/500... Training loss: 0.0009\n",
      "Epoch: 448/500... Training loss: 0.0706\n",
      "Epoch: 448/500... Training loss: 0.0030\n",
      "Epoch: 448/500... Training loss: 0.0031\n",
      "Epoch: 448/500... Training loss: 0.0076\n",
      "Epoch: 448/500... Training loss: 0.0064\n",
      "Epoch: 448/500... Training loss: 0.0071\n",
      "Epoch: 448/500... Training loss: 0.0062\n",
      "Epoch: 448/500... Training loss: 0.0022\n",
      "Epoch: 448/500... Training loss: 0.0031\n",
      "Epoch: 448/500... Training loss: 0.0370\n",
      "Epoch: 448/500... Training loss: 0.0005\n",
      "Epoch: 448/500... Training loss: 0.0075\n",
      "Epoch: 448/500... Training loss: 0.0050\n",
      "Epoch: 448/500... Training loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 448/500... Training loss: 0.0085\n",
      "Epoch: 448/500... Training loss: 0.0023\n",
      "Epoch: 448/500... Training loss: 0.0023\n",
      "Epoch: 448/500... Training loss: 0.0004\n",
      "Epoch: 448/500... Training loss: 0.0398\n",
      "Epoch: 448/500... Training loss: 0.0015\n",
      "Epoch: 448/500... Training loss: 0.0275\n",
      "Epoch: 448/500... Training loss: 0.0007\n",
      "Epoch: 448/500... Training loss: 0.0037\n",
      "Epoch: 449/500... Training loss: 0.0017\n",
      "Epoch: 449/500... Training loss: 0.0036\n",
      "Epoch: 449/500... Training loss: 0.0015\n",
      "Epoch: 449/500... Training loss: 0.0125\n",
      "Epoch: 449/500... Training loss: 0.0480\n",
      "Epoch: 449/500... Training loss: 0.0066\n",
      "Epoch: 449/500... Training loss: 0.0032\n",
      "Epoch: 449/500... Training loss: 0.0067\n",
      "Epoch: 449/500... Training loss: 0.0054\n",
      "Epoch: 449/500... Training loss: 0.0217\n",
      "Epoch: 449/500... Training loss: 0.0031\n",
      "Epoch: 449/500... Training loss: 0.0055\n",
      "Epoch: 449/500... Training loss: 0.0030\n",
      "Epoch: 449/500... Training loss: 0.0015\n",
      "Epoch: 449/500... Training loss: 0.0074\n",
      "Epoch: 449/500... Training loss: 0.0377\n",
      "Epoch: 449/500... Training loss: 0.0021\n",
      "Epoch: 449/500... Training loss: 0.0204\n",
      "Epoch: 449/500... Training loss: 0.0013\n",
      "Epoch: 449/500... Training loss: 0.0014\n",
      "Epoch: 449/500... Training loss: 0.0013\n",
      "Epoch: 449/500... Training loss: 0.0268\n",
      "Epoch: 449/500... Training loss: 0.0193\n",
      "Epoch: 449/500... Training loss: 0.0043\n",
      "Epoch: 449/500... Training loss: 0.0013\n",
      "Epoch: 449/500... Training loss: 0.0010\n",
      "Epoch: 449/500... Training loss: 0.0093\n",
      "Epoch: 449/500... Training loss: 0.0010\n",
      "Epoch: 449/500... Training loss: 0.0260\n",
      "Epoch: 449/500... Training loss: 0.0075\n",
      "Epoch: 449/500... Training loss: 0.0041\n",
      "Epoch: 450/500... Training loss: 0.0115\n",
      "Epoch: 450/500... Training loss: 0.0044\n",
      "Epoch: 450/500... Training loss: 0.0148\n",
      "Epoch: 450/500... Training loss: 0.1587\n",
      "Epoch: 450/500... Training loss: 0.0040\n",
      "Epoch: 450/500... Training loss: 0.0088\n",
      "Epoch: 450/500... Training loss: 0.0203\n",
      "Epoch: 450/500... Training loss: 0.0348\n",
      "Epoch: 450/500... Training loss: 0.0036\n",
      "Epoch: 450/500... Training loss: 0.0022\n",
      "Epoch: 450/500... Training loss: 0.0142\n",
      "Epoch: 450/500... Training loss: 0.0039\n",
      "Epoch: 450/500... Training loss: 0.0498\n",
      "Epoch: 450/500... Training loss: 0.0153\n",
      "Epoch: 450/500... Training loss: 0.0456\n",
      "Epoch: 450/500... Training loss: 0.0094\n",
      "Epoch: 450/500... Training loss: 0.0036\n",
      "Epoch: 450/500... Training loss: 0.0310\n",
      "Epoch: 450/500... Training loss: 0.0134\n",
      "Epoch: 450/500... Training loss: 0.0008\n",
      "Epoch: 450/500... Training loss: 0.0022\n",
      "Epoch: 450/500... Training loss: 0.0029\n",
      "Epoch: 450/500... Training loss: 0.0078\n",
      "Epoch: 450/500... Training loss: 0.0013\n",
      "Epoch: 450/500... Training loss: 0.0012\n",
      "Epoch: 450/500... Training loss: 0.0019\n",
      "Epoch: 450/500... Training loss: 0.0055\n",
      "Epoch: 450/500... Training loss: 0.0022\n",
      "Epoch: 450/500... Training loss: 0.0042\n",
      "Epoch: 450/500... Training loss: 0.0081\n",
      "Epoch: 450/500... Training loss: 0.0047\n",
      "Epoch: 451/500... Training loss: 0.0367\n",
      "Epoch: 451/500... Training loss: 0.0037\n",
      "Epoch: 451/500... Training loss: 0.1052\n",
      "Epoch: 451/500... Training loss: 0.0613\n",
      "Epoch: 451/500... Training loss: 0.0070\n",
      "Epoch: 451/500... Training loss: 0.0120\n",
      "Epoch: 451/500... Training loss: 0.0076\n",
      "Epoch: 451/500... Training loss: 0.0021\n",
      "Epoch: 451/500... Training loss: 0.0813\n",
      "Epoch: 451/500... Training loss: 0.0019\n",
      "Epoch: 451/500... Training loss: 0.0064\n",
      "Epoch: 451/500... Training loss: 0.0031\n",
      "Epoch: 451/500... Training loss: 0.0170\n",
      "Epoch: 451/500... Training loss: 0.0008\n",
      "Epoch: 451/500... Training loss: 0.0753\n",
      "Epoch: 451/500... Training loss: 0.0277\n",
      "Epoch: 451/500... Training loss: 0.0249\n",
      "Epoch: 451/500... Training loss: 0.0014\n",
      "Epoch: 451/500... Training loss: 0.0004\n",
      "Epoch: 451/500... Training loss: 0.0055\n",
      "Epoch: 451/500... Training loss: 0.0033\n",
      "Epoch: 451/500... Training loss: 0.0022\n",
      "Epoch: 451/500... Training loss: 0.0062\n",
      "Epoch: 451/500... Training loss: 0.0014\n",
      "Epoch: 451/500... Training loss: 0.0049\n",
      "Epoch: 451/500... Training loss: 0.0051\n",
      "Epoch: 451/500... Training loss: 0.0027\n",
      "Epoch: 451/500... Training loss: 0.0087\n",
      "Epoch: 451/500... Training loss: 0.0074\n",
      "Epoch: 451/500... Training loss: 0.0040\n",
      "Epoch: 451/500... Training loss: 0.0116\n",
      "Epoch: 452/500... Training loss: 0.0472\n",
      "Epoch: 452/500... Training loss: 0.0057\n",
      "Epoch: 452/500... Training loss: 0.0087\n",
      "Epoch: 452/500... Training loss: 0.0006\n",
      "Epoch: 452/500... Training loss: 0.0156\n",
      "Epoch: 452/500... Training loss: 0.0083\n",
      "Epoch: 452/500... Training loss: 0.0153\n",
      "Epoch: 452/500... Training loss: 0.0023\n",
      "Epoch: 452/500... Training loss: 0.0137\n",
      "Epoch: 452/500... Training loss: 0.0212\n",
      "Epoch: 452/500... Training loss: 0.0025\n",
      "Epoch: 452/500... Training loss: 0.0031\n",
      "Epoch: 452/500... Training loss: 0.0020\n",
      "Epoch: 452/500... Training loss: 0.0040\n",
      "Epoch: 452/500... Training loss: 0.0008\n",
      "Epoch: 452/500... Training loss: 0.0847\n",
      "Epoch: 452/500... Training loss: 0.0010\n",
      "Epoch: 452/500... Training loss: 0.0092\n",
      "Epoch: 452/500... Training loss: 0.0003\n",
      "Epoch: 452/500... Training loss: 0.0004\n",
      "Epoch: 452/500... Training loss: 0.0024\n",
      "Epoch: 452/500... Training loss: 0.0208\n",
      "Epoch: 452/500... Training loss: 0.0007\n",
      "Epoch: 452/500... Training loss: 0.0013\n",
      "Epoch: 452/500... Training loss: 0.0063\n",
      "Epoch: 452/500... Training loss: 0.0723\n",
      "Epoch: 452/500... Training loss: 0.0807\n",
      "Epoch: 452/500... Training loss: 0.0028\n",
      "Epoch: 452/500... Training loss: 0.0315\n",
      "Epoch: 452/500... Training loss: 0.0041\n",
      "Epoch: 452/500... Training loss: 0.0018\n",
      "Epoch: 453/500... Training loss: 0.0013\n",
      "Epoch: 453/500... Training loss: 0.0006\n",
      "Epoch: 453/500... Training loss: 0.0027\n",
      "Epoch: 453/500... Training loss: 0.0021\n",
      "Epoch: 453/500... Training loss: 0.0021\n",
      "Epoch: 453/500... Training loss: 0.0049\n",
      "Epoch: 453/500... Training loss: 0.0013\n",
      "Epoch: 453/500... Training loss: 0.0034\n",
      "Epoch: 453/500... Training loss: 0.0030\n",
      "Epoch: 453/500... Training loss: 0.0033\n",
      "Epoch: 453/500... Training loss: 0.0009\n",
      "Epoch: 453/500... Training loss: 0.0119\n",
      "Epoch: 453/500... Training loss: 0.0049\n",
      "Epoch: 453/500... Training loss: 0.0015\n",
      "Epoch: 453/500... Training loss: 0.0005\n",
      "Epoch: 453/500... Training loss: 0.0044\n",
      "Epoch: 453/500... Training loss: 0.0041\n",
      "Epoch: 453/500... Training loss: 0.0023\n",
      "Epoch: 453/500... Training loss: 0.0040\n",
      "Epoch: 453/500... Training loss: 0.0011\n",
      "Epoch: 453/500... Training loss: 0.0074\n",
      "Epoch: 453/500... Training loss: 0.0028\n",
      "Epoch: 453/500... Training loss: 0.0061\n",
      "Epoch: 453/500... Training loss: 0.0019\n",
      "Epoch: 453/500... Training loss: 0.0106\n",
      "Epoch: 453/500... Training loss: 0.0202\n",
      "Epoch: 453/500... Training loss: 0.0010\n",
      "Epoch: 453/500... Training loss: 0.0002\n",
      "Epoch: 453/500... Training loss: 0.0006\n",
      "Epoch: 453/500... Training loss: 0.0014\n",
      "Epoch: 453/500... Training loss: 0.0034\n",
      "Epoch: 454/500... Training loss: 0.0031\n",
      "Epoch: 454/500... Training loss: 0.0006\n",
      "Epoch: 454/500... Training loss: 0.0010\n",
      "Epoch: 454/500... Training loss: 0.0822\n",
      "Epoch: 454/500... Training loss: 0.0062\n",
      "Epoch: 454/500... Training loss: 0.0015\n",
      "Epoch: 454/500... Training loss: 0.0032\n",
      "Epoch: 454/500... Training loss: 0.0017\n",
      "Epoch: 454/500... Training loss: 0.0118\n",
      "Epoch: 454/500... Training loss: 0.0009\n",
      "Epoch: 454/500... Training loss: 0.0009\n",
      "Epoch: 454/500... Training loss: 0.0035\n",
      "Epoch: 454/500... Training loss: 0.0092\n",
      "Epoch: 454/500... Training loss: 0.0034\n",
      "Epoch: 454/500... Training loss: 0.0011\n",
      "Epoch: 454/500... Training loss: 0.0054\n",
      "Epoch: 454/500... Training loss: 0.0011\n",
      "Epoch: 454/500... Training loss: 0.0005\n",
      "Epoch: 454/500... Training loss: 0.0039\n",
      "Epoch: 454/500... Training loss: 0.0017\n",
      "Epoch: 454/500... Training loss: 0.0017\n",
      "Epoch: 454/500... Training loss: 0.0026\n",
      "Epoch: 454/500... Training loss: 0.0147\n",
      "Epoch: 454/500... Training loss: 0.0016\n",
      "Epoch: 454/500... Training loss: 0.0029\n",
      "Epoch: 454/500... Training loss: 0.0106\n",
      "Epoch: 454/500... Training loss: 0.0060\n",
      "Epoch: 454/500... Training loss: 0.0223\n",
      "Epoch: 454/500... Training loss: 0.0017\n",
      "Epoch: 454/500... Training loss: 0.0211\n",
      "Epoch: 454/500... Training loss: 0.0012\n",
      "Epoch: 455/500... Training loss: 0.0241\n",
      "Epoch: 455/500... Training loss: 0.0072\n",
      "Epoch: 455/500... Training loss: 0.0158\n",
      "Epoch: 455/500... Training loss: 0.0039\n",
      "Epoch: 455/500... Training loss: 0.0085\n",
      "Epoch: 455/500... Training loss: 0.0057\n",
      "Epoch: 455/500... Training loss: 0.0239\n",
      "Epoch: 455/500... Training loss: 0.0006\n",
      "Epoch: 455/500... Training loss: 0.0214\n",
      "Epoch: 455/500... Training loss: 0.0016\n",
      "Epoch: 455/500... Training loss: 0.0066\n",
      "Epoch: 455/500... Training loss: 0.0332\n",
      "Epoch: 455/500... Training loss: 0.0017\n",
      "Epoch: 455/500... Training loss: 0.0075\n",
      "Epoch: 455/500... Training loss: 0.0082\n",
      "Epoch: 455/500... Training loss: 0.0442\n",
      "Epoch: 455/500... Training loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 455/500... Training loss: 0.0265\n",
      "Epoch: 455/500... Training loss: 0.0119\n",
      "Epoch: 455/500... Training loss: 0.0004\n",
      "Epoch: 455/500... Training loss: 0.0008\n",
      "Epoch: 455/500... Training loss: 0.0026\n",
      "Epoch: 455/500... Training loss: 0.0027\n",
      "Epoch: 455/500... Training loss: 0.0016\n",
      "Epoch: 455/500... Training loss: 0.0047\n",
      "Epoch: 455/500... Training loss: 0.0004\n",
      "Epoch: 455/500... Training loss: 0.0005\n",
      "Epoch: 455/500... Training loss: 0.0429\n",
      "Epoch: 455/500... Training loss: 0.0131\n",
      "Epoch: 455/500... Training loss: 0.0337\n",
      "Epoch: 455/500... Training loss: 0.0150\n",
      "Epoch: 456/500... Training loss: 0.0024\n",
      "Epoch: 456/500... Training loss: 0.0632\n",
      "Epoch: 456/500... Training loss: 0.0008\n",
      "Epoch: 456/500... Training loss: 0.1436\n",
      "Epoch: 456/500... Training loss: 0.0095\n",
      "Epoch: 456/500... Training loss: 0.0632\n",
      "Epoch: 456/500... Training loss: 0.0033\n",
      "Epoch: 456/500... Training loss: 0.0009\n",
      "Epoch: 456/500... Training loss: 0.0006\n",
      "Epoch: 456/500... Training loss: 0.0040\n",
      "Epoch: 456/500... Training loss: 0.0025\n",
      "Epoch: 456/500... Training loss: 0.0165\n",
      "Epoch: 456/500... Training loss: 0.0019\n",
      "Epoch: 456/500... Training loss: 0.0005\n",
      "Epoch: 456/500... Training loss: 0.0379\n",
      "Epoch: 456/500... Training loss: 0.0442\n",
      "Epoch: 456/500... Training loss: 0.0012\n",
      "Epoch: 456/500... Training loss: 0.0010\n",
      "Epoch: 456/500... Training loss: 0.0011\n",
      "Epoch: 456/500... Training loss: 0.0098\n",
      "Epoch: 456/500... Training loss: 0.0031\n",
      "Epoch: 456/500... Training loss: 0.0024\n",
      "Epoch: 456/500... Training loss: 0.0026\n",
      "Epoch: 456/500... Training loss: 0.0191\n",
      "Epoch: 456/500... Training loss: 0.0267\n",
      "Epoch: 456/500... Training loss: 0.0610\n",
      "Epoch: 456/500... Training loss: 0.0013\n",
      "Epoch: 456/500... Training loss: 0.0045\n",
      "Epoch: 456/500... Training loss: 0.0054\n",
      "Epoch: 456/500... Training loss: 0.0478\n",
      "Epoch: 456/500... Training loss: 0.0029\n",
      "Epoch: 457/500... Training loss: 0.0014\n",
      "Epoch: 457/500... Training loss: 0.0022\n",
      "Epoch: 457/500... Training loss: 0.0010\n",
      "Epoch: 457/500... Training loss: 0.0045\n",
      "Epoch: 457/500... Training loss: 0.0078\n",
      "Epoch: 457/500... Training loss: 0.0071\n",
      "Epoch: 457/500... Training loss: 0.0051\n",
      "Epoch: 457/500... Training loss: 0.0019\n",
      "Epoch: 457/500... Training loss: 0.0242\n",
      "Epoch: 457/500... Training loss: 0.0087\n",
      "Epoch: 457/500... Training loss: 0.0190\n",
      "Epoch: 457/500... Training loss: 0.0041\n",
      "Epoch: 457/500... Training loss: 0.0004\n",
      "Epoch: 457/500... Training loss: 0.0124\n",
      "Epoch: 457/500... Training loss: 0.0109\n",
      "Epoch: 457/500... Training loss: 0.0127\n",
      "Epoch: 457/500... Training loss: 0.0012\n",
      "Epoch: 457/500... Training loss: 0.0110\n",
      "Epoch: 457/500... Training loss: 0.0048\n",
      "Epoch: 457/500... Training loss: 0.0344\n",
      "Epoch: 457/500... Training loss: 0.0028\n",
      "Epoch: 457/500... Training loss: 0.0047\n",
      "Epoch: 457/500... Training loss: 0.0049\n",
      "Epoch: 457/500... Training loss: 0.0356\n",
      "Epoch: 457/500... Training loss: 0.0022\n",
      "Epoch: 457/500... Training loss: 0.0072\n",
      "Epoch: 457/500... Training loss: 0.0382\n",
      "Epoch: 457/500... Training loss: 0.0094\n",
      "Epoch: 457/500... Training loss: 0.0023\n",
      "Epoch: 457/500... Training loss: 0.0273\n",
      "Epoch: 457/500... Training loss: 0.0023\n",
      "Epoch: 458/500... Training loss: 0.0036\n",
      "Epoch: 458/500... Training loss: 0.0029\n",
      "Epoch: 458/500... Training loss: 0.0190\n",
      "Epoch: 458/500... Training loss: 0.0483\n",
      "Epoch: 458/500... Training loss: 0.0418\n",
      "Epoch: 458/500... Training loss: 0.0367\n",
      "Epoch: 458/500... Training loss: 0.0007\n",
      "Epoch: 458/500... Training loss: 0.1078\n",
      "Epoch: 458/500... Training loss: 0.0530\n",
      "Epoch: 458/500... Training loss: 0.0008\n",
      "Epoch: 458/500... Training loss: 0.0063\n",
      "Epoch: 458/500... Training loss: 0.0493\n",
      "Epoch: 458/500... Training loss: 0.0012\n",
      "Epoch: 458/500... Training loss: 0.0639\n",
      "Epoch: 458/500... Training loss: 0.0464\n",
      "Epoch: 458/500... Training loss: 0.0516\n",
      "Epoch: 458/500... Training loss: 0.1249\n",
      "Epoch: 458/500... Training loss: 0.0267\n",
      "Epoch: 458/500... Training loss: 0.1099\n",
      "Epoch: 458/500... Training loss: 0.0066\n",
      "Epoch: 458/500... Training loss: 0.0030\n",
      "Epoch: 458/500... Training loss: 0.0007\n",
      "Epoch: 458/500... Training loss: 0.0636\n",
      "Epoch: 458/500... Training loss: 0.0058\n",
      "Epoch: 458/500... Training loss: 0.0101\n",
      "Epoch: 458/500... Training loss: 0.0063\n",
      "Epoch: 458/500... Training loss: 0.0663\n",
      "Epoch: 458/500... Training loss: 0.0044\n",
      "Epoch: 458/500... Training loss: 0.0727\n",
      "Epoch: 458/500... Training loss: 0.0020\n",
      "Epoch: 458/500... Training loss: 0.0225\n",
      "Epoch: 459/500... Training loss: 0.0068\n",
      "Epoch: 459/500... Training loss: 0.0153\n",
      "Epoch: 459/500... Training loss: 0.0009\n",
      "Epoch: 459/500... Training loss: 0.0025\n",
      "Epoch: 459/500... Training loss: 0.0016\n",
      "Epoch: 459/500... Training loss: 0.0065\n",
      "Epoch: 459/500... Training loss: 0.0280\n",
      "Epoch: 459/500... Training loss: 0.0120\n",
      "Epoch: 459/500... Training loss: 0.0025\n",
      "Epoch: 459/500... Training loss: 0.0059\n",
      "Epoch: 459/500... Training loss: 0.0046\n",
      "Epoch: 459/500... Training loss: 0.0055\n",
      "Epoch: 459/500... Training loss: 0.0010\n",
      "Epoch: 459/500... Training loss: 0.0020\n",
      "Epoch: 459/500... Training loss: 0.0092\n",
      "Epoch: 459/500... Training loss: 0.0029\n",
      "Epoch: 459/500... Training loss: 0.0025\n",
      "Epoch: 459/500... Training loss: 0.0011\n",
      "Epoch: 459/500... Training loss: 0.0067\n",
      "Epoch: 459/500... Training loss: 0.0012\n",
      "Epoch: 459/500... Training loss: 0.0078\n",
      "Epoch: 459/500... Training loss: 0.0001\n",
      "Epoch: 459/500... Training loss: 0.1519\n",
      "Epoch: 459/500... Training loss: 0.0257\n",
      "Epoch: 459/500... Training loss: 0.0199\n",
      "Epoch: 459/500... Training loss: 0.0024\n",
      "Epoch: 459/500... Training loss: 0.0057\n",
      "Epoch: 459/500... Training loss: 0.0008\n",
      "Epoch: 459/500... Training loss: 0.0572\n",
      "Epoch: 459/500... Training loss: 0.0124\n",
      "Epoch: 459/500... Training loss: 0.0078\n",
      "Epoch: 460/500... Training loss: 0.0164\n",
      "Epoch: 460/500... Training loss: 0.0447\n",
      "Epoch: 460/500... Training loss: 0.0012\n",
      "Epoch: 460/500... Training loss: 0.1342\n",
      "Epoch: 460/500... Training loss: 0.0123\n",
      "Epoch: 460/500... Training loss: 0.0077\n",
      "Epoch: 460/500... Training loss: 0.0380\n",
      "Epoch: 460/500... Training loss: 0.0036\n",
      "Epoch: 460/500... Training loss: 0.0081\n",
      "Epoch: 460/500... Training loss: 0.0042\n",
      "Epoch: 460/500... Training loss: 0.0024\n",
      "Epoch: 460/500... Training loss: 0.0009\n",
      "Epoch: 460/500... Training loss: 0.0430\n",
      "Epoch: 460/500... Training loss: 0.0012\n",
      "Epoch: 460/500... Training loss: 0.0368\n",
      "Epoch: 460/500... Training loss: 0.0064\n",
      "Epoch: 460/500... Training loss: 0.0018\n",
      "Epoch: 460/500... Training loss: 0.0250\n",
      "Epoch: 460/500... Training loss: 0.0018\n",
      "Epoch: 460/500... Training loss: 0.0019\n",
      "Epoch: 460/500... Training loss: 0.0045\n",
      "Epoch: 460/500... Training loss: 0.0085\n",
      "Epoch: 460/500... Training loss: 0.0030\n",
      "Epoch: 460/500... Training loss: 0.0008\n",
      "Epoch: 460/500... Training loss: 0.0050\n",
      "Epoch: 460/500... Training loss: 0.0073\n",
      "Epoch: 460/500... Training loss: 0.0015\n",
      "Epoch: 460/500... Training loss: 0.0017\n",
      "Epoch: 460/500... Training loss: 0.0033\n",
      "Epoch: 460/500... Training loss: 0.0056\n",
      "Epoch: 460/500... Training loss: 0.0009\n",
      "Epoch: 461/500... Training loss: 0.0103\n",
      "Epoch: 461/500... Training loss: 0.0386\n",
      "Epoch: 461/500... Training loss: 0.0034\n",
      "Epoch: 461/500... Training loss: 0.0031\n",
      "Epoch: 461/500... Training loss: 0.0043\n",
      "Epoch: 461/500... Training loss: 0.0062\n",
      "Epoch: 461/500... Training loss: 0.0052\n",
      "Epoch: 461/500... Training loss: 0.0118\n",
      "Epoch: 461/500... Training loss: 0.0091\n",
      "Epoch: 461/500... Training loss: 0.0014\n",
      "Epoch: 461/500... Training loss: 0.0022\n",
      "Epoch: 461/500... Training loss: 0.0026\n",
      "Epoch: 461/500... Training loss: 0.0011\n",
      "Epoch: 461/500... Training loss: 0.0016\n",
      "Epoch: 461/500... Training loss: 0.0025\n",
      "Epoch: 461/500... Training loss: 0.0051\n",
      "Epoch: 461/500... Training loss: 0.0228\n",
      "Epoch: 461/500... Training loss: 0.0062\n",
      "Epoch: 461/500... Training loss: 0.0090\n",
      "Epoch: 461/500... Training loss: 0.0016\n",
      "Epoch: 461/500... Training loss: 0.0026\n",
      "Epoch: 461/500... Training loss: 0.0010\n",
      "Epoch: 461/500... Training loss: 0.0009\n",
      "Epoch: 461/500... Training loss: 0.0480\n",
      "Epoch: 461/500... Training loss: 0.0024\n",
      "Epoch: 461/500... Training loss: 0.0028\n",
      "Epoch: 461/500... Training loss: 0.0040\n",
      "Epoch: 461/500... Training loss: 0.0016\n",
      "Epoch: 461/500... Training loss: 0.0037\n",
      "Epoch: 461/500... Training loss: 0.0014\n",
      "Epoch: 461/500... Training loss: 0.0029\n",
      "Epoch: 462/500... Training loss: 0.0476\n",
      "Epoch: 462/500... Training loss: 0.0125\n",
      "Epoch: 462/500... Training loss: 0.0008\n",
      "Epoch: 462/500... Training loss: 0.0213\n",
      "Epoch: 462/500... Training loss: 0.0048\n",
      "Epoch: 462/500... Training loss: 0.0055\n",
      "Epoch: 462/500... Training loss: 0.0046\n",
      "Epoch: 462/500... Training loss: 0.0036\n",
      "Epoch: 462/500... Training loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462/500... Training loss: 0.0035\n",
      "Epoch: 462/500... Training loss: 0.0079\n",
      "Epoch: 462/500... Training loss: 0.0033\n",
      "Epoch: 462/500... Training loss: 0.0026\n",
      "Epoch: 462/500... Training loss: 0.0013\n",
      "Epoch: 462/500... Training loss: 0.0019\n",
      "Epoch: 462/500... Training loss: 0.0013\n",
      "Epoch: 462/500... Training loss: 0.0035\n",
      "Epoch: 462/500... Training loss: 0.0013\n",
      "Epoch: 462/500... Training loss: 0.0007\n",
      "Epoch: 462/500... Training loss: 0.0015\n",
      "Epoch: 462/500... Training loss: 0.0034\n",
      "Epoch: 462/500... Training loss: 0.0052\n",
      "Epoch: 462/500... Training loss: 0.0022\n",
      "Epoch: 462/500... Training loss: 0.0161\n",
      "Epoch: 462/500... Training loss: 0.0068\n",
      "Epoch: 462/500... Training loss: 0.0058\n",
      "Epoch: 462/500... Training loss: 0.0294\n",
      "Epoch: 462/500... Training loss: 0.0085\n",
      "Epoch: 462/500... Training loss: 0.0095\n",
      "Epoch: 462/500... Training loss: 0.0023\n",
      "Epoch: 462/500... Training loss: 0.0018\n",
      "Epoch: 463/500... Training loss: 0.0275\n",
      "Epoch: 463/500... Training loss: 0.0634\n",
      "Epoch: 463/500... Training loss: 0.0048\n",
      "Epoch: 463/500... Training loss: 0.0025\n",
      "Epoch: 463/500... Training loss: 0.0005\n",
      "Epoch: 463/500... Training loss: 0.0178\n",
      "Epoch: 463/500... Training loss: 0.0028\n",
      "Epoch: 463/500... Training loss: 0.0027\n",
      "Epoch: 463/500... Training loss: 0.0009\n",
      "Epoch: 463/500... Training loss: 0.0048\n",
      "Epoch: 463/500... Training loss: 0.0147\n",
      "Epoch: 463/500... Training loss: 0.0054\n",
      "Epoch: 463/500... Training loss: 0.0123\n",
      "Epoch: 463/500... Training loss: 0.0013\n",
      "Epoch: 463/500... Training loss: 0.0031\n",
      "Epoch: 463/500... Training loss: 0.0164\n",
      "Epoch: 463/500... Training loss: 0.0022\n",
      "Epoch: 463/500... Training loss: 0.0006\n",
      "Epoch: 463/500... Training loss: 0.0085\n",
      "Epoch: 463/500... Training loss: 0.0027\n",
      "Epoch: 463/500... Training loss: 0.0063\n",
      "Epoch: 463/500... Training loss: 0.0013\n",
      "Epoch: 463/500... Training loss: 0.0064\n",
      "Epoch: 463/500... Training loss: 0.0007\n",
      "Epoch: 463/500... Training loss: 0.0097\n",
      "Epoch: 463/500... Training loss: 0.0322\n",
      "Epoch: 463/500... Training loss: 0.0011\n",
      "Epoch: 463/500... Training loss: 0.0065\n",
      "Epoch: 463/500... Training loss: 0.0009\n",
      "Epoch: 463/500... Training loss: 0.0007\n",
      "Epoch: 463/500... Training loss: 0.0028\n",
      "Epoch: 464/500... Training loss: 0.0004\n",
      "Epoch: 464/500... Training loss: 0.0561\n",
      "Epoch: 464/500... Training loss: 0.0017\n",
      "Epoch: 464/500... Training loss: 0.0113\n",
      "Epoch: 464/500... Training loss: 0.0011\n",
      "Epoch: 464/500... Training loss: 0.0054\n",
      "Epoch: 464/500... Training loss: 0.0160\n",
      "Epoch: 464/500... Training loss: 0.0072\n",
      "Epoch: 464/500... Training loss: 0.0005\n",
      "Epoch: 464/500... Training loss: 0.0005\n",
      "Epoch: 464/500... Training loss: 0.0027\n",
      "Epoch: 464/500... Training loss: 0.0009\n",
      "Epoch: 464/500... Training loss: 0.0120\n",
      "Epoch: 464/500... Training loss: 0.0300\n",
      "Epoch: 464/500... Training loss: 0.0179\n",
      "Epoch: 464/500... Training loss: 0.0009\n",
      "Epoch: 464/500... Training loss: 0.0022\n",
      "Epoch: 464/500... Training loss: 0.0104\n",
      "Epoch: 464/500... Training loss: 0.0024\n",
      "Epoch: 464/500... Training loss: 0.0304\n",
      "Epoch: 464/500... Training loss: 0.0090\n",
      "Epoch: 464/500... Training loss: 0.0015\n",
      "Epoch: 464/500... Training loss: 0.0037\n",
      "Epoch: 464/500... Training loss: 0.0041\n",
      "Epoch: 464/500... Training loss: 0.0023\n",
      "Epoch: 464/500... Training loss: 0.0191\n",
      "Epoch: 464/500... Training loss: 0.0092\n",
      "Epoch: 464/500... Training loss: 0.0004\n",
      "Epoch: 464/500... Training loss: 0.0273\n",
      "Epoch: 464/500... Training loss: 0.0011\n",
      "Epoch: 464/500... Training loss: 0.0058\n",
      "Epoch: 465/500... Training loss: 0.0025\n",
      "Epoch: 465/500... Training loss: 0.0016\n",
      "Epoch: 465/500... Training loss: 0.0065\n",
      "Epoch: 465/500... Training loss: 0.0381\n",
      "Epoch: 465/500... Training loss: 0.0305\n",
      "Epoch: 465/500... Training loss: 0.0013\n",
      "Epoch: 465/500... Training loss: 0.0263\n",
      "Epoch: 465/500... Training loss: 0.0021\n",
      "Epoch: 465/500... Training loss: 0.0180\n",
      "Epoch: 465/500... Training loss: 0.0046\n",
      "Epoch: 465/500... Training loss: 0.0049\n",
      "Epoch: 465/500... Training loss: 0.0054\n",
      "Epoch: 465/500... Training loss: 0.0049\n",
      "Epoch: 465/500... Training loss: 0.0101\n",
      "Epoch: 465/500... Training loss: 0.0111\n",
      "Epoch: 465/500... Training loss: 0.0014\n",
      "Epoch: 465/500... Training loss: 0.0023\n",
      "Epoch: 465/500... Training loss: 0.0003\n",
      "Epoch: 465/500... Training loss: 0.0007\n",
      "Epoch: 465/500... Training loss: 0.0191\n",
      "Epoch: 465/500... Training loss: 0.0262\n",
      "Epoch: 465/500... Training loss: 0.0047\n",
      "Epoch: 465/500... Training loss: 0.0174\n",
      "Epoch: 465/500... Training loss: 0.0007\n",
      "Epoch: 465/500... Training loss: 0.0131\n",
      "Epoch: 465/500... Training loss: 0.0088\n",
      "Epoch: 465/500... Training loss: 0.0013\n",
      "Epoch: 465/500... Training loss: 0.0006\n",
      "Epoch: 465/500... Training loss: 0.0016\n",
      "Epoch: 465/500... Training loss: 0.0057\n",
      "Epoch: 465/500... Training loss: 0.0020\n",
      "Epoch: 466/500... Training loss: 0.0039\n",
      "Epoch: 466/500... Training loss: 0.0005\n",
      "Epoch: 466/500... Training loss: 0.0016\n",
      "Epoch: 466/500... Training loss: 0.0832\n",
      "Epoch: 466/500... Training loss: 0.0093\n",
      "Epoch: 466/500... Training loss: 0.0056\n",
      "Epoch: 466/500... Training loss: 0.0020\n",
      "Epoch: 466/500... Training loss: 0.0034\n",
      "Epoch: 466/500... Training loss: 0.0015\n",
      "Epoch: 466/500... Training loss: 0.0009\n",
      "Epoch: 466/500... Training loss: 0.0036\n",
      "Epoch: 466/500... Training loss: 0.0036\n",
      "Epoch: 466/500... Training loss: 0.0166\n",
      "Epoch: 466/500... Training loss: 0.0017\n",
      "Epoch: 466/500... Training loss: 0.0005\n",
      "Epoch: 466/500... Training loss: 0.0057\n",
      "Epoch: 466/500... Training loss: 0.0020\n",
      "Epoch: 466/500... Training loss: 0.0012\n",
      "Epoch: 466/500... Training loss: 0.0012\n",
      "Epoch: 466/500... Training loss: 0.0532\n",
      "Epoch: 466/500... Training loss: 0.0075\n",
      "Epoch: 466/500... Training loss: 0.0103\n",
      "Epoch: 466/500... Training loss: 0.0033\n",
      "Epoch: 466/500... Training loss: 0.0018\n",
      "Epoch: 466/500... Training loss: 0.0022\n",
      "Epoch: 466/500... Training loss: 0.0050\n",
      "Epoch: 466/500... Training loss: 0.0028\n",
      "Epoch: 466/500... Training loss: 0.0005\n",
      "Epoch: 466/500... Training loss: 0.0006\n",
      "Epoch: 466/500... Training loss: 0.0041\n",
      "Epoch: 466/500... Training loss: 0.0031\n",
      "Epoch: 467/500... Training loss: 0.0278\n",
      "Epoch: 467/500... Training loss: 0.0022\n",
      "Epoch: 467/500... Training loss: 0.0007\n",
      "Epoch: 467/500... Training loss: 0.0277\n",
      "Epoch: 467/500... Training loss: 0.0081\n",
      "Epoch: 467/500... Training loss: 0.0094\n",
      "Epoch: 467/500... Training loss: 0.0079\n",
      "Epoch: 467/500... Training loss: 0.0019\n",
      "Epoch: 467/500... Training loss: 0.0011\n",
      "Epoch: 467/500... Training loss: 0.0113\n",
      "Epoch: 467/500... Training loss: 0.0005\n",
      "Epoch: 467/500... Training loss: 0.0113\n",
      "Epoch: 467/500... Training loss: 0.0540\n",
      "Epoch: 467/500... Training loss: 0.0456\n",
      "Epoch: 467/500... Training loss: 0.0060\n",
      "Epoch: 467/500... Training loss: 0.0040\n",
      "Epoch: 467/500... Training loss: 0.0109\n",
      "Epoch: 467/500... Training loss: 0.0007\n",
      "Epoch: 467/500... Training loss: 0.0011\n",
      "Epoch: 467/500... Training loss: 0.0025\n",
      "Epoch: 467/500... Training loss: 0.0150\n",
      "Epoch: 467/500... Training loss: 0.0206\n",
      "Epoch: 467/500... Training loss: 0.0030\n",
      "Epoch: 467/500... Training loss: 0.0037\n",
      "Epoch: 467/500... Training loss: 0.0329\n",
      "Epoch: 467/500... Training loss: 0.0013\n",
      "Epoch: 467/500... Training loss: 0.0179\n",
      "Epoch: 467/500... Training loss: 0.0011\n",
      "Epoch: 467/500... Training loss: 0.0573\n",
      "Epoch: 467/500... Training loss: 0.0025\n",
      "Epoch: 467/500... Training loss: 0.0089\n",
      "Epoch: 468/500... Training loss: 0.0002\n",
      "Epoch: 468/500... Training loss: 0.0037\n",
      "Epoch: 468/500... Training loss: 0.0342\n",
      "Epoch: 468/500... Training loss: 0.0012\n",
      "Epoch: 468/500... Training loss: 0.0054\n",
      "Epoch: 468/500... Training loss: 0.0006\n",
      "Epoch: 468/500... Training loss: 0.0008\n",
      "Epoch: 468/500... Training loss: 0.0432\n",
      "Epoch: 468/500... Training loss: 0.0331\n",
      "Epoch: 468/500... Training loss: 0.0025\n",
      "Epoch: 468/500... Training loss: 0.0011\n",
      "Epoch: 468/500... Training loss: 0.0022\n",
      "Epoch: 468/500... Training loss: 0.0047\n",
      "Epoch: 468/500... Training loss: 0.0101\n",
      "Epoch: 468/500... Training loss: 0.0101\n",
      "Epoch: 468/500... Training loss: 0.0030\n",
      "Epoch: 468/500... Training loss: 0.0008\n",
      "Epoch: 468/500... Training loss: 0.0046\n",
      "Epoch: 468/500... Training loss: 0.0195\n",
      "Epoch: 468/500... Training loss: 0.0010\n",
      "Epoch: 468/500... Training loss: 0.0010\n",
      "Epoch: 468/500... Training loss: 0.0013\n",
      "Epoch: 468/500... Training loss: 0.0020\n",
      "Epoch: 468/500... Training loss: 0.0186\n",
      "Epoch: 468/500... Training loss: 0.0007\n",
      "Epoch: 468/500... Training loss: 0.0074\n",
      "Epoch: 468/500... Training loss: 0.0004\n",
      "Epoch: 468/500... Training loss: 0.0009\n",
      "Epoch: 468/500... Training loss: 0.0010\n",
      "Epoch: 468/500... Training loss: 0.0035\n",
      "Epoch: 468/500... Training loss: 0.0030\n",
      "Epoch: 469/500... Training loss: 0.0054\n",
      "Epoch: 469/500... Training loss: 0.0069\n",
      "Epoch: 469/500... Training loss: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 469/500... Training loss: 0.0025\n",
      "Epoch: 469/500... Training loss: 0.0050\n",
      "Epoch: 469/500... Training loss: 0.0265\n",
      "Epoch: 469/500... Training loss: 0.0018\n",
      "Epoch: 469/500... Training loss: 0.0038\n",
      "Epoch: 469/500... Training loss: 0.0019\n",
      "Epoch: 469/500... Training loss: 0.0029\n",
      "Epoch: 469/500... Training loss: 0.0061\n",
      "Epoch: 469/500... Training loss: 0.0004\n",
      "Epoch: 469/500... Training loss: 0.0065\n",
      "Epoch: 469/500... Training loss: 0.0008\n",
      "Epoch: 469/500... Training loss: 0.0025\n",
      "Epoch: 469/500... Training loss: 0.0016\n",
      "Epoch: 469/500... Training loss: 0.0441\n",
      "Epoch: 469/500... Training loss: 0.0018\n",
      "Epoch: 469/500... Training loss: 0.0019\n",
      "Epoch: 469/500... Training loss: 0.0057\n",
      "Epoch: 469/500... Training loss: 0.0036\n",
      "Epoch: 469/500... Training loss: 0.0041\n",
      "Epoch: 469/500... Training loss: 0.0009\n",
      "Epoch: 469/500... Training loss: 0.0146\n",
      "Epoch: 469/500... Training loss: 0.0019\n",
      "Epoch: 469/500... Training loss: 0.0009\n",
      "Epoch: 469/500... Training loss: 0.0007\n",
      "Epoch: 469/500... Training loss: 0.0461\n",
      "Epoch: 469/500... Training loss: 0.0070\n",
      "Epoch: 469/500... Training loss: 0.0008\n",
      "Epoch: 469/500... Training loss: 0.0013\n",
      "Epoch: 470/500... Training loss: 0.0007\n",
      "Epoch: 470/500... Training loss: 0.0003\n",
      "Epoch: 470/500... Training loss: 0.0038\n",
      "Epoch: 470/500... Training loss: 0.0105\n",
      "Epoch: 470/500... Training loss: 0.0074\n",
      "Epoch: 470/500... Training loss: 0.0100\n",
      "Epoch: 470/500... Training loss: 0.0011\n",
      "Epoch: 470/500... Training loss: 0.0076\n",
      "Epoch: 470/500... Training loss: 0.0002\n",
      "Epoch: 470/500... Training loss: 0.0009\n",
      "Epoch: 470/500... Training loss: 0.0072\n",
      "Epoch: 470/500... Training loss: 0.0010\n",
      "Epoch: 470/500... Training loss: 0.0019\n",
      "Epoch: 470/500... Training loss: 0.0020\n",
      "Epoch: 470/500... Training loss: 0.0016\n",
      "Epoch: 470/500... Training loss: 0.0270\n",
      "Epoch: 470/500... Training loss: 0.0034\n",
      "Epoch: 470/500... Training loss: 0.0058\n",
      "Epoch: 470/500... Training loss: 0.0044\n",
      "Epoch: 470/500... Training loss: 0.0008\n",
      "Epoch: 470/500... Training loss: 0.0023\n",
      "Epoch: 470/500... Training loss: 0.0007\n",
      "Epoch: 470/500... Training loss: 0.0012\n",
      "Epoch: 470/500... Training loss: 0.0048\n",
      "Epoch: 470/500... Training loss: 0.0026\n",
      "Epoch: 470/500... Training loss: 0.0019\n",
      "Epoch: 470/500... Training loss: 0.0256\n",
      "Epoch: 470/500... Training loss: 0.0123\n",
      "Epoch: 470/500... Training loss: 0.0018\n",
      "Epoch: 470/500... Training loss: 0.0218\n",
      "Epoch: 470/500... Training loss: 0.0085\n",
      "Epoch: 471/500... Training loss: 0.0111\n",
      "Epoch: 471/500... Training loss: 0.0009\n",
      "Epoch: 471/500... Training loss: 0.0022\n",
      "Epoch: 471/500... Training loss: 0.0152\n",
      "Epoch: 471/500... Training loss: 0.0076\n",
      "Epoch: 471/500... Training loss: 0.0079\n",
      "Epoch: 471/500... Training loss: 0.0134\n",
      "Epoch: 471/500... Training loss: 0.0013\n",
      "Epoch: 471/500... Training loss: 0.0011\n",
      "Epoch: 471/500... Training loss: 0.0083\n",
      "Epoch: 471/500... Training loss: 0.0017\n",
      "Epoch: 471/500... Training loss: 0.0139\n",
      "Epoch: 471/500... Training loss: 0.0010\n",
      "Epoch: 471/500... Training loss: 0.0039\n",
      "Epoch: 471/500... Training loss: 0.0009\n",
      "Epoch: 471/500... Training loss: 0.0028\n",
      "Epoch: 471/500... Training loss: 0.0200\n",
      "Epoch: 471/500... Training loss: 0.0085\n",
      "Epoch: 471/500... Training loss: 0.0012\n",
      "Epoch: 471/500... Training loss: 0.0019\n",
      "Epoch: 471/500... Training loss: 0.0096\n",
      "Epoch: 471/500... Training loss: 0.0006\n",
      "Epoch: 471/500... Training loss: 0.0013\n",
      "Epoch: 471/500... Training loss: 0.0005\n",
      "Epoch: 471/500... Training loss: 0.0006\n",
      "Epoch: 471/500... Training loss: 0.0018\n",
      "Epoch: 471/500... Training loss: 0.0108\n",
      "Epoch: 471/500... Training loss: 0.0457\n",
      "Epoch: 471/500... Training loss: 0.0158\n",
      "Epoch: 471/500... Training loss: 0.0024\n",
      "Epoch: 471/500... Training loss: 0.0056\n",
      "Epoch: 472/500... Training loss: 0.0003\n",
      "Epoch: 472/500... Training loss: 0.0017\n",
      "Epoch: 472/500... Training loss: 0.0007\n",
      "Epoch: 472/500... Training loss: 0.0027\n",
      "Epoch: 472/500... Training loss: 0.0018\n",
      "Epoch: 472/500... Training loss: 0.0017\n",
      "Epoch: 472/500... Training loss: 0.0029\n",
      "Epoch: 472/500... Training loss: 0.0157\n",
      "Epoch: 472/500... Training loss: 0.0016\n",
      "Epoch: 472/500... Training loss: 0.0056\n",
      "Epoch: 472/500... Training loss: 0.0122\n",
      "Epoch: 472/500... Training loss: 0.0166\n",
      "Epoch: 472/500... Training loss: 0.0073\n",
      "Epoch: 472/500... Training loss: 0.0030\n",
      "Epoch: 472/500... Training loss: 0.0054\n",
      "Epoch: 472/500... Training loss: 0.0130\n",
      "Epoch: 472/500... Training loss: 0.0303\n",
      "Epoch: 472/500... Training loss: 0.0083\n",
      "Epoch: 472/500... Training loss: 0.0006\n",
      "Epoch: 472/500... Training loss: 0.0112\n",
      "Epoch: 472/500... Training loss: 0.0010\n",
      "Epoch: 472/500... Training loss: 0.0051\n",
      "Epoch: 472/500... Training loss: 0.0003\n",
      "Epoch: 472/500... Training loss: 0.0004\n",
      "Epoch: 472/500... Training loss: 0.0335\n",
      "Epoch: 472/500... Training loss: 0.0447\n",
      "Epoch: 472/500... Training loss: 0.0003\n",
      "Epoch: 472/500... Training loss: 0.0004\n",
      "Epoch: 472/500... Training loss: 0.0096\n",
      "Epoch: 472/500... Training loss: 0.0060\n",
      "Epoch: 472/500... Training loss: 0.0114\n",
      "Epoch: 473/500... Training loss: 0.0023\n",
      "Epoch: 473/500... Training loss: 0.0103\n",
      "Epoch: 473/500... Training loss: 0.0016\n",
      "Epoch: 473/500... Training loss: 0.0219\n",
      "Epoch: 473/500... Training loss: 0.0013\n",
      "Epoch: 473/500... Training loss: 0.0122\n",
      "Epoch: 473/500... Training loss: 0.0006\n",
      "Epoch: 473/500... Training loss: 0.0015\n",
      "Epoch: 473/500... Training loss: 0.0017\n",
      "Epoch: 473/500... Training loss: 0.0010\n",
      "Epoch: 473/500... Training loss: 0.0014\n",
      "Epoch: 473/500... Training loss: 0.0183\n",
      "Epoch: 473/500... Training loss: 0.0201\n",
      "Epoch: 473/500... Training loss: 0.0021\n",
      "Epoch: 473/500... Training loss: 0.0109\n",
      "Epoch: 473/500... Training loss: 0.0004\n",
      "Epoch: 473/500... Training loss: 0.0007\n",
      "Epoch: 473/500... Training loss: 0.0930\n",
      "Epoch: 473/500... Training loss: 0.0016\n",
      "Epoch: 473/500... Training loss: 0.0007\n",
      "Epoch: 473/500... Training loss: 0.0043\n",
      "Epoch: 473/500... Training loss: 0.0073\n",
      "Epoch: 473/500... Training loss: 0.0215\n",
      "Epoch: 473/500... Training loss: 0.0223\n",
      "Epoch: 473/500... Training loss: 0.0050\n",
      "Epoch: 473/500... Training loss: 0.0521\n",
      "Epoch: 473/500... Training loss: 0.0358\n",
      "Epoch: 473/500... Training loss: 0.0011\n",
      "Epoch: 473/500... Training loss: 0.0014\n",
      "Epoch: 473/500... Training loss: 0.0076\n",
      "Epoch: 473/500... Training loss: 0.0013\n",
      "Epoch: 474/500... Training loss: 0.0005\n",
      "Epoch: 474/500... Training loss: 0.0081\n",
      "Epoch: 474/500... Training loss: 0.0061\n",
      "Epoch: 474/500... Training loss: 0.0042\n",
      "Epoch: 474/500... Training loss: 0.0156\n",
      "Epoch: 474/500... Training loss: 0.0030\n",
      "Epoch: 474/500... Training loss: 0.0004\n",
      "Epoch: 474/500... Training loss: 0.0081\n",
      "Epoch: 474/500... Training loss: 0.0007\n",
      "Epoch: 474/500... Training loss: 0.0148\n",
      "Epoch: 474/500... Training loss: 0.0037\n",
      "Epoch: 474/500... Training loss: 0.0231\n",
      "Epoch: 474/500... Training loss: 0.0028\n",
      "Epoch: 474/500... Training loss: 0.0189\n",
      "Epoch: 474/500... Training loss: 0.0030\n",
      "Epoch: 474/500... Training loss: 0.0008\n",
      "Epoch: 474/500... Training loss: 0.0589\n",
      "Epoch: 474/500... Training loss: 0.0032\n",
      "Epoch: 474/500... Training loss: 0.0021\n",
      "Epoch: 474/500... Training loss: 0.0032\n",
      "Epoch: 474/500... Training loss: 0.0778\n",
      "Epoch: 474/500... Training loss: 0.0244\n",
      "Epoch: 474/500... Training loss: 0.0085\n",
      "Epoch: 474/500... Training loss: 0.0010\n",
      "Epoch: 474/500... Training loss: 0.0010\n",
      "Epoch: 474/500... Training loss: 0.0019\n",
      "Epoch: 474/500... Training loss: 0.0346\n",
      "Epoch: 474/500... Training loss: 0.0014\n",
      "Epoch: 474/500... Training loss: 0.0030\n",
      "Epoch: 474/500... Training loss: 0.0288\n",
      "Epoch: 474/500... Training loss: 0.0059\n",
      "Epoch: 475/500... Training loss: 0.0041\n",
      "Epoch: 475/500... Training loss: 0.0468\n",
      "Epoch: 475/500... Training loss: 0.0011\n",
      "Epoch: 475/500... Training loss: 0.0260\n",
      "Epoch: 475/500... Training loss: 0.0090\n",
      "Epoch: 475/500... Training loss: 0.0039\n",
      "Epoch: 475/500... Training loss: 0.0220\n",
      "Epoch: 475/500... Training loss: 0.0022\n",
      "Epoch: 475/500... Training loss: 0.0317\n",
      "Epoch: 475/500... Training loss: 0.0053\n",
      "Epoch: 475/500... Training loss: 0.0045\n",
      "Epoch: 475/500... Training loss: 0.0044\n",
      "Epoch: 475/500... Training loss: 0.0213\n",
      "Epoch: 475/500... Training loss: 0.0010\n",
      "Epoch: 475/500... Training loss: 0.0027\n",
      "Epoch: 475/500... Training loss: 0.0233\n",
      "Epoch: 475/500... Training loss: 0.0005\n",
      "Epoch: 475/500... Training loss: 0.0232\n",
      "Epoch: 475/500... Training loss: 0.0017\n",
      "Epoch: 475/500... Training loss: 0.0033\n",
      "Epoch: 475/500... Training loss: 0.0009\n",
      "Epoch: 475/500... Training loss: 0.0002\n",
      "Epoch: 475/500... Training loss: 0.0055\n",
      "Epoch: 475/500... Training loss: 0.0042\n",
      "Epoch: 475/500... Training loss: 0.0134\n",
      "Epoch: 475/500... Training loss: 0.0086\n",
      "Epoch: 475/500... Training loss: 0.0159\n",
      "Epoch: 475/500... Training loss: 0.0014\n",
      "Epoch: 475/500... Training loss: 0.0209\n",
      "Epoch: 475/500... Training loss: 0.0119\n",
      "Epoch: 475/500... Training loss: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 476/500... Training loss: 0.0053\n",
      "Epoch: 476/500... Training loss: 0.0165\n",
      "Epoch: 476/500... Training loss: 0.0035\n",
      "Epoch: 476/500... Training loss: 0.0296\n",
      "Epoch: 476/500... Training loss: 0.0194\n",
      "Epoch: 476/500... Training loss: 0.0040\n",
      "Epoch: 476/500... Training loss: 0.0369\n",
      "Epoch: 476/500... Training loss: 0.0016\n",
      "Epoch: 476/500... Training loss: 0.0047\n",
      "Epoch: 476/500... Training loss: 0.0188\n",
      "Epoch: 476/500... Training loss: 0.0030\n",
      "Epoch: 476/500... Training loss: 0.0152\n",
      "Epoch: 476/500... Training loss: 0.0022\n",
      "Epoch: 476/500... Training loss: 0.0006\n",
      "Epoch: 476/500... Training loss: 0.0012\n",
      "Epoch: 476/500... Training loss: 0.0360\n",
      "Epoch: 476/500... Training loss: 0.0146\n",
      "Epoch: 476/500... Training loss: 0.0019\n",
      "Epoch: 476/500... Training loss: 0.0031\n",
      "Epoch: 476/500... Training loss: 0.0006\n",
      "Epoch: 476/500... Training loss: 0.0005\n",
      "Epoch: 476/500... Training loss: 0.0509\n",
      "Epoch: 476/500... Training loss: 0.0011\n",
      "Epoch: 476/500... Training loss: 0.0011\n",
      "Epoch: 476/500... Training loss: 0.0009\n",
      "Epoch: 476/500... Training loss: 0.0053\n",
      "Epoch: 476/500... Training loss: 0.0005\n",
      "Epoch: 476/500... Training loss: 0.0010\n",
      "Epoch: 476/500... Training loss: 0.0249\n",
      "Epoch: 476/500... Training loss: 0.0435\n",
      "Epoch: 476/500... Training loss: 0.0041\n",
      "Epoch: 477/500... Training loss: 0.0053\n",
      "Epoch: 477/500... Training loss: 0.0013\n",
      "Epoch: 477/500... Training loss: 0.0032\n",
      "Epoch: 477/500... Training loss: 0.0151\n",
      "Epoch: 477/500... Training loss: 0.0044\n",
      "Epoch: 477/500... Training loss: 0.0291\n",
      "Epoch: 477/500... Training loss: 0.0142\n",
      "Epoch: 477/500... Training loss: 0.0215\n",
      "Epoch: 477/500... Training loss: 0.0057\n",
      "Epoch: 477/500... Training loss: 0.0054\n",
      "Epoch: 477/500... Training loss: 0.0480\n",
      "Epoch: 477/500... Training loss: 0.0063\n",
      "Epoch: 477/500... Training loss: 0.0207\n",
      "Epoch: 477/500... Training loss: 0.0161\n",
      "Epoch: 477/500... Training loss: 0.0039\n",
      "Epoch: 477/500... Training loss: 0.0012\n",
      "Epoch: 477/500... Training loss: 0.0049\n",
      "Epoch: 477/500... Training loss: 0.0004\n",
      "Epoch: 477/500... Training loss: 0.0111\n",
      "Epoch: 477/500... Training loss: 0.0067\n",
      "Epoch: 477/500... Training loss: 0.0010\n",
      "Epoch: 477/500... Training loss: 0.0006\n",
      "Epoch: 477/500... Training loss: 0.0030\n",
      "Epoch: 477/500... Training loss: 0.0010\n",
      "Epoch: 477/500... Training loss: 0.0212\n",
      "Epoch: 477/500... Training loss: 0.0078\n",
      "Epoch: 477/500... Training loss: 0.0002\n",
      "Epoch: 477/500... Training loss: 0.0021\n",
      "Epoch: 477/500... Training loss: 0.0006\n",
      "Epoch: 477/500... Training loss: 0.0006\n",
      "Epoch: 477/500... Training loss: 0.0021\n",
      "Epoch: 478/500... Training loss: 0.0026\n",
      "Epoch: 478/500... Training loss: 0.0002\n",
      "Epoch: 478/500... Training loss: 0.0007\n",
      "Epoch: 478/500... Training loss: 0.0085\n",
      "Epoch: 478/500... Training loss: 0.0583\n",
      "Epoch: 478/500... Training loss: 0.0067\n",
      "Epoch: 478/500... Training loss: 0.0016\n",
      "Epoch: 478/500... Training loss: 0.0108\n",
      "Epoch: 478/500... Training loss: 0.0041\n",
      "Epoch: 478/500... Training loss: 0.0046\n",
      "Epoch: 478/500... Training loss: 0.0037\n",
      "Epoch: 478/500... Training loss: 0.0059\n",
      "Epoch: 478/500... Training loss: 0.0060\n",
      "Epoch: 478/500... Training loss: 0.0114\n",
      "Epoch: 478/500... Training loss: 0.0031\n",
      "Epoch: 478/500... Training loss: 0.0055\n",
      "Epoch: 478/500... Training loss: 0.0012\n",
      "Epoch: 478/500... Training loss: 0.0016\n",
      "Epoch: 478/500... Training loss: 0.0006\n",
      "Epoch: 478/500... Training loss: 0.0025\n",
      "Epoch: 478/500... Training loss: 0.0004\n",
      "Epoch: 478/500... Training loss: 0.0002\n",
      "Epoch: 478/500... Training loss: 0.0350\n",
      "Epoch: 478/500... Training loss: 0.0003\n",
      "Epoch: 478/500... Training loss: 0.0059\n",
      "Epoch: 478/500... Training loss: 0.0094\n",
      "Epoch: 478/500... Training loss: 0.0003\n",
      "Epoch: 478/500... Training loss: 0.0256\n",
      "Epoch: 478/500... Training loss: 0.0090\n",
      "Epoch: 478/500... Training loss: 0.0028\n",
      "Epoch: 478/500... Training loss: 0.0018\n",
      "Epoch: 479/500... Training loss: 0.0005\n",
      "Epoch: 479/500... Training loss: 0.0041\n",
      "Epoch: 479/500... Training loss: 0.0009\n",
      "Epoch: 479/500... Training loss: 0.0016\n",
      "Epoch: 479/500... Training loss: 0.0040\n",
      "Epoch: 479/500... Training loss: 0.0077\n",
      "Epoch: 479/500... Training loss: 0.0068\n",
      "Epoch: 479/500... Training loss: 0.0021\n",
      "Epoch: 479/500... Training loss: 0.0057\n",
      "Epoch: 479/500... Training loss: 0.0008\n",
      "Epoch: 479/500... Training loss: 0.0288\n",
      "Epoch: 479/500... Training loss: 0.0100\n",
      "Epoch: 479/500... Training loss: 0.0006\n",
      "Epoch: 479/500... Training loss: 0.0028\n",
      "Epoch: 479/500... Training loss: 0.1032\n",
      "Epoch: 479/500... Training loss: 0.0004\n",
      "Epoch: 479/500... Training loss: 0.0007\n",
      "Epoch: 479/500... Training loss: 0.0193\n",
      "Epoch: 479/500... Training loss: 0.0013\n",
      "Epoch: 479/500... Training loss: 0.0014\n",
      "Epoch: 479/500... Training loss: 0.0197\n",
      "Epoch: 479/500... Training loss: 0.0020\n",
      "Epoch: 479/500... Training loss: 0.0506\n",
      "Epoch: 479/500... Training loss: 0.0008\n",
      "Epoch: 479/500... Training loss: 0.0014\n",
      "Epoch: 479/500... Training loss: 0.0004\n",
      "Epoch: 479/500... Training loss: 0.0063\n",
      "Epoch: 479/500... Training loss: 0.0019\n",
      "Epoch: 479/500... Training loss: 0.0009\n",
      "Epoch: 479/500... Training loss: 0.0072\n",
      "Epoch: 479/500... Training loss: 0.0003\n",
      "Epoch: 480/500... Training loss: 0.0011\n",
      "Epoch: 480/500... Training loss: 0.0026\n",
      "Epoch: 480/500... Training loss: 0.0225\n",
      "Epoch: 480/500... Training loss: 0.0348\n",
      "Epoch: 480/500... Training loss: 0.0003\n",
      "Epoch: 480/500... Training loss: 0.0624\n",
      "Epoch: 480/500... Training loss: 0.0005\n",
      "Epoch: 480/500... Training loss: 0.0079\n",
      "Epoch: 480/500... Training loss: 0.0016\n",
      "Epoch: 480/500... Training loss: 0.0137\n",
      "Epoch: 480/500... Training loss: 0.0305\n",
      "Epoch: 480/500... Training loss: 0.0034\n",
      "Epoch: 480/500... Training loss: 0.0002\n",
      "Epoch: 480/500... Training loss: 0.0541\n",
      "Epoch: 480/500... Training loss: 0.0042\n",
      "Epoch: 480/500... Training loss: 0.0013\n",
      "Epoch: 480/500... Training loss: 0.0554\n",
      "Epoch: 480/500... Training loss: 0.0256\n",
      "Epoch: 480/500... Training loss: 0.0006\n",
      "Epoch: 480/500... Training loss: 0.0030\n",
      "Epoch: 480/500... Training loss: 0.0009\n",
      "Epoch: 480/500... Training loss: 0.0054\n",
      "Epoch: 480/500... Training loss: 0.0031\n",
      "Epoch: 480/500... Training loss: 0.0425\n",
      "Epoch: 480/500... Training loss: 0.0224\n",
      "Epoch: 480/500... Training loss: 0.0135\n",
      "Epoch: 480/500... Training loss: 0.0188\n",
      "Epoch: 480/500... Training loss: 0.0006\n",
      "Epoch: 480/500... Training loss: 0.0010\n",
      "Epoch: 480/500... Training loss: 0.0132\n",
      "Epoch: 480/500... Training loss: 0.0232\n",
      "Epoch: 481/500... Training loss: 0.0417\n",
      "Epoch: 481/500... Training loss: 0.0089\n",
      "Epoch: 481/500... Training loss: 0.0021\n",
      "Epoch: 481/500... Training loss: 0.0009\n",
      "Epoch: 481/500... Training loss: 0.0030\n",
      "Epoch: 481/500... Training loss: 0.0243\n",
      "Epoch: 481/500... Training loss: 0.0007\n",
      "Epoch: 481/500... Training loss: 0.0011\n",
      "Epoch: 481/500... Training loss: 0.0025\n",
      "Epoch: 481/500... Training loss: 0.0139\n",
      "Epoch: 481/500... Training loss: 0.0080\n",
      "Epoch: 481/500... Training loss: 0.0122\n",
      "Epoch: 481/500... Training loss: 0.0007\n",
      "Epoch: 481/500... Training loss: 0.0011\n",
      "Epoch: 481/500... Training loss: 0.0144\n",
      "Epoch: 481/500... Training loss: 0.0021\n",
      "Epoch: 481/500... Training loss: 0.0018\n",
      "Epoch: 481/500... Training loss: 0.0005\n",
      "Epoch: 481/500... Training loss: 0.1208\n",
      "Epoch: 481/500... Training loss: 0.0004\n",
      "Epoch: 481/500... Training loss: 0.0048\n",
      "Epoch: 481/500... Training loss: 0.0291\n",
      "Epoch: 481/500... Training loss: 0.0013\n",
      "Epoch: 481/500... Training loss: 0.0007\n",
      "Epoch: 481/500... Training loss: 0.0112\n",
      "Epoch: 481/500... Training loss: 0.0003\n",
      "Epoch: 481/500... Training loss: 0.0155\n",
      "Epoch: 481/500... Training loss: 0.0214\n",
      "Epoch: 481/500... Training loss: 0.0018\n",
      "Epoch: 481/500... Training loss: 0.0011\n",
      "Epoch: 481/500... Training loss: 0.0008\n",
      "Epoch: 482/500... Training loss: 0.0822\n",
      "Epoch: 482/500... Training loss: 0.0010\n",
      "Epoch: 482/500... Training loss: 0.0078\n",
      "Epoch: 482/500... Training loss: 0.0010\n",
      "Epoch: 482/500... Training loss: 0.0010\n",
      "Epoch: 482/500... Training loss: 0.0008\n",
      "Epoch: 482/500... Training loss: 0.0016\n",
      "Epoch: 482/500... Training loss: 0.0028\n",
      "Epoch: 482/500... Training loss: 0.0322\n",
      "Epoch: 482/500... Training loss: 0.0005\n",
      "Epoch: 482/500... Training loss: 0.0032\n",
      "Epoch: 482/500... Training loss: 0.0016\n",
      "Epoch: 482/500... Training loss: 0.0641\n",
      "Epoch: 482/500... Training loss: 0.0009\n",
      "Epoch: 482/500... Training loss: 0.0012\n",
      "Epoch: 482/500... Training loss: 0.0008\n",
      "Epoch: 482/500... Training loss: 0.0134\n",
      "Epoch: 482/500... Training loss: 0.0062\n",
      "Epoch: 482/500... Training loss: 0.0144\n",
      "Epoch: 482/500... Training loss: 0.0035\n",
      "Epoch: 482/500... Training loss: 0.0004\n",
      "Epoch: 482/500... Training loss: 0.0831\n",
      "Epoch: 482/500... Training loss: 0.0012\n",
      "Epoch: 482/500... Training loss: 0.0615\n",
      "Epoch: 482/500... Training loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 482/500... Training loss: 0.0039\n",
      "Epoch: 482/500... Training loss: 0.1234\n",
      "Epoch: 482/500... Training loss: 0.0137\n",
      "Epoch: 482/500... Training loss: 0.0024\n",
      "Epoch: 482/500... Training loss: 0.0010\n",
      "Epoch: 482/500... Training loss: 0.0050\n",
      "Epoch: 483/500... Training loss: 0.0034\n",
      "Epoch: 483/500... Training loss: 0.0031\n",
      "Epoch: 483/500... Training loss: 0.0018\n",
      "Epoch: 483/500... Training loss: 0.0014\n",
      "Epoch: 483/500... Training loss: 0.0057\n",
      "Epoch: 483/500... Training loss: 0.0058\n",
      "Epoch: 483/500... Training loss: 0.0010\n",
      "Epoch: 483/500... Training loss: 0.0031\n",
      "Epoch: 483/500... Training loss: 0.0002\n",
      "Epoch: 483/500... Training loss: 0.0012\n",
      "Epoch: 483/500... Training loss: 0.0066\n",
      "Epoch: 483/500... Training loss: 0.0112\n",
      "Epoch: 483/500... Training loss: 0.0205\n",
      "Epoch: 483/500... Training loss: 0.0236\n",
      "Epoch: 483/500... Training loss: 0.0271\n",
      "Epoch: 483/500... Training loss: 0.0446\n",
      "Epoch: 483/500... Training loss: 0.0598\n",
      "Epoch: 483/500... Training loss: 0.0043\n",
      "Epoch: 483/500... Training loss: 0.0014\n",
      "Epoch: 483/500... Training loss: 0.0043\n",
      "Epoch: 483/500... Training loss: 0.0349\n",
      "Epoch: 483/500... Training loss: 0.0040\n",
      "Epoch: 483/500... Training loss: 0.0015\n",
      "Epoch: 483/500... Training loss: 0.0019\n",
      "Epoch: 483/500... Training loss: 0.0038\n",
      "Epoch: 483/500... Training loss: 0.0024\n",
      "Epoch: 483/500... Training loss: 0.0003\n",
      "Epoch: 483/500... Training loss: 0.0028\n",
      "Epoch: 483/500... Training loss: 0.0017\n",
      "Epoch: 483/500... Training loss: 0.0501\n",
      "Epoch: 483/500... Training loss: 0.0054\n",
      "Epoch: 484/500... Training loss: 0.0132\n",
      "Epoch: 484/500... Training loss: 0.0073\n",
      "Epoch: 484/500... Training loss: 0.0436\n",
      "Epoch: 484/500... Training loss: 0.0238\n",
      "Epoch: 484/500... Training loss: 0.0387\n",
      "Epoch: 484/500... Training loss: 0.0205\n",
      "Epoch: 484/500... Training loss: 0.0007\n",
      "Epoch: 484/500... Training loss: 0.0246\n",
      "Epoch: 484/500... Training loss: 0.0033\n",
      "Epoch: 484/500... Training loss: 0.0019\n",
      "Epoch: 484/500... Training loss: 0.0012\n",
      "Epoch: 484/500... Training loss: 0.0669\n",
      "Epoch: 484/500... Training loss: 0.0114\n",
      "Epoch: 484/500... Training loss: 0.0129\n",
      "Epoch: 484/500... Training loss: 0.0047\n",
      "Epoch: 484/500... Training loss: 0.0011\n",
      "Epoch: 484/500... Training loss: 0.0004\n",
      "Epoch: 484/500... Training loss: 0.0565\n",
      "Epoch: 484/500... Training loss: 0.0017\n",
      "Epoch: 484/500... Training loss: 0.0007\n",
      "Epoch: 484/500... Training loss: 0.0092\n",
      "Epoch: 484/500... Training loss: 0.0010\n",
      "Epoch: 484/500... Training loss: 0.0068\n",
      "Epoch: 484/500... Training loss: 0.0045\n",
      "Epoch: 484/500... Training loss: 0.0014\n",
      "Epoch: 484/500... Training loss: 0.0146\n",
      "Epoch: 484/500... Training loss: 0.0662\n",
      "Epoch: 484/500... Training loss: 0.0096\n",
      "Epoch: 484/500... Training loss: 0.0231\n",
      "Epoch: 484/500... Training loss: 0.0005\n",
      "Epoch: 484/500... Training loss: 0.0390\n",
      "Epoch: 485/500... Training loss: 0.0767\n",
      "Epoch: 485/500... Training loss: 0.0679\n",
      "Epoch: 485/500... Training loss: 0.0061\n",
      "Epoch: 485/500... Training loss: 0.0016\n",
      "Epoch: 485/500... Training loss: 0.0050\n",
      "Epoch: 485/500... Training loss: 0.0518\n",
      "Epoch: 485/500... Training loss: 0.0009\n",
      "Epoch: 485/500... Training loss: 0.0014\n",
      "Epoch: 485/500... Training loss: 0.0009\n",
      "Epoch: 485/500... Training loss: 0.0445\n",
      "Epoch: 485/500... Training loss: 0.0610\n",
      "Epoch: 485/500... Training loss: 0.0097\n",
      "Epoch: 485/500... Training loss: 0.0048\n",
      "Epoch: 485/500... Training loss: 0.0013\n",
      "Epoch: 485/500... Training loss: 0.0028\n",
      "Epoch: 485/500... Training loss: 0.0008\n",
      "Epoch: 485/500... Training loss: 0.0045\n",
      "Epoch: 485/500... Training loss: 0.0721\n",
      "Epoch: 485/500... Training loss: 0.0009\n",
      "Epoch: 485/500... Training loss: 0.0087\n",
      "Epoch: 485/500... Training loss: 0.0033\n",
      "Epoch: 485/500... Training loss: 0.0437\n",
      "Epoch: 485/500... Training loss: 0.0219\n",
      "Epoch: 485/500... Training loss: 0.0559\n",
      "Epoch: 485/500... Training loss: 0.0282\n",
      "Epoch: 485/500... Training loss: 0.0029\n",
      "Epoch: 485/500... Training loss: 0.0009\n",
      "Epoch: 485/500... Training loss: 0.0022\n",
      "Epoch: 485/500... Training loss: 0.0014\n",
      "Epoch: 485/500... Training loss: 0.0189\n",
      "Epoch: 485/500... Training loss: 0.0007\n",
      "Epoch: 486/500... Training loss: 0.0084\n",
      "Epoch: 486/500... Training loss: 0.1183\n",
      "Epoch: 486/500... Training loss: 0.0720\n",
      "Epoch: 486/500... Training loss: 0.0022\n",
      "Epoch: 486/500... Training loss: 0.0052\n",
      "Epoch: 486/500... Training loss: 0.0125\n",
      "Epoch: 486/500... Training loss: 0.0681\n",
      "Epoch: 486/500... Training loss: 0.0052\n",
      "Epoch: 486/500... Training loss: 0.0004\n",
      "Epoch: 486/500... Training loss: 0.0055\n",
      "Epoch: 486/500... Training loss: 0.0009\n",
      "Epoch: 486/500... Training loss: 0.0074\n",
      "Epoch: 486/500... Training loss: 0.0054\n",
      "Epoch: 486/500... Training loss: 0.0020\n",
      "Epoch: 486/500... Training loss: 0.0091\n",
      "Epoch: 486/500... Training loss: 0.0018\n",
      "Epoch: 486/500... Training loss: 0.0028\n",
      "Epoch: 486/500... Training loss: 0.0056\n",
      "Epoch: 486/500... Training loss: 0.0083\n",
      "Epoch: 486/500... Training loss: 0.0003\n",
      "Epoch: 486/500... Training loss: 0.0226\n",
      "Epoch: 486/500... Training loss: 0.0449\n",
      "Epoch: 486/500... Training loss: 0.0278\n",
      "Epoch: 486/500... Training loss: 0.0590\n",
      "Epoch: 486/500... Training loss: 0.0012\n",
      "Epoch: 486/500... Training loss: 0.0007\n",
      "Epoch: 486/500... Training loss: 0.0111\n",
      "Epoch: 486/500... Training loss: 0.0020\n",
      "Epoch: 486/500... Training loss: 0.0020\n",
      "Epoch: 486/500... Training loss: 0.0006\n",
      "Epoch: 486/500... Training loss: 0.0619\n",
      "Epoch: 487/500... Training loss: 0.0057\n",
      "Epoch: 487/500... Training loss: 0.0531\n",
      "Epoch: 487/500... Training loss: 0.0005\n",
      "Epoch: 487/500... Training loss: 0.0021\n",
      "Epoch: 487/500... Training loss: 0.0088\n",
      "Epoch: 487/500... Training loss: 0.0035\n",
      "Epoch: 487/500... Training loss: 0.0045\n",
      "Epoch: 487/500... Training loss: 0.0015\n",
      "Epoch: 487/500... Training loss: 0.0030\n",
      "Epoch: 487/500... Training loss: 0.0017\n",
      "Epoch: 487/500... Training loss: 0.0045\n",
      "Epoch: 487/500... Training loss: 0.0024\n",
      "Epoch: 487/500... Training loss: 0.0009\n",
      "Epoch: 487/500... Training loss: 0.0330\n",
      "Epoch: 487/500... Training loss: 0.0032\n",
      "Epoch: 487/500... Training loss: 0.0049\n",
      "Epoch: 487/500... Training loss: 0.0005\n",
      "Epoch: 487/500... Training loss: 0.0243\n",
      "Epoch: 487/500... Training loss: 0.0006\n",
      "Epoch: 487/500... Training loss: 0.0150\n",
      "Epoch: 487/500... Training loss: 0.0011\n",
      "Epoch: 487/500... Training loss: 0.0174\n",
      "Epoch: 487/500... Training loss: 0.0273\n",
      "Epoch: 487/500... Training loss: 0.0225\n",
      "Epoch: 487/500... Training loss: 0.0118\n",
      "Epoch: 487/500... Training loss: 0.0087\n",
      "Epoch: 487/500... Training loss: 0.0190\n",
      "Epoch: 487/500... Training loss: 0.0015\n",
      "Epoch: 487/500... Training loss: 0.0235\n",
      "Epoch: 487/500... Training loss: 0.0130\n",
      "Epoch: 487/500... Training loss: 0.0231\n",
      "Epoch: 488/500... Training loss: 0.0042\n",
      "Epoch: 488/500... Training loss: 0.0099\n",
      "Epoch: 488/500... Training loss: 0.0058\n",
      "Epoch: 488/500... Training loss: 0.0355\n",
      "Epoch: 488/500... Training loss: 0.0024\n",
      "Epoch: 488/500... Training loss: 0.0208\n",
      "Epoch: 488/500... Training loss: 0.0098\n",
      "Epoch: 488/500... Training loss: 0.0260\n",
      "Epoch: 488/500... Training loss: 0.0023\n",
      "Epoch: 488/500... Training loss: 0.0003\n",
      "Epoch: 488/500... Training loss: 0.0088\n",
      "Epoch: 488/500... Training loss: 0.0141\n",
      "Epoch: 488/500... Training loss: 0.0521\n",
      "Epoch: 488/500... Training loss: 0.0015\n",
      "Epoch: 488/500... Training loss: 0.0197\n",
      "Epoch: 488/500... Training loss: 0.0028\n",
      "Epoch: 488/500... Training loss: 0.0007\n",
      "Epoch: 488/500... Training loss: 0.0006\n",
      "Epoch: 488/500... Training loss: 0.0065\n",
      "Epoch: 488/500... Training loss: 0.0126\n",
      "Epoch: 488/500... Training loss: 0.0008\n",
      "Epoch: 488/500... Training loss: 0.0008\n",
      "Epoch: 488/500... Training loss: 0.0452\n",
      "Epoch: 488/500... Training loss: 0.0003\n",
      "Epoch: 488/500... Training loss: 0.0073\n",
      "Epoch: 488/500... Training loss: 0.0004\n",
      "Epoch: 488/500... Training loss: 0.0034\n",
      "Epoch: 488/500... Training loss: 0.0071\n",
      "Epoch: 488/500... Training loss: 0.0220\n",
      "Epoch: 488/500... Training loss: 0.0033\n",
      "Epoch: 488/500... Training loss: 0.0013\n",
      "Epoch: 489/500... Training loss: 0.0049\n",
      "Epoch: 489/500... Training loss: 0.0036\n",
      "Epoch: 489/500... Training loss: 0.0009\n",
      "Epoch: 489/500... Training loss: 0.0288\n",
      "Epoch: 489/500... Training loss: 0.0020\n",
      "Epoch: 489/500... Training loss: 0.0089\n",
      "Epoch: 489/500... Training loss: 0.0010\n",
      "Epoch: 489/500... Training loss: 0.0284\n",
      "Epoch: 489/500... Training loss: 0.0016\n",
      "Epoch: 489/500... Training loss: 0.0084\n",
      "Epoch: 489/500... Training loss: 0.0082\n",
      "Epoch: 489/500... Training loss: 0.0049\n",
      "Epoch: 489/500... Training loss: 0.0019\n",
      "Epoch: 489/500... Training loss: 0.0221\n",
      "Epoch: 489/500... Training loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 489/500... Training loss: 0.0029\n",
      "Epoch: 489/500... Training loss: 0.0380\n",
      "Epoch: 489/500... Training loss: 0.0012\n",
      "Epoch: 489/500... Training loss: 0.0107\n",
      "Epoch: 489/500... Training loss: 0.0160\n",
      "Epoch: 489/500... Training loss: 0.0050\n",
      "Epoch: 489/500... Training loss: 0.0037\n",
      "Epoch: 489/500... Training loss: 0.0369\n",
      "Epoch: 489/500... Training loss: 0.0015\n",
      "Epoch: 489/500... Training loss: 0.0018\n",
      "Epoch: 489/500... Training loss: 0.0025\n",
      "Epoch: 489/500... Training loss: 0.0267\n",
      "Epoch: 489/500... Training loss: 0.0010\n",
      "Epoch: 489/500... Training loss: 0.0079\n",
      "Epoch: 489/500... Training loss: 0.0021\n",
      "Epoch: 489/500... Training loss: 0.0316\n",
      "Epoch: 490/500... Training loss: 0.0016\n",
      "Epoch: 490/500... Training loss: 0.0019\n",
      "Epoch: 490/500... Training loss: 0.0022\n",
      "Epoch: 490/500... Training loss: 0.0012\n",
      "Epoch: 490/500... Training loss: 0.0011\n",
      "Epoch: 490/500... Training loss: 0.0283\n",
      "Epoch: 490/500... Training loss: 0.0006\n",
      "Epoch: 490/500... Training loss: 0.0018\n",
      "Epoch: 490/500... Training loss: 0.0015\n",
      "Epoch: 490/500... Training loss: 0.0070\n",
      "Epoch: 490/500... Training loss: 0.0020\n",
      "Epoch: 490/500... Training loss: 0.0308\n",
      "Epoch: 490/500... Training loss: 0.0099\n",
      "Epoch: 490/500... Training loss: 0.0006\n",
      "Epoch: 490/500... Training loss: 0.0032\n",
      "Epoch: 490/500... Training loss: 0.0058\n",
      "Epoch: 490/500... Training loss: 0.0138\n",
      "Epoch: 490/500... Training loss: 0.0013\n",
      "Epoch: 490/500... Training loss: 0.0010\n",
      "Epoch: 490/500... Training loss: 0.0036\n",
      "Epoch: 490/500... Training loss: 0.0038\n",
      "Epoch: 490/500... Training loss: 0.0870\n",
      "Epoch: 490/500... Training loss: 0.0030\n",
      "Epoch: 490/500... Training loss: 0.0003\n",
      "Epoch: 490/500... Training loss: 0.0019\n",
      "Epoch: 490/500... Training loss: 0.0043\n",
      "Epoch: 490/500... Training loss: 0.0527\n",
      "Epoch: 490/500... Training loss: 0.0008\n",
      "Epoch: 490/500... Training loss: 0.0057\n",
      "Epoch: 490/500... Training loss: 0.0151\n",
      "Epoch: 490/500... Training loss: 0.0015\n",
      "Epoch: 491/500... Training loss: 0.0030\n",
      "Epoch: 491/500... Training loss: 0.0073\n",
      "Epoch: 491/500... Training loss: 0.0005\n",
      "Epoch: 491/500... Training loss: 0.0178\n",
      "Epoch: 491/500... Training loss: 0.0021\n",
      "Epoch: 491/500... Training loss: 0.0722\n",
      "Epoch: 491/500... Training loss: 0.0040\n",
      "Epoch: 491/500... Training loss: 0.0013\n",
      "Epoch: 491/500... Training loss: 0.0274\n",
      "Epoch: 491/500... Training loss: 0.0007\n",
      "Epoch: 491/500... Training loss: 0.0313\n",
      "Epoch: 491/500... Training loss: 0.0010\n",
      "Epoch: 491/500... Training loss: 0.0011\n",
      "Epoch: 491/500... Training loss: 0.0082\n",
      "Epoch: 491/500... Training loss: 0.0019\n",
      "Epoch: 491/500... Training loss: 0.0018\n",
      "Epoch: 491/500... Training loss: 0.0007\n",
      "Epoch: 491/500... Training loss: 0.0004\n",
      "Epoch: 491/500... Training loss: 0.0257\n",
      "Epoch: 491/500... Training loss: 0.0039\n",
      "Epoch: 491/500... Training loss: 0.0017\n",
      "Epoch: 491/500... Training loss: 0.0007\n",
      "Epoch: 491/500... Training loss: 0.0041\n",
      "Epoch: 491/500... Training loss: 0.0002\n",
      "Epoch: 491/500... Training loss: 0.0015\n",
      "Epoch: 491/500... Training loss: 0.0389\n",
      "Epoch: 491/500... Training loss: 0.0249\n",
      "Epoch: 491/500... Training loss: 0.0020\n",
      "Epoch: 491/500... Training loss: 0.0008\n",
      "Epoch: 491/500... Training loss: 0.0003\n",
      "Epoch: 491/500... Training loss: 0.0035\n",
      "Epoch: 492/500... Training loss: 0.0018\n",
      "Epoch: 492/500... Training loss: 0.0057\n",
      "Epoch: 492/500... Training loss: 0.0007\n",
      "Epoch: 492/500... Training loss: 0.0010\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0061\n",
      "Epoch: 492/500... Training loss: 0.0007\n",
      "Epoch: 492/500... Training loss: 0.0041\n",
      "Epoch: 492/500... Training loss: 0.0020\n",
      "Epoch: 492/500... Training loss: 0.0090\n",
      "Epoch: 492/500... Training loss: 0.0011\n",
      "Epoch: 492/500... Training loss: 0.0252\n",
      "Epoch: 492/500... Training loss: 0.0015\n",
      "Epoch: 492/500... Training loss: 0.0009\n",
      "Epoch: 492/500... Training loss: 0.0039\n",
      "Epoch: 492/500... Training loss: 0.0008\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0027\n",
      "Epoch: 492/500... Training loss: 0.0067\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0033\n",
      "Epoch: 492/500... Training loss: 0.0008\n",
      "Epoch: 492/500... Training loss: 0.0216\n",
      "Epoch: 492/500... Training loss: 0.0008\n",
      "Epoch: 492/500... Training loss: 0.0087\n",
      "Epoch: 492/500... Training loss: 0.0141\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0191\n",
      "Epoch: 492/500... Training loss: 0.0060\n",
      "Epoch: 492/500... Training loss: 0.0100\n",
      "Epoch: 492/500... Training loss: 0.0018\n",
      "Epoch: 493/500... Training loss: 0.0030\n",
      "Epoch: 493/500... Training loss: 0.0192\n",
      "Epoch: 493/500... Training loss: 0.0024\n",
      "Epoch: 493/500... Training loss: 0.0030\n",
      "Epoch: 493/500... Training loss: 0.0030\n",
      "Epoch: 493/500... Training loss: 0.0026\n",
      "Epoch: 493/500... Training loss: 0.0008\n",
      "Epoch: 493/500... Training loss: 0.0014\n",
      "Epoch: 493/500... Training loss: 0.0116\n",
      "Epoch: 493/500... Training loss: 0.0009\n",
      "Epoch: 493/500... Training loss: 0.0165\n",
      "Epoch: 493/500... Training loss: 0.0260\n",
      "Epoch: 493/500... Training loss: 0.0050\n",
      "Epoch: 493/500... Training loss: 0.0012\n",
      "Epoch: 493/500... Training loss: 0.0013\n",
      "Epoch: 493/500... Training loss: 0.0501\n",
      "Epoch: 493/500... Training loss: 0.0015\n",
      "Epoch: 493/500... Training loss: 0.0032\n",
      "Epoch: 493/500... Training loss: 0.0003\n",
      "Epoch: 493/500... Training loss: 0.0325\n",
      "Epoch: 493/500... Training loss: 0.0546\n",
      "Epoch: 493/500... Training loss: 0.0050\n",
      "Epoch: 493/500... Training loss: 0.0054\n",
      "Epoch: 493/500... Training loss: 0.0005\n",
      "Epoch: 493/500... Training loss: 0.0023\n",
      "Epoch: 493/500... Training loss: 0.0042\n",
      "Epoch: 493/500... Training loss: 0.0350\n",
      "Epoch: 493/500... Training loss: 0.0005\n",
      "Epoch: 493/500... Training loss: 0.0151\n",
      "Epoch: 493/500... Training loss: 0.0020\n",
      "Epoch: 493/500... Training loss: 0.0200\n",
      "Epoch: 494/500... Training loss: 0.0008\n",
      "Epoch: 494/500... Training loss: 0.0123\n",
      "Epoch: 494/500... Training loss: 0.0023\n",
      "Epoch: 494/500... Training loss: 0.0082\n",
      "Epoch: 494/500... Training loss: 0.0046\n",
      "Epoch: 494/500... Training loss: 0.0341\n",
      "Epoch: 494/500... Training loss: 0.0019\n",
      "Epoch: 494/500... Training loss: 0.0038\n",
      "Epoch: 494/500... Training loss: 0.0425\n",
      "Epoch: 494/500... Training loss: 0.0017\n",
      "Epoch: 494/500... Training loss: 0.0020\n",
      "Epoch: 494/500... Training loss: 0.0101\n",
      "Epoch: 494/500... Training loss: 0.0056\n",
      "Epoch: 494/500... Training loss: 0.0099\n",
      "Epoch: 494/500... Training loss: 0.0006\n",
      "Epoch: 494/500... Training loss: 0.0066\n",
      "Epoch: 494/500... Training loss: 0.0013\n",
      "Epoch: 494/500... Training loss: 0.0484\n",
      "Epoch: 494/500... Training loss: 0.0004\n",
      "Epoch: 494/500... Training loss: 0.0013\n",
      "Epoch: 494/500... Training loss: 0.0487\n",
      "Epoch: 494/500... Training loss: 0.0048\n",
      "Epoch: 494/500... Training loss: 0.0863\n",
      "Epoch: 494/500... Training loss: 0.0007\n",
      "Epoch: 494/500... Training loss: 0.0022\n",
      "Epoch: 494/500... Training loss: 0.0117\n",
      "Epoch: 494/500... Training loss: 0.0024\n",
      "Epoch: 494/500... Training loss: 0.0467\n",
      "Epoch: 494/500... Training loss: 0.0007\n",
      "Epoch: 494/500... Training loss: 0.0048\n",
      "Epoch: 494/500... Training loss: 0.0008\n",
      "Epoch: 495/500... Training loss: 0.0017\n",
      "Epoch: 495/500... Training loss: 0.0007\n",
      "Epoch: 495/500... Training loss: 0.0006\n",
      "Epoch: 495/500... Training loss: 0.0009\n",
      "Epoch: 495/500... Training loss: 0.0007\n",
      "Epoch: 495/500... Training loss: 0.0028\n",
      "Epoch: 495/500... Training loss: 0.0009\n",
      "Epoch: 495/500... Training loss: 0.0057\n",
      "Epoch: 495/500... Training loss: 0.0015\n",
      "Epoch: 495/500... Training loss: 0.0238\n",
      "Epoch: 495/500... Training loss: 0.0017\n",
      "Epoch: 495/500... Training loss: 0.0028\n",
      "Epoch: 495/500... Training loss: 0.0115\n",
      "Epoch: 495/500... Training loss: 0.0003\n",
      "Epoch: 495/500... Training loss: 0.0068\n",
      "Epoch: 495/500... Training loss: 0.0015\n",
      "Epoch: 495/500... Training loss: 0.0020\n",
      "Epoch: 495/500... Training loss: 0.0007\n",
      "Epoch: 495/500... Training loss: 0.0472\n",
      "Epoch: 495/500... Training loss: 0.0114\n",
      "Epoch: 495/500... Training loss: 0.0058\n",
      "Epoch: 495/500... Training loss: 0.0011\n",
      "Epoch: 495/500... Training loss: 0.0306\n",
      "Epoch: 495/500... Training loss: 0.0010\n",
      "Epoch: 495/500... Training loss: 0.0006\n",
      "Epoch: 495/500... Training loss: 0.0709\n",
      "Epoch: 495/500... Training loss: 0.0179\n",
      "Epoch: 495/500... Training loss: 0.0028\n",
      "Epoch: 495/500... Training loss: 0.0015\n",
      "Epoch: 495/500... Training loss: 0.0026\n",
      "Epoch: 495/500... Training loss: 0.0015\n",
      "Epoch: 496/500... Training loss: 0.0007\n",
      "Epoch: 496/500... Training loss: 0.0029\n",
      "Epoch: 496/500... Training loss: 0.0008\n",
      "Epoch: 496/500... Training loss: 0.0008\n",
      "Epoch: 496/500... Training loss: 0.0020\n",
      "Epoch: 496/500... Training loss: 0.0068\n",
      "Epoch: 496/500... Training loss: 0.0096\n",
      "Epoch: 496/500... Training loss: 0.0027\n",
      "Epoch: 496/500... Training loss: 0.0012\n",
      "Epoch: 496/500... Training loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 496/500... Training loss: 0.0439\n",
      "Epoch: 496/500... Training loss: 0.0084\n",
      "Epoch: 496/500... Training loss: 0.0007\n",
      "Epoch: 496/500... Training loss: 0.0665\n",
      "Epoch: 496/500... Training loss: 0.0057\n",
      "Epoch: 496/500... Training loss: 0.0056\n",
      "Epoch: 496/500... Training loss: 0.1370\n",
      "Epoch: 496/500... Training loss: 0.0154\n",
      "Epoch: 496/500... Training loss: 0.0582\n",
      "Epoch: 496/500... Training loss: 0.0200\n",
      "Epoch: 496/500... Training loss: 0.0183\n",
      "Epoch: 496/500... Training loss: 0.0020\n",
      "Epoch: 496/500... Training loss: 0.0045\n",
      "Epoch: 496/500... Training loss: 0.0530\n",
      "Epoch: 496/500... Training loss: 0.0730\n",
      "Epoch: 496/500... Training loss: 0.0015\n",
      "Epoch: 496/500... Training loss: 0.0015\n",
      "Epoch: 496/500... Training loss: 0.0317\n",
      "Epoch: 496/500... Training loss: 0.0009\n",
      "Epoch: 496/500... Training loss: 0.0008\n",
      "Epoch: 496/500... Training loss: 0.0025\n",
      "Epoch: 497/500... Training loss: 0.0408\n",
      "Epoch: 497/500... Training loss: 0.0040\n",
      "Epoch: 497/500... Training loss: 0.0016\n",
      "Epoch: 497/500... Training loss: 0.0027\n",
      "Epoch: 497/500... Training loss: 0.0012\n",
      "Epoch: 497/500... Training loss: 0.0043\n",
      "Epoch: 497/500... Training loss: 0.0040\n",
      "Epoch: 497/500... Training loss: 0.0270\n",
      "Epoch: 497/500... Training loss: 0.1416\n",
      "Epoch: 497/500... Training loss: 0.0068\n",
      "Epoch: 497/500... Training loss: 0.0616\n",
      "Epoch: 497/500... Training loss: 0.0141\n",
      "Epoch: 497/500... Training loss: 0.0110\n",
      "Epoch: 497/500... Training loss: 0.0007\n",
      "Epoch: 497/500... Training loss: 0.0016\n",
      "Epoch: 497/500... Training loss: 0.0155\n",
      "Epoch: 497/500... Training loss: 0.0010\n",
      "Epoch: 497/500... Training loss: 0.0094\n",
      "Epoch: 497/500... Training loss: 0.0047\n",
      "Epoch: 497/500... Training loss: 0.0007\n",
      "Epoch: 497/500... Training loss: 0.0039\n",
      "Epoch: 497/500... Training loss: 0.0011\n",
      "Epoch: 497/500... Training loss: 0.0166\n",
      "Epoch: 497/500... Training loss: 0.0046\n",
      "Epoch: 497/500... Training loss: 0.0012\n",
      "Epoch: 497/500... Training loss: 0.0002\n",
      "Epoch: 497/500... Training loss: 0.0004\n",
      "Epoch: 497/500... Training loss: 0.0012\n",
      "Epoch: 497/500... Training loss: 0.0346\n",
      "Epoch: 497/500... Training loss: 0.0064\n",
      "Epoch: 497/500... Training loss: 0.0008\n",
      "Epoch: 498/500... Training loss: 0.1376\n",
      "Epoch: 498/500... Training loss: 0.0123\n",
      "Epoch: 498/500... Training loss: 0.0227\n",
      "Epoch: 498/500... Training loss: 0.0028\n",
      "Epoch: 498/500... Training loss: 0.0052\n",
      "Epoch: 498/500... Training loss: 0.0497\n",
      "Epoch: 498/500... Training loss: 0.0089\n",
      "Epoch: 498/500... Training loss: 0.0038\n",
      "Epoch: 498/500... Training loss: 0.1003\n",
      "Epoch: 498/500... Training loss: 0.0021\n",
      "Epoch: 498/500... Training loss: 0.0205\n",
      "Epoch: 498/500... Training loss: 0.0177\n",
      "Epoch: 498/500... Training loss: 0.0043\n",
      "Epoch: 498/500... Training loss: 0.0110\n",
      "Epoch: 498/500... Training loss: 0.0037\n",
      "Epoch: 498/500... Training loss: 0.0009\n",
      "Epoch: 498/500... Training loss: 0.0103\n",
      "Epoch: 498/500... Training loss: 0.0058\n",
      "Epoch: 498/500... Training loss: 0.0049\n",
      "Epoch: 498/500... Training loss: 0.0031\n",
      "Epoch: 498/500... Training loss: 0.1091\n",
      "Epoch: 498/500... Training loss: 0.0019\n",
      "Epoch: 498/500... Training loss: 0.0037\n",
      "Epoch: 498/500... Training loss: 0.0007\n",
      "Epoch: 498/500... Training loss: 0.0141\n",
      "Epoch: 498/500... Training loss: 0.0350\n",
      "Epoch: 498/500... Training loss: 0.0002\n",
      "Epoch: 498/500... Training loss: 0.0070\n",
      "Epoch: 498/500... Training loss: 0.0328\n",
      "Epoch: 498/500... Training loss: 0.0007\n",
      "Epoch: 498/500... Training loss: 0.0087\n",
      "Epoch: 499/500... Training loss: 0.0119\n",
      "Epoch: 499/500... Training loss: 0.0015\n",
      "Epoch: 499/500... Training loss: 0.0100\n",
      "Epoch: 499/500... Training loss: 0.0010\n",
      "Epoch: 499/500... Training loss: 0.0062\n",
      "Epoch: 499/500... Training loss: 0.0037\n",
      "Epoch: 499/500... Training loss: 0.0025\n",
      "Epoch: 499/500... Training loss: 0.0503\n",
      "Epoch: 499/500... Training loss: 0.0059\n",
      "Epoch: 499/500... Training loss: 0.0230\n",
      "Epoch: 499/500... Training loss: 0.0021\n",
      "Epoch: 499/500... Training loss: 0.0794\n",
      "Epoch: 499/500... Training loss: 0.0122\n",
      "Epoch: 499/500... Training loss: 0.0025\n",
      "Epoch: 499/500... Training loss: 0.0018\n",
      "Epoch: 499/500... Training loss: 0.0010\n",
      "Epoch: 499/500... Training loss: 0.0026\n",
      "Epoch: 499/500... Training loss: 0.0362\n",
      "Epoch: 499/500... Training loss: 0.0137\n",
      "Epoch: 499/500... Training loss: 0.0015\n",
      "Epoch: 499/500... Training loss: 0.0384\n",
      "Epoch: 499/500... Training loss: 0.0030\n",
      "Epoch: 499/500... Training loss: 0.0004\n",
      "Epoch: 499/500... Training loss: 0.0013\n",
      "Epoch: 499/500... Training loss: 0.0027\n",
      "Epoch: 499/500... Training loss: 0.0011\n",
      "Epoch: 499/500... Training loss: 0.0037\n",
      "Epoch: 499/500... Training loss: 0.0012\n",
      "Epoch: 499/500... Training loss: 0.0529\n",
      "Epoch: 499/500... Training loss: 0.0029\n",
      "Epoch: 499/500... Training loss: 0.0052\n",
      "Epoch: 500/500... Training loss: 0.0258\n",
      "Epoch: 500/500... Training loss: 0.0243\n",
      "Epoch: 500/500... Training loss: 0.0401\n",
      "Epoch: 500/500... Training loss: 0.0144\n",
      "Epoch: 500/500... Training loss: 0.0240\n",
      "Epoch: 500/500... Training loss: 0.0059\n",
      "Epoch: 500/500... Training loss: 0.0012\n",
      "Epoch: 500/500... Training loss: 0.0003\n",
      "Epoch: 500/500... Training loss: 0.0054\n",
      "Epoch: 500/500... Training loss: 0.0014\n",
      "Epoch: 500/500... Training loss: 0.0297\n",
      "Epoch: 500/500... Training loss: 0.0052\n",
      "Epoch: 500/500... Training loss: 0.0012\n",
      "Epoch: 500/500... Training loss: 0.0086\n",
      "Epoch: 500/500... Training loss: 0.0051\n",
      "Epoch: 500/500... Training loss: 0.0536\n",
      "Epoch: 500/500... Training loss: 0.0006\n",
      "Epoch: 500/500... Training loss: 0.0005\n",
      "Epoch: 500/500... Training loss: 0.0216\n",
      "Epoch: 500/500... Training loss: 0.0123\n",
      "Epoch: 500/500... Training loss: 0.0006\n",
      "Epoch: 500/500... Training loss: 0.0477\n",
      "Epoch: 500/500... Training loss: 0.0022\n",
      "Epoch: 500/500... Training loss: 0.0003\n",
      "Epoch: 500/500... Training loss: 0.0023\n",
      "Epoch: 500/500... Training loss: 0.0079\n",
      "Epoch: 500/500... Training loss: 0.0044\n",
      "Epoch: 500/500... Training loss: 0.0012\n",
      "Epoch: 500/500... Training loss: 0.0031\n",
      "Epoch: 500/500... Training loss: 0.0010\n",
      "Epoch: 500/500... Training loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# Adam optimizer\n",
    "opt = tf.train.AdamOptimizer(0.0005).minimize(cost)\n",
    "\n",
    "# Create the session\n",
    "sess = tf.Session()\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range((len(features)//batch_size) - 1):\n",
    "        batch = features[ii*batch_size:(ii + 1)*batch_size]\n",
    "        \n",
    "        # add random noise\n",
    "        for jj in batch:\n",
    "            jj[np.random.randint(vocab_size)] += 0.01\n",
    "            jj[np.random.randint(vocab_size)] -= 0.01\n",
    "        \n",
    "        targ = np.array(labels[ii*batch_size:(ii + 1)*batch_size])\n",
    "\n",
    "        feed = {inputs_: batch, targets_: targ}\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dallas', 'aulola'), ('wel', 'wale'), ('orchard park', 'orchard park'), ('holland', 'holland'), ('boonton', 'boston'), ('delanco', 'colden'), ('crompond', 'concord'), ('collins', 'collins'), ('north collins', 'north collins'), ('indiana', 'sardinia'), ('brant', 'brant'), ('evans', 'evans'), ('eden', 'eden'), ('hamburg', 'hamburg'), ('lackawanna', 'lackawanna'), ('west seneca', 'west seneca'), ('elma', 'elma'), ('marilla', 'marilla'), ('cheektowaga', 'cheektowaga'), ('canal campsites', 'lancapter'), ('seattle', 'aldest'), ('north arlington', 'grant islands'), ('amherst', 'amherst'), ('ceres', 'clarence'), ('newstead', 'newstead'), ('adamstown', 'tonawanda'), ('blakely borough', 'bufalo'), ('basking ridge', 'goshen ny'), ('tyrone bor', 'monroe ny')]\n"
     ]
    }
   ],
   "source": [
    "# originals\n",
    "# ['adams twp', 'cranberry twp', 'middlesex twp', 'mars boro', 'allegheny twp', \n",
    "# 'bruin boro', 'brady twp', 'slippery rock twp', 'buffalo twp', 'winfield twp', 'butler city', \n",
    "# 'butler twp', 'penn twp', 'callery boro', 'center twp', 'clay twp', 'cherry twp', 'cherry valley boro', \n",
    "# 'chicora boro', 'clearfield twp', 'donegal twp', 'summit twp', 'clinton twp', 'connoq boro', 'forward twp', \n",
    "# 'connoq twp', 'lancaster twp', 'seven fields boro', 'fairview twp', 'east butler boro']\n",
    "\n",
    "\n",
    "test_words = ['aulola', 'wale', 'orchard park', 'holland', 'boston', 'colden', \n",
    "              'concord', 'collins', 'north collins', 'sardinia', 'brant', 'evans', 'eden',\n",
    "              'hamburg', 'lackawanna', 'west seneca', 'elma', 'marilla', 'cheektowaga', \n",
    "              'lancapter', 'aldest', 'grant islands', 'amherst', 'clarence', 'newstead', \n",
    "              'tonawanda', 'bufalo', 'goshen ny', 'monroe ny']\n",
    "\n",
    "in_words = []\n",
    "for word in test_words:\n",
    "    X = np.zeros(vocab_size)\n",
    "    for j in range(len(word)):\n",
    "        if word[j] in vocab_to_id:\n",
    "            X[vocab_to_id[word[j]]] += 1\n",
    "            \n",
    "    # normalize input sizes \n",
    "    X = ((X - X.min()) / (X.max() - X.min())) + 0.001\n",
    "    in_words.append(X)\n",
    "    \n",
    "in_words = np.array(in_words)\n",
    "\n",
    "reconstructed, compressed = sess.run([logits, encoded], feed_dict={inputs_: in_words})\n",
    "\n",
    "out_words = []\n",
    "for out, inp in zip(reconstructed, test_words):\n",
    "    best_match = np.argmax(out)\n",
    "    \n",
    "    out_words.append((id_to_address[labels_to_id[best_match]], inp))\n",
    "    \n",
    "        \n",
    "print(out_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
