{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address parsing and correction\n",
    "\n",
    "In this notebook, I will describe the use of CRF models in [libpostal address parser](https://github.com/openvenues/libpostal) and how they differ from newer language processing methods, namely RNN and LSTM. In the CRF model each sequence is remembered and a tag is given to each word, depending on the neighbouring words.  The neighbouring words are kept in a structure which can be represented as a vector:\n",
    "\n",
    "![one-hot encodings](assets/ccrfDiagram.png)\n",
    "\n",
    "The main limitation here is in the vector that keeps the neighbourhood information. The model will learn to associate words to tags over time, however only in that fixed relative position with each other. If there are additional words to change the structure of an input, as it was during training, the output will not be reproducible. As an example lets take a model that has been trained with input of this format:\n",
    "\n",
    "64 Great Eastern Street London EC2A 3QR\n",
    "\n",
    "If we now insert new information about the whereabouts of our address into the input:\n",
    "\n",
    "64 Great Eastern Street Ingrove Court London EC2A 3QR\n",
    "\n",
    " Assume such an address exists but Ingrove Court does not need to be included for the postman to identify this address. The model cannot tell you whether Ingrove is part of the street. It has never seen data before to show it that explicitly Ingrove Court is an optional part of the address. This is why it is a good idea to find common points in the data where there can be additional words with different contextual meaning eg. street names, suburbs, cities etc etc... Commonly in NLP only the most common words are used to represent meaning of a sentence or tagging of word meanings.\n",
    "\n",
    "An LSTM in contrast, is capable of remembering word occurances that are several words away and will. This is by virtue of a non-linearity in nearby word association that is not simply composed of a vector, rather it is a state represented by neural networks.\n",
    "\n",
    "In order to demonstrate this associations I will create word embeddings for a small set of addresses. I'll convert addresses to vectors through TensorFlow and understand the common meaning behind them.\n",
    "\n",
    "\n",
    "Embeddings are just a single layer neural network. We call this layer the embedding layer and the weights are embedding weights. We skip the multiplication into the embedding layer by instead directly grabbing the hidden layer values from the weight matrix. \n",
    "\n",
    "![lookup](assets/lookup_matrix.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the [openaddress US North East dataset](https://s3.amazonaws.com/data.openaddresses.io/openaddr-collected-us_northeast.zip), and extract onto 'openaddr' directory if not found. read the csv files and load address dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data:\n",
      " LON                 -69.7958\n",
      "LAT                  44.6535\n",
      "NUMBER                  1033\n",
      "STREET             E Pond Rd\n",
      "UNIT                     NaN\n",
      "CITY                     NaN\n",
      "DISTRICT            Somerset\n",
      "REGION                    ME\n",
      "POSTCODE                4978\n",
      "ID                       NaN\n",
      "HASH        8bbbfb5152ee2563\n",
      "Name: 2, dtype: object\n",
      "Example data:\n",
      " LON                   -80.0287\n",
      "LAT                    40.7328\n",
      "NUMBER                    1260\n",
      "STREET      MARS-EVANS CITY RD\n",
      "UNIT                       NaN\n",
      "CITY                 ADAMS TWP\n",
      "DISTRICT                   NaN\n",
      "REGION                     NaN\n",
      "POSTCODE                   NaN\n",
      "ID                         NaN\n",
      "HASH          1b447375afa847e4\n",
      "Name: 2, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3,4,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "dataset_folder_path = 'openaddr'\n",
    "dataset_filename = 'openaddr-collected-us_northeast.zip'\n",
    "dataset_name = 'Openaddress Dataset'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/data.openaddresses.io/openaddr-collected-us_northeast.zip',\n",
    "            dataset_filename,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\n",
    "\n",
    "\n",
    "id_to_address = {}\n",
    "address_to_id = {}\n",
    "i = 0\n",
    "for state in os.listdir('./openaddr/us'):\n",
    "    \n",
    "    for filename in glob.glob('./openaddr/us/{}/*.csv'.format(state)):\n",
    "        csv = pd.read_csv(filename)\n",
    "        if i == 0:\n",
    "            print(\"Example data:\\n {}\".format(csv.iloc[2]))\n",
    "\n",
    "        stack = np.stack((csv['CITY'],), axis=-1)\n",
    "        for j in stack:\n",
    "            addr = \" \".join([str(k).lower()\n",
    "                             for k in j if not isinstance(k, type(np.nan))])\n",
    "            if addr not in address_to_id and addr != '' and addr != ' ':\n",
    "                id_to_address[i] = addr\n",
    "                address_to_id[addr] = i\n",
    "                i += 1\n",
    "\n",
    "del csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The addresses have all been converted to lower case and only city names are being used and tested for correction cases. vocabulary is the letters from which the city is made up of. We vectorise by counting the number of letters and normalizing to the total number between zero and one. Visualisations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adams twp', 'cranberry twp', 'middlesex twp', 'mars boro', 'allegheny twp', 'bruin boro', 'brady twp', 'slippery rock twp', 'buffalo twp', 'winfield twp', 'butler city', 'butler twp', 'penn twp', 'callery boro', 'center twp', 'clay twp', 'cherry twp', 'cherry valley boro', 'chicora boro', 'clearfield twp', 'donegal twp', 'summit twp', 'clinton twp', 'connoq boro', 'forward twp', 'connoq twp', 'lancaster twp', 'seven fields boro', 'fairview twp', 'east butler boro']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in address_to_id.keys()][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addresses: 4155\n",
      "Total unique letters: 45\n"
     ]
    }
   ],
   "source": [
    "print(\"Total addresses: {}\".format(len(address_to_id)))\n",
    "\n",
    "vocab_to_id = {}\n",
    "int_to_vocab = {}\n",
    "idx = 0\n",
    "for address in address_to_id.keys():\n",
    "    for j in range(len(address)):\n",
    "        if address[j] not in vocab_to_id:\n",
    "            vocab_to_id[address[j]] = idx\n",
    "            int_to_vocab[idx] = address[j]\n",
    "            idx += 1\n",
    "\n",
    "vocab_size = len(vocab_to_id)\n",
    "print(\"Total unique letters: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example feature vector and label:\n",
      "[1.001e+00 1.000e-03 1.001e+00 1.001e+00 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.001e+00 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03 1.000e-03\n",
      " 1.000e-03 1.000e-03 1.000e-03]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "labels_to_id = {}\n",
    "count = 0\n",
    "\n",
    "for address, idx in address_to_id.items():\n",
    "    X = np.zeros(vocab_size)\n",
    "    Y = np.zeros(len(address_to_id))\n",
    "    for j in range(len(address)):\n",
    "        X[vocab_to_id[address[j]]] += 1 \n",
    "    \n",
    "    # normalize input sizes \n",
    "    X = ((X - X.min()) / (X.max() - X.min())) + 0.001\n",
    "    \n",
    "    features.append(X)\n",
    "    \n",
    "    labels_to_id[idx] = count\n",
    "    Y[idx] = 1\n",
    "    labels.append(Y)\n",
    "    count += 1\n",
    "    \n",
    "print(\"Example feature vector and label:\")\n",
    "print(features[500])\n",
    "print(labels[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 41, 32)\n",
      "(?, 37, 64)\n",
      "(?, 33, 128)\n",
      "(?, 33)\n",
      "(?, 500)\n",
      "(?, 4155)\n"
     ]
    }
   ],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 500\n",
    "alpha = 0.1\n",
    "\n",
    "# Input and target placeholders\n",
    "inp_shape = vocab_size\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32 ,(None, inp_shape))\n",
    "targets_ = tf.placeholder(tf.float32 ,(None, len(address_to_id)))\n",
    "\n",
    "# Input layer is 45\n",
    "x1 = tf.expand_dims(inputs_, axis=-1)\n",
    "x1 = tf.layers.conv1d(x1, filters=32, kernel_size=5, strides=1, padding='valid')\n",
    "x1 = tf.nn.dropout(x1, 0.5)\n",
    "relu1 = tf.maximum(alpha * x1, x1)\n",
    "print(relu1.shape)\n",
    "# 41x32\n",
    "\n",
    "x2 = tf.layers.conv1d(relu1, filters=64, kernel_size=5, strides=1, padding='valid')\n",
    "x2 = tf.nn.dropout(x2, 0.5)\n",
    "relu2 = tf.maximum(alpha * x2, x2)\n",
    "print(relu2.shape)\n",
    "# 37x64\n",
    "\n",
    "x3 = tf.layers.conv1d(relu2, filters=128, kernel_size=5, strides=1, padding='valid')\n",
    "x3 = tf.nn.dropout(x3, 0.5)\n",
    "relu3 = tf.maximum(alpha * x3, x3)\n",
    "print(relu3.shape)\n",
    "# 33x128\n",
    "\n",
    "# global average pooling layer\n",
    "first_h_dim = tf.reduce_mean(relu3, axis=2)\n",
    "print(first_h_dim.shape)\n",
    "\n",
    "# dense layer\n",
    "encoded = tf.layers.dense(first_h_dim, encoding_dim)\n",
    "relu4 = tf.maximum(alpha * encoded, encoded)\n",
    "print(relu4.shape)\n",
    "\n",
    "# Output layer logits\n",
    "logits = tf.layers.dense(relu4, len(address_to_id), activation=None)\n",
    "print(logits.shape)\n",
    "# Sigmoid output from logits\n",
    "#decoded = tf.nn.sigmoid(logits, name='outputs')\n",
    "\n",
    "# loss = tf.log(tf.reduce_sum(tf.abs(targets_ - logits)) + 1)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=targets_, logits=logits)\n",
    "# Mean of the loss\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500... Training loss: 8.3322\n",
      "Epoch: 1/500... Training loss: 8.3323\n",
      "Epoch: 1/500... Training loss: 8.3326\n",
      "Epoch: 1/500... Training loss: 8.3325\n",
      "Epoch: 1/500... Training loss: 8.3327\n",
      "Epoch: 1/500... Training loss: 8.3327\n",
      "Epoch: 1/500... Training loss: 8.3328\n",
      "Epoch: 1/500... Training loss: 8.3333\n",
      "Epoch: 1/500... Training loss: 8.3335\n",
      "Epoch: 1/500... Training loss: 8.3338\n",
      "Epoch: 1/500... Training loss: 8.3340\n",
      "Epoch: 1/500... Training loss: 8.3344\n",
      "Epoch: 1/500... Training loss: 8.3344\n",
      "Epoch: 1/500... Training loss: 8.3345\n",
      "Epoch: 1/500... Training loss: 8.3350\n",
      "Epoch: 1/500... Training loss: 8.3350\n",
      "Epoch: 1/500... Training loss: 8.3351\n",
      "Epoch: 1/500... Training loss: 8.3354\n",
      "Epoch: 1/500... Training loss: 8.3355\n",
      "Epoch: 1/500... Training loss: 8.3356\n",
      "Epoch: 1/500... Training loss: 8.3358\n",
      "Epoch: 1/500... Training loss: 8.3361\n",
      "Epoch: 1/500... Training loss: 8.3364\n",
      "Epoch: 1/500... Training loss: 8.3366\n",
      "Epoch: 1/500... Training loss: 8.3367\n",
      "Epoch: 1/500... Training loss: 8.3372\n",
      "Epoch: 1/500... Training loss: 8.3377\n",
      "Epoch: 1/500... Training loss: 8.3377\n",
      "Epoch: 1/500... Training loss: 8.3384\n",
      "Epoch: 1/500... Training loss: 8.3390\n",
      "Epoch: 1/500... Training loss: 8.3397\n",
      "Epoch: 2/500... Training loss: 8.3300\n",
      "Epoch: 2/500... Training loss: 8.3305\n",
      "Epoch: 2/500... Training loss: 8.3308\n",
      "Epoch: 2/500... Training loss: 8.3311\n",
      "Epoch: 2/500... Training loss: 8.3310\n",
      "Epoch: 2/500... Training loss: 8.3313\n",
      "Epoch: 2/500... Training loss: 8.3316\n",
      "Epoch: 2/500... Training loss: 8.3316\n",
      "Epoch: 2/500... Training loss: 8.3318\n",
      "Epoch: 2/500... Training loss: 8.3322\n",
      "Epoch: 2/500... Training loss: 8.3321\n",
      "Epoch: 2/500... Training loss: 8.3323\n",
      "Epoch: 2/500... Training loss: 8.3324\n",
      "Epoch: 2/500... Training loss: 8.3325\n",
      "Epoch: 2/500... Training loss: 8.3325\n",
      "Epoch: 2/500... Training loss: 8.3326\n",
      "Epoch: 2/500... Training loss: 8.3329\n",
      "Epoch: 2/500... Training loss: 8.3331\n",
      "Epoch: 2/500... Training loss: 8.3335\n",
      "Epoch: 2/500... Training loss: 8.3340\n",
      "Epoch: 2/500... Training loss: 8.3345\n",
      "Epoch: 2/500... Training loss: 8.3350\n",
      "Epoch: 2/500... Training loss: 8.3355\n",
      "Epoch: 2/500... Training loss: 8.3361\n",
      "Epoch: 2/500... Training loss: 8.3366\n",
      "Epoch: 2/500... Training loss: 8.3372\n",
      "Epoch: 2/500... Training loss: 8.3377\n",
      "Epoch: 2/500... Training loss: 8.3382\n",
      "Epoch: 2/500... Training loss: 8.3387\n",
      "Epoch: 2/500... Training loss: 8.3392\n",
      "Epoch: 2/500... Training loss: 8.3396\n",
      "Epoch: 3/500... Training loss: 8.3238\n",
      "Epoch: 3/500... Training loss: 8.3246\n",
      "Epoch: 3/500... Training loss: 8.3252\n",
      "Epoch: 3/500... Training loss: 8.3258\n",
      "Epoch: 3/500... Training loss: 8.3263\n",
      "Epoch: 3/500... Training loss: 8.3268\n",
      "Epoch: 3/500... Training loss: 8.3272\n",
      "Epoch: 3/500... Training loss: 8.3277\n",
      "Epoch: 3/500... Training loss: 8.3281\n",
      "Epoch: 3/500... Training loss: 8.3285\n",
      "Epoch: 3/500... Training loss: 8.3290\n",
      "Epoch: 3/500... Training loss: 8.3294\n",
      "Epoch: 3/500... Training loss: 8.3298\n",
      "Epoch: 3/500... Training loss: 8.3302\n",
      "Epoch: 3/500... Training loss: 8.3306\n",
      "Epoch: 3/500... Training loss: 8.3310\n",
      "Epoch: 3/500... Training loss: 8.3315\n",
      "Epoch: 3/500... Training loss: 8.3320\n",
      "Epoch: 3/500... Training loss: 8.3326\n",
      "Epoch: 3/500... Training loss: 8.3331\n",
      "Epoch: 3/500... Training loss: 8.3338\n",
      "Epoch: 3/500... Training loss: 8.3344\n",
      "Epoch: 3/500... Training loss: 8.3350\n",
      "Epoch: 3/500... Training loss: 8.3355\n",
      "Epoch: 3/500... Training loss: 8.3361\n",
      "Epoch: 3/500... Training loss: 8.3367\n",
      "Epoch: 3/500... Training loss: 8.3372\n",
      "Epoch: 3/500... Training loss: 8.3377\n",
      "Epoch: 3/500... Training loss: 8.3381\n",
      "Epoch: 3/500... Training loss: 8.3386\n",
      "Epoch: 3/500... Training loss: 8.3390\n",
      "Epoch: 4/500... Training loss: 8.3231\n",
      "Epoch: 4/500... Training loss: 8.3239\n",
      "Epoch: 4/500... Training loss: 8.3245\n",
      "Epoch: 4/500... Training loss: 8.3251\n",
      "Epoch: 4/500... Training loss: 8.3256\n",
      "Epoch: 4/500... Training loss: 8.3261\n",
      "Epoch: 4/500... Training loss: 8.3266\n",
      "Epoch: 4/500... Training loss: 8.3270\n",
      "Epoch: 4/500... Training loss: 8.3275\n",
      "Epoch: 4/500... Training loss: 8.3278\n",
      "Epoch: 4/500... Training loss: 8.3283\n",
      "Epoch: 4/500... Training loss: 8.3287\n",
      "Epoch: 4/500... Training loss: 8.3291\n",
      "Epoch: 4/500... Training loss: 8.3295\n",
      "Epoch: 4/500... Training loss: 8.3299\n",
      "Epoch: 4/500... Training loss: 8.3304\n",
      "Epoch: 4/500... Training loss: 8.3308\n",
      "Epoch: 4/500... Training loss: 8.3313\n",
      "Epoch: 4/500... Training loss: 8.3319\n",
      "Epoch: 4/500... Training loss: 8.3325\n",
      "Epoch: 4/500... Training loss: 8.3330\n",
      "Epoch: 4/500... Training loss: 8.3336\n",
      "Epoch: 4/500... Training loss: 8.3342\n",
      "Epoch: 4/500... Training loss: 8.3348\n",
      "Epoch: 4/500... Training loss: 8.3353\n",
      "Epoch: 4/500... Training loss: 8.3359\n",
      "Epoch: 4/500... Training loss: 8.3364\n",
      "Epoch: 4/500... Training loss: 8.3369\n",
      "Epoch: 4/500... Training loss: 8.3374\n",
      "Epoch: 4/500... Training loss: 8.3378\n",
      "Epoch: 4/500... Training loss: 8.3382\n",
      "Epoch: 5/500... Training loss: 8.3224\n",
      "Epoch: 5/500... Training loss: 8.3232\n",
      "Epoch: 5/500... Training loss: 8.3238\n",
      "Epoch: 5/500... Training loss: 8.3244\n",
      "Epoch: 5/500... Training loss: 8.3249\n",
      "Epoch: 5/500... Training loss: 8.3254\n",
      "Epoch: 5/500... Training loss: 8.3258\n",
      "Epoch: 5/500... Training loss: 8.3263\n",
      "Epoch: 5/500... Training loss: 8.3267\n",
      "Epoch: 5/500... Training loss: 8.3272\n",
      "Epoch: 5/500... Training loss: 8.3276\n",
      "Epoch: 5/500... Training loss: 8.3280\n",
      "Epoch: 5/500... Training loss: 8.3285\n",
      "Epoch: 5/500... Training loss: 8.3289\n",
      "Epoch: 5/500... Training loss: 8.3293\n",
      "Epoch: 5/500... Training loss: 8.3298\n",
      "Epoch: 5/500... Training loss: 8.3301\n",
      "Epoch: 5/500... Training loss: 8.3306\n",
      "Epoch: 5/500... Training loss: 8.3313\n",
      "Epoch: 5/500... Training loss: 8.3317\n",
      "Epoch: 5/500... Training loss: 8.3324\n",
      "Epoch: 5/500... Training loss: 8.3329\n",
      "Epoch: 5/500... Training loss: 8.3334\n",
      "Epoch: 5/500... Training loss: 8.3340\n",
      "Epoch: 5/500... Training loss: 8.3346\n",
      "Epoch: 5/500... Training loss: 8.3352\n",
      "Epoch: 5/500... Training loss: 8.3358\n",
      "Epoch: 5/500... Training loss: 8.3363\n",
      "Epoch: 5/500... Training loss: 8.3367\n",
      "Epoch: 5/500... Training loss: 8.3372\n",
      "Epoch: 5/500... Training loss: 8.3376\n",
      "Epoch: 6/500... Training loss: 8.3215\n",
      "Epoch: 6/500... Training loss: 8.3224\n",
      "Epoch: 6/500... Training loss: 8.3231\n",
      "Epoch: 6/500... Training loss: 8.3238\n",
      "Epoch: 6/500... Training loss: 8.3243\n",
      "Epoch: 6/500... Training loss: 8.3249\n",
      "Epoch: 6/500... Training loss: 8.3253\n",
      "Epoch: 6/500... Training loss: 8.3258\n",
      "Epoch: 6/500... Training loss: 8.3262\n",
      "Epoch: 6/500... Training loss: 8.3265\n",
      "Epoch: 6/500... Training loss: 8.3270\n",
      "Epoch: 6/500... Training loss: 8.3273\n",
      "Epoch: 6/500... Training loss: 8.3277\n",
      "Epoch: 6/500... Training loss: 8.3282\n",
      "Epoch: 6/500... Training loss: 8.3286\n",
      "Epoch: 6/500... Training loss: 8.3288\n",
      "Epoch: 6/500... Training loss: 8.3293\n",
      "Epoch: 6/500... Training loss: 8.3297\n",
      "Epoch: 6/500... Training loss: 8.3302\n",
      "Epoch: 6/500... Training loss: 8.3305\n",
      "Epoch: 6/500... Training loss: 8.3314\n",
      "Epoch: 6/500... Training loss: 8.3315\n",
      "Epoch: 6/500... Training loss: 8.3322\n",
      "Epoch: 6/500... Training loss: 8.3326\n",
      "Epoch: 6/500... Training loss: 8.3334\n",
      "Epoch: 6/500... Training loss: 8.3341\n",
      "Epoch: 6/500... Training loss: 8.3350\n",
      "Epoch: 6/500... Training loss: 8.3364\n",
      "Epoch: 6/500... Training loss: 8.3369\n",
      "Epoch: 6/500... Training loss: 8.3376\n",
      "Epoch: 6/500... Training loss: 8.3378\n",
      "Epoch: 7/500... Training loss: 8.3187\n",
      "Epoch: 7/500... Training loss: 8.3202\n",
      "Epoch: 7/500... Training loss: 8.3211\n",
      "Epoch: 7/500... Training loss: 8.3223\n",
      "Epoch: 7/500... Training loss: 8.3224\n",
      "Epoch: 7/500... Training loss: 8.3230\n",
      "Epoch: 7/500... Training loss: 8.3232\n",
      "Epoch: 7/500... Training loss: 8.3240\n",
      "Epoch: 7/500... Training loss: 8.3242\n",
      "Epoch: 7/500... Training loss: 8.3243\n",
      "Epoch: 7/500... Training loss: 8.3243\n",
      "Epoch: 7/500... Training loss: 8.3246\n",
      "Epoch: 7/500... Training loss: 8.3245\n",
      "Epoch: 7/500... Training loss: 8.3281\n",
      "Epoch: 7/500... Training loss: 8.3278\n",
      "Epoch: 7/500... Training loss: 8.3268\n",
      "Epoch: 7/500... Training loss: 8.3250\n",
      "Epoch: 7/500... Training loss: 8.3249\n",
      "Epoch: 7/500... Training loss: 8.3251\n",
      "Epoch: 7/500... Training loss: 8.3213\n",
      "Epoch: 7/500... Training loss: 8.3226\n",
      "Epoch: 7/500... Training loss: 8.3144\n",
      "Epoch: 7/500... Training loss: 8.3172\n",
      "Epoch: 7/500... Training loss: 8.3110\n",
      "Epoch: 7/500... Training loss: 8.3083\n",
      "Epoch: 7/500... Training loss: 8.3042\n",
      "Epoch: 7/500... Training loss: 8.3011\n",
      "Epoch: 7/500... Training loss: 8.3079\n",
      "Epoch: 7/500... Training loss: 8.3267\n",
      "Epoch: 7/500... Training loss: 8.3623\n",
      "Epoch: 7/500... Training loss: 8.3928\n",
      "Epoch: 8/500... Training loss: 8.1807\n",
      "Epoch: 8/500... Training loss: 8.2052\n",
      "Epoch: 8/500... Training loss: 8.2150\n",
      "Epoch: 8/500... Training loss: 8.2510\n",
      "Epoch: 8/500... Training loss: 8.2387\n",
      "Epoch: 8/500... Training loss: 8.2507\n",
      "Epoch: 8/500... Training loss: 8.2382\n",
      "Epoch: 8/500... Training loss: 8.2464\n",
      "Epoch: 8/500... Training loss: 8.2296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/500... Training loss: 8.2111\n",
      "Epoch: 8/500... Training loss: 8.1771\n",
      "Epoch: 8/500... Training loss: 8.1401\n",
      "Epoch: 8/500... Training loss: 8.0983\n",
      "Epoch: 8/500... Training loss: 8.1891\n",
      "Epoch: 8/500... Training loss: 8.1354\n",
      "Epoch: 8/500... Training loss: 8.1351\n",
      "Epoch: 8/500... Training loss: 8.0781\n",
      "Epoch: 8/500... Training loss: 8.0532\n",
      "Epoch: 8/500... Training loss: 8.0707\n",
      "Epoch: 8/500... Training loss: 8.0526\n",
      "Epoch: 8/500... Training loss: 8.0112\n",
      "Epoch: 8/500... Training loss: 7.8902\n",
      "Epoch: 8/500... Training loss: 7.9451\n",
      "Epoch: 8/500... Training loss: 7.8519\n",
      "Epoch: 8/500... Training loss: 7.7582\n",
      "Epoch: 8/500... Training loss: 7.7161\n",
      "Epoch: 8/500... Training loss: 7.6434\n",
      "Epoch: 8/500... Training loss: 7.6053\n",
      "Epoch: 8/500... Training loss: 7.6815\n",
      "Epoch: 8/500... Training loss: 7.8804\n",
      "Epoch: 8/500... Training loss: 8.1125\n",
      "Epoch: 9/500... Training loss: 7.0419\n",
      "Epoch: 9/500... Training loss: 7.1811\n",
      "Epoch: 9/500... Training loss: 7.3796\n",
      "Epoch: 9/500... Training loss: 7.6158\n",
      "Epoch: 9/500... Training loss: 7.4794\n",
      "Epoch: 9/500... Training loss: 7.4798\n",
      "Epoch: 9/500... Training loss: 7.4208\n",
      "Epoch: 9/500... Training loss: 7.3496\n",
      "Epoch: 9/500... Training loss: 7.2566\n",
      "Epoch: 9/500... Training loss: 7.1771\n",
      "Epoch: 9/500... Training loss: 7.1412\n",
      "Epoch: 9/500... Training loss: 6.9147\n",
      "Epoch: 9/500... Training loss: 6.7385\n",
      "Epoch: 9/500... Training loss: 6.9292\n",
      "Epoch: 9/500... Training loss: 6.9364\n",
      "Epoch: 9/500... Training loss: 6.9104\n",
      "Epoch: 9/500... Training loss: 6.8261\n",
      "Epoch: 9/500... Training loss: 6.7216\n",
      "Epoch: 9/500... Training loss: 6.8075\n",
      "Epoch: 9/500... Training loss: 6.9051\n",
      "Epoch: 9/500... Training loss: 6.8460\n",
      "Epoch: 9/500... Training loss: 6.6378\n",
      "Epoch: 9/500... Training loss: 6.7489\n",
      "Epoch: 9/500... Training loss: 6.7287\n",
      "Epoch: 9/500... Training loss: 6.6805\n",
      "Epoch: 9/500... Training loss: 6.6411\n",
      "Epoch: 9/500... Training loss: 6.6747\n",
      "Epoch: 9/500... Training loss: 6.6574\n",
      "Epoch: 9/500... Training loss: 6.5777\n",
      "Epoch: 9/500... Training loss: 6.6832\n",
      "Epoch: 9/500... Training loss: 6.8662\n",
      "Epoch: 10/500... Training loss: 6.0475\n",
      "Epoch: 10/500... Training loss: 6.0549\n",
      "Epoch: 10/500... Training loss: 6.3174\n",
      "Epoch: 10/500... Training loss: 6.5514\n",
      "Epoch: 10/500... Training loss: 6.3959\n",
      "Epoch: 10/500... Training loss: 6.4320\n",
      "Epoch: 10/500... Training loss: 6.3601\n",
      "Epoch: 10/500... Training loss: 6.2609\n",
      "Epoch: 10/500... Training loss: 6.2808\n",
      "Epoch: 10/500... Training loss: 6.0702\n",
      "Epoch: 10/500... Training loss: 6.0759\n",
      "Epoch: 10/500... Training loss: 5.8989\n",
      "Epoch: 10/500... Training loss: 5.5860\n",
      "Epoch: 10/500... Training loss: 5.6917\n",
      "Epoch: 10/500... Training loss: 5.7664\n",
      "Epoch: 10/500... Training loss: 5.6181\n",
      "Epoch: 10/500... Training loss: 5.4607\n",
      "Epoch: 10/500... Training loss: 5.2140\n",
      "Epoch: 10/500... Training loss: 5.5153\n",
      "Epoch: 10/500... Training loss: 5.2874\n",
      "Epoch: 10/500... Training loss: 5.4454\n",
      "Epoch: 10/500... Training loss: 5.3126\n",
      "Epoch: 10/500... Training loss: 5.2906\n",
      "Epoch: 10/500... Training loss: 5.3353\n",
      "Epoch: 10/500... Training loss: 5.2409\n",
      "Epoch: 10/500... Training loss: 5.2462\n",
      "Epoch: 10/500... Training loss: 5.1411\n",
      "Epoch: 10/500... Training loss: 5.3027\n",
      "Epoch: 10/500... Training loss: 5.1585\n",
      "Epoch: 10/500... Training loss: 5.1305\n",
      "Epoch: 10/500... Training loss: 5.1614\n",
      "Epoch: 11/500... Training loss: 4.7692\n",
      "Epoch: 11/500... Training loss: 4.9280\n",
      "Epoch: 11/500... Training loss: 5.2062\n",
      "Epoch: 11/500... Training loss: 5.1982\n",
      "Epoch: 11/500... Training loss: 5.1958\n",
      "Epoch: 11/500... Training loss: 5.2745\n",
      "Epoch: 11/500... Training loss: 5.3017\n",
      "Epoch: 11/500... Training loss: 5.2572\n",
      "Epoch: 11/500... Training loss: 5.2392\n",
      "Epoch: 11/500... Training loss: 5.3423\n",
      "Epoch: 11/500... Training loss: 5.4416\n",
      "Epoch: 11/500... Training loss: 5.2161\n",
      "Epoch: 11/500... Training loss: 4.9484\n",
      "Epoch: 11/500... Training loss: 5.0048\n",
      "Epoch: 11/500... Training loss: 5.2063\n",
      "Epoch: 11/500... Training loss: 4.9811\n",
      "Epoch: 11/500... Training loss: 4.7905\n",
      "Epoch: 11/500... Training loss: 4.5045\n",
      "Epoch: 11/500... Training loss: 4.6609\n",
      "Epoch: 11/500... Training loss: 4.1134\n",
      "Epoch: 11/500... Training loss: 4.4349\n",
      "Epoch: 11/500... Training loss: 4.4552\n",
      "Epoch: 11/500... Training loss: 4.3495\n",
      "Epoch: 11/500... Training loss: 4.4332\n",
      "Epoch: 11/500... Training loss: 4.5025\n",
      "Epoch: 11/500... Training loss: 4.5529\n",
      "Epoch: 11/500... Training loss: 4.5733\n",
      "Epoch: 11/500... Training loss: 4.6966\n",
      "Epoch: 11/500... Training loss: 4.5644\n",
      "Epoch: 11/500... Training loss: 4.6044\n",
      "Epoch: 11/500... Training loss: 4.3316\n",
      "Epoch: 12/500... Training loss: 4.1003\n",
      "Epoch: 12/500... Training loss: 4.0977\n",
      "Epoch: 12/500... Training loss: 4.2899\n",
      "Epoch: 12/500... Training loss: 4.3513\n",
      "Epoch: 12/500... Training loss: 4.1364\n",
      "Epoch: 12/500... Training loss: 4.1690\n",
      "Epoch: 12/500... Training loss: 4.2431\n",
      "Epoch: 12/500... Training loss: 4.3690\n",
      "Epoch: 12/500... Training loss: 4.3406\n",
      "Epoch: 12/500... Training loss: 4.6447\n",
      "Epoch: 12/500... Training loss: 4.7147\n",
      "Epoch: 12/500... Training loss: 4.6084\n",
      "Epoch: 12/500... Training loss: 4.4597\n",
      "Epoch: 12/500... Training loss: 4.5193\n",
      "Epoch: 12/500... Training loss: 5.1017\n",
      "Epoch: 12/500... Training loss: 4.6692\n",
      "Epoch: 12/500... Training loss: 4.6118\n",
      "Epoch: 12/500... Training loss: 4.2498\n",
      "Epoch: 12/500... Training loss: 4.2556\n",
      "Epoch: 12/500... Training loss: 4.0002\n",
      "Epoch: 12/500... Training loss: 4.1654\n",
      "Epoch: 12/500... Training loss: 3.7359\n",
      "Epoch: 12/500... Training loss: 3.3484\n",
      "Epoch: 12/500... Training loss: 3.6277\n",
      "Epoch: 12/500... Training loss: 3.4368\n",
      "Epoch: 12/500... Training loss: 3.3499\n",
      "Epoch: 12/500... Training loss: 3.3596\n",
      "Epoch: 12/500... Training loss: 3.5010\n",
      "Epoch: 12/500... Training loss: 3.4955\n",
      "Epoch: 12/500... Training loss: 3.9541\n",
      "Epoch: 12/500... Training loss: 3.9828\n",
      "Epoch: 13/500... Training loss: 3.5140\n",
      "Epoch: 13/500... Training loss: 3.5441\n",
      "Epoch: 13/500... Training loss: 3.8087\n",
      "Epoch: 13/500... Training loss: 4.3602\n",
      "Epoch: 13/500... Training loss: 4.1545\n",
      "Epoch: 13/500... Training loss: 4.2136\n",
      "Epoch: 13/500... Training loss: 3.7734\n",
      "Epoch: 13/500... Training loss: 3.6781\n",
      "Epoch: 13/500... Training loss: 3.4812\n",
      "Epoch: 13/500... Training loss: 3.5524\n",
      "Epoch: 13/500... Training loss: 3.5492\n",
      "Epoch: 13/500... Training loss: 3.6083\n",
      "Epoch: 13/500... Training loss: 3.4197\n",
      "Epoch: 13/500... Training loss: 3.3464\n",
      "Epoch: 13/500... Training loss: 4.0507\n",
      "Epoch: 13/500... Training loss: 3.7200\n",
      "Epoch: 13/500... Training loss: 3.8220\n",
      "Epoch: 13/500... Training loss: 3.6854\n",
      "Epoch: 13/500... Training loss: 3.9365\n",
      "Epoch: 13/500... Training loss: 3.8046\n",
      "Epoch: 13/500... Training loss: 4.1717\n",
      "Epoch: 13/500... Training loss: 4.0053\n",
      "Epoch: 13/500... Training loss: 3.6051\n",
      "Epoch: 13/500... Training loss: 3.6590\n",
      "Epoch: 13/500... Training loss: 3.8198\n",
      "Epoch: 13/500... Training loss: 3.6575\n",
      "Epoch: 13/500... Training loss: 3.5328\n",
      "Epoch: 13/500... Training loss: 3.9165\n",
      "Epoch: 13/500... Training loss: 3.4995\n",
      "Epoch: 13/500... Training loss: 3.4119\n",
      "Epoch: 13/500... Training loss: 2.9553\n",
      "Epoch: 14/500... Training loss: 3.2736\n",
      "Epoch: 14/500... Training loss: 2.9093\n",
      "Epoch: 14/500... Training loss: 2.9751\n",
      "Epoch: 14/500... Training loss: 3.5372\n",
      "Epoch: 14/500... Training loss: 3.4522\n",
      "Epoch: 14/500... Training loss: 3.8324\n",
      "Epoch: 14/500... Training loss: 3.9670\n",
      "Epoch: 14/500... Training loss: 4.0229\n",
      "Epoch: 14/500... Training loss: 3.8522\n",
      "Epoch: 14/500... Training loss: 4.0307\n",
      "Epoch: 14/500... Training loss: 4.1177\n",
      "Epoch: 14/500... Training loss: 3.9959\n",
      "Epoch: 14/500... Training loss: 3.4250\n",
      "Epoch: 14/500... Training loss: 3.3619\n",
      "Epoch: 14/500... Training loss: 3.7381\n",
      "Epoch: 14/500... Training loss: 3.1486\n",
      "Epoch: 14/500... Training loss: 3.1305\n",
      "Epoch: 14/500... Training loss: 2.9850\n",
      "Epoch: 14/500... Training loss: 2.9211\n",
      "Epoch: 14/500... Training loss: 2.6857\n",
      "Epoch: 14/500... Training loss: 3.2949\n",
      "Epoch: 14/500... Training loss: 2.9678\n",
      "Epoch: 14/500... Training loss: 2.7641\n",
      "Epoch: 14/500... Training loss: 3.0411\n",
      "Epoch: 14/500... Training loss: 3.1606\n",
      "Epoch: 14/500... Training loss: 3.1107\n",
      "Epoch: 14/500... Training loss: 3.3368\n",
      "Epoch: 14/500... Training loss: 3.6600\n",
      "Epoch: 14/500... Training loss: 3.3614\n",
      "Epoch: 14/500... Training loss: 3.4092\n",
      "Epoch: 14/500... Training loss: 3.0556\n",
      "Epoch: 15/500... Training loss: 3.5594\n",
      "Epoch: 15/500... Training loss: 3.2057\n",
      "Epoch: 15/500... Training loss: 3.1659\n",
      "Epoch: 15/500... Training loss: 3.1162\n",
      "Epoch: 15/500... Training loss: 2.7006\n",
      "Epoch: 15/500... Training loss: 2.9485\n",
      "Epoch: 15/500... Training loss: 2.6245\n",
      "Epoch: 15/500... Training loss: 2.5909\n",
      "Epoch: 15/500... Training loss: 2.7425\n",
      "Epoch: 15/500... Training loss: 2.7891\n",
      "Epoch: 15/500... Training loss: 2.6523\n",
      "Epoch: 15/500... Training loss: 3.1589\n",
      "Epoch: 15/500... Training loss: 2.8803\n",
      "Epoch: 15/500... Training loss: 2.9862\n",
      "Epoch: 15/500... Training loss: 3.1717\n",
      "Epoch: 15/500... Training loss: 2.7649\n",
      "Epoch: 15/500... Training loss: 2.8984\n",
      "Epoch: 15/500... Training loss: 2.6279\n",
      "Epoch: 15/500... Training loss: 2.7936\n",
      "Epoch: 15/500... Training loss: 2.2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/500... Training loss: 2.6385\n",
      "Epoch: 15/500... Training loss: 2.4950\n",
      "Epoch: 15/500... Training loss: 2.1548\n",
      "Epoch: 15/500... Training loss: 2.2765\n",
      "Epoch: 15/500... Training loss: 2.4482\n",
      "Epoch: 15/500... Training loss: 2.3945\n",
      "Epoch: 15/500... Training loss: 2.3681\n",
      "Epoch: 15/500... Training loss: 2.8531\n",
      "Epoch: 15/500... Training loss: 2.6264\n",
      "Epoch: 15/500... Training loss: 2.6192\n",
      "Epoch: 15/500... Training loss: 2.2952\n",
      "Epoch: 16/500... Training loss: 2.5871\n",
      "Epoch: 16/500... Training loss: 2.7351\n",
      "Epoch: 16/500... Training loss: 2.6989\n",
      "Epoch: 16/500... Training loss: 2.7235\n",
      "Epoch: 16/500... Training loss: 2.4095\n",
      "Epoch: 16/500... Training loss: 2.6310\n",
      "Epoch: 16/500... Training loss: 2.3611\n",
      "Epoch: 16/500... Training loss: 2.4553\n",
      "Epoch: 16/500... Training loss: 2.4286\n",
      "Epoch: 16/500... Training loss: 2.4903\n",
      "Epoch: 16/500... Training loss: 2.6429\n",
      "Epoch: 16/500... Training loss: 2.5373\n",
      "Epoch: 16/500... Training loss: 2.5653\n",
      "Epoch: 16/500... Training loss: 2.3883\n",
      "Epoch: 16/500... Training loss: 2.5958\n",
      "Epoch: 16/500... Training loss: 2.3098\n",
      "Epoch: 16/500... Training loss: 2.3613\n",
      "Epoch: 16/500... Training loss: 2.3374\n",
      "Epoch: 16/500... Training loss: 2.6004\n",
      "Epoch: 16/500... Training loss: 1.8590\n",
      "Epoch: 16/500... Training loss: 2.5030\n",
      "Epoch: 16/500... Training loss: 2.3866\n",
      "Epoch: 16/500... Training loss: 1.9822\n",
      "Epoch: 16/500... Training loss: 2.0818\n",
      "Epoch: 16/500... Training loss: 2.1855\n",
      "Epoch: 16/500... Training loss: 2.0890\n",
      "Epoch: 16/500... Training loss: 2.3307\n",
      "Epoch: 16/500... Training loss: 2.4276\n",
      "Epoch: 16/500... Training loss: 2.2200\n",
      "Epoch: 16/500... Training loss: 2.2490\n",
      "Epoch: 16/500... Training loss: 1.9601\n",
      "Epoch: 17/500... Training loss: 2.4693\n",
      "Epoch: 17/500... Training loss: 2.2550\n",
      "Epoch: 17/500... Training loss: 2.3446\n",
      "Epoch: 17/500... Training loss: 2.5194\n",
      "Epoch: 17/500... Training loss: 2.2517\n",
      "Epoch: 17/500... Training loss: 2.3752\n",
      "Epoch: 17/500... Training loss: 2.2130\n",
      "Epoch: 17/500... Training loss: 2.0522\n",
      "Epoch: 17/500... Training loss: 1.9924\n",
      "Epoch: 17/500... Training loss: 2.0776\n",
      "Epoch: 17/500... Training loss: 2.3156\n",
      "Epoch: 17/500... Training loss: 2.3358\n",
      "Epoch: 17/500... Training loss: 2.1240\n",
      "Epoch: 17/500... Training loss: 2.1431\n",
      "Epoch: 17/500... Training loss: 2.3646\n",
      "Epoch: 17/500... Training loss: 1.8504\n",
      "Epoch: 17/500... Training loss: 2.1351\n",
      "Epoch: 17/500... Training loss: 2.2217\n",
      "Epoch: 17/500... Training loss: 2.0865\n",
      "Epoch: 17/500... Training loss: 1.6112\n",
      "Epoch: 17/500... Training loss: 2.0784\n",
      "Epoch: 17/500... Training loss: 1.9557\n",
      "Epoch: 17/500... Training loss: 1.6917\n",
      "Epoch: 17/500... Training loss: 1.9022\n",
      "Epoch: 17/500... Training loss: 1.8030\n",
      "Epoch: 17/500... Training loss: 1.9745\n",
      "Epoch: 17/500... Training loss: 1.8818\n",
      "Epoch: 17/500... Training loss: 2.0748\n",
      "Epoch: 17/500... Training loss: 1.8192\n",
      "Epoch: 17/500... Training loss: 1.8669\n",
      "Epoch: 17/500... Training loss: 1.7735\n",
      "Epoch: 18/500... Training loss: 2.0806\n",
      "Epoch: 18/500... Training loss: 2.1675\n",
      "Epoch: 18/500... Training loss: 2.1884\n",
      "Epoch: 18/500... Training loss: 2.2363\n",
      "Epoch: 18/500... Training loss: 1.9759\n",
      "Epoch: 18/500... Training loss: 2.0880\n",
      "Epoch: 18/500... Training loss: 2.0386\n",
      "Epoch: 18/500... Training loss: 1.9408\n",
      "Epoch: 18/500... Training loss: 1.9091\n",
      "Epoch: 18/500... Training loss: 1.8822\n",
      "Epoch: 18/500... Training loss: 2.1503\n",
      "Epoch: 18/500... Training loss: 2.1125\n",
      "Epoch: 18/500... Training loss: 1.9616\n",
      "Epoch: 18/500... Training loss: 1.8282\n",
      "Epoch: 18/500... Training loss: 2.1488\n",
      "Epoch: 18/500... Training loss: 1.7163\n",
      "Epoch: 18/500... Training loss: 1.8628\n",
      "Epoch: 18/500... Training loss: 1.7824\n",
      "Epoch: 18/500... Training loss: 1.8469\n",
      "Epoch: 18/500... Training loss: 1.4841\n",
      "Epoch: 18/500... Training loss: 1.8711\n",
      "Epoch: 18/500... Training loss: 1.6932\n",
      "Epoch: 18/500... Training loss: 1.5361\n",
      "Epoch: 18/500... Training loss: 1.5481\n",
      "Epoch: 18/500... Training loss: 1.5599\n",
      "Epoch: 18/500... Training loss: 1.6338\n",
      "Epoch: 18/500... Training loss: 1.5926\n",
      "Epoch: 18/500... Training loss: 1.8093\n",
      "Epoch: 18/500... Training loss: 1.8259\n",
      "Epoch: 18/500... Training loss: 1.9260\n",
      "Epoch: 18/500... Training loss: 1.6397\n",
      "Epoch: 19/500... Training loss: 1.9798\n",
      "Epoch: 19/500... Training loss: 1.9371\n",
      "Epoch: 19/500... Training loss: 2.0527\n",
      "Epoch: 19/500... Training loss: 2.0044\n",
      "Epoch: 19/500... Training loss: 1.5554\n",
      "Epoch: 19/500... Training loss: 1.9102\n",
      "Epoch: 19/500... Training loss: 1.7865\n",
      "Epoch: 19/500... Training loss: 1.6100\n",
      "Epoch: 19/500... Training loss: 1.7430\n",
      "Epoch: 19/500... Training loss: 1.8860\n",
      "Epoch: 19/500... Training loss: 1.8622\n",
      "Epoch: 19/500... Training loss: 1.9139\n",
      "Epoch: 19/500... Training loss: 1.7982\n",
      "Epoch: 19/500... Training loss: 1.6562\n",
      "Epoch: 19/500... Training loss: 2.0597\n",
      "Epoch: 19/500... Training loss: 1.4717\n",
      "Epoch: 19/500... Training loss: 1.3567\n",
      "Epoch: 19/500... Training loss: 1.7640\n",
      "Epoch: 19/500... Training loss: 1.6375\n",
      "Epoch: 19/500... Training loss: 1.4476\n",
      "Epoch: 19/500... Training loss: 1.6743\n",
      "Epoch: 19/500... Training loss: 1.3916\n",
      "Epoch: 19/500... Training loss: 1.3890\n",
      "Epoch: 19/500... Training loss: 1.5447\n",
      "Epoch: 19/500... Training loss: 1.5832\n",
      "Epoch: 19/500... Training loss: 1.5561\n",
      "Epoch: 19/500... Training loss: 1.5637\n",
      "Epoch: 19/500... Training loss: 1.6523\n",
      "Epoch: 19/500... Training loss: 1.5416\n",
      "Epoch: 19/500... Training loss: 1.6383\n",
      "Epoch: 19/500... Training loss: 1.3463\n",
      "Epoch: 20/500... Training loss: 1.6234\n",
      "Epoch: 20/500... Training loss: 1.7505\n",
      "Epoch: 20/500... Training loss: 1.7388\n",
      "Epoch: 20/500... Training loss: 1.8862\n",
      "Epoch: 20/500... Training loss: 1.7525\n",
      "Epoch: 20/500... Training loss: 1.7666\n",
      "Epoch: 20/500... Training loss: 1.5618\n",
      "Epoch: 20/500... Training loss: 1.6847\n",
      "Epoch: 20/500... Training loss: 1.5502\n",
      "Epoch: 20/500... Training loss: 1.5716\n",
      "Epoch: 20/500... Training loss: 2.0024\n",
      "Epoch: 20/500... Training loss: 1.9062\n",
      "Epoch: 20/500... Training loss: 1.5948\n",
      "Epoch: 20/500... Training loss: 1.3452\n",
      "Epoch: 20/500... Training loss: 1.7670\n",
      "Epoch: 20/500... Training loss: 1.3293\n",
      "Epoch: 20/500... Training loss: 1.4531\n",
      "Epoch: 20/500... Training loss: 1.3653\n",
      "Epoch: 20/500... Training loss: 1.4945\n",
      "Epoch: 20/500... Training loss: 1.2283\n",
      "Epoch: 20/500... Training loss: 1.5349\n",
      "Epoch: 20/500... Training loss: 1.4686\n",
      "Epoch: 20/500... Training loss: 1.1802\n",
      "Epoch: 20/500... Training loss: 1.2466\n",
      "Epoch: 20/500... Training loss: 1.3108\n",
      "Epoch: 20/500... Training loss: 1.4179\n",
      "Epoch: 20/500... Training loss: 1.3222\n",
      "Epoch: 20/500... Training loss: 1.6835\n",
      "Epoch: 20/500... Training loss: 1.3988\n",
      "Epoch: 20/500... Training loss: 1.3190\n",
      "Epoch: 20/500... Training loss: 1.1911\n",
      "Epoch: 21/500... Training loss: 1.6380\n",
      "Epoch: 21/500... Training loss: 1.6717\n",
      "Epoch: 21/500... Training loss: 1.5089\n",
      "Epoch: 21/500... Training loss: 1.6175\n",
      "Epoch: 21/500... Training loss: 1.6160\n",
      "Epoch: 21/500... Training loss: 1.5053\n",
      "Epoch: 21/500... Training loss: 1.6398\n",
      "Epoch: 21/500... Training loss: 1.4511\n",
      "Epoch: 21/500... Training loss: 1.4690\n",
      "Epoch: 21/500... Training loss: 1.6298\n",
      "Epoch: 21/500... Training loss: 1.7713\n",
      "Epoch: 21/500... Training loss: 1.5923\n",
      "Epoch: 21/500... Training loss: 1.4837\n",
      "Epoch: 21/500... Training loss: 1.1961\n",
      "Epoch: 21/500... Training loss: 1.7926\n",
      "Epoch: 21/500... Training loss: 1.1226\n",
      "Epoch: 21/500... Training loss: 1.2395\n",
      "Epoch: 21/500... Training loss: 1.6516\n",
      "Epoch: 21/500... Training loss: 1.2532\n",
      "Epoch: 21/500... Training loss: 1.0301\n",
      "Epoch: 21/500... Training loss: 1.3803\n",
      "Epoch: 21/500... Training loss: 1.3134\n",
      "Epoch: 21/500... Training loss: 1.2570\n",
      "Epoch: 21/500... Training loss: 1.0598\n",
      "Epoch: 21/500... Training loss: 1.2958\n",
      "Epoch: 21/500... Training loss: 1.3170\n",
      "Epoch: 21/500... Training loss: 1.3774\n",
      "Epoch: 21/500... Training loss: 1.5507\n",
      "Epoch: 21/500... Training loss: 1.4003\n",
      "Epoch: 21/500... Training loss: 1.3782\n",
      "Epoch: 21/500... Training loss: 1.0832\n",
      "Epoch: 22/500... Training loss: 1.4340\n",
      "Epoch: 22/500... Training loss: 1.4726\n",
      "Epoch: 22/500... Training loss: 1.3731\n",
      "Epoch: 22/500... Training loss: 1.5970\n",
      "Epoch: 22/500... Training loss: 1.3436\n",
      "Epoch: 22/500... Training loss: 1.4369\n",
      "Epoch: 22/500... Training loss: 1.3703\n",
      "Epoch: 22/500... Training loss: 1.3361\n",
      "Epoch: 22/500... Training loss: 1.3142\n",
      "Epoch: 22/500... Training loss: 1.3154\n",
      "Epoch: 22/500... Training loss: 1.4412\n",
      "Epoch: 22/500... Training loss: 1.4763\n",
      "Epoch: 22/500... Training loss: 1.3234\n",
      "Epoch: 22/500... Training loss: 1.1753\n",
      "Epoch: 22/500... Training loss: 1.5510\n",
      "Epoch: 22/500... Training loss: 0.8750\n",
      "Epoch: 22/500... Training loss: 1.2072\n",
      "Epoch: 22/500... Training loss: 1.1946\n",
      "Epoch: 22/500... Training loss: 1.2430\n",
      "Epoch: 22/500... Training loss: 0.9868\n",
      "Epoch: 22/500... Training loss: 1.2101\n",
      "Epoch: 22/500... Training loss: 1.3599\n",
      "Epoch: 22/500... Training loss: 1.0417\n",
      "Epoch: 22/500... Training loss: 1.2110\n",
      "Epoch: 22/500... Training loss: 1.1134\n",
      "Epoch: 22/500... Training loss: 1.1652\n",
      "Epoch: 22/500... Training loss: 1.5105\n",
      "Epoch: 22/500... Training loss: 1.2450\n",
      "Epoch: 22/500... Training loss: 1.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/500... Training loss: 1.1649\n",
      "Epoch: 22/500... Training loss: 0.9848\n",
      "Epoch: 23/500... Training loss: 1.6827\n",
      "Epoch: 23/500... Training loss: 1.4174\n",
      "Epoch: 23/500... Training loss: 1.3302\n",
      "Epoch: 23/500... Training loss: 1.3530\n",
      "Epoch: 23/500... Training loss: 1.0778\n",
      "Epoch: 23/500... Training loss: 1.3316\n",
      "Epoch: 23/500... Training loss: 1.1143\n",
      "Epoch: 23/500... Training loss: 1.2549\n",
      "Epoch: 23/500... Training loss: 1.1586\n",
      "Epoch: 23/500... Training loss: 1.3425\n",
      "Epoch: 23/500... Training loss: 1.5794\n",
      "Epoch: 23/500... Training loss: 1.4959\n",
      "Epoch: 23/500... Training loss: 1.1619\n",
      "Epoch: 23/500... Training loss: 1.1716\n",
      "Epoch: 23/500... Training loss: 1.3511\n",
      "Epoch: 23/500... Training loss: 1.0093\n",
      "Epoch: 23/500... Training loss: 1.1032\n",
      "Epoch: 23/500... Training loss: 1.2904\n",
      "Epoch: 23/500... Training loss: 1.1200\n",
      "Epoch: 23/500... Training loss: 1.0834\n",
      "Epoch: 23/500... Training loss: 1.4323\n",
      "Epoch: 23/500... Training loss: 1.2709\n",
      "Epoch: 23/500... Training loss: 0.9868\n",
      "Epoch: 23/500... Training loss: 0.9622\n",
      "Epoch: 23/500... Training loss: 1.3270\n",
      "Epoch: 23/500... Training loss: 1.0985\n",
      "Epoch: 23/500... Training loss: 1.1731\n",
      "Epoch: 23/500... Training loss: 1.1986\n",
      "Epoch: 23/500... Training loss: 1.2186\n",
      "Epoch: 23/500... Training loss: 1.2035\n",
      "Epoch: 23/500... Training loss: 0.9566\n",
      "Epoch: 24/500... Training loss: 1.3097\n",
      "Epoch: 24/500... Training loss: 1.4599\n",
      "Epoch: 24/500... Training loss: 1.3943\n",
      "Epoch: 24/500... Training loss: 1.2102\n",
      "Epoch: 24/500... Training loss: 1.0912\n",
      "Epoch: 24/500... Training loss: 1.3047\n",
      "Epoch: 24/500... Training loss: 1.1497\n",
      "Epoch: 24/500... Training loss: 1.1692\n",
      "Epoch: 24/500... Training loss: 1.1507\n",
      "Epoch: 24/500... Training loss: 1.3752\n",
      "Epoch: 24/500... Training loss: 1.6826\n",
      "Epoch: 24/500... Training loss: 1.5406\n",
      "Epoch: 24/500... Training loss: 1.2254\n",
      "Epoch: 24/500... Training loss: 1.0980\n",
      "Epoch: 24/500... Training loss: 1.1154\n",
      "Epoch: 24/500... Training loss: 0.8512\n",
      "Epoch: 24/500... Training loss: 1.1803\n",
      "Epoch: 24/500... Training loss: 1.0913\n",
      "Epoch: 24/500... Training loss: 1.1397\n",
      "Epoch: 24/500... Training loss: 0.9416\n",
      "Epoch: 24/500... Training loss: 1.1636\n",
      "Epoch: 24/500... Training loss: 1.0975\n",
      "Epoch: 24/500... Training loss: 0.9773\n",
      "Epoch: 24/500... Training loss: 1.0750\n",
      "Epoch: 24/500... Training loss: 1.0140\n",
      "Epoch: 24/500... Training loss: 0.9520\n",
      "Epoch: 24/500... Training loss: 1.2493\n",
      "Epoch: 24/500... Training loss: 1.0730\n",
      "Epoch: 24/500... Training loss: 0.9285\n",
      "Epoch: 24/500... Training loss: 1.1577\n",
      "Epoch: 24/500... Training loss: 0.8721\n",
      "Epoch: 25/500... Training loss: 1.2440\n",
      "Epoch: 25/500... Training loss: 1.2330\n",
      "Epoch: 25/500... Training loss: 1.1678\n",
      "Epoch: 25/500... Training loss: 1.1179\n",
      "Epoch: 25/500... Training loss: 0.9076\n",
      "Epoch: 25/500... Training loss: 1.0748\n",
      "Epoch: 25/500... Training loss: 0.9316\n",
      "Epoch: 25/500... Training loss: 1.0188\n",
      "Epoch: 25/500... Training loss: 0.9486\n",
      "Epoch: 25/500... Training loss: 1.2063\n",
      "Epoch: 25/500... Training loss: 1.2605\n",
      "Epoch: 25/500... Training loss: 1.3774\n",
      "Epoch: 25/500... Training loss: 1.2815\n",
      "Epoch: 25/500... Training loss: 0.9391\n",
      "Epoch: 25/500... Training loss: 1.0832\n",
      "Epoch: 25/500... Training loss: 0.8929\n",
      "Epoch: 25/500... Training loss: 1.0265\n",
      "Epoch: 25/500... Training loss: 0.9479\n",
      "Epoch: 25/500... Training loss: 1.0068\n",
      "Epoch: 25/500... Training loss: 0.8951\n",
      "Epoch: 25/500... Training loss: 1.0486\n",
      "Epoch: 25/500... Training loss: 1.1850\n",
      "Epoch: 25/500... Training loss: 0.9326\n",
      "Epoch: 25/500... Training loss: 0.9362\n",
      "Epoch: 25/500... Training loss: 0.9896\n",
      "Epoch: 25/500... Training loss: 0.7705\n",
      "Epoch: 25/500... Training loss: 1.0047\n",
      "Epoch: 25/500... Training loss: 0.8877\n",
      "Epoch: 25/500... Training loss: 0.8924\n",
      "Epoch: 25/500... Training loss: 0.9642\n",
      "Epoch: 25/500... Training loss: 0.8778\n",
      "Epoch: 26/500... Training loss: 1.1688\n",
      "Epoch: 26/500... Training loss: 1.3899\n",
      "Epoch: 26/500... Training loss: 1.1127\n",
      "Epoch: 26/500... Training loss: 1.1894\n",
      "Epoch: 26/500... Training loss: 0.9657\n",
      "Epoch: 26/500... Training loss: 1.0565\n",
      "Epoch: 26/500... Training loss: 0.8889\n",
      "Epoch: 26/500... Training loss: 1.1447\n",
      "Epoch: 26/500... Training loss: 0.9821\n",
      "Epoch: 26/500... Training loss: 1.1571\n",
      "Epoch: 26/500... Training loss: 1.5076\n",
      "Epoch: 26/500... Training loss: 1.3540\n",
      "Epoch: 26/500... Training loss: 0.9527\n",
      "Epoch: 26/500... Training loss: 0.8698\n",
      "Epoch: 26/500... Training loss: 1.1189\n",
      "Epoch: 26/500... Training loss: 0.6580\n",
      "Epoch: 26/500... Training loss: 1.0554\n",
      "Epoch: 26/500... Training loss: 0.9022\n",
      "Epoch: 26/500... Training loss: 1.1428\n",
      "Epoch: 26/500... Training loss: 0.7756\n",
      "Epoch: 26/500... Training loss: 0.9782\n",
      "Epoch: 26/500... Training loss: 0.9226\n",
      "Epoch: 26/500... Training loss: 0.8520\n",
      "Epoch: 26/500... Training loss: 0.8588\n",
      "Epoch: 26/500... Training loss: 0.7870\n",
      "Epoch: 26/500... Training loss: 0.8101\n",
      "Epoch: 26/500... Training loss: 1.0767\n",
      "Epoch: 26/500... Training loss: 1.1643\n",
      "Epoch: 26/500... Training loss: 0.6875\n",
      "Epoch: 26/500... Training loss: 1.0109\n",
      "Epoch: 26/500... Training loss: 0.7328\n",
      "Epoch: 27/500... Training loss: 1.1053\n",
      "Epoch: 27/500... Training loss: 0.9449\n",
      "Epoch: 27/500... Training loss: 0.8067\n",
      "Epoch: 27/500... Training loss: 1.1956\n",
      "Epoch: 27/500... Training loss: 1.1539\n",
      "Epoch: 27/500... Training loss: 1.0437\n",
      "Epoch: 27/500... Training loss: 0.9777\n",
      "Epoch: 27/500... Training loss: 0.8246\n",
      "Epoch: 27/500... Training loss: 0.9736\n",
      "Epoch: 27/500... Training loss: 1.0412\n",
      "Epoch: 27/500... Training loss: 1.4131\n",
      "Epoch: 27/500... Training loss: 1.0285\n",
      "Epoch: 27/500... Training loss: 1.0221\n",
      "Epoch: 27/500... Training loss: 0.9019\n",
      "Epoch: 27/500... Training loss: 0.9496\n",
      "Epoch: 27/500... Training loss: 0.6254\n",
      "Epoch: 27/500... Training loss: 0.8497\n",
      "Epoch: 27/500... Training loss: 1.0272\n",
      "Epoch: 27/500... Training loss: 0.9918\n",
      "Epoch: 27/500... Training loss: 0.7282\n",
      "Epoch: 27/500... Training loss: 0.9515\n",
      "Epoch: 27/500... Training loss: 1.0477\n",
      "Epoch: 27/500... Training loss: 0.8802\n",
      "Epoch: 27/500... Training loss: 0.9503\n",
      "Epoch: 27/500... Training loss: 0.9133\n",
      "Epoch: 27/500... Training loss: 0.7452\n",
      "Epoch: 27/500... Training loss: 0.8023\n",
      "Epoch: 27/500... Training loss: 0.8642\n",
      "Epoch: 27/500... Training loss: 0.9553\n",
      "Epoch: 27/500... Training loss: 0.9927\n",
      "Epoch: 27/500... Training loss: 0.8597\n",
      "Epoch: 28/500... Training loss: 1.2135\n",
      "Epoch: 28/500... Training loss: 1.2512\n",
      "Epoch: 28/500... Training loss: 0.8354\n",
      "Epoch: 28/500... Training loss: 1.0317\n",
      "Epoch: 28/500... Training loss: 0.8068\n",
      "Epoch: 28/500... Training loss: 0.9851\n",
      "Epoch: 28/500... Training loss: 0.8626\n",
      "Epoch: 28/500... Training loss: 1.0101\n",
      "Epoch: 28/500... Training loss: 0.9319\n",
      "Epoch: 28/500... Training loss: 0.9655\n",
      "Epoch: 28/500... Training loss: 1.1507\n",
      "Epoch: 28/500... Training loss: 1.1207\n",
      "Epoch: 28/500... Training loss: 0.9093\n",
      "Epoch: 28/500... Training loss: 0.8307\n",
      "Epoch: 28/500... Training loss: 0.9953\n",
      "Epoch: 28/500... Training loss: 0.6619\n",
      "Epoch: 28/500... Training loss: 0.9687\n",
      "Epoch: 28/500... Training loss: 0.9880\n",
      "Epoch: 28/500... Training loss: 0.8838\n",
      "Epoch: 28/500... Training loss: 0.6693\n",
      "Epoch: 28/500... Training loss: 0.9540\n",
      "Epoch: 28/500... Training loss: 0.8338\n",
      "Epoch: 28/500... Training loss: 0.7389\n",
      "Epoch: 28/500... Training loss: 0.7928\n",
      "Epoch: 28/500... Training loss: 0.8045\n",
      "Epoch: 28/500... Training loss: 1.0045\n",
      "Epoch: 28/500... Training loss: 0.9172\n",
      "Epoch: 28/500... Training loss: 0.9809\n",
      "Epoch: 28/500... Training loss: 0.7811\n",
      "Epoch: 28/500... Training loss: 0.9328\n",
      "Epoch: 28/500... Training loss: 0.6714\n",
      "Epoch: 29/500... Training loss: 1.0156\n",
      "Epoch: 29/500... Training loss: 0.8106\n",
      "Epoch: 29/500... Training loss: 0.8859\n",
      "Epoch: 29/500... Training loss: 1.1365\n",
      "Epoch: 29/500... Training loss: 0.8722\n",
      "Epoch: 29/500... Training loss: 0.9065\n",
      "Epoch: 29/500... Training loss: 0.9532\n",
      "Epoch: 29/500... Training loss: 0.9391\n",
      "Epoch: 29/500... Training loss: 0.8538\n",
      "Epoch: 29/500... Training loss: 1.0645\n",
      "Epoch: 29/500... Training loss: 1.2058\n",
      "Epoch: 29/500... Training loss: 0.9985\n",
      "Epoch: 29/500... Training loss: 1.0282\n",
      "Epoch: 29/500... Training loss: 0.9427\n",
      "Epoch: 29/500... Training loss: 1.0321\n",
      "Epoch: 29/500... Training loss: 0.7115\n",
      "Epoch: 29/500... Training loss: 0.9937\n",
      "Epoch: 29/500... Training loss: 0.8638\n",
      "Epoch: 29/500... Training loss: 0.7923\n",
      "Epoch: 29/500... Training loss: 0.8166\n",
      "Epoch: 29/500... Training loss: 0.8281\n",
      "Epoch: 29/500... Training loss: 1.0349\n",
      "Epoch: 29/500... Training loss: 0.6370\n",
      "Epoch: 29/500... Training loss: 0.7573\n",
      "Epoch: 29/500... Training loss: 0.8200\n",
      "Epoch: 29/500... Training loss: 0.7379\n",
      "Epoch: 29/500... Training loss: 0.9911\n",
      "Epoch: 29/500... Training loss: 0.8288\n",
      "Epoch: 29/500... Training loss: 0.8959\n",
      "Epoch: 29/500... Training loss: 0.8735\n",
      "Epoch: 29/500... Training loss: 0.6860\n",
      "Epoch: 30/500... Training loss: 0.9981\n",
      "Epoch: 30/500... Training loss: 0.9012\n",
      "Epoch: 30/500... Training loss: 1.0266\n",
      "Epoch: 30/500... Training loss: 1.0811\n",
      "Epoch: 30/500... Training loss: 1.0182\n",
      "Epoch: 30/500... Training loss: 0.9010\n",
      "Epoch: 30/500... Training loss: 0.7365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/500... Training loss: 0.9229\n",
      "Epoch: 30/500... Training loss: 0.7921\n",
      "Epoch: 30/500... Training loss: 0.7491\n",
      "Epoch: 30/500... Training loss: 1.1599\n",
      "Epoch: 30/500... Training loss: 1.1555\n",
      "Epoch: 30/500... Training loss: 0.9829\n",
      "Epoch: 30/500... Training loss: 0.6862\n",
      "Epoch: 30/500... Training loss: 0.9526\n",
      "Epoch: 30/500... Training loss: 0.5999\n",
      "Epoch: 30/500... Training loss: 0.6860\n",
      "Epoch: 30/500... Training loss: 0.8942\n",
      "Epoch: 30/500... Training loss: 0.8559\n",
      "Epoch: 30/500... Training loss: 0.6624\n",
      "Epoch: 30/500... Training loss: 1.0038\n",
      "Epoch: 30/500... Training loss: 0.8710\n",
      "Epoch: 30/500... Training loss: 0.7223\n",
      "Epoch: 30/500... Training loss: 0.7912\n",
      "Epoch: 30/500... Training loss: 0.7149\n",
      "Epoch: 30/500... Training loss: 0.7506\n",
      "Epoch: 30/500... Training loss: 0.9519\n",
      "Epoch: 30/500... Training loss: 0.8314\n",
      "Epoch: 30/500... Training loss: 0.8548\n",
      "Epoch: 30/500... Training loss: 0.7065\n",
      "Epoch: 30/500... Training loss: 0.6613\n",
      "Epoch: 31/500... Training loss: 1.1805\n",
      "Epoch: 31/500... Training loss: 1.1947\n",
      "Epoch: 31/500... Training loss: 0.8700\n",
      "Epoch: 31/500... Training loss: 0.9813\n",
      "Epoch: 31/500... Training loss: 0.8432\n",
      "Epoch: 31/500... Training loss: 0.7467\n",
      "Epoch: 31/500... Training loss: 0.8497\n",
      "Epoch: 31/500... Training loss: 0.8850\n",
      "Epoch: 31/500... Training loss: 0.6442\n",
      "Epoch: 31/500... Training loss: 1.0364\n",
      "Epoch: 31/500... Training loss: 1.2419\n",
      "Epoch: 31/500... Training loss: 1.1025\n",
      "Epoch: 31/500... Training loss: 0.8808\n",
      "Epoch: 31/500... Training loss: 0.8001\n",
      "Epoch: 31/500... Training loss: 1.1295\n",
      "Epoch: 31/500... Training loss: 0.4827\n",
      "Epoch: 31/500... Training loss: 0.9203\n",
      "Epoch: 31/500... Training loss: 0.7991\n",
      "Epoch: 31/500... Training loss: 0.8689\n",
      "Epoch: 31/500... Training loss: 0.6641\n",
      "Epoch: 31/500... Training loss: 0.9712\n",
      "Epoch: 31/500... Training loss: 0.7141\n",
      "Epoch: 31/500... Training loss: 0.7267\n",
      "Epoch: 31/500... Training loss: 0.5947\n",
      "Epoch: 31/500... Training loss: 0.6756\n",
      "Epoch: 31/500... Training loss: 0.6376\n",
      "Epoch: 31/500... Training loss: 0.7725\n",
      "Epoch: 31/500... Training loss: 0.6372\n",
      "Epoch: 31/500... Training loss: 0.7419\n",
      "Epoch: 31/500... Training loss: 0.7266\n",
      "Epoch: 31/500... Training loss: 0.6404\n",
      "Epoch: 32/500... Training loss: 0.9560\n",
      "Epoch: 32/500... Training loss: 0.8380\n",
      "Epoch: 32/500... Training loss: 0.9532\n",
      "Epoch: 32/500... Training loss: 0.6841\n",
      "Epoch: 32/500... Training loss: 0.6601\n",
      "Epoch: 32/500... Training loss: 0.7195\n",
      "Epoch: 32/500... Training loss: 0.7893\n",
      "Epoch: 32/500... Training loss: 0.8265\n",
      "Epoch: 32/500... Training loss: 0.8774\n",
      "Epoch: 32/500... Training loss: 0.7134\n",
      "Epoch: 32/500... Training loss: 0.9664\n",
      "Epoch: 32/500... Training loss: 0.9043\n",
      "Epoch: 32/500... Training loss: 0.8909\n",
      "Epoch: 32/500... Training loss: 0.8378\n",
      "Epoch: 32/500... Training loss: 0.8754\n",
      "Epoch: 32/500... Training loss: 0.8141\n",
      "Epoch: 32/500... Training loss: 0.8279\n",
      "Epoch: 32/500... Training loss: 0.8530\n",
      "Epoch: 32/500... Training loss: 0.7969\n",
      "Epoch: 32/500... Training loss: 0.5812\n",
      "Epoch: 32/500... Training loss: 0.8241\n",
      "Epoch: 32/500... Training loss: 0.7811\n",
      "Epoch: 32/500... Training loss: 0.6159\n",
      "Epoch: 32/500... Training loss: 0.4569\n",
      "Epoch: 32/500... Training loss: 0.7568\n",
      "Epoch: 32/500... Training loss: 0.6995\n",
      "Epoch: 32/500... Training loss: 0.6965\n",
      "Epoch: 32/500... Training loss: 0.8343\n",
      "Epoch: 32/500... Training loss: 0.7853\n",
      "Epoch: 32/500... Training loss: 0.7180\n",
      "Epoch: 32/500... Training loss: 0.5892\n",
      "Epoch: 33/500... Training loss: 0.8769\n",
      "Epoch: 33/500... Training loss: 0.9346\n",
      "Epoch: 33/500... Training loss: 0.8146\n",
      "Epoch: 33/500... Training loss: 0.7988\n",
      "Epoch: 33/500... Training loss: 0.7584\n",
      "Epoch: 33/500... Training loss: 0.8622\n",
      "Epoch: 33/500... Training loss: 0.8241\n",
      "Epoch: 33/500... Training loss: 0.8834\n",
      "Epoch: 33/500... Training loss: 0.6933\n",
      "Epoch: 33/500... Training loss: 0.9021\n",
      "Epoch: 33/500... Training loss: 1.1425\n",
      "Epoch: 33/500... Training loss: 1.1265\n",
      "Epoch: 33/500... Training loss: 0.7701\n",
      "Epoch: 33/500... Training loss: 0.7073\n",
      "Epoch: 33/500... Training loss: 0.7137\n",
      "Epoch: 33/500... Training loss: 0.6186\n",
      "Epoch: 33/500... Training loss: 0.7040\n",
      "Epoch: 33/500... Training loss: 0.6326\n",
      "Epoch: 33/500... Training loss: 0.6936\n",
      "Epoch: 33/500... Training loss: 0.5923\n",
      "Epoch: 33/500... Training loss: 0.6898\n",
      "Epoch: 33/500... Training loss: 0.7549\n",
      "Epoch: 33/500... Training loss: 0.5402\n",
      "Epoch: 33/500... Training loss: 0.6002\n",
      "Epoch: 33/500... Training loss: 0.6165\n",
      "Epoch: 33/500... Training loss: 0.5954\n",
      "Epoch: 33/500... Training loss: 0.6469\n",
      "Epoch: 33/500... Training loss: 0.6316\n",
      "Epoch: 33/500... Training loss: 0.6300\n",
      "Epoch: 33/500... Training loss: 0.6616\n",
      "Epoch: 33/500... Training loss: 0.4983\n",
      "Epoch: 34/500... Training loss: 0.8006\n",
      "Epoch: 34/500... Training loss: 0.8151\n",
      "Epoch: 34/500... Training loss: 0.9469\n",
      "Epoch: 34/500... Training loss: 0.8934\n",
      "Epoch: 34/500... Training loss: 0.7673\n",
      "Epoch: 34/500... Training loss: 0.6481\n",
      "Epoch: 34/500... Training loss: 0.8017\n",
      "Epoch: 34/500... Training loss: 0.7144\n",
      "Epoch: 34/500... Training loss: 0.5700\n",
      "Epoch: 34/500... Training loss: 0.6986\n",
      "Epoch: 34/500... Training loss: 0.8504\n",
      "Epoch: 34/500... Training loss: 1.0218\n",
      "Epoch: 34/500... Training loss: 0.6517\n",
      "Epoch: 34/500... Training loss: 0.6920\n",
      "Epoch: 34/500... Training loss: 0.7978\n",
      "Epoch: 34/500... Training loss: 0.5666\n",
      "Epoch: 34/500... Training loss: 0.5326\n",
      "Epoch: 34/500... Training loss: 0.7587\n",
      "Epoch: 34/500... Training loss: 0.8199\n",
      "Epoch: 34/500... Training loss: 0.5860\n",
      "Epoch: 34/500... Training loss: 0.8599\n",
      "Epoch: 34/500... Training loss: 0.6389\n",
      "Epoch: 34/500... Training loss: 0.5455\n",
      "Epoch: 34/500... Training loss: 0.6432\n",
      "Epoch: 34/500... Training loss: 0.5064\n",
      "Epoch: 34/500... Training loss: 0.7250\n",
      "Epoch: 34/500... Training loss: 0.7189\n",
      "Epoch: 34/500... Training loss: 0.7202\n",
      "Epoch: 34/500... Training loss: 0.5572\n",
      "Epoch: 34/500... Training loss: 0.6817\n",
      "Epoch: 34/500... Training loss: 0.8581\n",
      "Epoch: 35/500... Training loss: 0.8444\n",
      "Epoch: 35/500... Training loss: 0.6462\n",
      "Epoch: 35/500... Training loss: 0.6949\n",
      "Epoch: 35/500... Training loss: 0.7738\n",
      "Epoch: 35/500... Training loss: 0.6551\n",
      "Epoch: 35/500... Training loss: 0.7404\n",
      "Epoch: 35/500... Training loss: 0.8370\n",
      "Epoch: 35/500... Training loss: 0.7723\n",
      "Epoch: 35/500... Training loss: 0.6183\n",
      "Epoch: 35/500... Training loss: 0.7367\n",
      "Epoch: 35/500... Training loss: 0.9890\n",
      "Epoch: 35/500... Training loss: 0.8113\n",
      "Epoch: 35/500... Training loss: 1.0017\n",
      "Epoch: 35/500... Training loss: 0.4676\n",
      "Epoch: 35/500... Training loss: 0.6841\n",
      "Epoch: 35/500... Training loss: 0.3777\n",
      "Epoch: 35/500... Training loss: 0.5563\n",
      "Epoch: 35/500... Training loss: 0.7023\n",
      "Epoch: 35/500... Training loss: 0.5665\n",
      "Epoch: 35/500... Training loss: 0.6008\n",
      "Epoch: 35/500... Training loss: 0.6272\n",
      "Epoch: 35/500... Training loss: 0.6938\n",
      "Epoch: 35/500... Training loss: 0.6096\n",
      "Epoch: 35/500... Training loss: 0.6673\n",
      "Epoch: 35/500... Training loss: 0.6014\n",
      "Epoch: 35/500... Training loss: 0.5437\n",
      "Epoch: 35/500... Training loss: 0.4815\n",
      "Epoch: 35/500... Training loss: 0.5918\n",
      "Epoch: 35/500... Training loss: 0.5345\n",
      "Epoch: 35/500... Training loss: 0.5353\n",
      "Epoch: 35/500... Training loss: 0.5751\n",
      "Epoch: 36/500... Training loss: 0.6706\n",
      "Epoch: 36/500... Training loss: 0.7843\n",
      "Epoch: 36/500... Training loss: 0.8643\n",
      "Epoch: 36/500... Training loss: 0.8525\n",
      "Epoch: 36/500... Training loss: 0.7282\n",
      "Epoch: 36/500... Training loss: 0.7596\n",
      "Epoch: 36/500... Training loss: 0.6099\n",
      "Epoch: 36/500... Training loss: 0.6296\n",
      "Epoch: 36/500... Training loss: 0.6773\n",
      "Epoch: 36/500... Training loss: 0.8266\n",
      "Epoch: 36/500... Training loss: 0.7903\n",
      "Epoch: 36/500... Training loss: 0.8337\n",
      "Epoch: 36/500... Training loss: 0.6648\n",
      "Epoch: 36/500... Training loss: 0.5847\n",
      "Epoch: 36/500... Training loss: 0.6408\n",
      "Epoch: 36/500... Training loss: 0.5473\n",
      "Epoch: 36/500... Training loss: 0.4735\n",
      "Epoch: 36/500... Training loss: 0.5890\n",
      "Epoch: 36/500... Training loss: 0.7887\n",
      "Epoch: 36/500... Training loss: 0.4409\n",
      "Epoch: 36/500... Training loss: 0.6795\n",
      "Epoch: 36/500... Training loss: 0.6312\n",
      "Epoch: 36/500... Training loss: 0.6496\n",
      "Epoch: 36/500... Training loss: 0.6202\n",
      "Epoch: 36/500... Training loss: 0.5935\n",
      "Epoch: 36/500... Training loss: 0.6749\n",
      "Epoch: 36/500... Training loss: 0.7056\n",
      "Epoch: 36/500... Training loss: 0.6974\n",
      "Epoch: 36/500... Training loss: 0.5377\n",
      "Epoch: 36/500... Training loss: 0.6785\n",
      "Epoch: 36/500... Training loss: 0.6802\n",
      "Epoch: 37/500... Training loss: 0.6898\n",
      "Epoch: 37/500... Training loss: 0.8767\n",
      "Epoch: 37/500... Training loss: 0.8012\n",
      "Epoch: 37/500... Training loss: 0.7822\n",
      "Epoch: 37/500... Training loss: 0.6663\n",
      "Epoch: 37/500... Training loss: 0.7135\n",
      "Epoch: 37/500... Training loss: 0.6770\n",
      "Epoch: 37/500... Training loss: 0.6650\n",
      "Epoch: 37/500... Training loss: 0.7709\n",
      "Epoch: 37/500... Training loss: 0.6441\n",
      "Epoch: 37/500... Training loss: 0.8439\n",
      "Epoch: 37/500... Training loss: 0.8576\n",
      "Epoch: 37/500... Training loss: 0.9426\n",
      "Epoch: 37/500... Training loss: 0.5709\n",
      "Epoch: 37/500... Training loss: 0.6683\n",
      "Epoch: 37/500... Training loss: 0.4517\n",
      "Epoch: 37/500... Training loss: 0.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/500... Training loss: 0.5788\n",
      "Epoch: 37/500... Training loss: 0.7401\n",
      "Epoch: 37/500... Training loss: 0.5511\n",
      "Epoch: 37/500... Training loss: 0.5833\n",
      "Epoch: 37/500... Training loss: 0.6511\n",
      "Epoch: 37/500... Training loss: 0.6857\n",
      "Epoch: 37/500... Training loss: 0.5574\n",
      "Epoch: 37/500... Training loss: 0.5559\n",
      "Epoch: 37/500... Training loss: 0.5367\n",
      "Epoch: 37/500... Training loss: 0.5929\n",
      "Epoch: 37/500... Training loss: 0.5781\n",
      "Epoch: 37/500... Training loss: 0.5161\n",
      "Epoch: 37/500... Training loss: 0.5597\n",
      "Epoch: 37/500... Training loss: 0.5664\n",
      "Epoch: 38/500... Training loss: 0.9327\n",
      "Epoch: 38/500... Training loss: 0.8140\n",
      "Epoch: 38/500... Training loss: 0.6610\n",
      "Epoch: 38/500... Training loss: 0.7635\n",
      "Epoch: 38/500... Training loss: 0.6236\n",
      "Epoch: 38/500... Training loss: 0.7000\n",
      "Epoch: 38/500... Training loss: 0.6324\n",
      "Epoch: 38/500... Training loss: 0.5876\n",
      "Epoch: 38/500... Training loss: 0.7294\n",
      "Epoch: 38/500... Training loss: 0.7212\n",
      "Epoch: 38/500... Training loss: 0.9973\n",
      "Epoch: 38/500... Training loss: 0.7394\n",
      "Epoch: 38/500... Training loss: 0.9088\n",
      "Epoch: 38/500... Training loss: 0.5510\n",
      "Epoch: 38/500... Training loss: 0.7442\n",
      "Epoch: 38/500... Training loss: 0.4343\n",
      "Epoch: 38/500... Training loss: 0.4964\n",
      "Epoch: 38/500... Training loss: 0.5989\n",
      "Epoch: 38/500... Training loss: 0.6039\n",
      "Epoch: 38/500... Training loss: 0.3270\n",
      "Epoch: 38/500... Training loss: 0.5951\n",
      "Epoch: 38/500... Training loss: 0.5063\n",
      "Epoch: 38/500... Training loss: 0.5812\n",
      "Epoch: 38/500... Training loss: 0.5215\n",
      "Epoch: 38/500... Training loss: 0.4624\n",
      "Epoch: 38/500... Training loss: 0.4288\n",
      "Epoch: 38/500... Training loss: 0.5171\n",
      "Epoch: 38/500... Training loss: 0.4701\n",
      "Epoch: 38/500... Training loss: 0.5555\n",
      "Epoch: 38/500... Training loss: 0.5637\n",
      "Epoch: 38/500... Training loss: 0.7266\n",
      "Epoch: 39/500... Training loss: 0.7697\n",
      "Epoch: 39/500... Training loss: 0.8060\n",
      "Epoch: 39/500... Training loss: 0.8040\n",
      "Epoch: 39/500... Training loss: 0.6779\n",
      "Epoch: 39/500... Training loss: 0.5940\n",
      "Epoch: 39/500... Training loss: 0.6009\n",
      "Epoch: 39/500... Training loss: 0.6477\n",
      "Epoch: 39/500... Training loss: 0.8130\n",
      "Epoch: 39/500... Training loss: 0.5015\n",
      "Epoch: 39/500... Training loss: 0.7203\n",
      "Epoch: 39/500... Training loss: 0.9936\n",
      "Epoch: 39/500... Training loss: 0.7451\n",
      "Epoch: 39/500... Training loss: 0.7733\n",
      "Epoch: 39/500... Training loss: 0.4620\n",
      "Epoch: 39/500... Training loss: 0.6146\n",
      "Epoch: 39/500... Training loss: 0.3632\n",
      "Epoch: 39/500... Training loss: 0.6227\n",
      "Epoch: 39/500... Training loss: 0.5954\n",
      "Epoch: 39/500... Training loss: 0.5295\n",
      "Epoch: 39/500... Training loss: 0.3735\n",
      "Epoch: 39/500... Training loss: 0.4829\n",
      "Epoch: 39/500... Training loss: 0.6243\n",
      "Epoch: 39/500... Training loss: 0.5280\n",
      "Epoch: 39/500... Training loss: 0.5234\n",
      "Epoch: 39/500... Training loss: 0.4786\n",
      "Epoch: 39/500... Training loss: 0.4940\n",
      "Epoch: 39/500... Training loss: 0.7620\n",
      "Epoch: 39/500... Training loss: 0.5433\n",
      "Epoch: 39/500... Training loss: 0.5369\n",
      "Epoch: 39/500... Training loss: 0.4895\n",
      "Epoch: 39/500... Training loss: 0.3355\n",
      "Epoch: 40/500... Training loss: 0.7848\n",
      "Epoch: 40/500... Training loss: 0.6967\n",
      "Epoch: 40/500... Training loss: 0.6201\n",
      "Epoch: 40/500... Training loss: 0.8409\n",
      "Epoch: 40/500... Training loss: 0.5343\n",
      "Epoch: 40/500... Training loss: 0.5540\n",
      "Epoch: 40/500... Training loss: 0.6852\n",
      "Epoch: 40/500... Training loss: 0.6370\n",
      "Epoch: 40/500... Training loss: 0.6140\n",
      "Epoch: 40/500... Training loss: 0.7272\n",
      "Epoch: 40/500... Training loss: 0.7738\n",
      "Epoch: 40/500... Training loss: 0.7576\n",
      "Epoch: 40/500... Training loss: 0.5741\n",
      "Epoch: 40/500... Training loss: 0.4911\n",
      "Epoch: 40/500... Training loss: 0.7129\n",
      "Epoch: 40/500... Training loss: 0.4578\n",
      "Epoch: 40/500... Training loss: 0.4667\n",
      "Epoch: 40/500... Training loss: 0.6306\n",
      "Epoch: 40/500... Training loss: 0.6471\n",
      "Epoch: 40/500... Training loss: 0.4220\n",
      "Epoch: 40/500... Training loss: 0.5651\n",
      "Epoch: 40/500... Training loss: 0.6808\n",
      "Epoch: 40/500... Training loss: 0.4379\n",
      "Epoch: 40/500... Training loss: 0.5468\n",
      "Epoch: 40/500... Training loss: 0.5055\n",
      "Epoch: 40/500... Training loss: 0.4894\n",
      "Epoch: 40/500... Training loss: 0.5936\n",
      "Epoch: 40/500... Training loss: 0.6077\n",
      "Epoch: 40/500... Training loss: 0.3890\n",
      "Epoch: 40/500... Training loss: 0.6092\n",
      "Epoch: 40/500... Training loss: 0.3925\n",
      "Epoch: 41/500... Training loss: 0.5746\n",
      "Epoch: 41/500... Training loss: 0.6520\n",
      "Epoch: 41/500... Training loss: 0.5050\n",
      "Epoch: 41/500... Training loss: 0.7248\n",
      "Epoch: 41/500... Training loss: 0.4610\n",
      "Epoch: 41/500... Training loss: 0.7571\n",
      "Epoch: 41/500... Training loss: 0.5917\n",
      "Epoch: 41/500... Training loss: 0.7089\n",
      "Epoch: 41/500... Training loss: 0.7573\n",
      "Epoch: 41/500... Training loss: 0.4619\n",
      "Epoch: 41/500... Training loss: 0.7980\n",
      "Epoch: 41/500... Training loss: 0.6863\n",
      "Epoch: 41/500... Training loss: 0.7476\n",
      "Epoch: 41/500... Training loss: 0.4602\n",
      "Epoch: 41/500... Training loss: 0.5367\n",
      "Epoch: 41/500... Training loss: 0.3865\n",
      "Epoch: 41/500... Training loss: 0.4904\n",
      "Epoch: 41/500... Training loss: 0.4079\n",
      "Epoch: 41/500... Training loss: 0.5501\n",
      "Epoch: 41/500... Training loss: 0.4231\n",
      "Epoch: 41/500... Training loss: 0.5478\n",
      "Epoch: 41/500... Training loss: 0.5007\n",
      "Epoch: 41/500... Training loss: 0.6671\n",
      "Epoch: 41/500... Training loss: 0.5115\n",
      "Epoch: 41/500... Training loss: 0.5625\n",
      "Epoch: 41/500... Training loss: 0.5469\n",
      "Epoch: 41/500... Training loss: 0.6089\n",
      "Epoch: 41/500... Training loss: 0.6088\n",
      "Epoch: 41/500... Training loss: 0.4859\n",
      "Epoch: 41/500... Training loss: 0.6659\n",
      "Epoch: 41/500... Training loss: 0.5655\n",
      "Epoch: 42/500... Training loss: 0.8881\n",
      "Epoch: 42/500... Training loss: 0.5123\n",
      "Epoch: 42/500... Training loss: 0.4701\n",
      "Epoch: 42/500... Training loss: 0.7117\n",
      "Epoch: 42/500... Training loss: 0.5546\n",
      "Epoch: 42/500... Training loss: 0.6650\n",
      "Epoch: 42/500... Training loss: 0.6008\n",
      "Epoch: 42/500... Training loss: 0.6285\n",
      "Epoch: 42/500... Training loss: 0.5592\n",
      "Epoch: 42/500... Training loss: 0.6616\n",
      "Epoch: 42/500... Training loss: 0.9365\n",
      "Epoch: 42/500... Training loss: 0.9774\n",
      "Epoch: 42/500... Training loss: 0.6817\n",
      "Epoch: 42/500... Training loss: 0.4517\n",
      "Epoch: 42/500... Training loss: 0.6719\n",
      "Epoch: 42/500... Training loss: 0.4129\n",
      "Epoch: 42/500... Training loss: 0.3856\n",
      "Epoch: 42/500... Training loss: 0.6259\n",
      "Epoch: 42/500... Training loss: 0.3734\n",
      "Epoch: 42/500... Training loss: 0.4590\n",
      "Epoch: 42/500... Training loss: 0.5568\n",
      "Epoch: 42/500... Training loss: 0.5614\n",
      "Epoch: 42/500... Training loss: 0.5731\n",
      "Epoch: 42/500... Training loss: 0.5260\n",
      "Epoch: 42/500... Training loss: 0.5855\n",
      "Epoch: 42/500... Training loss: 0.5261\n",
      "Epoch: 42/500... Training loss: 0.6619\n",
      "Epoch: 42/500... Training loss: 0.4181\n",
      "Epoch: 42/500... Training loss: 0.4382\n",
      "Epoch: 42/500... Training loss: 0.5779\n",
      "Epoch: 42/500... Training loss: 0.3316\n",
      "Epoch: 43/500... Training loss: 0.5870\n",
      "Epoch: 43/500... Training loss: 0.7130\n",
      "Epoch: 43/500... Training loss: 0.6980\n",
      "Epoch: 43/500... Training loss: 0.7359\n",
      "Epoch: 43/500... Training loss: 0.6749\n",
      "Epoch: 43/500... Training loss: 0.5704\n",
      "Epoch: 43/500... Training loss: 0.5819\n",
      "Epoch: 43/500... Training loss: 0.5432\n",
      "Epoch: 43/500... Training loss: 0.4550\n",
      "Epoch: 43/500... Training loss: 0.5385\n",
      "Epoch: 43/500... Training loss: 0.8548\n",
      "Epoch: 43/500... Training loss: 0.7261\n",
      "Epoch: 43/500... Training loss: 0.6288\n",
      "Epoch: 43/500... Training loss: 0.5322\n",
      "Epoch: 43/500... Training loss: 0.5151\n",
      "Epoch: 43/500... Training loss: 0.3669\n",
      "Epoch: 43/500... Training loss: 0.4536\n",
      "Epoch: 43/500... Training loss: 0.4341\n",
      "Epoch: 43/500... Training loss: 0.4513\n",
      "Epoch: 43/500... Training loss: 0.4073\n",
      "Epoch: 43/500... Training loss: 0.5203\n",
      "Epoch: 43/500... Training loss: 0.6416\n",
      "Epoch: 43/500... Training loss: 0.5119\n",
      "Epoch: 43/500... Training loss: 0.5175\n",
      "Epoch: 43/500... Training loss: 0.3993\n",
      "Epoch: 43/500... Training loss: 0.3877\n",
      "Epoch: 43/500... Training loss: 0.5990\n",
      "Epoch: 43/500... Training loss: 0.5571\n",
      "Epoch: 43/500... Training loss: 0.4042\n",
      "Epoch: 43/500... Training loss: 0.5531\n",
      "Epoch: 43/500... Training loss: 0.5741\n",
      "Epoch: 44/500... Training loss: 0.6230\n",
      "Epoch: 44/500... Training loss: 0.5055\n",
      "Epoch: 44/500... Training loss: 0.4861\n",
      "Epoch: 44/500... Training loss: 0.7048\n",
      "Epoch: 44/500... Training loss: 0.4920\n",
      "Epoch: 44/500... Training loss: 0.5338\n",
      "Epoch: 44/500... Training loss: 0.6276\n",
      "Epoch: 44/500... Training loss: 0.5899\n",
      "Epoch: 44/500... Training loss: 0.5192\n",
      "Epoch: 44/500... Training loss: 0.5532\n",
      "Epoch: 44/500... Training loss: 0.6468\n",
      "Epoch: 44/500... Training loss: 0.7835\n",
      "Epoch: 44/500... Training loss: 0.6070\n",
      "Epoch: 44/500... Training loss: 0.5711\n",
      "Epoch: 44/500... Training loss: 0.6596\n",
      "Epoch: 44/500... Training loss: 0.3925\n",
      "Epoch: 44/500... Training loss: 0.4885\n",
      "Epoch: 44/500... Training loss: 0.3684\n",
      "Epoch: 44/500... Training loss: 0.6833\n",
      "Epoch: 44/500... Training loss: 0.4067\n",
      "Epoch: 44/500... Training loss: 0.4823\n",
      "Epoch: 44/500... Training loss: 0.6462\n",
      "Epoch: 44/500... Training loss: 0.4735\n",
      "Epoch: 44/500... Training loss: 0.4764\n",
      "Epoch: 44/500... Training loss: 0.5436\n",
      "Epoch: 44/500... Training loss: 0.4945\n",
      "Epoch: 44/500... Training loss: 0.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/500... Training loss: 0.4282\n",
      "Epoch: 44/500... Training loss: 0.4128\n",
      "Epoch: 44/500... Training loss: 0.3665\n",
      "Epoch: 44/500... Training loss: 0.2775\n",
      "Epoch: 45/500... Training loss: 0.6285\n",
      "Epoch: 45/500... Training loss: 0.3809\n",
      "Epoch: 45/500... Training loss: 0.5622\n",
      "Epoch: 45/500... Training loss: 0.5287\n",
      "Epoch: 45/500... Training loss: 0.6015\n",
      "Epoch: 45/500... Training loss: 0.4663\n",
      "Epoch: 45/500... Training loss: 0.5328\n",
      "Epoch: 45/500... Training loss: 0.4897\n",
      "Epoch: 45/500... Training loss: 0.4985\n",
      "Epoch: 45/500... Training loss: 0.4994\n",
      "Epoch: 45/500... Training loss: 0.6852\n",
      "Epoch: 45/500... Training loss: 0.8568\n",
      "Epoch: 45/500... Training loss: 0.5063\n",
      "Epoch: 45/500... Training loss: 0.4132\n",
      "Epoch: 45/500... Training loss: 0.5345\n",
      "Epoch: 45/500... Training loss: 0.2797\n",
      "Epoch: 45/500... Training loss: 0.4984\n",
      "Epoch: 45/500... Training loss: 0.5752\n",
      "Epoch: 45/500... Training loss: 0.4516\n",
      "Epoch: 45/500... Training loss: 0.3785\n",
      "Epoch: 45/500... Training loss: 0.3437\n",
      "Epoch: 45/500... Training loss: 0.5704\n",
      "Epoch: 45/500... Training loss: 0.5567\n",
      "Epoch: 45/500... Training loss: 0.4854\n",
      "Epoch: 45/500... Training loss: 0.3743\n",
      "Epoch: 45/500... Training loss: 0.4400\n",
      "Epoch: 45/500... Training loss: 0.4341\n",
      "Epoch: 45/500... Training loss: 0.4210\n",
      "Epoch: 45/500... Training loss: 0.3813\n",
      "Epoch: 45/500... Training loss: 0.4674\n",
      "Epoch: 45/500... Training loss: 0.4881\n",
      "Epoch: 46/500... Training loss: 0.5236\n",
      "Epoch: 46/500... Training loss: 0.4023\n",
      "Epoch: 46/500... Training loss: 0.5711\n",
      "Epoch: 46/500... Training loss: 0.6267\n",
      "Epoch: 46/500... Training loss: 0.3193\n",
      "Epoch: 46/500... Training loss: 0.5679\n",
      "Epoch: 46/500... Training loss: 0.5237\n",
      "Epoch: 46/500... Training loss: 0.6225\n",
      "Epoch: 46/500... Training loss: 0.4401\n",
      "Epoch: 46/500... Training loss: 0.5201\n",
      "Epoch: 46/500... Training loss: 0.7882\n",
      "Epoch: 46/500... Training loss: 0.5465\n",
      "Epoch: 46/500... Training loss: 0.4464\n",
      "Epoch: 46/500... Training loss: 0.4878\n",
      "Epoch: 46/500... Training loss: 0.4514\n",
      "Epoch: 46/500... Training loss: 0.3405\n",
      "Epoch: 46/500... Training loss: 0.3458\n",
      "Epoch: 46/500... Training loss: 0.5406\n",
      "Epoch: 46/500... Training loss: 0.8392\n",
      "Epoch: 46/500... Training loss: 0.4445\n",
      "Epoch: 46/500... Training loss: 0.3744\n",
      "Epoch: 46/500... Training loss: 0.5276\n",
      "Epoch: 46/500... Training loss: 0.3795\n",
      "Epoch: 46/500... Training loss: 0.4554\n",
      "Epoch: 46/500... Training loss: 0.4562\n",
      "Epoch: 46/500... Training loss: 0.5605\n",
      "Epoch: 46/500... Training loss: 0.4847\n",
      "Epoch: 46/500... Training loss: 0.4555\n",
      "Epoch: 46/500... Training loss: 0.5058\n",
      "Epoch: 46/500... Training loss: 0.5420\n",
      "Epoch: 46/500... Training loss: 0.4969\n",
      "Epoch: 47/500... Training loss: 0.5513\n",
      "Epoch: 47/500... Training loss: 0.6128\n",
      "Epoch: 47/500... Training loss: 0.7989\n",
      "Epoch: 47/500... Training loss: 0.8027\n",
      "Epoch: 47/500... Training loss: 0.6018\n",
      "Epoch: 47/500... Training loss: 0.4215\n",
      "Epoch: 47/500... Training loss: 0.5657\n",
      "Epoch: 47/500... Training loss: 0.4528\n",
      "Epoch: 47/500... Training loss: 0.6059\n",
      "Epoch: 47/500... Training loss: 0.5084\n",
      "Epoch: 47/500... Training loss: 0.8257\n",
      "Epoch: 47/500... Training loss: 0.6663\n",
      "Epoch: 47/500... Training loss: 0.5110\n",
      "Epoch: 47/500... Training loss: 0.5197\n",
      "Epoch: 47/500... Training loss: 0.6309\n",
      "Epoch: 47/500... Training loss: 0.2766\n",
      "Epoch: 47/500... Training loss: 0.5747\n",
      "Epoch: 47/500... Training loss: 0.5598\n",
      "Epoch: 47/500... Training loss: 0.4277\n",
      "Epoch: 47/500... Training loss: 0.3882\n",
      "Epoch: 47/500... Training loss: 0.5356\n",
      "Epoch: 47/500... Training loss: 0.4633\n",
      "Epoch: 47/500... Training loss: 0.5431\n",
      "Epoch: 47/500... Training loss: 0.4801\n",
      "Epoch: 47/500... Training loss: 0.6271\n",
      "Epoch: 47/500... Training loss: 0.4194\n",
      "Epoch: 47/500... Training loss: 0.4555\n",
      "Epoch: 47/500... Training loss: 0.4259\n",
      "Epoch: 47/500... Training loss: 0.3181\n",
      "Epoch: 47/500... Training loss: 0.4744\n",
      "Epoch: 47/500... Training loss: 0.3641\n",
      "Epoch: 48/500... Training loss: 0.6094\n",
      "Epoch: 48/500... Training loss: 0.5029\n",
      "Epoch: 48/500... Training loss: 0.4852\n",
      "Epoch: 48/500... Training loss: 0.6509\n",
      "Epoch: 48/500... Training loss: 0.4837\n",
      "Epoch: 48/500... Training loss: 0.5264\n",
      "Epoch: 48/500... Training loss: 0.4915\n",
      "Epoch: 48/500... Training loss: 0.6196\n",
      "Epoch: 48/500... Training loss: 0.5618\n",
      "Epoch: 48/500... Training loss: 0.6226\n",
      "Epoch: 48/500... Training loss: 0.6770\n",
      "Epoch: 48/500... Training loss: 0.5357\n",
      "Epoch: 48/500... Training loss: 0.5397\n",
      "Epoch: 48/500... Training loss: 0.4698\n",
      "Epoch: 48/500... Training loss: 0.3927\n",
      "Epoch: 48/500... Training loss: 0.3243\n",
      "Epoch: 48/500... Training loss: 0.3859\n",
      "Epoch: 48/500... Training loss: 0.5137\n",
      "Epoch: 48/500... Training loss: 0.4808\n",
      "Epoch: 48/500... Training loss: 0.4417\n",
      "Epoch: 48/500... Training loss: 0.3688\n",
      "Epoch: 48/500... Training loss: 0.5571\n",
      "Epoch: 48/500... Training loss: 0.4437\n",
      "Epoch: 48/500... Training loss: 0.4035\n",
      "Epoch: 48/500... Training loss: 0.4020\n",
      "Epoch: 48/500... Training loss: 0.6091\n",
      "Epoch: 48/500... Training loss: 0.3826\n",
      "Epoch: 48/500... Training loss: 0.3633\n",
      "Epoch: 48/500... Training loss: 0.4448\n",
      "Epoch: 48/500... Training loss: 0.3661\n",
      "Epoch: 48/500... Training loss: 0.4535\n",
      "Epoch: 49/500... Training loss: 0.5374\n",
      "Epoch: 49/500... Training loss: 0.6678\n",
      "Epoch: 49/500... Training loss: 0.3276\n",
      "Epoch: 49/500... Training loss: 0.4707\n",
      "Epoch: 49/500... Training loss: 0.2806\n",
      "Epoch: 49/500... Training loss: 0.6144\n",
      "Epoch: 49/500... Training loss: 0.6290\n",
      "Epoch: 49/500... Training loss: 0.4252\n",
      "Epoch: 49/500... Training loss: 0.4566\n",
      "Epoch: 49/500... Training loss: 0.3552\n",
      "Epoch: 49/500... Training loss: 0.7232\n",
      "Epoch: 49/500... Training loss: 0.8714\n",
      "Epoch: 49/500... Training loss: 0.5112\n",
      "Epoch: 49/500... Training loss: 0.4880\n",
      "Epoch: 49/500... Training loss: 0.3548\n",
      "Epoch: 49/500... Training loss: 0.2928\n",
      "Epoch: 49/500... Training loss: 0.4779\n",
      "Epoch: 49/500... Training loss: 0.4712\n",
      "Epoch: 49/500... Training loss: 0.5066\n",
      "Epoch: 49/500... Training loss: 0.3777\n",
      "Epoch: 49/500... Training loss: 0.3821\n",
      "Epoch: 49/500... Training loss: 0.4793\n",
      "Epoch: 49/500... Training loss: 0.5647\n",
      "Epoch: 49/500... Training loss: 0.3334\n",
      "Epoch: 49/500... Training loss: 0.3585\n",
      "Epoch: 49/500... Training loss: 0.2778\n",
      "Epoch: 49/500... Training loss: 0.5092\n",
      "Epoch: 49/500... Training loss: 0.4139\n",
      "Epoch: 49/500... Training loss: 0.5300\n",
      "Epoch: 49/500... Training loss: 0.5254\n",
      "Epoch: 49/500... Training loss: 0.3347\n",
      "Epoch: 50/500... Training loss: 0.5393\n",
      "Epoch: 50/500... Training loss: 0.4528\n",
      "Epoch: 50/500... Training loss: 0.5845\n",
      "Epoch: 50/500... Training loss: 0.6168\n",
      "Epoch: 50/500... Training loss: 0.5982\n",
      "Epoch: 50/500... Training loss: 0.6067\n",
      "Epoch: 50/500... Training loss: 0.4090\n",
      "Epoch: 50/500... Training loss: 0.5274\n",
      "Epoch: 50/500... Training loss: 0.3253\n",
      "Epoch: 50/500... Training loss: 0.4498\n",
      "Epoch: 50/500... Training loss: 0.4242\n",
      "Epoch: 50/500... Training loss: 0.6304\n",
      "Epoch: 50/500... Training loss: 0.5560\n",
      "Epoch: 50/500... Training loss: 0.3383\n",
      "Epoch: 50/500... Training loss: 0.6643\n",
      "Epoch: 50/500... Training loss: 0.3246\n",
      "Epoch: 50/500... Training loss: 0.3499\n",
      "Epoch: 50/500... Training loss: 0.4707\n",
      "Epoch: 50/500... Training loss: 0.4795\n",
      "Epoch: 50/500... Training loss: 0.4528\n",
      "Epoch: 50/500... Training loss: 0.4781\n",
      "Epoch: 50/500... Training loss: 0.7009\n",
      "Epoch: 50/500... Training loss: 0.3310\n",
      "Epoch: 50/500... Training loss: 0.4989\n",
      "Epoch: 50/500... Training loss: 0.5106\n",
      "Epoch: 50/500... Training loss: 0.3923\n",
      "Epoch: 50/500... Training loss: 0.4370\n",
      "Epoch: 50/500... Training loss: 0.3873\n",
      "Epoch: 50/500... Training loss: 0.3464\n",
      "Epoch: 50/500... Training loss: 0.4264\n",
      "Epoch: 50/500... Training loss: 0.3915\n",
      "Epoch: 51/500... Training loss: 0.5255\n",
      "Epoch: 51/500... Training loss: 0.5366\n",
      "Epoch: 51/500... Training loss: 0.5378\n",
      "Epoch: 51/500... Training loss: 0.5419\n",
      "Epoch: 51/500... Training loss: 0.4500\n",
      "Epoch: 51/500... Training loss: 0.5742\n",
      "Epoch: 51/500... Training loss: 0.4594\n",
      "Epoch: 51/500... Training loss: 0.6028\n",
      "Epoch: 51/500... Training loss: 0.4066\n",
      "Epoch: 51/500... Training loss: 0.6574\n",
      "Epoch: 51/500... Training loss: 0.6066\n",
      "Epoch: 51/500... Training loss: 0.5831\n",
      "Epoch: 51/500... Training loss: 0.6840\n",
      "Epoch: 51/500... Training loss: 0.4268\n",
      "Epoch: 51/500... Training loss: 0.2922\n",
      "Epoch: 51/500... Training loss: 0.4253\n",
      "Epoch: 51/500... Training loss: 0.4019\n",
      "Epoch: 51/500... Training loss: 0.5249\n",
      "Epoch: 51/500... Training loss: 0.5132\n",
      "Epoch: 51/500... Training loss: 0.2718\n",
      "Epoch: 51/500... Training loss: 0.6220\n",
      "Epoch: 51/500... Training loss: 0.4324\n",
      "Epoch: 51/500... Training loss: 0.5521\n",
      "Epoch: 51/500... Training loss: 0.2877\n",
      "Epoch: 51/500... Training loss: 0.3241\n",
      "Epoch: 51/500... Training loss: 0.3201\n",
      "Epoch: 51/500... Training loss: 0.4650\n",
      "Epoch: 51/500... Training loss: 0.5515\n",
      "Epoch: 51/500... Training loss: 0.3737\n",
      "Epoch: 51/500... Training loss: 0.4251\n",
      "Epoch: 51/500... Training loss: 0.2382\n",
      "Epoch: 52/500... Training loss: 0.4698\n",
      "Epoch: 52/500... Training loss: 0.4869\n",
      "Epoch: 52/500... Training loss: 0.4900\n",
      "Epoch: 52/500... Training loss: 0.5722\n",
      "Epoch: 52/500... Training loss: 0.4991\n",
      "Epoch: 52/500... Training loss: 0.4156\n",
      "Epoch: 52/500... Training loss: 0.4850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/500... Training loss: 0.4799\n",
      "Epoch: 52/500... Training loss: 0.4563\n",
      "Epoch: 52/500... Training loss: 0.3641\n",
      "Epoch: 52/500... Training loss: 0.5644\n",
      "Epoch: 52/500... Training loss: 0.8821\n",
      "Epoch: 52/500... Training loss: 0.4243\n",
      "Epoch: 52/500... Training loss: 0.2433\n",
      "Epoch: 52/500... Training loss: 0.4474\n",
      "Epoch: 52/500... Training loss: 0.3090\n",
      "Epoch: 52/500... Training loss: 0.3323\n",
      "Epoch: 52/500... Training loss: 0.4970\n",
      "Epoch: 52/500... Training loss: 0.4993\n",
      "Epoch: 52/500... Training loss: 0.2937\n",
      "Epoch: 52/500... Training loss: 0.3803\n",
      "Epoch: 52/500... Training loss: 0.4802\n",
      "Epoch: 52/500... Training loss: 0.3047\n",
      "Epoch: 52/500... Training loss: 0.3698\n",
      "Epoch: 52/500... Training loss: 0.5005\n",
      "Epoch: 52/500... Training loss: 0.3874\n",
      "Epoch: 52/500... Training loss: 0.4495\n",
      "Epoch: 52/500... Training loss: 0.3437\n",
      "Epoch: 52/500... Training loss: 0.3569\n",
      "Epoch: 52/500... Training loss: 0.3640\n",
      "Epoch: 52/500... Training loss: 0.3165\n",
      "Epoch: 53/500... Training loss: 0.4372\n",
      "Epoch: 53/500... Training loss: 0.5319\n",
      "Epoch: 53/500... Training loss: 0.4235\n",
      "Epoch: 53/500... Training loss: 0.4702\n",
      "Epoch: 53/500... Training loss: 0.4202\n",
      "Epoch: 53/500... Training loss: 0.5139\n",
      "Epoch: 53/500... Training loss: 0.3600\n",
      "Epoch: 53/500... Training loss: 0.3450\n",
      "Epoch: 53/500... Training loss: 0.4412\n",
      "Epoch: 53/500... Training loss: 0.5016\n",
      "Epoch: 53/500... Training loss: 0.5450\n",
      "Epoch: 53/500... Training loss: 0.7446\n",
      "Epoch: 53/500... Training loss: 0.6340\n",
      "Epoch: 53/500... Training loss: 0.3309\n",
      "Epoch: 53/500... Training loss: 0.4428\n",
      "Epoch: 53/500... Training loss: 0.2531\n",
      "Epoch: 53/500... Training loss: 0.4395\n",
      "Epoch: 53/500... Training loss: 0.2746\n",
      "Epoch: 53/500... Training loss: 0.3226\n",
      "Epoch: 53/500... Training loss: 0.2859\n",
      "Epoch: 53/500... Training loss: 0.4029\n",
      "Epoch: 53/500... Training loss: 0.4749\n",
      "Epoch: 53/500... Training loss: 0.3855\n",
      "Epoch: 53/500... Training loss: 0.3880\n",
      "Epoch: 53/500... Training loss: 0.3809\n",
      "Epoch: 53/500... Training loss: 0.4118\n",
      "Epoch: 53/500... Training loss: 0.6296\n",
      "Epoch: 53/500... Training loss: 0.3417\n",
      "Epoch: 53/500... Training loss: 0.3247\n",
      "Epoch: 53/500... Training loss: 0.4591\n",
      "Epoch: 53/500... Training loss: 0.2903\n",
      "Epoch: 54/500... Training loss: 0.4155\n",
      "Epoch: 54/500... Training loss: 0.3094\n",
      "Epoch: 54/500... Training loss: 0.4284\n",
      "Epoch: 54/500... Training loss: 0.6328\n",
      "Epoch: 54/500... Training loss: 0.4717\n",
      "Epoch: 54/500... Training loss: 0.4246\n",
      "Epoch: 54/500... Training loss: 0.4112\n",
      "Epoch: 54/500... Training loss: 0.3309\n",
      "Epoch: 54/500... Training loss: 0.3546\n",
      "Epoch: 54/500... Training loss: 0.4096\n",
      "Epoch: 54/500... Training loss: 0.5436\n",
      "Epoch: 54/500... Training loss: 0.6979\n",
      "Epoch: 54/500... Training loss: 0.5504\n",
      "Epoch: 54/500... Training loss: 0.2295\n",
      "Epoch: 54/500... Training loss: 0.4578\n",
      "Epoch: 54/500... Training loss: 0.4093\n",
      "Epoch: 54/500... Training loss: 0.5068\n",
      "Epoch: 54/500... Training loss: 0.2933\n",
      "Epoch: 54/500... Training loss: 0.3354\n",
      "Epoch: 54/500... Training loss: 0.3066\n",
      "Epoch: 54/500... Training loss: 0.4419\n",
      "Epoch: 54/500... Training loss: 0.3516\n",
      "Epoch: 54/500... Training loss: 0.3727\n",
      "Epoch: 54/500... Training loss: 0.3198\n",
      "Epoch: 54/500... Training loss: 0.3142\n",
      "Epoch: 54/500... Training loss: 0.5089\n",
      "Epoch: 54/500... Training loss: 0.3271\n",
      "Epoch: 54/500... Training loss: 0.3880\n",
      "Epoch: 54/500... Training loss: 0.4485\n",
      "Epoch: 54/500... Training loss: 0.4466\n",
      "Epoch: 54/500... Training loss: 0.3321\n",
      "Epoch: 55/500... Training loss: 0.4609\n",
      "Epoch: 55/500... Training loss: 0.5061\n",
      "Epoch: 55/500... Training loss: 0.3700\n",
      "Epoch: 55/500... Training loss: 0.5562\n",
      "Epoch: 55/500... Training loss: 0.4829\n",
      "Epoch: 55/500... Training loss: 0.4412\n",
      "Epoch: 55/500... Training loss: 0.3471\n",
      "Epoch: 55/500... Training loss: 0.4068\n",
      "Epoch: 55/500... Training loss: 0.3426\n",
      "Epoch: 55/500... Training loss: 0.4491\n",
      "Epoch: 55/500... Training loss: 0.4968\n",
      "Epoch: 55/500... Training loss: 0.5152\n",
      "Epoch: 55/500... Training loss: 0.6185\n",
      "Epoch: 55/500... Training loss: 0.4369\n",
      "Epoch: 55/500... Training loss: 0.3422\n",
      "Epoch: 55/500... Training loss: 0.2305\n",
      "Epoch: 55/500... Training loss: 0.3402\n",
      "Epoch: 55/500... Training loss: 0.3904\n",
      "Epoch: 55/500... Training loss: 0.3985\n",
      "Epoch: 55/500... Training loss: 0.3414\n",
      "Epoch: 55/500... Training loss: 0.3800\n",
      "Epoch: 55/500... Training loss: 0.4051\n",
      "Epoch: 55/500... Training loss: 0.3829\n",
      "Epoch: 55/500... Training loss: 0.2665\n",
      "Epoch: 55/500... Training loss: 0.3980\n",
      "Epoch: 55/500... Training loss: 0.3314\n",
      "Epoch: 55/500... Training loss: 0.3378\n",
      "Epoch: 55/500... Training loss: 0.3911\n",
      "Epoch: 55/500... Training loss: 0.2611\n",
      "Epoch: 55/500... Training loss: 0.3347\n",
      "Epoch: 55/500... Training loss: 0.4010\n",
      "Epoch: 56/500... Training loss: 0.5148\n",
      "Epoch: 56/500... Training loss: 0.5694\n",
      "Epoch: 56/500... Training loss: 0.4088\n",
      "Epoch: 56/500... Training loss: 0.5685\n",
      "Epoch: 56/500... Training loss: 0.2563\n",
      "Epoch: 56/500... Training loss: 0.5339\n",
      "Epoch: 56/500... Training loss: 0.4167\n",
      "Epoch: 56/500... Training loss: 0.4118\n",
      "Epoch: 56/500... Training loss: 0.3611\n",
      "Epoch: 56/500... Training loss: 0.5179\n",
      "Epoch: 56/500... Training loss: 0.6901\n",
      "Epoch: 56/500... Training loss: 0.5905\n",
      "Epoch: 56/500... Training loss: 0.5767\n",
      "Epoch: 56/500... Training loss: 0.2658\n",
      "Epoch: 56/500... Training loss: 0.5171\n",
      "Epoch: 56/500... Training loss: 0.3334\n",
      "Epoch: 56/500... Training loss: 0.3440\n",
      "Epoch: 56/500... Training loss: 0.4061\n",
      "Epoch: 56/500... Training loss: 0.3636\n",
      "Epoch: 56/500... Training loss: 0.2740\n",
      "Epoch: 56/500... Training loss: 0.2321\n",
      "Epoch: 56/500... Training loss: 0.3966\n",
      "Epoch: 56/500... Training loss: 0.3857\n",
      "Epoch: 56/500... Training loss: 0.3836\n",
      "Epoch: 56/500... Training loss: 0.3237\n",
      "Epoch: 56/500... Training loss: 0.3468\n",
      "Epoch: 56/500... Training loss: 0.4760\n",
      "Epoch: 56/500... Training loss: 0.3419\n",
      "Epoch: 56/500... Training loss: 0.2584\n",
      "Epoch: 56/500... Training loss: 0.3299\n",
      "Epoch: 56/500... Training loss: 0.2594\n",
      "Epoch: 57/500... Training loss: 0.4604\n",
      "Epoch: 57/500... Training loss: 0.4918\n",
      "Epoch: 57/500... Training loss: 0.4099\n",
      "Epoch: 57/500... Training loss: 0.4435\n",
      "Epoch: 57/500... Training loss: 0.4728\n",
      "Epoch: 57/500... Training loss: 0.4228\n",
      "Epoch: 57/500... Training loss: 0.3831\n",
      "Epoch: 57/500... Training loss: 0.2970\n",
      "Epoch: 57/500... Training loss: 0.4632\n",
      "Epoch: 57/500... Training loss: 0.4888\n",
      "Epoch: 57/500... Training loss: 0.4847\n",
      "Epoch: 57/500... Training loss: 0.5375\n",
      "Epoch: 57/500... Training loss: 0.3942\n",
      "Epoch: 57/500... Training loss: 0.2630\n",
      "Epoch: 57/500... Training loss: 0.2372\n",
      "Epoch: 57/500... Training loss: 0.2115\n",
      "Epoch: 57/500... Training loss: 0.3660\n",
      "Epoch: 57/500... Training loss: 0.3227\n",
      "Epoch: 57/500... Training loss: 0.3850\n",
      "Epoch: 57/500... Training loss: 0.3222\n",
      "Epoch: 57/500... Training loss: 0.4127\n",
      "Epoch: 57/500... Training loss: 0.4360\n",
      "Epoch: 57/500... Training loss: 0.4903\n",
      "Epoch: 57/500... Training loss: 0.3306\n",
      "Epoch: 57/500... Training loss: 0.2851\n",
      "Epoch: 57/500... Training loss: 0.3776\n",
      "Epoch: 57/500... Training loss: 0.4521\n",
      "Epoch: 57/500... Training loss: 0.3200\n",
      "Epoch: 57/500... Training loss: 0.3633\n",
      "Epoch: 57/500... Training loss: 0.3227\n",
      "Epoch: 57/500... Training loss: 0.2440\n",
      "Epoch: 58/500... Training loss: 0.6123\n",
      "Epoch: 58/500... Training loss: 0.2532\n",
      "Epoch: 58/500... Training loss: 0.5641\n",
      "Epoch: 58/500... Training loss: 0.6150\n",
      "Epoch: 58/500... Training loss: 0.3570\n",
      "Epoch: 58/500... Training loss: 0.4179\n",
      "Epoch: 58/500... Training loss: 0.3952\n",
      "Epoch: 58/500... Training loss: 0.4534\n",
      "Epoch: 58/500... Training loss: 0.3654\n",
      "Epoch: 58/500... Training loss: 0.3840\n",
      "Epoch: 58/500... Training loss: 0.6735\n",
      "Epoch: 58/500... Training loss: 0.5355\n",
      "Epoch: 58/500... Training loss: 0.4645\n",
      "Epoch: 58/500... Training loss: 0.3764\n",
      "Epoch: 58/500... Training loss: 0.4417\n",
      "Epoch: 58/500... Training loss: 0.2832\n",
      "Epoch: 58/500... Training loss: 0.3012\n",
      "Epoch: 58/500... Training loss: 0.2216\n",
      "Epoch: 58/500... Training loss: 0.3038\n",
      "Epoch: 58/500... Training loss: 0.4951\n",
      "Epoch: 58/500... Training loss: 0.4038\n",
      "Epoch: 58/500... Training loss: 0.4274\n",
      "Epoch: 58/500... Training loss: 0.4188\n",
      "Epoch: 58/500... Training loss: 0.3034\n",
      "Epoch: 58/500... Training loss: 0.3086\n",
      "Epoch: 58/500... Training loss: 0.2678\n",
      "Epoch: 58/500... Training loss: 0.2945\n",
      "Epoch: 58/500... Training loss: 0.3320\n",
      "Epoch: 58/500... Training loss: 0.3259\n",
      "Epoch: 58/500... Training loss: 0.3417\n",
      "Epoch: 58/500... Training loss: 0.3505\n",
      "Epoch: 59/500... Training loss: 0.4865\n",
      "Epoch: 59/500... Training loss: 0.4266\n",
      "Epoch: 59/500... Training loss: 0.3497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/500... Training loss: 0.4043\n",
      "Epoch: 59/500... Training loss: 0.4451\n",
      "Epoch: 59/500... Training loss: 0.4856\n",
      "Epoch: 59/500... Training loss: 0.3130\n",
      "Epoch: 59/500... Training loss: 0.4411\n",
      "Epoch: 59/500... Training loss: 0.3305\n",
      "Epoch: 59/500... Training loss: 0.4940\n",
      "Epoch: 59/500... Training loss: 0.4381\n",
      "Epoch: 59/500... Training loss: 0.6247\n",
      "Epoch: 59/500... Training loss: 0.4115\n",
      "Epoch: 59/500... Training loss: 0.3485\n",
      "Epoch: 59/500... Training loss: 0.3090\n",
      "Epoch: 59/500... Training loss: 0.2392\n",
      "Epoch: 59/500... Training loss: 0.4262\n",
      "Epoch: 59/500... Training loss: 0.3512\n",
      "Epoch: 59/500... Training loss: 0.5846\n",
      "Epoch: 59/500... Training loss: 0.5493\n",
      "Epoch: 59/500... Training loss: 0.3270\n",
      "Epoch: 59/500... Training loss: 0.3513\n",
      "Epoch: 59/500... Training loss: 0.3885\n",
      "Epoch: 59/500... Training loss: 0.2595\n",
      "Epoch: 59/500... Training loss: 0.3808\n",
      "Epoch: 59/500... Training loss: 0.2608\n",
      "Epoch: 59/500... Training loss: 0.3683\n",
      "Epoch: 59/500... Training loss: 0.2666\n",
      "Epoch: 59/500... Training loss: 0.3041\n",
      "Epoch: 59/500... Training loss: 0.4141\n",
      "Epoch: 59/500... Training loss: 0.3319\n",
      "Epoch: 60/500... Training loss: 0.3524\n",
      "Epoch: 60/500... Training loss: 0.4552\n",
      "Epoch: 60/500... Training loss: 0.3894\n",
      "Epoch: 60/500... Training loss: 0.4044\n",
      "Epoch: 60/500... Training loss: 0.3882\n",
      "Epoch: 60/500... Training loss: 0.5805\n",
      "Epoch: 60/500... Training loss: 0.4115\n",
      "Epoch: 60/500... Training loss: 0.3676\n",
      "Epoch: 60/500... Training loss: 0.3613\n",
      "Epoch: 60/500... Training loss: 0.3965\n",
      "Epoch: 60/500... Training loss: 0.5711\n",
      "Epoch: 60/500... Training loss: 0.4680\n",
      "Epoch: 60/500... Training loss: 0.5082\n",
      "Epoch: 60/500... Training loss: 0.2743\n",
      "Epoch: 60/500... Training loss: 0.3046\n",
      "Epoch: 60/500... Training loss: 0.3883\n",
      "Epoch: 60/500... Training loss: 0.2840\n",
      "Epoch: 60/500... Training loss: 0.4505\n",
      "Epoch: 60/500... Training loss: 0.3603\n",
      "Epoch: 60/500... Training loss: 0.2344\n",
      "Epoch: 60/500... Training loss: 0.4478\n",
      "Epoch: 60/500... Training loss: 0.4209\n",
      "Epoch: 60/500... Training loss: 0.2821\n",
      "Epoch: 60/500... Training loss: 0.3037\n",
      "Epoch: 60/500... Training loss: 0.3728\n",
      "Epoch: 60/500... Training loss: 0.3628\n",
      "Epoch: 60/500... Training loss: 0.3074\n",
      "Epoch: 60/500... Training loss: 0.3465\n",
      "Epoch: 60/500... Training loss: 0.3586\n",
      "Epoch: 60/500... Training loss: 0.3038\n",
      "Epoch: 60/500... Training loss: 0.3685\n",
      "Epoch: 61/500... Training loss: 0.4986\n",
      "Epoch: 61/500... Training loss: 0.2554\n",
      "Epoch: 61/500... Training loss: 0.3915\n",
      "Epoch: 61/500... Training loss: 0.3972\n",
      "Epoch: 61/500... Training loss: 0.2618\n",
      "Epoch: 61/500... Training loss: 0.3856\n",
      "Epoch: 61/500... Training loss: 0.3583\n",
      "Epoch: 61/500... Training loss: 0.4147\n",
      "Epoch: 61/500... Training loss: 0.3745\n",
      "Epoch: 61/500... Training loss: 0.4078\n",
      "Epoch: 61/500... Training loss: 0.5032\n",
      "Epoch: 61/500... Training loss: 0.4694\n",
      "Epoch: 61/500... Training loss: 0.3575\n",
      "Epoch: 61/500... Training loss: 0.3136\n",
      "Epoch: 61/500... Training loss: 0.3632\n",
      "Epoch: 61/500... Training loss: 0.1745\n",
      "Epoch: 61/500... Training loss: 0.2131\n",
      "Epoch: 61/500... Training loss: 0.2724\n",
      "Epoch: 61/500... Training loss: 0.4914\n",
      "Epoch: 61/500... Training loss: 0.2636\n",
      "Epoch: 61/500... Training loss: 0.3295\n",
      "Epoch: 61/500... Training loss: 0.3112\n",
      "Epoch: 61/500... Training loss: 0.4886\n",
      "Epoch: 61/500... Training loss: 0.3178\n",
      "Epoch: 61/500... Training loss: 0.3480\n",
      "Epoch: 61/500... Training loss: 0.2781\n",
      "Epoch: 61/500... Training loss: 0.3379\n",
      "Epoch: 61/500... Training loss: 0.3355\n",
      "Epoch: 61/500... Training loss: 0.2196\n",
      "Epoch: 61/500... Training loss: 0.4100\n",
      "Epoch: 61/500... Training loss: 0.2956\n",
      "Epoch: 62/500... Training loss: 0.2725\n",
      "Epoch: 62/500... Training loss: 0.3158\n",
      "Epoch: 62/500... Training loss: 0.5679\n",
      "Epoch: 62/500... Training loss: 0.4712\n",
      "Epoch: 62/500... Training loss: 0.3355\n",
      "Epoch: 62/500... Training loss: 0.3626\n",
      "Epoch: 62/500... Training loss: 0.3353\n",
      "Epoch: 62/500... Training loss: 0.3788\n",
      "Epoch: 62/500... Training loss: 0.3443\n",
      "Epoch: 62/500... Training loss: 0.3643\n",
      "Epoch: 62/500... Training loss: 0.4039\n",
      "Epoch: 62/500... Training loss: 0.5397\n",
      "Epoch: 62/500... Training loss: 0.3733\n",
      "Epoch: 62/500... Training loss: 0.2204\n",
      "Epoch: 62/500... Training loss: 0.3333\n",
      "Epoch: 62/500... Training loss: 0.2653\n",
      "Epoch: 62/500... Training loss: 0.2492\n",
      "Epoch: 62/500... Training loss: 0.3836\n",
      "Epoch: 62/500... Training loss: 0.3873\n",
      "Epoch: 62/500... Training loss: 0.3292\n",
      "Epoch: 62/500... Training loss: 0.2637\n",
      "Epoch: 62/500... Training loss: 0.4042\n",
      "Epoch: 62/500... Training loss: 0.2738\n",
      "Epoch: 62/500... Training loss: 0.3388\n",
      "Epoch: 62/500... Training loss: 0.4255\n",
      "Epoch: 62/500... Training loss: 0.4853\n",
      "Epoch: 62/500... Training loss: 0.2654\n",
      "Epoch: 62/500... Training loss: 0.3068\n",
      "Epoch: 62/500... Training loss: 0.2231\n",
      "Epoch: 62/500... Training loss: 0.3432\n",
      "Epoch: 62/500... Training loss: 0.4005\n",
      "Epoch: 63/500... Training loss: 0.3512\n",
      "Epoch: 63/500... Training loss: 0.3705\n",
      "Epoch: 63/500... Training loss: 0.2789\n",
      "Epoch: 63/500... Training loss: 0.4266\n",
      "Epoch: 63/500... Training loss: 0.3108\n",
      "Epoch: 63/500... Training loss: 0.3873\n",
      "Epoch: 63/500... Training loss: 0.4474\n",
      "Epoch: 63/500... Training loss: 0.4013\n",
      "Epoch: 63/500... Training loss: 0.3382\n",
      "Epoch: 63/500... Training loss: 0.3620\n",
      "Epoch: 63/500... Training loss: 0.4101\n",
      "Epoch: 63/500... Training loss: 0.4375\n",
      "Epoch: 63/500... Training loss: 0.4241\n",
      "Epoch: 63/500... Training loss: 0.2839\n",
      "Epoch: 63/500... Training loss: 0.1950\n",
      "Epoch: 63/500... Training loss: 0.2449\n",
      "Epoch: 63/500... Training loss: 0.5097\n",
      "Epoch: 63/500... Training loss: 0.3353\n",
      "Epoch: 63/500... Training loss: 0.4890\n",
      "Epoch: 63/500... Training loss: 0.2840\n",
      "Epoch: 63/500... Training loss: 0.2401\n",
      "Epoch: 63/500... Training loss: 0.4032\n",
      "Epoch: 63/500... Training loss: 0.4140\n",
      "Epoch: 63/500... Training loss: 0.2589\n",
      "Epoch: 63/500... Training loss: 0.3133\n",
      "Epoch: 63/500... Training loss: 0.2099\n",
      "Epoch: 63/500... Training loss: 0.3599\n",
      "Epoch: 63/500... Training loss: 0.2325\n",
      "Epoch: 63/500... Training loss: 0.2268\n",
      "Epoch: 63/500... Training loss: 0.3538\n",
      "Epoch: 63/500... Training loss: 0.2966\n",
      "Epoch: 64/500... Training loss: 0.1830\n",
      "Epoch: 64/500... Training loss: 0.3980\n",
      "Epoch: 64/500... Training loss: 0.3621\n",
      "Epoch: 64/500... Training loss: 0.4142\n",
      "Epoch: 64/500... Training loss: 0.3619\n",
      "Epoch: 64/500... Training loss: 0.2672\n",
      "Epoch: 64/500... Training loss: 0.3666\n",
      "Epoch: 64/500... Training loss: 0.4165\n",
      "Epoch: 64/500... Training loss: 0.3480\n",
      "Epoch: 64/500... Training loss: 0.3332\n",
      "Epoch: 64/500... Training loss: 0.2783\n",
      "Epoch: 64/500... Training loss: 0.4171\n",
      "Epoch: 64/500... Training loss: 0.4954\n",
      "Epoch: 64/500... Training loss: 0.2807\n",
      "Epoch: 64/500... Training loss: 0.3131\n",
      "Epoch: 64/500... Training loss: 0.3534\n",
      "Epoch: 64/500... Training loss: 0.3123\n",
      "Epoch: 64/500... Training loss: 0.3487\n",
      "Epoch: 64/500... Training loss: 0.3881\n",
      "Epoch: 64/500... Training loss: 0.2633\n",
      "Epoch: 64/500... Training loss: 0.2136\n",
      "Epoch: 64/500... Training loss: 0.2808\n",
      "Epoch: 64/500... Training loss: 0.3151\n",
      "Epoch: 64/500... Training loss: 0.3290\n",
      "Epoch: 64/500... Training loss: 0.3484\n",
      "Epoch: 64/500... Training loss: 0.4335\n",
      "Epoch: 64/500... Training loss: 0.3389\n",
      "Epoch: 64/500... Training loss: 0.1834\n",
      "Epoch: 64/500... Training loss: 0.3268\n",
      "Epoch: 64/500... Training loss: 0.2743\n",
      "Epoch: 64/500... Training loss: 0.2636\n",
      "Epoch: 65/500... Training loss: 0.2315\n",
      "Epoch: 65/500... Training loss: 0.3816\n",
      "Epoch: 65/500... Training loss: 0.3442\n",
      "Epoch: 65/500... Training loss: 0.4003\n",
      "Epoch: 65/500... Training loss: 0.2281\n",
      "Epoch: 65/500... Training loss: 0.4442\n",
      "Epoch: 65/500... Training loss: 0.2936\n",
      "Epoch: 65/500... Training loss: 0.3335\n",
      "Epoch: 65/500... Training loss: 0.3360\n",
      "Epoch: 65/500... Training loss: 0.2688\n",
      "Epoch: 65/500... Training loss: 0.4676\n",
      "Epoch: 65/500... Training loss: 0.3283\n",
      "Epoch: 65/500... Training loss: 0.3755\n",
      "Epoch: 65/500... Training loss: 0.3201\n",
      "Epoch: 65/500... Training loss: 0.3679\n",
      "Epoch: 65/500... Training loss: 0.2024\n",
      "Epoch: 65/500... Training loss: 0.2423\n",
      "Epoch: 65/500... Training loss: 0.5439\n",
      "Epoch: 65/500... Training loss: 0.2725\n",
      "Epoch: 65/500... Training loss: 0.3435\n",
      "Epoch: 65/500... Training loss: 0.1688\n",
      "Epoch: 65/500... Training loss: 0.3027\n",
      "Epoch: 65/500... Training loss: 0.3731\n",
      "Epoch: 65/500... Training loss: 0.2160\n",
      "Epoch: 65/500... Training loss: 0.2631\n",
      "Epoch: 65/500... Training loss: 0.2282\n",
      "Epoch: 65/500... Training loss: 0.2223\n",
      "Epoch: 65/500... Training loss: 0.2311\n",
      "Epoch: 65/500... Training loss: 0.1716\n",
      "Epoch: 65/500... Training loss: 0.3883\n",
      "Epoch: 65/500... Training loss: 0.3805\n",
      "Epoch: 66/500... Training loss: 0.3982\n",
      "Epoch: 66/500... Training loss: 0.4544\n",
      "Epoch: 66/500... Training loss: 0.2363\n",
      "Epoch: 66/500... Training loss: 0.4252\n",
      "Epoch: 66/500... Training loss: 0.3489\n",
      "Epoch: 66/500... Training loss: 0.2672\n",
      "Epoch: 66/500... Training loss: 0.3562\n",
      "Epoch: 66/500... Training loss: 0.3970\n",
      "Epoch: 66/500... Training loss: 0.3063\n",
      "Epoch: 66/500... Training loss: 0.3278\n",
      "Epoch: 66/500... Training loss: 0.3639\n",
      "Epoch: 66/500... Training loss: 0.4925\n",
      "Epoch: 66/500... Training loss: 0.4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/500... Training loss: 0.2516\n",
      "Epoch: 66/500... Training loss: 0.3482\n",
      "Epoch: 66/500... Training loss: 0.2305\n",
      "Epoch: 66/500... Training loss: 0.2720\n",
      "Epoch: 66/500... Training loss: 0.2810\n",
      "Epoch: 66/500... Training loss: 0.3494\n",
      "Epoch: 66/500... Training loss: 0.2339\n",
      "Epoch: 66/500... Training loss: 0.1650\n",
      "Epoch: 66/500... Training loss: 0.3411\n",
      "Epoch: 66/500... Training loss: 0.3061\n",
      "Epoch: 66/500... Training loss: 0.2668\n",
      "Epoch: 66/500... Training loss: 0.2776\n",
      "Epoch: 66/500... Training loss: 0.2115\n",
      "Epoch: 66/500... Training loss: 0.4220\n",
      "Epoch: 66/500... Training loss: 0.2588\n",
      "Epoch: 66/500... Training loss: 0.2824\n",
      "Epoch: 66/500... Training loss: 0.4254\n",
      "Epoch: 66/500... Training loss: 0.3035\n",
      "Epoch: 67/500... Training loss: 0.3322\n",
      "Epoch: 67/500... Training loss: 0.2514\n",
      "Epoch: 67/500... Training loss: 0.3818\n",
      "Epoch: 67/500... Training loss: 0.3084\n",
      "Epoch: 67/500... Training loss: 0.3204\n",
      "Epoch: 67/500... Training loss: 0.4821\n",
      "Epoch: 67/500... Training loss: 0.3194\n",
      "Epoch: 67/500... Training loss: 0.2553\n",
      "Epoch: 67/500... Training loss: 0.4790\n",
      "Epoch: 67/500... Training loss: 0.3351\n",
      "Epoch: 67/500... Training loss: 0.4770\n",
      "Epoch: 67/500... Training loss: 0.3684\n",
      "Epoch: 67/500... Training loss: 0.2675\n",
      "Epoch: 67/500... Training loss: 0.3137\n",
      "Epoch: 67/500... Training loss: 0.1910\n",
      "Epoch: 67/500... Training loss: 0.3052\n",
      "Epoch: 67/500... Training loss: 0.3890\n",
      "Epoch: 67/500... Training loss: 0.2812\n",
      "Epoch: 67/500... Training loss: 0.3173\n",
      "Epoch: 67/500... Training loss: 0.2794\n",
      "Epoch: 67/500... Training loss: 0.2810\n",
      "Epoch: 67/500... Training loss: 0.3241\n",
      "Epoch: 67/500... Training loss: 0.5464\n",
      "Epoch: 67/500... Training loss: 0.3213\n",
      "Epoch: 67/500... Training loss: 0.4288\n",
      "Epoch: 67/500... Training loss: 0.3179\n",
      "Epoch: 67/500... Training loss: 0.2289\n",
      "Epoch: 67/500... Training loss: 0.1563\n",
      "Epoch: 67/500... Training loss: 0.2823\n",
      "Epoch: 67/500... Training loss: 0.2491\n",
      "Epoch: 67/500... Training loss: 0.3307\n",
      "Epoch: 68/500... Training loss: 0.2431\n",
      "Epoch: 68/500... Training loss: 0.3201\n",
      "Epoch: 68/500... Training loss: 0.3245\n",
      "Epoch: 68/500... Training loss: 0.4085\n",
      "Epoch: 68/500... Training loss: 0.3052\n",
      "Epoch: 68/500... Training loss: 0.2322\n",
      "Epoch: 68/500... Training loss: 0.2750\n",
      "Epoch: 68/500... Training loss: 0.2880\n",
      "Epoch: 68/500... Training loss: 0.3972\n",
      "Epoch: 68/500... Training loss: 0.3372\n",
      "Epoch: 68/500... Training loss: 0.3787\n",
      "Epoch: 68/500... Training loss: 0.3810\n",
      "Epoch: 68/500... Training loss: 0.4036\n",
      "Epoch: 68/500... Training loss: 0.3111\n",
      "Epoch: 68/500... Training loss: 0.3672\n",
      "Epoch: 68/500... Training loss: 0.3797\n",
      "Epoch: 68/500... Training loss: 0.2626\n",
      "Epoch: 68/500... Training loss: 0.3305\n",
      "Epoch: 68/500... Training loss: 0.2804\n",
      "Epoch: 68/500... Training loss: 0.2334\n",
      "Epoch: 68/500... Training loss: 0.2707\n",
      "Epoch: 68/500... Training loss: 0.3898\n",
      "Epoch: 68/500... Training loss: 0.3638\n",
      "Epoch: 68/500... Training loss: 0.2117\n",
      "Epoch: 68/500... Training loss: 0.3872\n",
      "Epoch: 68/500... Training loss: 0.2877\n",
      "Epoch: 68/500... Training loss: 0.2148\n",
      "Epoch: 68/500... Training loss: 0.2517\n",
      "Epoch: 68/500... Training loss: 0.1600\n",
      "Epoch: 68/500... Training loss: 0.3311\n",
      "Epoch: 68/500... Training loss: 0.1607\n",
      "Epoch: 69/500... Training loss: 0.3408\n",
      "Epoch: 69/500... Training loss: 0.4000\n",
      "Epoch: 69/500... Training loss: 0.3206\n",
      "Epoch: 69/500... Training loss: 0.4095\n",
      "Epoch: 69/500... Training loss: 0.3612\n",
      "Epoch: 69/500... Training loss: 0.4422\n",
      "Epoch: 69/500... Training loss: 0.3380\n",
      "Epoch: 69/500... Training loss: 0.4735\n",
      "Epoch: 69/500... Training loss: 0.2663\n",
      "Epoch: 69/500... Training loss: 0.3239\n",
      "Epoch: 69/500... Training loss: 0.3941\n",
      "Epoch: 69/500... Training loss: 0.4296\n",
      "Epoch: 69/500... Training loss: 0.2846\n",
      "Epoch: 69/500... Training loss: 0.2762\n",
      "Epoch: 69/500... Training loss: 0.3134\n",
      "Epoch: 69/500... Training loss: 0.1883\n",
      "Epoch: 69/500... Training loss: 0.2359\n",
      "Epoch: 69/500... Training loss: 0.2500\n",
      "Epoch: 69/500... Training loss: 0.2808\n",
      "Epoch: 69/500... Training loss: 0.1880\n",
      "Epoch: 69/500... Training loss: 0.2820\n",
      "Epoch: 69/500... Training loss: 0.2961\n",
      "Epoch: 69/500... Training loss: 0.3809\n",
      "Epoch: 69/500... Training loss: 0.2542\n",
      "Epoch: 69/500... Training loss: 0.2123\n",
      "Epoch: 69/500... Training loss: 0.2374\n",
      "Epoch: 69/500... Training loss: 0.2807\n",
      "Epoch: 69/500... Training loss: 0.3560\n",
      "Epoch: 69/500... Training loss: 0.1998\n",
      "Epoch: 69/500... Training loss: 0.2616\n",
      "Epoch: 69/500... Training loss: 0.2252\n",
      "Epoch: 70/500... Training loss: 0.3536\n",
      "Epoch: 70/500... Training loss: 0.3375\n",
      "Epoch: 70/500... Training loss: 0.3116\n",
      "Epoch: 70/500... Training loss: 0.3659\n",
      "Epoch: 70/500... Training loss: 0.3195\n",
      "Epoch: 70/500... Training loss: 0.3514\n",
      "Epoch: 70/500... Training loss: 0.2744\n",
      "Epoch: 70/500... Training loss: 0.2196\n",
      "Epoch: 70/500... Training loss: 0.2002\n",
      "Epoch: 70/500... Training loss: 0.3305\n",
      "Epoch: 70/500... Training loss: 0.3255\n",
      "Epoch: 70/500... Training loss: 0.4946\n",
      "Epoch: 70/500... Training loss: 0.5009\n",
      "Epoch: 70/500... Training loss: 0.1890\n",
      "Epoch: 70/500... Training loss: 0.1974\n",
      "Epoch: 70/500... Training loss: 0.2155\n",
      "Epoch: 70/500... Training loss: 0.2452\n",
      "Epoch: 70/500... Training loss: 0.1478\n",
      "Epoch: 70/500... Training loss: 0.2560\n",
      "Epoch: 70/500... Training loss: 0.1080\n",
      "Epoch: 70/500... Training loss: 0.3492\n",
      "Epoch: 70/500... Training loss: 0.2657\n",
      "Epoch: 70/500... Training loss: 0.4825\n",
      "Epoch: 70/500... Training loss: 0.2528\n",
      "Epoch: 70/500... Training loss: 0.2783\n",
      "Epoch: 70/500... Training loss: 0.2433\n",
      "Epoch: 70/500... Training loss: 0.2350\n",
      "Epoch: 70/500... Training loss: 0.1978\n",
      "Epoch: 70/500... Training loss: 0.2471\n",
      "Epoch: 70/500... Training loss: 0.2988\n",
      "Epoch: 70/500... Training loss: 0.2613\n",
      "Epoch: 71/500... Training loss: 0.5055\n",
      "Epoch: 71/500... Training loss: 0.2535\n",
      "Epoch: 71/500... Training loss: 0.2782\n",
      "Epoch: 71/500... Training loss: 0.3316\n",
      "Epoch: 71/500... Training loss: 0.2902\n",
      "Epoch: 71/500... Training loss: 0.3018\n",
      "Epoch: 71/500... Training loss: 0.1878\n",
      "Epoch: 71/500... Training loss: 0.3417\n",
      "Epoch: 71/500... Training loss: 0.2161\n",
      "Epoch: 71/500... Training loss: 0.2576\n",
      "Epoch: 71/500... Training loss: 0.4804\n",
      "Epoch: 71/500... Training loss: 0.4481\n",
      "Epoch: 71/500... Training loss: 0.3051\n",
      "Epoch: 71/500... Training loss: 0.1738\n",
      "Epoch: 71/500... Training loss: 0.2467\n",
      "Epoch: 71/500... Training loss: 0.1427\n",
      "Epoch: 71/500... Training loss: 0.2355\n",
      "Epoch: 71/500... Training loss: 0.2981\n",
      "Epoch: 71/500... Training loss: 0.2164\n",
      "Epoch: 71/500... Training loss: 0.2973\n",
      "Epoch: 71/500... Training loss: 0.1995\n",
      "Epoch: 71/500... Training loss: 0.2672\n",
      "Epoch: 71/500... Training loss: 0.2421\n",
      "Epoch: 71/500... Training loss: 0.2605\n",
      "Epoch: 71/500... Training loss: 0.1855\n",
      "Epoch: 71/500... Training loss: 0.1616\n",
      "Epoch: 71/500... Training loss: 0.2807\n",
      "Epoch: 71/500... Training loss: 0.2771\n",
      "Epoch: 71/500... Training loss: 0.1793\n",
      "Epoch: 71/500... Training loss: 0.1814\n",
      "Epoch: 71/500... Training loss: 0.3434\n",
      "Epoch: 72/500... Training loss: 0.4350\n",
      "Epoch: 72/500... Training loss: 0.2905\n",
      "Epoch: 72/500... Training loss: 0.2259\n",
      "Epoch: 72/500... Training loss: 0.2802\n",
      "Epoch: 72/500... Training loss: 0.2037\n",
      "Epoch: 72/500... Training loss: 0.2494\n",
      "Epoch: 72/500... Training loss: 0.2122\n",
      "Epoch: 72/500... Training loss: 0.1943\n",
      "Epoch: 72/500... Training loss: 0.2540\n",
      "Epoch: 72/500... Training loss: 0.1550\n",
      "Epoch: 72/500... Training loss: 0.2883\n",
      "Epoch: 72/500... Training loss: 0.4020\n",
      "Epoch: 72/500... Training loss: 0.2916\n",
      "Epoch: 72/500... Training loss: 0.3521\n",
      "Epoch: 72/500... Training loss: 0.3488\n",
      "Epoch: 72/500... Training loss: 0.0862\n",
      "Epoch: 72/500... Training loss: 0.2390\n",
      "Epoch: 72/500... Training loss: 0.1785\n",
      "Epoch: 72/500... Training loss: 0.3481\n",
      "Epoch: 72/500... Training loss: 0.2101\n",
      "Epoch: 72/500... Training loss: 0.3116\n",
      "Epoch: 72/500... Training loss: 0.2491\n",
      "Epoch: 72/500... Training loss: 0.2779\n",
      "Epoch: 72/500... Training loss: 0.2684\n",
      "Epoch: 72/500... Training loss: 0.3855\n",
      "Epoch: 72/500... Training loss: 0.1667\n",
      "Epoch: 72/500... Training loss: 0.2382\n",
      "Epoch: 72/500... Training loss: 0.2732\n",
      "Epoch: 72/500... Training loss: 0.1662\n",
      "Epoch: 72/500... Training loss: 0.1764\n",
      "Epoch: 72/500... Training loss: 0.3904\n",
      "Epoch: 73/500... Training loss: 0.3600\n",
      "Epoch: 73/500... Training loss: 0.2364\n",
      "Epoch: 73/500... Training loss: 0.2106\n",
      "Epoch: 73/500... Training loss: 0.3103\n",
      "Epoch: 73/500... Training loss: 0.1537\n",
      "Epoch: 73/500... Training loss: 0.3282\n",
      "Epoch: 73/500... Training loss: 0.1876\n",
      "Epoch: 73/500... Training loss: 0.3442\n",
      "Epoch: 73/500... Training loss: 0.4220\n",
      "Epoch: 73/500... Training loss: 0.2100\n",
      "Epoch: 73/500... Training loss: 0.6337\n",
      "Epoch: 73/500... Training loss: 0.4118\n",
      "Epoch: 73/500... Training loss: 0.3555\n",
      "Epoch: 73/500... Training loss: 0.1953\n",
      "Epoch: 73/500... Training loss: 0.2225\n",
      "Epoch: 73/500... Training loss: 0.1943\n",
      "Epoch: 73/500... Training loss: 0.2325\n",
      "Epoch: 73/500... Training loss: 0.2037\n",
      "Epoch: 73/500... Training loss: 0.3156\n",
      "Epoch: 73/500... Training loss: 0.3337\n",
      "Epoch: 73/500... Training loss: 0.3232\n",
      "Epoch: 73/500... Training loss: 0.2060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/500... Training loss: 0.3839\n",
      "Epoch: 73/500... Training loss: 0.2943\n",
      "Epoch: 73/500... Training loss: 0.1642\n",
      "Epoch: 73/500... Training loss: 0.3295\n",
      "Epoch: 73/500... Training loss: 0.2190\n",
      "Epoch: 73/500... Training loss: 0.1705\n",
      "Epoch: 73/500... Training loss: 0.1913\n",
      "Epoch: 73/500... Training loss: 0.2311\n",
      "Epoch: 73/500... Training loss: 0.3244\n",
      "Epoch: 74/500... Training loss: 0.3929\n",
      "Epoch: 74/500... Training loss: 0.4275\n",
      "Epoch: 74/500... Training loss: 0.2263\n",
      "Epoch: 74/500... Training loss: 0.3374\n",
      "Epoch: 74/500... Training loss: 0.3762\n",
      "Epoch: 74/500... Training loss: 0.2717\n",
      "Epoch: 74/500... Training loss: 0.1940\n",
      "Epoch: 74/500... Training loss: 0.2501\n",
      "Epoch: 74/500... Training loss: 0.3131\n",
      "Epoch: 74/500... Training loss: 0.3906\n",
      "Epoch: 74/500... Training loss: 0.3840\n",
      "Epoch: 74/500... Training loss: 0.4675\n",
      "Epoch: 74/500... Training loss: 0.3401\n",
      "Epoch: 74/500... Training loss: 0.1912\n",
      "Epoch: 74/500... Training loss: 0.2810\n",
      "Epoch: 74/500... Training loss: 0.1548\n",
      "Epoch: 74/500... Training loss: 0.2676\n",
      "Epoch: 74/500... Training loss: 0.2348\n",
      "Epoch: 74/500... Training loss: 0.4060\n",
      "Epoch: 74/500... Training loss: 0.1789\n",
      "Epoch: 74/500... Training loss: 0.1692\n",
      "Epoch: 74/500... Training loss: 0.4603\n",
      "Epoch: 74/500... Training loss: 0.2661\n",
      "Epoch: 74/500... Training loss: 0.2336\n",
      "Epoch: 74/500... Training loss: 0.4236\n",
      "Epoch: 74/500... Training loss: 0.1683\n",
      "Epoch: 74/500... Training loss: 0.2949\n",
      "Epoch: 74/500... Training loss: 0.4339\n",
      "Epoch: 74/500... Training loss: 0.2884\n",
      "Epoch: 74/500... Training loss: 0.3034\n",
      "Epoch: 74/500... Training loss: 0.3432\n",
      "Epoch: 75/500... Training loss: 0.3026\n",
      "Epoch: 75/500... Training loss: 0.2239\n",
      "Epoch: 75/500... Training loss: 0.2801\n",
      "Epoch: 75/500... Training loss: 0.2911\n",
      "Epoch: 75/500... Training loss: 0.3242\n",
      "Epoch: 75/500... Training loss: 0.2863\n",
      "Epoch: 75/500... Training loss: 0.2705\n",
      "Epoch: 75/500... Training loss: 0.2966\n",
      "Epoch: 75/500... Training loss: 0.2477\n",
      "Epoch: 75/500... Training loss: 0.2479\n",
      "Epoch: 75/500... Training loss: 0.3876\n",
      "Epoch: 75/500... Training loss: 0.3508\n",
      "Epoch: 75/500... Training loss: 0.4908\n",
      "Epoch: 75/500... Training loss: 0.2039\n",
      "Epoch: 75/500... Training loss: 0.3072\n",
      "Epoch: 75/500... Training loss: 0.1625\n",
      "Epoch: 75/500... Training loss: 0.2080\n",
      "Epoch: 75/500... Training loss: 0.2340\n",
      "Epoch: 75/500... Training loss: 0.3818\n",
      "Epoch: 75/500... Training loss: 0.2027\n",
      "Epoch: 75/500... Training loss: 0.4115\n",
      "Epoch: 75/500... Training loss: 0.2061\n",
      "Epoch: 75/500... Training loss: 0.2808\n",
      "Epoch: 75/500... Training loss: 0.1989\n",
      "Epoch: 75/500... Training loss: 0.1406\n",
      "Epoch: 75/500... Training loss: 0.2274\n",
      "Epoch: 75/500... Training loss: 0.1704\n",
      "Epoch: 75/500... Training loss: 0.2077\n",
      "Epoch: 75/500... Training loss: 0.1692\n",
      "Epoch: 75/500... Training loss: 0.2201\n",
      "Epoch: 75/500... Training loss: 0.1533\n",
      "Epoch: 76/500... Training loss: 0.1923\n",
      "Epoch: 76/500... Training loss: 0.3476\n",
      "Epoch: 76/500... Training loss: 0.3461\n",
      "Epoch: 76/500... Training loss: 0.2499\n",
      "Epoch: 76/500... Training loss: 0.2783\n",
      "Epoch: 76/500... Training loss: 0.2682\n",
      "Epoch: 76/500... Training loss: 0.2705\n",
      "Epoch: 76/500... Training loss: 0.2560\n",
      "Epoch: 76/500... Training loss: 0.3475\n",
      "Epoch: 76/500... Training loss: 0.3633\n",
      "Epoch: 76/500... Training loss: 0.3082\n",
      "Epoch: 76/500... Training loss: 0.3350\n",
      "Epoch: 76/500... Training loss: 0.2997\n",
      "Epoch: 76/500... Training loss: 0.2483\n",
      "Epoch: 76/500... Training loss: 0.1681\n",
      "Epoch: 76/500... Training loss: 0.0919\n",
      "Epoch: 76/500... Training loss: 0.1583\n",
      "Epoch: 76/500... Training loss: 0.1996\n",
      "Epoch: 76/500... Training loss: 0.2053\n",
      "Epoch: 76/500... Training loss: 0.1149\n",
      "Epoch: 76/500... Training loss: 0.2004\n",
      "Epoch: 76/500... Training loss: 0.1976\n",
      "Epoch: 76/500... Training loss: 0.2945\n",
      "Epoch: 76/500... Training loss: 0.2259\n",
      "Epoch: 76/500... Training loss: 0.3654\n",
      "Epoch: 76/500... Training loss: 0.2288\n",
      "Epoch: 76/500... Training loss: 0.2134\n",
      "Epoch: 76/500... Training loss: 0.1481\n",
      "Epoch: 76/500... Training loss: 0.1786\n",
      "Epoch: 76/500... Training loss: 0.3611\n",
      "Epoch: 76/500... Training loss: 0.2479\n",
      "Epoch: 77/500... Training loss: 0.2188\n",
      "Epoch: 77/500... Training loss: 0.4016\n",
      "Epoch: 77/500... Training loss: 0.3414\n",
      "Epoch: 77/500... Training loss: 0.2890\n",
      "Epoch: 77/500... Training loss: 0.2982\n",
      "Epoch: 77/500... Training loss: 0.1800\n",
      "Epoch: 77/500... Training loss: 0.1864\n",
      "Epoch: 77/500... Training loss: 0.2438\n",
      "Epoch: 77/500... Training loss: 0.1948\n",
      "Epoch: 77/500... Training loss: 0.3356\n",
      "Epoch: 77/500... Training loss: 0.3132\n",
      "Epoch: 77/500... Training loss: 0.2453\n",
      "Epoch: 77/500... Training loss: 0.4365\n",
      "Epoch: 77/500... Training loss: 0.2442\n",
      "Epoch: 77/500... Training loss: 0.3530\n",
      "Epoch: 77/500... Training loss: 0.2100\n",
      "Epoch: 77/500... Training loss: 0.2032\n",
      "Epoch: 77/500... Training loss: 0.2780\n",
      "Epoch: 77/500... Training loss: 0.3810\n",
      "Epoch: 77/500... Training loss: 0.1848\n",
      "Epoch: 77/500... Training loss: 0.1345\n",
      "Epoch: 77/500... Training loss: 0.2236\n",
      "Epoch: 77/500... Training loss: 0.2945\n",
      "Epoch: 77/500... Training loss: 0.1599\n",
      "Epoch: 77/500... Training loss: 0.2291\n",
      "Epoch: 77/500... Training loss: 0.2230\n",
      "Epoch: 77/500... Training loss: 0.2100\n",
      "Epoch: 77/500... Training loss: 0.1922\n",
      "Epoch: 77/500... Training loss: 0.2945\n",
      "Epoch: 77/500... Training loss: 0.2681\n",
      "Epoch: 77/500... Training loss: 0.1938\n",
      "Epoch: 78/500... Training loss: 0.4510\n",
      "Epoch: 78/500... Training loss: 0.2759\n",
      "Epoch: 78/500... Training loss: 0.2715\n",
      "Epoch: 78/500... Training loss: 0.2922\n",
      "Epoch: 78/500... Training loss: 0.2694\n",
      "Epoch: 78/500... Training loss: 0.2420\n",
      "Epoch: 78/500... Training loss: 0.2882\n",
      "Epoch: 78/500... Training loss: 0.2602\n",
      "Epoch: 78/500... Training loss: 0.2040\n",
      "Epoch: 78/500... Training loss: 0.1730\n",
      "Epoch: 78/500... Training loss: 0.2378\n",
      "Epoch: 78/500... Training loss: 0.3677\n",
      "Epoch: 78/500... Training loss: 0.3960\n",
      "Epoch: 78/500... Training loss: 0.2443\n",
      "Epoch: 78/500... Training loss: 0.2889\n",
      "Epoch: 78/500... Training loss: 0.1667\n",
      "Epoch: 78/500... Training loss: 0.2388\n",
      "Epoch: 78/500... Training loss: 0.2495\n",
      "Epoch: 78/500... Training loss: 0.1816\n",
      "Epoch: 78/500... Training loss: 0.1304\n",
      "Epoch: 78/500... Training loss: 0.3309\n",
      "Epoch: 78/500... Training loss: 0.1911\n",
      "Epoch: 78/500... Training loss: 0.1740\n",
      "Epoch: 78/500... Training loss: 0.2273\n",
      "Epoch: 78/500... Training loss: 0.1400\n",
      "Epoch: 78/500... Training loss: 0.2377\n",
      "Epoch: 78/500... Training loss: 0.2525\n",
      "Epoch: 78/500... Training loss: 0.1177\n",
      "Epoch: 78/500... Training loss: 0.2000\n",
      "Epoch: 78/500... Training loss: 0.2110\n",
      "Epoch: 78/500... Training loss: 0.2707\n",
      "Epoch: 79/500... Training loss: 0.3786\n",
      "Epoch: 79/500... Training loss: 0.2438\n",
      "Epoch: 79/500... Training loss: 0.2583\n",
      "Epoch: 79/500... Training loss: 0.4396\n",
      "Epoch: 79/500... Training loss: 0.1634\n",
      "Epoch: 79/500... Training loss: 0.2428\n",
      "Epoch: 79/500... Training loss: 0.2626\n",
      "Epoch: 79/500... Training loss: 0.2822\n",
      "Epoch: 79/500... Training loss: 0.2505\n",
      "Epoch: 79/500... Training loss: 0.1347\n",
      "Epoch: 79/500... Training loss: 0.3809\n",
      "Epoch: 79/500... Training loss: 0.3495\n",
      "Epoch: 79/500... Training loss: 0.4117\n",
      "Epoch: 79/500... Training loss: 0.1531\n",
      "Epoch: 79/500... Training loss: 0.2675\n",
      "Epoch: 79/500... Training loss: 0.1936\n",
      "Epoch: 79/500... Training loss: 0.1828\n",
      "Epoch: 79/500... Training loss: 0.1930\n",
      "Epoch: 79/500... Training loss: 0.1365\n",
      "Epoch: 79/500... Training loss: 0.1406\n",
      "Epoch: 79/500... Training loss: 0.2276\n",
      "Epoch: 79/500... Training loss: 0.2126\n",
      "Epoch: 79/500... Training loss: 0.2334\n",
      "Epoch: 79/500... Training loss: 0.1496\n",
      "Epoch: 79/500... Training loss: 0.1935\n",
      "Epoch: 79/500... Training loss: 0.1626\n",
      "Epoch: 79/500... Training loss: 0.2325\n",
      "Epoch: 79/500... Training loss: 0.2059\n",
      "Epoch: 79/500... Training loss: 0.2149\n",
      "Epoch: 79/500... Training loss: 0.1673\n",
      "Epoch: 79/500... Training loss: 0.1586\n",
      "Epoch: 80/500... Training loss: 0.3502\n",
      "Epoch: 80/500... Training loss: 0.1699\n",
      "Epoch: 80/500... Training loss: 0.1994\n",
      "Epoch: 80/500... Training loss: 0.3131\n",
      "Epoch: 80/500... Training loss: 0.2276\n",
      "Epoch: 80/500... Training loss: 0.3080\n",
      "Epoch: 80/500... Training loss: 0.1744\n",
      "Epoch: 80/500... Training loss: 0.2364\n",
      "Epoch: 80/500... Training loss: 0.2788\n",
      "Epoch: 80/500... Training loss: 0.1454\n",
      "Epoch: 80/500... Training loss: 0.5188\n",
      "Epoch: 80/500... Training loss: 0.2984\n",
      "Epoch: 80/500... Training loss: 0.2477\n",
      "Epoch: 80/500... Training loss: 0.1873\n",
      "Epoch: 80/500... Training loss: 0.1771\n",
      "Epoch: 80/500... Training loss: 0.1095\n",
      "Epoch: 80/500... Training loss: 0.1822\n",
      "Epoch: 80/500... Training loss: 0.4301\n",
      "Epoch: 80/500... Training loss: 0.1930\n",
      "Epoch: 80/500... Training loss: 0.1874\n",
      "Epoch: 80/500... Training loss: 0.2047\n",
      "Epoch: 80/500... Training loss: 0.2219\n",
      "Epoch: 80/500... Training loss: 0.1763\n",
      "Epoch: 80/500... Training loss: 0.2173\n",
      "Epoch: 80/500... Training loss: 0.1820\n",
      "Epoch: 80/500... Training loss: 0.1776\n",
      "Epoch: 80/500... Training loss: 0.2065\n",
      "Epoch: 80/500... Training loss: 0.1844\n",
      "Epoch: 80/500... Training loss: 0.0978\n",
      "Epoch: 80/500... Training loss: 0.1537\n",
      "Epoch: 80/500... Training loss: 0.1934\n",
      "Epoch: 81/500... Training loss: 0.1611\n",
      "Epoch: 81/500... Training loss: 0.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/500... Training loss: 0.3389\n",
      "Epoch: 81/500... Training loss: 0.2445\n",
      "Epoch: 81/500... Training loss: 0.1411\n",
      "Epoch: 81/500... Training loss: 0.3183\n",
      "Epoch: 81/500... Training loss: 0.1501\n",
      "Epoch: 81/500... Training loss: 0.3734\n",
      "Epoch: 81/500... Training loss: 0.1602\n",
      "Epoch: 81/500... Training loss: 0.2061\n",
      "Epoch: 81/500... Training loss: 0.3522\n",
      "Epoch: 81/500... Training loss: 0.2550\n",
      "Epoch: 81/500... Training loss: 0.2236\n",
      "Epoch: 81/500... Training loss: 0.2883\n",
      "Epoch: 81/500... Training loss: 0.3194\n",
      "Epoch: 81/500... Training loss: 0.1027\n",
      "Epoch: 81/500... Training loss: 0.2165\n",
      "Epoch: 81/500... Training loss: 0.1516\n",
      "Epoch: 81/500... Training loss: 0.1229\n",
      "Epoch: 81/500... Training loss: 0.1812\n",
      "Epoch: 81/500... Training loss: 0.2420\n",
      "Epoch: 81/500... Training loss: 0.1209\n",
      "Epoch: 81/500... Training loss: 0.1430\n",
      "Epoch: 81/500... Training loss: 0.1626\n",
      "Epoch: 81/500... Training loss: 0.1495\n",
      "Epoch: 81/500... Training loss: 0.3250\n",
      "Epoch: 81/500... Training loss: 0.2696\n",
      "Epoch: 81/500... Training loss: 0.2430\n",
      "Epoch: 81/500... Training loss: 0.3579\n",
      "Epoch: 81/500... Training loss: 0.2880\n",
      "Epoch: 81/500... Training loss: 0.2045\n",
      "Epoch: 82/500... Training loss: 0.3245\n",
      "Epoch: 82/500... Training loss: 0.1645\n",
      "Epoch: 82/500... Training loss: 0.2227\n",
      "Epoch: 82/500... Training loss: 0.2231\n",
      "Epoch: 82/500... Training loss: 0.2958\n",
      "Epoch: 82/500... Training loss: 0.2329\n",
      "Epoch: 82/500... Training loss: 0.3657\n",
      "Epoch: 82/500... Training loss: 0.2194\n",
      "Epoch: 82/500... Training loss: 0.1457\n",
      "Epoch: 82/500... Training loss: 0.1978\n",
      "Epoch: 82/500... Training loss: 0.5247\n",
      "Epoch: 82/500... Training loss: 0.2693\n",
      "Epoch: 82/500... Training loss: 0.2647\n",
      "Epoch: 82/500... Training loss: 0.1377\n",
      "Epoch: 82/500... Training loss: 0.2950\n",
      "Epoch: 82/500... Training loss: 0.1820\n",
      "Epoch: 82/500... Training loss: 0.2239\n",
      "Epoch: 82/500... Training loss: 0.2152\n",
      "Epoch: 82/500... Training loss: 0.1555\n",
      "Epoch: 82/500... Training loss: 0.3207\n",
      "Epoch: 82/500... Training loss: 0.1238\n",
      "Epoch: 82/500... Training loss: 0.1953\n",
      "Epoch: 82/500... Training loss: 0.3425\n",
      "Epoch: 82/500... Training loss: 0.1576\n",
      "Epoch: 82/500... Training loss: 0.1478\n",
      "Epoch: 82/500... Training loss: 0.1856\n",
      "Epoch: 82/500... Training loss: 0.2524\n",
      "Epoch: 82/500... Training loss: 0.1220\n",
      "Epoch: 82/500... Training loss: 0.1098\n",
      "Epoch: 82/500... Training loss: 0.1892\n",
      "Epoch: 82/500... Training loss: 0.2044\n",
      "Epoch: 83/500... Training loss: 0.2380\n",
      "Epoch: 83/500... Training loss: 0.3043\n",
      "Epoch: 83/500... Training loss: 0.2944\n",
      "Epoch: 83/500... Training loss: 0.2258\n",
      "Epoch: 83/500... Training loss: 0.2893\n",
      "Epoch: 83/500... Training loss: 0.3312\n",
      "Epoch: 83/500... Training loss: 0.2633\n",
      "Epoch: 83/500... Training loss: 0.2434\n",
      "Epoch: 83/500... Training loss: 0.1741\n",
      "Epoch: 83/500... Training loss: 0.2763\n",
      "Epoch: 83/500... Training loss: 0.3332\n",
      "Epoch: 83/500... Training loss: 0.3147\n",
      "Epoch: 83/500... Training loss: 0.1962\n",
      "Epoch: 83/500... Training loss: 0.2684\n",
      "Epoch: 83/500... Training loss: 0.2243\n",
      "Epoch: 83/500... Training loss: 0.1209\n",
      "Epoch: 83/500... Training loss: 0.2931\n",
      "Epoch: 83/500... Training loss: 0.2151\n",
      "Epoch: 83/500... Training loss: 0.2589\n",
      "Epoch: 83/500... Training loss: 0.2495\n",
      "Epoch: 83/500... Training loss: 0.2946\n",
      "Epoch: 83/500... Training loss: 0.2305\n",
      "Epoch: 83/500... Training loss: 0.2345\n",
      "Epoch: 83/500... Training loss: 0.2258\n",
      "Epoch: 83/500... Training loss: 0.1929\n",
      "Epoch: 83/500... Training loss: 0.1621\n",
      "Epoch: 83/500... Training loss: 0.2660\n",
      "Epoch: 83/500... Training loss: 0.3402\n",
      "Epoch: 83/500... Training loss: 0.2881\n",
      "Epoch: 83/500... Training loss: 0.1016\n",
      "Epoch: 83/500... Training loss: 0.2021\n",
      "Epoch: 84/500... Training loss: 0.2814\n",
      "Epoch: 84/500... Training loss: 0.2269\n",
      "Epoch: 84/500... Training loss: 0.3541\n",
      "Epoch: 84/500... Training loss: 0.3511\n",
      "Epoch: 84/500... Training loss: 0.1830\n",
      "Epoch: 84/500... Training loss: 0.2041\n",
      "Epoch: 84/500... Training loss: 0.3582\n",
      "Epoch: 84/500... Training loss: 0.2343\n",
      "Epoch: 84/500... Training loss: 0.1508\n",
      "Epoch: 84/500... Training loss: 0.2546\n",
      "Epoch: 84/500... Training loss: 0.2915\n",
      "Epoch: 84/500... Training loss: 0.2387\n",
      "Epoch: 84/500... Training loss: 0.3141\n",
      "Epoch: 84/500... Training loss: 0.1879\n",
      "Epoch: 84/500... Training loss: 0.3013\n",
      "Epoch: 84/500... Training loss: 0.1797\n",
      "Epoch: 84/500... Training loss: 0.2382\n",
      "Epoch: 84/500... Training loss: 0.2172\n",
      "Epoch: 84/500... Training loss: 0.1525\n",
      "Epoch: 84/500... Training loss: 0.1700\n",
      "Epoch: 84/500... Training loss: 0.2611\n",
      "Epoch: 84/500... Training loss: 0.2451\n",
      "Epoch: 84/500... Training loss: 0.1781\n",
      "Epoch: 84/500... Training loss: 0.2610\n",
      "Epoch: 84/500... Training loss: 0.1331\n",
      "Epoch: 84/500... Training loss: 0.1863\n",
      "Epoch: 84/500... Training loss: 0.2443\n",
      "Epoch: 84/500... Training loss: 0.2302\n",
      "Epoch: 84/500... Training loss: 0.2054\n",
      "Epoch: 84/500... Training loss: 0.1593\n",
      "Epoch: 84/500... Training loss: 0.1255\n",
      "Epoch: 85/500... Training loss: 0.1740\n",
      "Epoch: 85/500... Training loss: 0.2484\n",
      "Epoch: 85/500... Training loss: 0.3516\n",
      "Epoch: 85/500... Training loss: 0.2674\n",
      "Epoch: 85/500... Training loss: 0.2605\n",
      "Epoch: 85/500... Training loss: 0.3619\n",
      "Epoch: 85/500... Training loss: 0.2001\n",
      "Epoch: 85/500... Training loss: 0.2219\n",
      "Epoch: 85/500... Training loss: 0.2165\n",
      "Epoch: 85/500... Training loss: 0.3896\n",
      "Epoch: 85/500... Training loss: 0.3598\n",
      "Epoch: 85/500... Training loss: 0.2500\n",
      "Epoch: 85/500... Training loss: 0.2957\n",
      "Epoch: 85/500... Training loss: 0.1405\n",
      "Epoch: 85/500... Training loss: 0.2578\n",
      "Epoch: 85/500... Training loss: 0.1530\n",
      "Epoch: 85/500... Training loss: 0.1289\n",
      "Epoch: 85/500... Training loss: 0.1691\n",
      "Epoch: 85/500... Training loss: 0.2405\n",
      "Epoch: 85/500... Training loss: 0.1428\n",
      "Epoch: 85/500... Training loss: 0.1900\n",
      "Epoch: 85/500... Training loss: 0.2704\n",
      "Epoch: 85/500... Training loss: 0.1853\n",
      "Epoch: 85/500... Training loss: 0.1985\n",
      "Epoch: 85/500... Training loss: 0.2145\n",
      "Epoch: 85/500... Training loss: 0.1759\n",
      "Epoch: 85/500... Training loss: 0.2196\n",
      "Epoch: 85/500... Training loss: 0.1356\n",
      "Epoch: 85/500... Training loss: 0.1393\n",
      "Epoch: 85/500... Training loss: 0.1960\n",
      "Epoch: 85/500... Training loss: 0.1262\n",
      "Epoch: 86/500... Training loss: 0.1703\n",
      "Epoch: 86/500... Training loss: 0.2929\n",
      "Epoch: 86/500... Training loss: 0.2059\n",
      "Epoch: 86/500... Training loss: 0.2421\n",
      "Epoch: 86/500... Training loss: 0.2272\n",
      "Epoch: 86/500... Training loss: 0.2108\n",
      "Epoch: 86/500... Training loss: 0.1224\n",
      "Epoch: 86/500... Training loss: 0.1595\n",
      "Epoch: 86/500... Training loss: 0.1135\n",
      "Epoch: 86/500... Training loss: 0.3327\n",
      "Epoch: 86/500... Training loss: 0.3070\n",
      "Epoch: 86/500... Training loss: 0.2764\n",
      "Epoch: 86/500... Training loss: 0.3064\n",
      "Epoch: 86/500... Training loss: 0.2359\n",
      "Epoch: 86/500... Training loss: 0.2193\n",
      "Epoch: 86/500... Training loss: 0.0853\n",
      "Epoch: 86/500... Training loss: 0.1611\n",
      "Epoch: 86/500... Training loss: 0.2071\n",
      "Epoch: 86/500... Training loss: 0.2820\n",
      "Epoch: 86/500... Training loss: 0.1118\n",
      "Epoch: 86/500... Training loss: 0.2181\n",
      "Epoch: 86/500... Training loss: 0.1933\n",
      "Epoch: 86/500... Training loss: 0.2642\n",
      "Epoch: 86/500... Training loss: 0.2153\n",
      "Epoch: 86/500... Training loss: 0.2829\n",
      "Epoch: 86/500... Training loss: 0.1545\n",
      "Epoch: 86/500... Training loss: 0.1682\n",
      "Epoch: 86/500... Training loss: 0.2333\n",
      "Epoch: 86/500... Training loss: 0.1209\n",
      "Epoch: 86/500... Training loss: 0.1336\n",
      "Epoch: 86/500... Training loss: 0.1010\n",
      "Epoch: 87/500... Training loss: 0.1764\n",
      "Epoch: 87/500... Training loss: 0.3151\n",
      "Epoch: 87/500... Training loss: 0.1705\n",
      "Epoch: 87/500... Training loss: 0.4262\n",
      "Epoch: 87/500... Training loss: 0.1388\n",
      "Epoch: 87/500... Training loss: 0.1505\n",
      "Epoch: 87/500... Training loss: 0.1236\n",
      "Epoch: 87/500... Training loss: 0.2111\n",
      "Epoch: 87/500... Training loss: 0.1842\n",
      "Epoch: 87/500... Training loss: 0.2374\n",
      "Epoch: 87/500... Training loss: 0.3626\n",
      "Epoch: 87/500... Training loss: 0.2239\n",
      "Epoch: 87/500... Training loss: 0.2687\n",
      "Epoch: 87/500... Training loss: 0.1580\n",
      "Epoch: 87/500... Training loss: 0.1725\n",
      "Epoch: 87/500... Training loss: 0.1534\n",
      "Epoch: 87/500... Training loss: 0.1808\n",
      "Epoch: 87/500... Training loss: 0.1828\n",
      "Epoch: 87/500... Training loss: 0.2254\n",
      "Epoch: 87/500... Training loss: 0.1388\n",
      "Epoch: 87/500... Training loss: 0.1707\n",
      "Epoch: 87/500... Training loss: 0.1696\n",
      "Epoch: 87/500... Training loss: 0.1384\n",
      "Epoch: 87/500... Training loss: 0.1478\n",
      "Epoch: 87/500... Training loss: 0.1003\n",
      "Epoch: 87/500... Training loss: 0.2890\n",
      "Epoch: 87/500... Training loss: 0.1314\n",
      "Epoch: 87/500... Training loss: 0.1863\n",
      "Epoch: 87/500... Training loss: 0.2215\n",
      "Epoch: 87/500... Training loss: 0.1786\n",
      "Epoch: 87/500... Training loss: 0.1031\n",
      "Epoch: 88/500... Training loss: 0.1504\n",
      "Epoch: 88/500... Training loss: 0.2938\n",
      "Epoch: 88/500... Training loss: 0.2313\n",
      "Epoch: 88/500... Training loss: 0.3586\n",
      "Epoch: 88/500... Training loss: 0.1900\n",
      "Epoch: 88/500... Training loss: 0.2129\n",
      "Epoch: 88/500... Training loss: 0.1741\n",
      "Epoch: 88/500... Training loss: 0.1487\n",
      "Epoch: 88/500... Training loss: 0.1962\n",
      "Epoch: 88/500... Training loss: 0.2046\n",
      "Epoch: 88/500... Training loss: 0.3448\n",
      "Epoch: 88/500... Training loss: 0.4597\n",
      "Epoch: 88/500... Training loss: 0.2152\n",
      "Epoch: 88/500... Training loss: 0.2876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/500... Training loss: 0.1493\n",
      "Epoch: 88/500... Training loss: 0.0958\n",
      "Epoch: 88/500... Training loss: 0.1579\n",
      "Epoch: 88/500... Training loss: 0.1855\n",
      "Epoch: 88/500... Training loss: 0.2051\n",
      "Epoch: 88/500... Training loss: 0.2079\n",
      "Epoch: 88/500... Training loss: 0.2155\n",
      "Epoch: 88/500... Training loss: 0.1484\n",
      "Epoch: 88/500... Training loss: 0.2577\n",
      "Epoch: 88/500... Training loss: 0.1824\n",
      "Epoch: 88/500... Training loss: 0.1621\n",
      "Epoch: 88/500... Training loss: 0.1528\n",
      "Epoch: 88/500... Training loss: 0.2444\n",
      "Epoch: 88/500... Training loss: 0.3569\n",
      "Epoch: 88/500... Training loss: 0.2143\n",
      "Epoch: 88/500... Training loss: 0.1585\n",
      "Epoch: 88/500... Training loss: 0.1961\n",
      "Epoch: 89/500... Training loss: 0.1961\n",
      "Epoch: 89/500... Training loss: 0.1798\n",
      "Epoch: 89/500... Training loss: 0.1253\n",
      "Epoch: 89/500... Training loss: 0.2770\n",
      "Epoch: 89/500... Training loss: 0.1997\n",
      "Epoch: 89/500... Training loss: 0.2362\n",
      "Epoch: 89/500... Training loss: 0.2450\n",
      "Epoch: 89/500... Training loss: 0.2439\n",
      "Epoch: 89/500... Training loss: 0.1560\n",
      "Epoch: 89/500... Training loss: 0.1982\n",
      "Epoch: 89/500... Training loss: 0.2420\n",
      "Epoch: 89/500... Training loss: 0.2072\n",
      "Epoch: 89/500... Training loss: 0.1630\n",
      "Epoch: 89/500... Training loss: 0.2271\n",
      "Epoch: 89/500... Training loss: 0.1267\n",
      "Epoch: 89/500... Training loss: 0.1810\n",
      "Epoch: 89/500... Training loss: 0.2527\n",
      "Epoch: 89/500... Training loss: 0.1874\n",
      "Epoch: 89/500... Training loss: 0.2123\n",
      "Epoch: 89/500... Training loss: 0.1791\n",
      "Epoch: 89/500... Training loss: 0.2123\n",
      "Epoch: 89/500... Training loss: 0.2282\n",
      "Epoch: 89/500... Training loss: 0.1311\n",
      "Epoch: 89/500... Training loss: 0.1439\n",
      "Epoch: 89/500... Training loss: 0.1909\n",
      "Epoch: 89/500... Training loss: 0.1367\n",
      "Epoch: 89/500... Training loss: 0.2022\n",
      "Epoch: 89/500... Training loss: 0.2068\n",
      "Epoch: 89/500... Training loss: 0.2093\n",
      "Epoch: 89/500... Training loss: 0.1355\n",
      "Epoch: 89/500... Training loss: 0.1664\n",
      "Epoch: 90/500... Training loss: 0.1963\n",
      "Epoch: 90/500... Training loss: 0.3259\n",
      "Epoch: 90/500... Training loss: 0.1904\n",
      "Epoch: 90/500... Training loss: 0.2058\n",
      "Epoch: 90/500... Training loss: 0.2167\n",
      "Epoch: 90/500... Training loss: 0.2328\n",
      "Epoch: 90/500... Training loss: 0.1352\n",
      "Epoch: 90/500... Training loss: 0.3298\n",
      "Epoch: 90/500... Training loss: 0.2116\n",
      "Epoch: 90/500... Training loss: 0.1982\n",
      "Epoch: 90/500... Training loss: 0.2804\n",
      "Epoch: 90/500... Training loss: 0.1804\n",
      "Epoch: 90/500... Training loss: 0.2018\n",
      "Epoch: 90/500... Training loss: 0.1546\n",
      "Epoch: 90/500... Training loss: 0.2415\n",
      "Epoch: 90/500... Training loss: 0.1917\n",
      "Epoch: 90/500... Training loss: 0.1233\n",
      "Epoch: 90/500... Training loss: 0.1569\n",
      "Epoch: 90/500... Training loss: 0.2583\n",
      "Epoch: 90/500... Training loss: 0.1786\n",
      "Epoch: 90/500... Training loss: 0.2510\n",
      "Epoch: 90/500... Training loss: 0.1785\n",
      "Epoch: 90/500... Training loss: 0.2126\n",
      "Epoch: 90/500... Training loss: 0.1337\n",
      "Epoch: 90/500... Training loss: 0.1665\n",
      "Epoch: 90/500... Training loss: 0.1781\n",
      "Epoch: 90/500... Training loss: 0.2229\n",
      "Epoch: 90/500... Training loss: 0.0815\n",
      "Epoch: 90/500... Training loss: 0.1983\n",
      "Epoch: 90/500... Training loss: 0.0995\n",
      "Epoch: 90/500... Training loss: 0.2619\n",
      "Epoch: 91/500... Training loss: 0.2898\n",
      "Epoch: 91/500... Training loss: 0.1988\n",
      "Epoch: 91/500... Training loss: 0.1957\n",
      "Epoch: 91/500... Training loss: 0.1580\n",
      "Epoch: 91/500... Training loss: 0.4447\n",
      "Epoch: 91/500... Training loss: 0.1792\n",
      "Epoch: 91/500... Training loss: 0.1467\n",
      "Epoch: 91/500... Training loss: 0.2191\n",
      "Epoch: 91/500... Training loss: 0.2373\n",
      "Epoch: 91/500... Training loss: 0.1451\n",
      "Epoch: 91/500... Training loss: 0.1763\n",
      "Epoch: 91/500... Training loss: 0.3546\n",
      "Epoch: 91/500... Training loss: 0.1670\n",
      "Epoch: 91/500... Training loss: 0.2156\n",
      "Epoch: 91/500... Training loss: 0.1976\n",
      "Epoch: 91/500... Training loss: 0.1203\n",
      "Epoch: 91/500... Training loss: 0.1272\n",
      "Epoch: 91/500... Training loss: 0.1739\n",
      "Epoch: 91/500... Training loss: 0.1171\n",
      "Epoch: 91/500... Training loss: 0.2265\n",
      "Epoch: 91/500... Training loss: 0.1250\n",
      "Epoch: 91/500... Training loss: 0.2628\n",
      "Epoch: 91/500... Training loss: 0.1785\n",
      "Epoch: 91/500... Training loss: 0.1534\n",
      "Epoch: 91/500... Training loss: 0.1418\n",
      "Epoch: 91/500... Training loss: 0.1323\n",
      "Epoch: 91/500... Training loss: 0.1146\n",
      "Epoch: 91/500... Training loss: 0.2016\n",
      "Epoch: 91/500... Training loss: 0.1258\n",
      "Epoch: 91/500... Training loss: 0.1088\n",
      "Epoch: 91/500... Training loss: 0.3041\n",
      "Epoch: 92/500... Training loss: 0.2876\n",
      "Epoch: 92/500... Training loss: 0.2677\n",
      "Epoch: 92/500... Training loss: 0.2132\n",
      "Epoch: 92/500... Training loss: 0.2254\n",
      "Epoch: 92/500... Training loss: 0.1983\n",
      "Epoch: 92/500... Training loss: 0.2180\n",
      "Epoch: 92/500... Training loss: 0.1715\n",
      "Epoch: 92/500... Training loss: 0.1777\n",
      "Epoch: 92/500... Training loss: 0.2548\n",
      "Epoch: 92/500... Training loss: 0.1617\n",
      "Epoch: 92/500... Training loss: 0.4796\n",
      "Epoch: 92/500... Training loss: 0.3499\n",
      "Epoch: 92/500... Training loss: 0.2193\n",
      "Epoch: 92/500... Training loss: 0.1413\n",
      "Epoch: 92/500... Training loss: 0.0983\n",
      "Epoch: 92/500... Training loss: 0.0848\n",
      "Epoch: 92/500... Training loss: 0.0987\n",
      "Epoch: 92/500... Training loss: 0.2113\n",
      "Epoch: 92/500... Training loss: 0.2269\n",
      "Epoch: 92/500... Training loss: 0.2001\n",
      "Epoch: 92/500... Training loss: 0.2128\n",
      "Epoch: 92/500... Training loss: 0.2107\n",
      "Epoch: 92/500... Training loss: 0.1989\n",
      "Epoch: 92/500... Training loss: 0.1437\n",
      "Epoch: 92/500... Training loss: 0.3458\n",
      "Epoch: 92/500... Training loss: 0.1481\n",
      "Epoch: 92/500... Training loss: 0.2730\n",
      "Epoch: 92/500... Training loss: 0.1110\n",
      "Epoch: 92/500... Training loss: 0.1055\n",
      "Epoch: 92/500... Training loss: 0.1335\n",
      "Epoch: 92/500... Training loss: 0.1651\n",
      "Epoch: 93/500... Training loss: 0.2359\n",
      "Epoch: 93/500... Training loss: 0.0736\n",
      "Epoch: 93/500... Training loss: 0.2505\n",
      "Epoch: 93/500... Training loss: 0.2616\n",
      "Epoch: 93/500... Training loss: 0.1880\n",
      "Epoch: 93/500... Training loss: 0.1787\n",
      "Epoch: 93/500... Training loss: 0.1663\n",
      "Epoch: 93/500... Training loss: 0.3274\n",
      "Epoch: 93/500... Training loss: 0.1272\n",
      "Epoch: 93/500... Training loss: 0.1545\n",
      "Epoch: 93/500... Training loss: 0.3134\n",
      "Epoch: 93/500... Training loss: 0.1375\n",
      "Epoch: 93/500... Training loss: 0.2738\n",
      "Epoch: 93/500... Training loss: 0.1856\n",
      "Epoch: 93/500... Training loss: 0.3290\n",
      "Epoch: 93/500... Training loss: 0.0786\n",
      "Epoch: 93/500... Training loss: 0.3041\n",
      "Epoch: 93/500... Training loss: 0.1571\n",
      "Epoch: 93/500... Training loss: 0.1033\n",
      "Epoch: 93/500... Training loss: 0.0755\n",
      "Epoch: 93/500... Training loss: 0.1636\n",
      "Epoch: 93/500... Training loss: 0.2142\n",
      "Epoch: 93/500... Training loss: 0.1081\n",
      "Epoch: 93/500... Training loss: 0.1347\n",
      "Epoch: 93/500... Training loss: 0.3002\n",
      "Epoch: 93/500... Training loss: 0.1846\n",
      "Epoch: 93/500... Training loss: 0.0985\n",
      "Epoch: 93/500... Training loss: 0.2167\n",
      "Epoch: 93/500... Training loss: 0.2423\n",
      "Epoch: 93/500... Training loss: 0.1335\n",
      "Epoch: 93/500... Training loss: 0.1891\n",
      "Epoch: 94/500... Training loss: 0.1575\n",
      "Epoch: 94/500... Training loss: 0.3832\n",
      "Epoch: 94/500... Training loss: 0.2317\n",
      "Epoch: 94/500... Training loss: 0.1392\n",
      "Epoch: 94/500... Training loss: 0.1406\n",
      "Epoch: 94/500... Training loss: 0.1971\n",
      "Epoch: 94/500... Training loss: 0.2859\n",
      "Epoch: 94/500... Training loss: 0.2123\n",
      "Epoch: 94/500... Training loss: 0.1948\n",
      "Epoch: 94/500... Training loss: 0.1724\n",
      "Epoch: 94/500... Training loss: 0.2497\n",
      "Epoch: 94/500... Training loss: 0.1671\n",
      "Epoch: 94/500... Training loss: 0.2937\n",
      "Epoch: 94/500... Training loss: 0.1008\n",
      "Epoch: 94/500... Training loss: 0.0973\n",
      "Epoch: 94/500... Training loss: 0.2142\n",
      "Epoch: 94/500... Training loss: 0.0974\n",
      "Epoch: 94/500... Training loss: 0.0996\n",
      "Epoch: 94/500... Training loss: 0.2108\n",
      "Epoch: 94/500... Training loss: 0.1153\n",
      "Epoch: 94/500... Training loss: 0.2623\n",
      "Epoch: 94/500... Training loss: 0.1793\n",
      "Epoch: 94/500... Training loss: 0.1865\n",
      "Epoch: 94/500... Training loss: 0.2574\n",
      "Epoch: 94/500... Training loss: 0.1585\n",
      "Epoch: 94/500... Training loss: 0.2256\n",
      "Epoch: 94/500... Training loss: 0.2098\n",
      "Epoch: 94/500... Training loss: 0.1072\n",
      "Epoch: 94/500... Training loss: 0.0983\n",
      "Epoch: 94/500... Training loss: 0.0885\n",
      "Epoch: 94/500... Training loss: 0.1195\n",
      "Epoch: 95/500... Training loss: 0.1629\n",
      "Epoch: 95/500... Training loss: 0.1631\n",
      "Epoch: 95/500... Training loss: 0.1391\n",
      "Epoch: 95/500... Training loss: 0.2791\n",
      "Epoch: 95/500... Training loss: 0.1405\n",
      "Epoch: 95/500... Training loss: 0.1383\n",
      "Epoch: 95/500... Training loss: 0.1488\n",
      "Epoch: 95/500... Training loss: 0.2232\n",
      "Epoch: 95/500... Training loss: 0.1272\n",
      "Epoch: 95/500... Training loss: 0.1685\n",
      "Epoch: 95/500... Training loss: 0.4112\n",
      "Epoch: 95/500... Training loss: 0.2047\n",
      "Epoch: 95/500... Training loss: 0.1488\n",
      "Epoch: 95/500... Training loss: 0.1134\n",
      "Epoch: 95/500... Training loss: 0.1374\n",
      "Epoch: 95/500... Training loss: 0.1094\n",
      "Epoch: 95/500... Training loss: 0.1764\n",
      "Epoch: 95/500... Training loss: 0.1551\n",
      "Epoch: 95/500... Training loss: 0.1910\n",
      "Epoch: 95/500... Training loss: 0.2903\n",
      "Epoch: 95/500... Training loss: 0.1866\n",
      "Epoch: 95/500... Training loss: 0.3388\n",
      "Epoch: 95/500... Training loss: 0.0731\n",
      "Epoch: 95/500... Training loss: 0.1449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/500... Training loss: 0.2395\n",
      "Epoch: 95/500... Training loss: 0.2545\n",
      "Epoch: 95/500... Training loss: 0.1262\n",
      "Epoch: 95/500... Training loss: 0.1772\n",
      "Epoch: 95/500... Training loss: 0.1198\n",
      "Epoch: 95/500... Training loss: 0.2520\n",
      "Epoch: 95/500... Training loss: 0.2798\n",
      "Epoch: 96/500... Training loss: 0.3126\n",
      "Epoch: 96/500... Training loss: 0.2307\n",
      "Epoch: 96/500... Training loss: 0.0917\n",
      "Epoch: 96/500... Training loss: 0.2032\n",
      "Epoch: 96/500... Training loss: 0.1933\n",
      "Epoch: 96/500... Training loss: 0.1373\n",
      "Epoch: 96/500... Training loss: 0.1876\n",
      "Epoch: 96/500... Training loss: 0.1770\n",
      "Epoch: 96/500... Training loss: 0.2183\n",
      "Epoch: 96/500... Training loss: 0.0836\n",
      "Epoch: 96/500... Training loss: 0.2361\n",
      "Epoch: 96/500... Training loss: 0.2025\n",
      "Epoch: 96/500... Training loss: 0.2949\n",
      "Epoch: 96/500... Training loss: 0.1556\n",
      "Epoch: 96/500... Training loss: 0.1179\n",
      "Epoch: 96/500... Training loss: 0.2228\n",
      "Epoch: 96/500... Training loss: 0.1458\n",
      "Epoch: 96/500... Training loss: 0.2282\n",
      "Epoch: 96/500... Training loss: 0.2220\n",
      "Epoch: 96/500... Training loss: 0.2303\n",
      "Epoch: 96/500... Training loss: 0.1781\n",
      "Epoch: 96/500... Training loss: 0.1356\n",
      "Epoch: 96/500... Training loss: 0.1895\n",
      "Epoch: 96/500... Training loss: 0.1234\n",
      "Epoch: 96/500... Training loss: 0.1099\n",
      "Epoch: 96/500... Training loss: 0.1143\n",
      "Epoch: 96/500... Training loss: 0.1531\n",
      "Epoch: 96/500... Training loss: 0.2141\n",
      "Epoch: 96/500... Training loss: 0.1652\n",
      "Epoch: 96/500... Training loss: 0.1001\n",
      "Epoch: 96/500... Training loss: 0.1788\n",
      "Epoch: 97/500... Training loss: 0.2336\n",
      "Epoch: 97/500... Training loss: 0.0830\n",
      "Epoch: 97/500... Training loss: 0.1848\n",
      "Epoch: 97/500... Training loss: 0.3014\n",
      "Epoch: 97/500... Training loss: 0.1992\n",
      "Epoch: 97/500... Training loss: 0.2560\n",
      "Epoch: 97/500... Training loss: 0.1535\n",
      "Epoch: 97/500... Training loss: 0.2582\n",
      "Epoch: 97/500... Training loss: 0.2224\n",
      "Epoch: 97/500... Training loss: 0.1980\n",
      "Epoch: 97/500... Training loss: 0.2007\n",
      "Epoch: 97/500... Training loss: 0.1626\n",
      "Epoch: 97/500... Training loss: 0.3583\n",
      "Epoch: 97/500... Training loss: 0.1012\n",
      "Epoch: 97/500... Training loss: 0.1740\n",
      "Epoch: 97/500... Training loss: 0.1642\n",
      "Epoch: 97/500... Training loss: 0.1747\n",
      "Epoch: 97/500... Training loss: 0.0728\n",
      "Epoch: 97/500... Training loss: 0.2253\n",
      "Epoch: 97/500... Training loss: 0.1847\n",
      "Epoch: 97/500... Training loss: 0.1509\n",
      "Epoch: 97/500... Training loss: 0.1571\n",
      "Epoch: 97/500... Training loss: 0.2442\n",
      "Epoch: 97/500... Training loss: 0.1451\n",
      "Epoch: 97/500... Training loss: 0.0953\n",
      "Epoch: 97/500... Training loss: 0.2129\n",
      "Epoch: 97/500... Training loss: 0.0847\n",
      "Epoch: 97/500... Training loss: 0.1667\n",
      "Epoch: 97/500... Training loss: 0.0568\n",
      "Epoch: 97/500... Training loss: 0.0451\n",
      "Epoch: 97/500... Training loss: 0.1231\n",
      "Epoch: 98/500... Training loss: 0.1242\n",
      "Epoch: 98/500... Training loss: 0.2857\n",
      "Epoch: 98/500... Training loss: 0.1342\n",
      "Epoch: 98/500... Training loss: 0.1107\n",
      "Epoch: 98/500... Training loss: 0.1739\n",
      "Epoch: 98/500... Training loss: 0.1854\n",
      "Epoch: 98/500... Training loss: 0.3044\n",
      "Epoch: 98/500... Training loss: 0.1248\n",
      "Epoch: 98/500... Training loss: 0.1321\n",
      "Epoch: 98/500... Training loss: 0.1204\n",
      "Epoch: 98/500... Training loss: 0.2216\n",
      "Epoch: 98/500... Training loss: 0.2647\n",
      "Epoch: 98/500... Training loss: 0.2790\n",
      "Epoch: 98/500... Training loss: 0.0792\n",
      "Epoch: 98/500... Training loss: 0.1047\n",
      "Epoch: 98/500... Training loss: 0.1690\n",
      "Epoch: 98/500... Training loss: 0.2273\n",
      "Epoch: 98/500... Training loss: 0.2363\n",
      "Epoch: 98/500... Training loss: 0.1215\n",
      "Epoch: 98/500... Training loss: 0.1076\n",
      "Epoch: 98/500... Training loss: 0.0977\n",
      "Epoch: 98/500... Training loss: 0.0840\n",
      "Epoch: 98/500... Training loss: 0.0883\n",
      "Epoch: 98/500... Training loss: 0.0651\n",
      "Epoch: 98/500... Training loss: 0.1652\n",
      "Epoch: 98/500... Training loss: 0.1132\n",
      "Epoch: 98/500... Training loss: 0.0771\n",
      "Epoch: 98/500... Training loss: 0.2347\n",
      "Epoch: 98/500... Training loss: 0.1359\n",
      "Epoch: 98/500... Training loss: 0.1249\n",
      "Epoch: 98/500... Training loss: 0.0784\n",
      "Epoch: 99/500... Training loss: 0.1587\n",
      "Epoch: 99/500... Training loss: 0.2842\n",
      "Epoch: 99/500... Training loss: 0.0815\n",
      "Epoch: 99/500... Training loss: 0.2219\n",
      "Epoch: 99/500... Training loss: 0.2381\n",
      "Epoch: 99/500... Training loss: 0.1669\n",
      "Epoch: 99/500... Training loss: 0.1657\n",
      "Epoch: 99/500... Training loss: 0.1304\n",
      "Epoch: 99/500... Training loss: 0.1374\n",
      "Epoch: 99/500... Training loss: 0.1473\n",
      "Epoch: 99/500... Training loss: 0.2897\n",
      "Epoch: 99/500... Training loss: 0.1296\n",
      "Epoch: 99/500... Training loss: 0.1338\n",
      "Epoch: 99/500... Training loss: 0.0595\n",
      "Epoch: 99/500... Training loss: 0.2022\n",
      "Epoch: 99/500... Training loss: 0.1060\n",
      "Epoch: 99/500... Training loss: 0.1525\n",
      "Epoch: 99/500... Training loss: 0.1312\n",
      "Epoch: 99/500... Training loss: 0.1812\n",
      "Epoch: 99/500... Training loss: 0.1529\n",
      "Epoch: 99/500... Training loss: 0.1271\n",
      "Epoch: 99/500... Training loss: 0.1585\n",
      "Epoch: 99/500... Training loss: 0.1306\n",
      "Epoch: 99/500... Training loss: 0.2056\n",
      "Epoch: 99/500... Training loss: 0.0942\n",
      "Epoch: 99/500... Training loss: 0.0896\n",
      "Epoch: 99/500... Training loss: 0.2204\n",
      "Epoch: 99/500... Training loss: 0.1738\n",
      "Epoch: 99/500... Training loss: 0.1386\n",
      "Epoch: 99/500... Training loss: 0.1300\n",
      "Epoch: 99/500... Training loss: 0.0889\n",
      "Epoch: 100/500... Training loss: 0.1857\n",
      "Epoch: 100/500... Training loss: 0.2061\n",
      "Epoch: 100/500... Training loss: 0.1778\n",
      "Epoch: 100/500... Training loss: 0.3112\n",
      "Epoch: 100/500... Training loss: 0.2342\n",
      "Epoch: 100/500... Training loss: 0.2411\n",
      "Epoch: 100/500... Training loss: 0.2269\n",
      "Epoch: 100/500... Training loss: 0.1171\n",
      "Epoch: 100/500... Training loss: 0.1498\n",
      "Epoch: 100/500... Training loss: 0.1180\n",
      "Epoch: 100/500... Training loss: 0.1972\n",
      "Epoch: 100/500... Training loss: 0.2106\n",
      "Epoch: 100/500... Training loss: 0.2766\n",
      "Epoch: 100/500... Training loss: 0.1877\n",
      "Epoch: 100/500... Training loss: 0.1288\n",
      "Epoch: 100/500... Training loss: 0.1182\n",
      "Epoch: 100/500... Training loss: 0.0849\n",
      "Epoch: 100/500... Training loss: 0.1695\n",
      "Epoch: 100/500... Training loss: 0.1060\n",
      "Epoch: 100/500... Training loss: 0.1785\n",
      "Epoch: 100/500... Training loss: 0.1096\n",
      "Epoch: 100/500... Training loss: 0.0819\n",
      "Epoch: 100/500... Training loss: 0.1552\n",
      "Epoch: 100/500... Training loss: 0.1596\n",
      "Epoch: 100/500... Training loss: 0.2215\n",
      "Epoch: 100/500... Training loss: 0.1368\n",
      "Epoch: 100/500... Training loss: 0.1166\n",
      "Epoch: 100/500... Training loss: 0.1129\n",
      "Epoch: 100/500... Training loss: 0.2134\n",
      "Epoch: 100/500... Training loss: 0.0997\n",
      "Epoch: 100/500... Training loss: 0.1441\n",
      "Epoch: 101/500... Training loss: 0.2344\n",
      "Epoch: 101/500... Training loss: 0.2032\n",
      "Epoch: 101/500... Training loss: 0.3181\n",
      "Epoch: 101/500... Training loss: 0.2181\n",
      "Epoch: 101/500... Training loss: 0.0970\n",
      "Epoch: 101/500... Training loss: 0.1248\n",
      "Epoch: 101/500... Training loss: 0.1783\n",
      "Epoch: 101/500... Training loss: 0.2747\n",
      "Epoch: 101/500... Training loss: 0.1244\n",
      "Epoch: 101/500... Training loss: 0.1931\n",
      "Epoch: 101/500... Training loss: 0.2184\n",
      "Epoch: 101/500... Training loss: 0.1884\n",
      "Epoch: 101/500... Training loss: 0.1269\n",
      "Epoch: 101/500... Training loss: 0.1184\n",
      "Epoch: 101/500... Training loss: 0.2111\n",
      "Epoch: 101/500... Training loss: 0.1035\n",
      "Epoch: 101/500... Training loss: 0.1189\n",
      "Epoch: 101/500... Training loss: 0.1671\n",
      "Epoch: 101/500... Training loss: 0.1612\n",
      "Epoch: 101/500... Training loss: 0.1280\n",
      "Epoch: 101/500... Training loss: 0.0680\n",
      "Epoch: 101/500... Training loss: 0.1086\n",
      "Epoch: 101/500... Training loss: 0.1026\n",
      "Epoch: 101/500... Training loss: 0.1148\n",
      "Epoch: 101/500... Training loss: 0.0746\n",
      "Epoch: 101/500... Training loss: 0.1499\n",
      "Epoch: 101/500... Training loss: 0.2424\n",
      "Epoch: 101/500... Training loss: 0.2094\n",
      "Epoch: 101/500... Training loss: 0.0869\n",
      "Epoch: 101/500... Training loss: 0.1106\n",
      "Epoch: 101/500... Training loss: 0.1336\n",
      "Epoch: 102/500... Training loss: 0.1827\n",
      "Epoch: 102/500... Training loss: 0.2082\n",
      "Epoch: 102/500... Training loss: 0.1511\n",
      "Epoch: 102/500... Training loss: 0.1490\n",
      "Epoch: 102/500... Training loss: 0.1865\n",
      "Epoch: 102/500... Training loss: 0.1036\n",
      "Epoch: 102/500... Training loss: 0.2683\n",
      "Epoch: 102/500... Training loss: 0.2738\n",
      "Epoch: 102/500... Training loss: 0.2477\n",
      "Epoch: 102/500... Training loss: 0.1674\n",
      "Epoch: 102/500... Training loss: 0.2372\n",
      "Epoch: 102/500... Training loss: 0.2318\n",
      "Epoch: 102/500... Training loss: 0.1837\n",
      "Epoch: 102/500... Training loss: 0.2086\n",
      "Epoch: 102/500... Training loss: 0.1430\n",
      "Epoch: 102/500... Training loss: 0.1035\n",
      "Epoch: 102/500... Training loss: 0.1264\n",
      "Epoch: 102/500... Training loss: 0.1029\n",
      "Epoch: 102/500... Training loss: 0.2121\n",
      "Epoch: 102/500... Training loss: 0.0972\n",
      "Epoch: 102/500... Training loss: 0.0919\n",
      "Epoch: 102/500... Training loss: 0.2587\n",
      "Epoch: 102/500... Training loss: 0.2366\n",
      "Epoch: 102/500... Training loss: 0.0498\n",
      "Epoch: 102/500... Training loss: 0.1068\n",
      "Epoch: 102/500... Training loss: 0.0916\n",
      "Epoch: 102/500... Training loss: 0.0583\n",
      "Epoch: 102/500... Training loss: 0.1120\n",
      "Epoch: 102/500... Training loss: 0.1813\n",
      "Epoch: 102/500... Training loss: 0.1771\n",
      "Epoch: 102/500... Training loss: 0.2748\n",
      "Epoch: 103/500... Training loss: 0.2573\n",
      "Epoch: 103/500... Training loss: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103/500... Training loss: 0.1127\n",
      "Epoch: 103/500... Training loss: 0.1585\n",
      "Epoch: 103/500... Training loss: 0.1950\n",
      "Epoch: 103/500... Training loss: 0.1444\n",
      "Epoch: 103/500... Training loss: 0.1162\n",
      "Epoch: 103/500... Training loss: 0.1829\n",
      "Epoch: 103/500... Training loss: 0.1011\n",
      "Epoch: 103/500... Training loss: 0.1215\n",
      "Epoch: 103/500... Training loss: 0.1475\n",
      "Epoch: 103/500... Training loss: 0.1261\n",
      "Epoch: 103/500... Training loss: 0.1382\n",
      "Epoch: 103/500... Training loss: 0.1700\n",
      "Epoch: 103/500... Training loss: 0.0908\n",
      "Epoch: 103/500... Training loss: 0.0575\n",
      "Epoch: 103/500... Training loss: 0.1811\n",
      "Epoch: 103/500... Training loss: 0.2299\n",
      "Epoch: 103/500... Training loss: 0.0590\n",
      "Epoch: 103/500... Training loss: 0.0701\n",
      "Epoch: 103/500... Training loss: 0.2496\n",
      "Epoch: 103/500... Training loss: 0.1663\n",
      "Epoch: 103/500... Training loss: 0.1329\n",
      "Epoch: 103/500... Training loss: 0.2070\n",
      "Epoch: 103/500... Training loss: 0.1581\n",
      "Epoch: 103/500... Training loss: 0.2253\n",
      "Epoch: 103/500... Training loss: 0.1872\n",
      "Epoch: 103/500... Training loss: 0.0818\n",
      "Epoch: 103/500... Training loss: 0.0603\n",
      "Epoch: 103/500... Training loss: 0.1589\n",
      "Epoch: 103/500... Training loss: 0.0630\n",
      "Epoch: 104/500... Training loss: 0.1561\n",
      "Epoch: 104/500... Training loss: 0.1369\n",
      "Epoch: 104/500... Training loss: 0.1393\n",
      "Epoch: 104/500... Training loss: 0.1618\n",
      "Epoch: 104/500... Training loss: 0.1108\n",
      "Epoch: 104/500... Training loss: 0.1742\n",
      "Epoch: 104/500... Training loss: 0.1753\n",
      "Epoch: 104/500... Training loss: 0.1203\n",
      "Epoch: 104/500... Training loss: 0.1592\n",
      "Epoch: 104/500... Training loss: 0.1387\n",
      "Epoch: 104/500... Training loss: 0.1844\n",
      "Epoch: 104/500... Training loss: 0.1841\n",
      "Epoch: 104/500... Training loss: 0.1647\n",
      "Epoch: 104/500... Training loss: 0.1048\n",
      "Epoch: 104/500... Training loss: 0.1206\n",
      "Epoch: 104/500... Training loss: 0.1459\n",
      "Epoch: 104/500... Training loss: 0.1302\n",
      "Epoch: 104/500... Training loss: 0.1817\n",
      "Epoch: 104/500... Training loss: 0.3896\n",
      "Epoch: 104/500... Training loss: 0.0929\n",
      "Epoch: 104/500... Training loss: 0.1040\n",
      "Epoch: 104/500... Training loss: 0.1434\n",
      "Epoch: 104/500... Training loss: 0.1211\n",
      "Epoch: 104/500... Training loss: 0.1270\n",
      "Epoch: 104/500... Training loss: 0.1120\n",
      "Epoch: 104/500... Training loss: 0.0974\n",
      "Epoch: 104/500... Training loss: 0.1406\n",
      "Epoch: 104/500... Training loss: 0.2273\n",
      "Epoch: 104/500... Training loss: 0.0993\n",
      "Epoch: 104/500... Training loss: 0.1454\n",
      "Epoch: 104/500... Training loss: 0.0827\n",
      "Epoch: 105/500... Training loss: 0.1081\n",
      "Epoch: 105/500... Training loss: 0.0812\n",
      "Epoch: 105/500... Training loss: 0.1358\n",
      "Epoch: 105/500... Training loss: 0.3191\n",
      "Epoch: 105/500... Training loss: 0.2371\n",
      "Epoch: 105/500... Training loss: 0.1143\n",
      "Epoch: 105/500... Training loss: 0.2259\n",
      "Epoch: 105/500... Training loss: 0.1903\n",
      "Epoch: 105/500... Training loss: 0.1247\n",
      "Epoch: 105/500... Training loss: 0.1016\n",
      "Epoch: 105/500... Training loss: 0.2079\n",
      "Epoch: 105/500... Training loss: 0.1294\n",
      "Epoch: 105/500... Training loss: 0.1526\n",
      "Epoch: 105/500... Training loss: 0.0861\n",
      "Epoch: 105/500... Training loss: 0.0783\n",
      "Epoch: 105/500... Training loss: 0.1085\n",
      "Epoch: 105/500... Training loss: 0.0736\n",
      "Epoch: 105/500... Training loss: 0.1520\n",
      "Epoch: 105/500... Training loss: 0.1392\n",
      "Epoch: 105/500... Training loss: 0.0597\n",
      "Epoch: 105/500... Training loss: 0.1784\n",
      "Epoch: 105/500... Training loss: 0.0822\n",
      "Epoch: 105/500... Training loss: 0.0749\n",
      "Epoch: 105/500... Training loss: 0.1218\n",
      "Epoch: 105/500... Training loss: 0.1519\n",
      "Epoch: 105/500... Training loss: 0.1770\n",
      "Epoch: 105/500... Training loss: 0.1553\n",
      "Epoch: 105/500... Training loss: 0.1582\n",
      "Epoch: 105/500... Training loss: 0.0633\n",
      "Epoch: 105/500... Training loss: 0.1328\n",
      "Epoch: 105/500... Training loss: 0.0629\n",
      "Epoch: 106/500... Training loss: 0.1990\n",
      "Epoch: 106/500... Training loss: 0.2032\n",
      "Epoch: 106/500... Training loss: 0.1164\n",
      "Epoch: 106/500... Training loss: 0.2040\n",
      "Epoch: 106/500... Training loss: 0.1558\n",
      "Epoch: 106/500... Training loss: 0.1821\n",
      "Epoch: 106/500... Training loss: 0.1118\n",
      "Epoch: 106/500... Training loss: 0.1558\n",
      "Epoch: 106/500... Training loss: 0.0983\n",
      "Epoch: 106/500... Training loss: 0.0881\n",
      "Epoch: 106/500... Training loss: 0.2585\n",
      "Epoch: 106/500... Training loss: 0.2432\n",
      "Epoch: 106/500... Training loss: 0.1817\n",
      "Epoch: 106/500... Training loss: 0.1434\n",
      "Epoch: 106/500... Training loss: 0.1632\n",
      "Epoch: 106/500... Training loss: 0.0575\n",
      "Epoch: 106/500... Training loss: 0.1218\n",
      "Epoch: 106/500... Training loss: 0.2050\n",
      "Epoch: 106/500... Training loss: 0.2688\n",
      "Epoch: 106/500... Training loss: 0.1843\n",
      "Epoch: 106/500... Training loss: 0.0779\n",
      "Epoch: 106/500... Training loss: 0.0703\n",
      "Epoch: 106/500... Training loss: 0.0697\n",
      "Epoch: 106/500... Training loss: 0.0567\n",
      "Epoch: 106/500... Training loss: 0.1503\n",
      "Epoch: 106/500... Training loss: 0.1029\n",
      "Epoch: 106/500... Training loss: 0.0812\n",
      "Epoch: 106/500... Training loss: 0.0921\n",
      "Epoch: 106/500... Training loss: 0.1385\n",
      "Epoch: 106/500... Training loss: 0.1011\n",
      "Epoch: 106/500... Training loss: 0.0658\n",
      "Epoch: 107/500... Training loss: 0.1546\n",
      "Epoch: 107/500... Training loss: 0.1224\n",
      "Epoch: 107/500... Training loss: 0.1143\n",
      "Epoch: 107/500... Training loss: 0.1589\n",
      "Epoch: 107/500... Training loss: 0.2539\n",
      "Epoch: 107/500... Training loss: 0.1062\n",
      "Epoch: 107/500... Training loss: 0.0698\n",
      "Epoch: 107/500... Training loss: 0.1509\n",
      "Epoch: 107/500... Training loss: 0.3081\n",
      "Epoch: 107/500... Training loss: 0.1341\n",
      "Epoch: 107/500... Training loss: 0.1329\n",
      "Epoch: 107/500... Training loss: 0.1847\n",
      "Epoch: 107/500... Training loss: 0.2056\n",
      "Epoch: 107/500... Training loss: 0.1464\n",
      "Epoch: 107/500... Training loss: 0.1339\n",
      "Epoch: 107/500... Training loss: 0.1183\n",
      "Epoch: 107/500... Training loss: 0.0874\n",
      "Epoch: 107/500... Training loss: 0.1389\n",
      "Epoch: 107/500... Training loss: 0.1015\n",
      "Epoch: 107/500... Training loss: 0.0620\n",
      "Epoch: 107/500... Training loss: 0.0830\n",
      "Epoch: 107/500... Training loss: 0.0980\n",
      "Epoch: 107/500... Training loss: 0.2460\n",
      "Epoch: 107/500... Training loss: 0.0366\n",
      "Epoch: 107/500... Training loss: 0.0690\n",
      "Epoch: 107/500... Training loss: 0.0713\n",
      "Epoch: 107/500... Training loss: 0.2088\n",
      "Epoch: 107/500... Training loss: 0.0717\n",
      "Epoch: 107/500... Training loss: 0.0725\n",
      "Epoch: 107/500... Training loss: 0.1269\n",
      "Epoch: 107/500... Training loss: 0.1117\n",
      "Epoch: 108/500... Training loss: 0.1340\n",
      "Epoch: 108/500... Training loss: 0.1268\n",
      "Epoch: 108/500... Training loss: 0.1778\n",
      "Epoch: 108/500... Training loss: 0.1620\n",
      "Epoch: 108/500... Training loss: 0.1675\n",
      "Epoch: 108/500... Training loss: 0.1306\n",
      "Epoch: 108/500... Training loss: 0.1204\n",
      "Epoch: 108/500... Training loss: 0.1572\n",
      "Epoch: 108/500... Training loss: 0.1224\n",
      "Epoch: 108/500... Training loss: 0.0840\n",
      "Epoch: 108/500... Training loss: 0.2187\n",
      "Epoch: 108/500... Training loss: 0.1985\n",
      "Epoch: 108/500... Training loss: 0.1588\n",
      "Epoch: 108/500... Training loss: 0.0878\n",
      "Epoch: 108/500... Training loss: 0.0612\n",
      "Epoch: 108/500... Training loss: 0.1071\n",
      "Epoch: 108/500... Training loss: 0.1540\n",
      "Epoch: 108/500... Training loss: 0.1005\n",
      "Epoch: 108/500... Training loss: 0.1785\n",
      "Epoch: 108/500... Training loss: 0.0720\n",
      "Epoch: 108/500... Training loss: 0.1347\n",
      "Epoch: 108/500... Training loss: 0.1995\n",
      "Epoch: 108/500... Training loss: 0.2125\n",
      "Epoch: 108/500... Training loss: 0.0519\n",
      "Epoch: 108/500... Training loss: 0.0520\n",
      "Epoch: 108/500... Training loss: 0.0716\n",
      "Epoch: 108/500... Training loss: 0.0729\n",
      "Epoch: 108/500... Training loss: 0.0623\n",
      "Epoch: 108/500... Training loss: 0.0617\n",
      "Epoch: 108/500... Training loss: 0.0917\n",
      "Epoch: 108/500... Training loss: 0.0946\n",
      "Epoch: 109/500... Training loss: 0.1058\n",
      "Epoch: 109/500... Training loss: 0.1382\n",
      "Epoch: 109/500... Training loss: 0.0758\n",
      "Epoch: 109/500... Training loss: 0.1618\n",
      "Epoch: 109/500... Training loss: 0.0577\n",
      "Epoch: 109/500... Training loss: 0.1530\n",
      "Epoch: 109/500... Training loss: 0.0982\n",
      "Epoch: 109/500... Training loss: 0.0622\n",
      "Epoch: 109/500... Training loss: 0.1644\n",
      "Epoch: 109/500... Training loss: 0.1190\n",
      "Epoch: 109/500... Training loss: 0.2873\n",
      "Epoch: 109/500... Training loss: 0.1628\n",
      "Epoch: 109/500... Training loss: 0.1453\n",
      "Epoch: 109/500... Training loss: 0.0509\n",
      "Epoch: 109/500... Training loss: 0.0898\n",
      "Epoch: 109/500... Training loss: 0.0796\n",
      "Epoch: 109/500... Training loss: 0.1957\n",
      "Epoch: 109/500... Training loss: 0.0736\n",
      "Epoch: 109/500... Training loss: 0.1519\n",
      "Epoch: 109/500... Training loss: 0.1112\n",
      "Epoch: 109/500... Training loss: 0.0688\n",
      "Epoch: 109/500... Training loss: 0.1951\n",
      "Epoch: 109/500... Training loss: 0.0672\n",
      "Epoch: 109/500... Training loss: 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/500... Training loss: 0.1091\n",
      "Epoch: 109/500... Training loss: 0.1090\n",
      "Epoch: 109/500... Training loss: 0.1838\n",
      "Epoch: 109/500... Training loss: 0.1662\n",
      "Epoch: 109/500... Training loss: 0.0983\n",
      "Epoch: 109/500... Training loss: 0.1506\n",
      "Epoch: 109/500... Training loss: 0.1848\n",
      "Epoch: 110/500... Training loss: 0.1399\n",
      "Epoch: 110/500... Training loss: 0.1411\n",
      "Epoch: 110/500... Training loss: 0.0782\n",
      "Epoch: 110/500... Training loss: 0.1040\n",
      "Epoch: 110/500... Training loss: 0.1063\n",
      "Epoch: 110/500... Training loss: 0.1432\n",
      "Epoch: 110/500... Training loss: 0.1225\n",
      "Epoch: 110/500... Training loss: 0.1192\n",
      "Epoch: 110/500... Training loss: 0.1807\n",
      "Epoch: 110/500... Training loss: 0.1694\n",
      "Epoch: 110/500... Training loss: 0.1892\n",
      "Epoch: 110/500... Training loss: 0.1013\n",
      "Epoch: 110/500... Training loss: 0.2464\n",
      "Epoch: 110/500... Training loss: 0.1623\n",
      "Epoch: 110/500... Training loss: 0.0942\n",
      "Epoch: 110/500... Training loss: 0.0582\n",
      "Epoch: 110/500... Training loss: 0.1394\n",
      "Epoch: 110/500... Training loss: 0.1223\n",
      "Epoch: 110/500... Training loss: 0.1258\n",
      "Epoch: 110/500... Training loss: 0.0822\n",
      "Epoch: 110/500... Training loss: 0.0642\n",
      "Epoch: 110/500... Training loss: 0.0806\n",
      "Epoch: 110/500... Training loss: 0.1398\n",
      "Epoch: 110/500... Training loss: 0.0902\n",
      "Epoch: 110/500... Training loss: 0.1070\n",
      "Epoch: 110/500... Training loss: 0.1266\n",
      "Epoch: 110/500... Training loss: 0.1211\n",
      "Epoch: 110/500... Training loss: 0.1101\n",
      "Epoch: 110/500... Training loss: 0.0505\n",
      "Epoch: 110/500... Training loss: 0.0454\n",
      "Epoch: 110/500... Training loss: 0.1294\n",
      "Epoch: 111/500... Training loss: 0.1692\n",
      "Epoch: 111/500... Training loss: 0.1828\n",
      "Epoch: 111/500... Training loss: 0.1479\n",
      "Epoch: 111/500... Training loss: 0.1848\n",
      "Epoch: 111/500... Training loss: 0.1453\n",
      "Epoch: 111/500... Training loss: 0.1999\n",
      "Epoch: 111/500... Training loss: 0.1334\n",
      "Epoch: 111/500... Training loss: 0.1795\n",
      "Epoch: 111/500... Training loss: 0.1228\n",
      "Epoch: 111/500... Training loss: 0.1022\n",
      "Epoch: 111/500... Training loss: 0.1908\n",
      "Epoch: 111/500... Training loss: 0.1150\n",
      "Epoch: 111/500... Training loss: 0.1968\n",
      "Epoch: 111/500... Training loss: 0.1020\n",
      "Epoch: 111/500... Training loss: 0.2087\n",
      "Epoch: 111/500... Training loss: 0.0503\n",
      "Epoch: 111/500... Training loss: 0.1123\n",
      "Epoch: 111/500... Training loss: 0.1169\n",
      "Epoch: 111/500... Training loss: 0.2179\n",
      "Epoch: 111/500... Training loss: 0.1278\n",
      "Epoch: 111/500... Training loss: 0.1306\n",
      "Epoch: 111/500... Training loss: 0.1139\n",
      "Epoch: 111/500... Training loss: 0.1052\n",
      "Epoch: 111/500... Training loss: 0.0600\n",
      "Epoch: 111/500... Training loss: 0.1097\n",
      "Epoch: 111/500... Training loss: 0.1069\n",
      "Epoch: 111/500... Training loss: 0.1039\n",
      "Epoch: 111/500... Training loss: 0.0928\n",
      "Epoch: 111/500... Training loss: 0.0621\n",
      "Epoch: 111/500... Training loss: 0.1481\n",
      "Epoch: 111/500... Training loss: 0.0973\n",
      "Epoch: 112/500... Training loss: 0.1230\n",
      "Epoch: 112/500... Training loss: 0.1983\n",
      "Epoch: 112/500... Training loss: 0.1123\n",
      "Epoch: 112/500... Training loss: 0.1303\n",
      "Epoch: 112/500... Training loss: 0.0615\n",
      "Epoch: 112/500... Training loss: 0.1014\n",
      "Epoch: 112/500... Training loss: 0.0573\n",
      "Epoch: 112/500... Training loss: 0.0959\n",
      "Epoch: 112/500... Training loss: 0.0753\n",
      "Epoch: 112/500... Training loss: 0.1963\n",
      "Epoch: 112/500... Training loss: 0.2169\n",
      "Epoch: 112/500... Training loss: 0.2947\n",
      "Epoch: 112/500... Training loss: 0.2815\n",
      "Epoch: 112/500... Training loss: 0.0868\n",
      "Epoch: 112/500... Training loss: 0.2402\n",
      "Epoch: 112/500... Training loss: 0.1397\n",
      "Epoch: 112/500... Training loss: 0.0488\n",
      "Epoch: 112/500... Training loss: 0.1297\n",
      "Epoch: 112/500... Training loss: 0.2421\n",
      "Epoch: 112/500... Training loss: 0.1582\n",
      "Epoch: 112/500... Training loss: 0.1624\n",
      "Epoch: 112/500... Training loss: 0.2114\n",
      "Epoch: 112/500... Training loss: 0.1189\n",
      "Epoch: 112/500... Training loss: 0.1508\n",
      "Epoch: 112/500... Training loss: 0.2140\n",
      "Epoch: 112/500... Training loss: 0.2551\n",
      "Epoch: 112/500... Training loss: 0.1259\n",
      "Epoch: 112/500... Training loss: 0.0664\n",
      "Epoch: 112/500... Training loss: 0.1044\n",
      "Epoch: 112/500... Training loss: 0.1324\n",
      "Epoch: 112/500... Training loss: 0.0777\n",
      "Epoch: 113/500... Training loss: 0.3241\n",
      "Epoch: 113/500... Training loss: 0.0645\n",
      "Epoch: 113/500... Training loss: 0.1674\n",
      "Epoch: 113/500... Training loss: 0.1124\n",
      "Epoch: 113/500... Training loss: 0.0843\n",
      "Epoch: 113/500... Training loss: 0.0700\n",
      "Epoch: 113/500... Training loss: 0.1026\n",
      "Epoch: 113/500... Training loss: 0.1399\n",
      "Epoch: 113/500... Training loss: 0.1994\n",
      "Epoch: 113/500... Training loss: 0.0981\n",
      "Epoch: 113/500... Training loss: 0.1670\n",
      "Epoch: 113/500... Training loss: 0.0975\n",
      "Epoch: 113/500... Training loss: 0.1131\n",
      "Epoch: 113/500... Training loss: 0.0704\n",
      "Epoch: 113/500... Training loss: 0.1919\n",
      "Epoch: 113/500... Training loss: 0.1249\n",
      "Epoch: 113/500... Training loss: 0.0828\n",
      "Epoch: 113/500... Training loss: 0.2589\n",
      "Epoch: 113/500... Training loss: 0.1501\n",
      "Epoch: 113/500... Training loss: 0.0752\n",
      "Epoch: 113/500... Training loss: 0.2985\n",
      "Epoch: 113/500... Training loss: 0.1682\n",
      "Epoch: 113/500... Training loss: 0.3325\n",
      "Epoch: 113/500... Training loss: 0.1932\n",
      "Epoch: 113/500... Training loss: 0.0934\n",
      "Epoch: 113/500... Training loss: 0.0569\n",
      "Epoch: 113/500... Training loss: 0.0916\n",
      "Epoch: 113/500... Training loss: 0.2230\n",
      "Epoch: 113/500... Training loss: 0.0454\n",
      "Epoch: 113/500... Training loss: 0.1756\n",
      "Epoch: 113/500... Training loss: 0.1236\n",
      "Epoch: 114/500... Training loss: 0.1543\n",
      "Epoch: 114/500... Training loss: 0.0406\n",
      "Epoch: 114/500... Training loss: 0.1601\n",
      "Epoch: 114/500... Training loss: 0.1357\n",
      "Epoch: 114/500... Training loss: 0.1502\n",
      "Epoch: 114/500... Training loss: 0.1093\n",
      "Epoch: 114/500... Training loss: 0.0542\n",
      "Epoch: 114/500... Training loss: 0.1280\n",
      "Epoch: 114/500... Training loss: 0.0382\n",
      "Epoch: 114/500... Training loss: 0.0612\n",
      "Epoch: 114/500... Training loss: 0.0515\n",
      "Epoch: 114/500... Training loss: 0.2106\n",
      "Epoch: 114/500... Training loss: 0.1488\n",
      "Epoch: 114/500... Training loss: 0.0504\n",
      "Epoch: 114/500... Training loss: 0.0486\n",
      "Epoch: 114/500... Training loss: 0.2159\n",
      "Epoch: 114/500... Training loss: 0.0804\n",
      "Epoch: 114/500... Training loss: 0.1359\n",
      "Epoch: 114/500... Training loss: 0.0886\n",
      "Epoch: 114/500... Training loss: 0.0642\n",
      "Epoch: 114/500... Training loss: 0.1928\n",
      "Epoch: 114/500... Training loss: 0.1227\n",
      "Epoch: 114/500... Training loss: 0.1396\n",
      "Epoch: 114/500... Training loss: 0.1409\n",
      "Epoch: 114/500... Training loss: 0.0685\n",
      "Epoch: 114/500... Training loss: 0.2510\n",
      "Epoch: 114/500... Training loss: 0.1578\n",
      "Epoch: 114/500... Training loss: 0.1171\n",
      "Epoch: 114/500... Training loss: 0.0503\n",
      "Epoch: 114/500... Training loss: 0.1732\n",
      "Epoch: 114/500... Training loss: 0.0665\n",
      "Epoch: 115/500... Training loss: 0.0743\n",
      "Epoch: 115/500... Training loss: 0.0579\n",
      "Epoch: 115/500... Training loss: 0.1777\n",
      "Epoch: 115/500... Training loss: 0.1933\n",
      "Epoch: 115/500... Training loss: 0.1358\n",
      "Epoch: 115/500... Training loss: 0.1913\n",
      "Epoch: 115/500... Training loss: 0.0931\n",
      "Epoch: 115/500... Training loss: 0.1682\n",
      "Epoch: 115/500... Training loss: 0.2244\n",
      "Epoch: 115/500... Training loss: 0.0841\n",
      "Epoch: 115/500... Training loss: 0.0901\n",
      "Epoch: 115/500... Training loss: 0.0757\n",
      "Epoch: 115/500... Training loss: 0.1033\n",
      "Epoch: 115/500... Training loss: 0.0773\n",
      "Epoch: 115/500... Training loss: 0.1127\n",
      "Epoch: 115/500... Training loss: 0.0576\n",
      "Epoch: 115/500... Training loss: 0.0687\n",
      "Epoch: 115/500... Training loss: 0.1038\n",
      "Epoch: 115/500... Training loss: 0.1080\n",
      "Epoch: 115/500... Training loss: 0.0402\n",
      "Epoch: 115/500... Training loss: 0.2156\n",
      "Epoch: 115/500... Training loss: 0.0605\n",
      "Epoch: 115/500... Training loss: 0.0870\n",
      "Epoch: 115/500... Training loss: 0.0469\n",
      "Epoch: 115/500... Training loss: 0.0397\n",
      "Epoch: 115/500... Training loss: 0.1214\n",
      "Epoch: 115/500... Training loss: 0.0977\n",
      "Epoch: 115/500... Training loss: 0.1243\n",
      "Epoch: 115/500... Training loss: 0.1162\n",
      "Epoch: 115/500... Training loss: 0.1759\n",
      "Epoch: 115/500... Training loss: 0.0650\n",
      "Epoch: 116/500... Training loss: 0.2403\n",
      "Epoch: 116/500... Training loss: 0.0855\n",
      "Epoch: 116/500... Training loss: 0.0672\n",
      "Epoch: 116/500... Training loss: 0.0928\n",
      "Epoch: 116/500... Training loss: 0.0552\n",
      "Epoch: 116/500... Training loss: 0.1013\n",
      "Epoch: 116/500... Training loss: 0.0532\n",
      "Epoch: 116/500... Training loss: 0.2059\n",
      "Epoch: 116/500... Training loss: 0.0881\n",
      "Epoch: 116/500... Training loss: 0.0843\n",
      "Epoch: 116/500... Training loss: 0.1074\n",
      "Epoch: 116/500... Training loss: 0.0949\n",
      "Epoch: 116/500... Training loss: 0.1980\n",
      "Epoch: 116/500... Training loss: 0.0630\n",
      "Epoch: 116/500... Training loss: 0.1131\n",
      "Epoch: 116/500... Training loss: 0.0438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116/500... Training loss: 0.0928\n",
      "Epoch: 116/500... Training loss: 0.1630\n",
      "Epoch: 116/500... Training loss: 0.0489\n",
      "Epoch: 116/500... Training loss: 0.1646\n",
      "Epoch: 116/500... Training loss: 0.1398\n",
      "Epoch: 116/500... Training loss: 0.0721\n",
      "Epoch: 116/500... Training loss: 0.0941\n",
      "Epoch: 116/500... Training loss: 0.0942\n",
      "Epoch: 116/500... Training loss: 0.1357\n",
      "Epoch: 116/500... Training loss: 0.1097\n",
      "Epoch: 116/500... Training loss: 0.0717\n",
      "Epoch: 116/500... Training loss: 0.2008\n",
      "Epoch: 116/500... Training loss: 0.0793\n",
      "Epoch: 116/500... Training loss: 0.0270\n",
      "Epoch: 116/500... Training loss: 0.0829\n",
      "Epoch: 117/500... Training loss: 0.0669\n",
      "Epoch: 117/500... Training loss: 0.2510\n",
      "Epoch: 117/500... Training loss: 0.1170\n",
      "Epoch: 117/500... Training loss: 0.1035\n",
      "Epoch: 117/500... Training loss: 0.0890\n",
      "Epoch: 117/500... Training loss: 0.0899\n",
      "Epoch: 117/500... Training loss: 0.0962\n",
      "Epoch: 117/500... Training loss: 0.1367\n",
      "Epoch: 117/500... Training loss: 0.0433\n",
      "Epoch: 117/500... Training loss: 0.1151\n",
      "Epoch: 117/500... Training loss: 0.2199\n",
      "Epoch: 117/500... Training loss: 0.1382\n",
      "Epoch: 117/500... Training loss: 0.1316\n",
      "Epoch: 117/500... Training loss: 0.1502\n",
      "Epoch: 117/500... Training loss: 0.1937\n",
      "Epoch: 117/500... Training loss: 0.0821\n",
      "Epoch: 117/500... Training loss: 0.0319\n",
      "Epoch: 117/500... Training loss: 0.1780\n",
      "Epoch: 117/500... Training loss: 0.1426\n",
      "Epoch: 117/500... Training loss: 0.0803\n",
      "Epoch: 117/500... Training loss: 0.0699\n",
      "Epoch: 117/500... Training loss: 0.2733\n",
      "Epoch: 117/500... Training loss: 0.1214\n",
      "Epoch: 117/500... Training loss: 0.1814\n",
      "Epoch: 117/500... Training loss: 0.1281\n",
      "Epoch: 117/500... Training loss: 0.0665\n",
      "Epoch: 117/500... Training loss: 0.0977\n",
      "Epoch: 117/500... Training loss: 0.0412\n",
      "Epoch: 117/500... Training loss: 0.0967\n",
      "Epoch: 117/500... Training loss: 0.0830\n",
      "Epoch: 117/500... Training loss: 0.0732\n",
      "Epoch: 118/500... Training loss: 0.2399\n",
      "Epoch: 118/500... Training loss: 0.1173\n",
      "Epoch: 118/500... Training loss: 0.0742\n",
      "Epoch: 118/500... Training loss: 0.1469\n",
      "Epoch: 118/500... Training loss: 0.0574\n",
      "Epoch: 118/500... Training loss: 0.1092\n",
      "Epoch: 118/500... Training loss: 0.1792\n",
      "Epoch: 118/500... Training loss: 0.0786\n",
      "Epoch: 118/500... Training loss: 0.2585\n",
      "Epoch: 118/500... Training loss: 0.1458\n",
      "Epoch: 118/500... Training loss: 0.0999\n",
      "Epoch: 118/500... Training loss: 0.0635\n",
      "Epoch: 118/500... Training loss: 0.1578\n",
      "Epoch: 118/500... Training loss: 0.0417\n",
      "Epoch: 118/500... Training loss: 0.1809\n",
      "Epoch: 118/500... Training loss: 0.0487\n",
      "Epoch: 118/500... Training loss: 0.1020\n",
      "Epoch: 118/500... Training loss: 0.1307\n",
      "Epoch: 118/500... Training loss: 0.2068\n",
      "Epoch: 118/500... Training loss: 0.0675\n",
      "Epoch: 118/500... Training loss: 0.1400\n",
      "Epoch: 118/500... Training loss: 0.1221\n",
      "Epoch: 118/500... Training loss: 0.1754\n",
      "Epoch: 118/500... Training loss: 0.1170\n",
      "Epoch: 118/500... Training loss: 0.0780\n",
      "Epoch: 118/500... Training loss: 0.1029\n",
      "Epoch: 118/500... Training loss: 0.0808\n",
      "Epoch: 118/500... Training loss: 0.0451\n",
      "Epoch: 118/500... Training loss: 0.0494\n",
      "Epoch: 118/500... Training loss: 0.0692\n",
      "Epoch: 118/500... Training loss: 0.0688\n",
      "Epoch: 119/500... Training loss: 0.0684\n",
      "Epoch: 119/500... Training loss: 0.1811\n",
      "Epoch: 119/500... Training loss: 0.1693\n",
      "Epoch: 119/500... Training loss: 0.0842\n",
      "Epoch: 119/500... Training loss: 0.0899\n",
      "Epoch: 119/500... Training loss: 0.1327\n",
      "Epoch: 119/500... Training loss: 0.0557\n",
      "Epoch: 119/500... Training loss: 0.2038\n",
      "Epoch: 119/500... Training loss: 0.1296\n",
      "Epoch: 119/500... Training loss: 0.0959\n",
      "Epoch: 119/500... Training loss: 0.0741\n",
      "Epoch: 119/500... Training loss: 0.1910\n",
      "Epoch: 119/500... Training loss: 0.1486\n",
      "Epoch: 119/500... Training loss: 0.0829\n",
      "Epoch: 119/500... Training loss: 0.1183\n",
      "Epoch: 119/500... Training loss: 0.0883\n",
      "Epoch: 119/500... Training loss: 0.1047\n",
      "Epoch: 119/500... Training loss: 0.1306\n",
      "Epoch: 119/500... Training loss: 0.2029\n",
      "Epoch: 119/500... Training loss: 0.0920\n",
      "Epoch: 119/500... Training loss: 0.2516\n",
      "Epoch: 119/500... Training loss: 0.0704\n",
      "Epoch: 119/500... Training loss: 0.2239\n",
      "Epoch: 119/500... Training loss: 0.0912\n",
      "Epoch: 119/500... Training loss: 0.0641\n",
      "Epoch: 119/500... Training loss: 0.1094\n",
      "Epoch: 119/500... Training loss: 0.1135\n",
      "Epoch: 119/500... Training loss: 0.0601\n",
      "Epoch: 119/500... Training loss: 0.1344\n",
      "Epoch: 119/500... Training loss: 0.1728\n",
      "Epoch: 119/500... Training loss: 0.0409\n",
      "Epoch: 120/500... Training loss: 0.0845\n",
      "Epoch: 120/500... Training loss: 0.1068\n",
      "Epoch: 120/500... Training loss: 0.1175\n",
      "Epoch: 120/500... Training loss: 0.0823\n",
      "Epoch: 120/500... Training loss: 0.1790\n",
      "Epoch: 120/500... Training loss: 0.0883\n",
      "Epoch: 120/500... Training loss: 0.0956\n",
      "Epoch: 120/500... Training loss: 0.1207\n",
      "Epoch: 120/500... Training loss: 0.2351\n",
      "Epoch: 120/500... Training loss: 0.0617\n",
      "Epoch: 120/500... Training loss: 0.1729\n",
      "Epoch: 120/500... Training loss: 0.2013\n",
      "Epoch: 120/500... Training loss: 0.2736\n",
      "Epoch: 120/500... Training loss: 0.1781\n",
      "Epoch: 120/500... Training loss: 0.1057\n",
      "Epoch: 120/500... Training loss: 0.1239\n",
      "Epoch: 120/500... Training loss: 0.1535\n",
      "Epoch: 120/500... Training loss: 0.2236\n",
      "Epoch: 120/500... Training loss: 0.1138\n",
      "Epoch: 120/500... Training loss: 0.1849\n",
      "Epoch: 120/500... Training loss: 0.3142\n",
      "Epoch: 120/500... Training loss: 0.2007\n",
      "Epoch: 120/500... Training loss: 0.0720\n",
      "Epoch: 120/500... Training loss: 0.0920\n",
      "Epoch: 120/500... Training loss: 0.0516\n",
      "Epoch: 120/500... Training loss: 0.1128\n",
      "Epoch: 120/500... Training loss: 0.0516\n",
      "Epoch: 120/500... Training loss: 0.1020\n",
      "Epoch: 120/500... Training loss: 0.1407\n",
      "Epoch: 120/500... Training loss: 0.0551\n",
      "Epoch: 120/500... Training loss: 0.0581\n",
      "Epoch: 121/500... Training loss: 0.2095\n",
      "Epoch: 121/500... Training loss: 0.1927\n",
      "Epoch: 121/500... Training loss: 0.1085\n",
      "Epoch: 121/500... Training loss: 0.0702\n",
      "Epoch: 121/500... Training loss: 0.0608\n",
      "Epoch: 121/500... Training loss: 0.1371\n",
      "Epoch: 121/500... Training loss: 0.1843\n",
      "Epoch: 121/500... Training loss: 0.2217\n",
      "Epoch: 121/500... Training loss: 0.0386\n",
      "Epoch: 121/500... Training loss: 0.0493\n",
      "Epoch: 121/500... Training loss: 0.1175\n",
      "Epoch: 121/500... Training loss: 0.2054\n",
      "Epoch: 121/500... Training loss: 0.1972\n",
      "Epoch: 121/500... Training loss: 0.0414\n",
      "Epoch: 121/500... Training loss: 0.1322\n",
      "Epoch: 121/500... Training loss: 0.0750\n",
      "Epoch: 121/500... Training loss: 0.0800\n",
      "Epoch: 121/500... Training loss: 0.1627\n",
      "Epoch: 121/500... Training loss: 0.0727\n",
      "Epoch: 121/500... Training loss: 0.0730\n",
      "Epoch: 121/500... Training loss: 0.1025\n",
      "Epoch: 121/500... Training loss: 0.0488\n",
      "Epoch: 121/500... Training loss: 0.1108\n",
      "Epoch: 121/500... Training loss: 0.1541\n",
      "Epoch: 121/500... Training loss: 0.1937\n",
      "Epoch: 121/500... Training loss: 0.1228\n",
      "Epoch: 121/500... Training loss: 0.1018\n",
      "Epoch: 121/500... Training loss: 0.1921\n",
      "Epoch: 121/500... Training loss: 0.0580\n",
      "Epoch: 121/500... Training loss: 0.0984\n",
      "Epoch: 121/500... Training loss: 0.0509\n",
      "Epoch: 122/500... Training loss: 0.1238\n",
      "Epoch: 122/500... Training loss: 0.1076\n",
      "Epoch: 122/500... Training loss: 0.0738\n",
      "Epoch: 122/500... Training loss: 0.1696\n",
      "Epoch: 122/500... Training loss: 0.0661\n",
      "Epoch: 122/500... Training loss: 0.0686\n",
      "Epoch: 122/500... Training loss: 0.0927\n",
      "Epoch: 122/500... Training loss: 0.1319\n",
      "Epoch: 122/500... Training loss: 0.0362\n",
      "Epoch: 122/500... Training loss: 0.0609\n",
      "Epoch: 122/500... Training loss: 0.1182\n",
      "Epoch: 122/500... Training loss: 0.1502\n",
      "Epoch: 122/500... Training loss: 0.1286\n",
      "Epoch: 122/500... Training loss: 0.0503\n",
      "Epoch: 122/500... Training loss: 0.1515\n",
      "Epoch: 122/500... Training loss: 0.0784\n",
      "Epoch: 122/500... Training loss: 0.0373\n",
      "Epoch: 122/500... Training loss: 0.0531\n",
      "Epoch: 122/500... Training loss: 0.0601\n",
      "Epoch: 122/500... Training loss: 0.0989\n",
      "Epoch: 122/500... Training loss: 0.0991\n",
      "Epoch: 122/500... Training loss: 0.1040\n",
      "Epoch: 122/500... Training loss: 0.1628\n",
      "Epoch: 122/500... Training loss: 0.0222\n",
      "Epoch: 122/500... Training loss: 0.1352\n",
      "Epoch: 122/500... Training loss: 0.1772\n",
      "Epoch: 122/500... Training loss: 0.0536\n",
      "Epoch: 122/500... Training loss: 0.0500\n",
      "Epoch: 122/500... Training loss: 0.0870\n",
      "Epoch: 122/500... Training loss: 0.1632\n",
      "Epoch: 122/500... Training loss: 0.0580\n",
      "Epoch: 123/500... Training loss: 0.1128\n",
      "Epoch: 123/500... Training loss: 0.1060\n",
      "Epoch: 123/500... Training loss: 0.0585\n",
      "Epoch: 123/500... Training loss: 0.0954\n",
      "Epoch: 123/500... Training loss: 0.1048\n",
      "Epoch: 123/500... Training loss: 0.2057\n",
      "Epoch: 123/500... Training loss: 0.2187\n",
      "Epoch: 123/500... Training loss: 0.1055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123/500... Training loss: 0.0327\n",
      "Epoch: 123/500... Training loss: 0.0550\n",
      "Epoch: 123/500... Training loss: 0.1372\n",
      "Epoch: 123/500... Training loss: 0.2212\n",
      "Epoch: 123/500... Training loss: 0.1404\n",
      "Epoch: 123/500... Training loss: 0.0439\n",
      "Epoch: 123/500... Training loss: 0.0778\n",
      "Epoch: 123/500... Training loss: 0.0645\n",
      "Epoch: 123/500... Training loss: 0.1099\n",
      "Epoch: 123/500... Training loss: 0.1633\n",
      "Epoch: 123/500... Training loss: 0.1675\n",
      "Epoch: 123/500... Training loss: 0.0705\n",
      "Epoch: 123/500... Training loss: 0.1209\n",
      "Epoch: 123/500... Training loss: 0.1151\n",
      "Epoch: 123/500... Training loss: 0.1160\n",
      "Epoch: 123/500... Training loss: 0.0748\n",
      "Epoch: 123/500... Training loss: 0.0960\n",
      "Epoch: 123/500... Training loss: 0.0824\n",
      "Epoch: 123/500... Training loss: 0.1197\n",
      "Epoch: 123/500... Training loss: 0.0862\n",
      "Epoch: 123/500... Training loss: 0.0853\n",
      "Epoch: 123/500... Training loss: 0.0802\n",
      "Epoch: 123/500... Training loss: 0.0591\n",
      "Epoch: 124/500... Training loss: 0.1785\n",
      "Epoch: 124/500... Training loss: 0.1037\n",
      "Epoch: 124/500... Training loss: 0.0830\n",
      "Epoch: 124/500... Training loss: 0.0838\n",
      "Epoch: 124/500... Training loss: 0.1178\n",
      "Epoch: 124/500... Training loss: 0.0361\n",
      "Epoch: 124/500... Training loss: 0.0951\n",
      "Epoch: 124/500... Training loss: 0.1343\n",
      "Epoch: 124/500... Training loss: 0.1568\n",
      "Epoch: 124/500... Training loss: 0.1214\n",
      "Epoch: 124/500... Training loss: 0.1656\n",
      "Epoch: 124/500... Training loss: 0.2255\n",
      "Epoch: 124/500... Training loss: 0.1410\n",
      "Epoch: 124/500... Training loss: 0.1160\n",
      "Epoch: 124/500... Training loss: 0.0799\n",
      "Epoch: 124/500... Training loss: 0.0531\n",
      "Epoch: 124/500... Training loss: 0.0835\n",
      "Epoch: 124/500... Training loss: 0.0228\n",
      "Epoch: 124/500... Training loss: 0.0609\n",
      "Epoch: 124/500... Training loss: 0.2068\n",
      "Epoch: 124/500... Training loss: 0.1288\n",
      "Epoch: 124/500... Training loss: 0.0824\n",
      "Epoch: 124/500... Training loss: 0.1049\n",
      "Epoch: 124/500... Training loss: 0.1265\n",
      "Epoch: 124/500... Training loss: 0.0958\n",
      "Epoch: 124/500... Training loss: 0.1610\n",
      "Epoch: 124/500... Training loss: 0.1102\n",
      "Epoch: 124/500... Training loss: 0.1527\n",
      "Epoch: 124/500... Training loss: 0.0509\n",
      "Epoch: 124/500... Training loss: 0.1691\n",
      "Epoch: 124/500... Training loss: 0.1047\n",
      "Epoch: 125/500... Training loss: 0.3123\n",
      "Epoch: 125/500... Training loss: 0.0741\n",
      "Epoch: 125/500... Training loss: 0.0492\n",
      "Epoch: 125/500... Training loss: 0.1335\n",
      "Epoch: 125/500... Training loss: 0.2396\n",
      "Epoch: 125/500... Training loss: 0.0521\n",
      "Epoch: 125/500... Training loss: 0.0525\n",
      "Epoch: 125/500... Training loss: 0.2487\n",
      "Epoch: 125/500... Training loss: 0.0396\n",
      "Epoch: 125/500... Training loss: 0.1015\n",
      "Epoch: 125/500... Training loss: 0.2684\n",
      "Epoch: 125/500... Training loss: 0.1084\n",
      "Epoch: 125/500... Training loss: 0.0896\n",
      "Epoch: 125/500... Training loss: 0.0383\n",
      "Epoch: 125/500... Training loss: 0.0980\n",
      "Epoch: 125/500... Training loss: 0.0536\n",
      "Epoch: 125/500... Training loss: 0.0971\n",
      "Epoch: 125/500... Training loss: 0.1148\n",
      "Epoch: 125/500... Training loss: 0.0403\n",
      "Epoch: 125/500... Training loss: 0.0572\n",
      "Epoch: 125/500... Training loss: 0.0662\n",
      "Epoch: 125/500... Training loss: 0.1804\n",
      "Epoch: 125/500... Training loss: 0.0658\n",
      "Epoch: 125/500... Training loss: 0.1371\n",
      "Epoch: 125/500... Training loss: 0.0984\n",
      "Epoch: 125/500... Training loss: 0.1052\n",
      "Epoch: 125/500... Training loss: 0.0968\n",
      "Epoch: 125/500... Training loss: 0.1118\n",
      "Epoch: 125/500... Training loss: 0.0578\n",
      "Epoch: 125/500... Training loss: 0.1198\n",
      "Epoch: 125/500... Training loss: 0.1344\n",
      "Epoch: 126/500... Training loss: 0.2314\n",
      "Epoch: 126/500... Training loss: 0.1877\n",
      "Epoch: 126/500... Training loss: 0.0629\n",
      "Epoch: 126/500... Training loss: 0.0907\n",
      "Epoch: 126/500... Training loss: 0.0590\n",
      "Epoch: 126/500... Training loss: 0.1333\n",
      "Epoch: 126/500... Training loss: 0.1291\n",
      "Epoch: 126/500... Training loss: 0.0902\n",
      "Epoch: 126/500... Training loss: 0.1539\n",
      "Epoch: 126/500... Training loss: 0.1523\n",
      "Epoch: 126/500... Training loss: 0.1414\n",
      "Epoch: 126/500... Training loss: 0.1448\n",
      "Epoch: 126/500... Training loss: 0.2383\n",
      "Epoch: 126/500... Training loss: 0.1320\n",
      "Epoch: 126/500... Training loss: 0.1826\n",
      "Epoch: 126/500... Training loss: 0.0847\n",
      "Epoch: 126/500... Training loss: 0.0578\n",
      "Epoch: 126/500... Training loss: 0.0728\n",
      "Epoch: 126/500... Training loss: 0.0813\n",
      "Epoch: 126/500... Training loss: 0.0687\n",
      "Epoch: 126/500... Training loss: 0.0710\n",
      "Epoch: 126/500... Training loss: 0.0511\n",
      "Epoch: 126/500... Training loss: 0.0759\n",
      "Epoch: 126/500... Training loss: 0.0523\n",
      "Epoch: 126/500... Training loss: 0.0684\n",
      "Epoch: 126/500... Training loss: 0.1396\n",
      "Epoch: 126/500... Training loss: 0.1123\n",
      "Epoch: 126/500... Training loss: 0.1495\n",
      "Epoch: 126/500... Training loss: 0.0919\n",
      "Epoch: 126/500... Training loss: 0.0756\n",
      "Epoch: 126/500... Training loss: 0.2122\n",
      "Epoch: 127/500... Training loss: 0.1543\n",
      "Epoch: 127/500... Training loss: 0.1019\n",
      "Epoch: 127/500... Training loss: 0.0775\n",
      "Epoch: 127/500... Training loss: 0.1693\n",
      "Epoch: 127/500... Training loss: 0.0983\n",
      "Epoch: 127/500... Training loss: 0.1588\n",
      "Epoch: 127/500... Training loss: 0.0965\n",
      "Epoch: 127/500... Training loss: 0.1214\n",
      "Epoch: 127/500... Training loss: 0.0509\n",
      "Epoch: 127/500... Training loss: 0.0370\n",
      "Epoch: 127/500... Training loss: 0.1473\n",
      "Epoch: 127/500... Training loss: 0.0915\n",
      "Epoch: 127/500... Training loss: 0.0735\n",
      "Epoch: 127/500... Training loss: 0.2461\n",
      "Epoch: 127/500... Training loss: 0.0826\n",
      "Epoch: 127/500... Training loss: 0.0540\n",
      "Epoch: 127/500... Training loss: 0.2302\n",
      "Epoch: 127/500... Training loss: 0.0600\n",
      "Epoch: 127/500... Training loss: 0.0991\n",
      "Epoch: 127/500... Training loss: 0.1175\n",
      "Epoch: 127/500... Training loss: 0.0712\n",
      "Epoch: 127/500... Training loss: 0.0360\n",
      "Epoch: 127/500... Training loss: 0.0811\n",
      "Epoch: 127/500... Training loss: 0.0635\n",
      "Epoch: 127/500... Training loss: 0.1421\n",
      "Epoch: 127/500... Training loss: 0.1485\n",
      "Epoch: 127/500... Training loss: 0.1149\n",
      "Epoch: 127/500... Training loss: 0.1377\n",
      "Epoch: 127/500... Training loss: 0.0667\n",
      "Epoch: 127/500... Training loss: 0.0808\n",
      "Epoch: 127/500... Training loss: 0.1006\n",
      "Epoch: 128/500... Training loss: 0.1288\n",
      "Epoch: 128/500... Training loss: 0.0516\n",
      "Epoch: 128/500... Training loss: 0.0708\n",
      "Epoch: 128/500... Training loss: 0.1882\n",
      "Epoch: 128/500... Training loss: 0.0578\n",
      "Epoch: 128/500... Training loss: 0.2447\n",
      "Epoch: 128/500... Training loss: 0.2382\n",
      "Epoch: 128/500... Training loss: 0.1315\n",
      "Epoch: 128/500... Training loss: 0.0801\n",
      "Epoch: 128/500... Training loss: 0.0385\n",
      "Epoch: 128/500... Training loss: 0.1630\n",
      "Epoch: 128/500... Training loss: 0.1018\n",
      "Epoch: 128/500... Training loss: 0.1313\n",
      "Epoch: 128/500... Training loss: 0.0438\n",
      "Epoch: 128/500... Training loss: 0.0863\n",
      "Epoch: 128/500... Training loss: 0.1772\n",
      "Epoch: 128/500... Training loss: 0.1046\n",
      "Epoch: 128/500... Training loss: 0.1076\n",
      "Epoch: 128/500... Training loss: 0.1137\n",
      "Epoch: 128/500... Training loss: 0.1353\n",
      "Epoch: 128/500... Training loss: 0.0559\n",
      "Epoch: 128/500... Training loss: 0.0554\n",
      "Epoch: 128/500... Training loss: 0.1557\n",
      "Epoch: 128/500... Training loss: 0.0375\n",
      "Epoch: 128/500... Training loss: 0.0449\n",
      "Epoch: 128/500... Training loss: 0.0760\n",
      "Epoch: 128/500... Training loss: 0.1556\n",
      "Epoch: 128/500... Training loss: 0.0365\n",
      "Epoch: 128/500... Training loss: 0.0840\n",
      "Epoch: 128/500... Training loss: 0.1085\n",
      "Epoch: 128/500... Training loss: 0.0668\n",
      "Epoch: 129/500... Training loss: 0.1086\n",
      "Epoch: 129/500... Training loss: 0.0591\n",
      "Epoch: 129/500... Training loss: 0.1071\n",
      "Epoch: 129/500... Training loss: 0.2005\n",
      "Epoch: 129/500... Training loss: 0.0833\n",
      "Epoch: 129/500... Training loss: 0.0923\n",
      "Epoch: 129/500... Training loss: 0.0869\n",
      "Epoch: 129/500... Training loss: 0.1036\n",
      "Epoch: 129/500... Training loss: 0.0567\n",
      "Epoch: 129/500... Training loss: 0.0734\n",
      "Epoch: 129/500... Training loss: 0.1885\n",
      "Epoch: 129/500... Training loss: 0.1637\n",
      "Epoch: 129/500... Training loss: 0.0996\n",
      "Epoch: 129/500... Training loss: 0.0823\n",
      "Epoch: 129/500... Training loss: 0.0396\n",
      "Epoch: 129/500... Training loss: 0.0731\n",
      "Epoch: 129/500... Training loss: 0.0657\n",
      "Epoch: 129/500... Training loss: 0.0955\n",
      "Epoch: 129/500... Training loss: 0.2489\n",
      "Epoch: 129/500... Training loss: 0.0743\n",
      "Epoch: 129/500... Training loss: 0.0303\n",
      "Epoch: 129/500... Training loss: 0.0516\n",
      "Epoch: 129/500... Training loss: 0.0229\n",
      "Epoch: 129/500... Training loss: 0.1637\n",
      "Epoch: 129/500... Training loss: 0.0723\n",
      "Epoch: 129/500... Training loss: 0.0391\n",
      "Epoch: 129/500... Training loss: 0.1020\n",
      "Epoch: 129/500... Training loss: 0.0389\n",
      "Epoch: 129/500... Training loss: 0.1205\n",
      "Epoch: 129/500... Training loss: 0.0508\n",
      "Epoch: 129/500... Training loss: 0.0643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130/500... Training loss: 0.0971\n",
      "Epoch: 130/500... Training loss: 0.0650\n",
      "Epoch: 130/500... Training loss: 0.0928\n",
      "Epoch: 130/500... Training loss: 0.0881\n",
      "Epoch: 130/500... Training loss: 0.0568\n",
      "Epoch: 130/500... Training loss: 0.1046\n",
      "Epoch: 130/500... Training loss: 0.0839\n",
      "Epoch: 130/500... Training loss: 0.0659\n",
      "Epoch: 130/500... Training loss: 0.0958\n",
      "Epoch: 130/500... Training loss: 0.1104\n",
      "Epoch: 130/500... Training loss: 0.0805\n",
      "Epoch: 130/500... Training loss: 0.1253\n",
      "Epoch: 130/500... Training loss: 0.0867\n",
      "Epoch: 130/500... Training loss: 0.2240\n",
      "Epoch: 130/500... Training loss: 0.0777\n",
      "Epoch: 130/500... Training loss: 0.1209\n",
      "Epoch: 130/500... Training loss: 0.0595\n",
      "Epoch: 130/500... Training loss: 0.0758\n",
      "Epoch: 130/500... Training loss: 0.1453\n",
      "Epoch: 130/500... Training loss: 0.1620\n",
      "Epoch: 130/500... Training loss: 0.0878\n",
      "Epoch: 130/500... Training loss: 0.1098\n",
      "Epoch: 130/500... Training loss: 0.0855\n",
      "Epoch: 130/500... Training loss: 0.0617\n",
      "Epoch: 130/500... Training loss: 0.1177\n",
      "Epoch: 130/500... Training loss: 0.0754\n",
      "Epoch: 130/500... Training loss: 0.0942\n",
      "Epoch: 130/500... Training loss: 0.0386\n",
      "Epoch: 130/500... Training loss: 0.0921\n",
      "Epoch: 130/500... Training loss: 0.0252\n",
      "Epoch: 130/500... Training loss: 0.0600\n",
      "Epoch: 131/500... Training loss: 0.0587\n",
      "Epoch: 131/500... Training loss: 0.0798\n",
      "Epoch: 131/500... Training loss: 0.0541\n",
      "Epoch: 131/500... Training loss: 0.1248\n",
      "Epoch: 131/500... Training loss: 0.1676\n",
      "Epoch: 131/500... Training loss: 0.1508\n",
      "Epoch: 131/500... Training loss: 0.0944\n",
      "Epoch: 131/500... Training loss: 0.0585\n",
      "Epoch: 131/500... Training loss: 0.0516\n",
      "Epoch: 131/500... Training loss: 0.0549\n",
      "Epoch: 131/500... Training loss: 0.1458\n",
      "Epoch: 131/500... Training loss: 0.1189\n",
      "Epoch: 131/500... Training loss: 0.0944\n",
      "Epoch: 131/500... Training loss: 0.1548\n",
      "Epoch: 131/500... Training loss: 0.1120\n",
      "Epoch: 131/500... Training loss: 0.1022\n",
      "Epoch: 131/500... Training loss: 0.0670\n",
      "Epoch: 131/500... Training loss: 0.0340\n",
      "Epoch: 131/500... Training loss: 0.0810\n",
      "Epoch: 131/500... Training loss: 0.0261\n",
      "Epoch: 131/500... Training loss: 0.0774\n",
      "Epoch: 131/500... Training loss: 0.0287\n",
      "Epoch: 131/500... Training loss: 0.0287\n",
      "Epoch: 131/500... Training loss: 0.0334\n",
      "Epoch: 131/500... Training loss: 0.0272\n",
      "Epoch: 131/500... Training loss: 0.0608\n",
      "Epoch: 131/500... Training loss: 0.0733\n",
      "Epoch: 131/500... Training loss: 0.0520\n",
      "Epoch: 131/500... Training loss: 0.0200\n",
      "Epoch: 131/500... Training loss: 0.0800\n",
      "Epoch: 131/500... Training loss: 0.0145\n",
      "Epoch: 132/500... Training loss: 0.0524\n",
      "Epoch: 132/500... Training loss: 0.0562\n",
      "Epoch: 132/500... Training loss: 0.0669\n",
      "Epoch: 132/500... Training loss: 0.1410\n",
      "Epoch: 132/500... Training loss: 0.1541\n",
      "Epoch: 132/500... Training loss: 0.1140\n",
      "Epoch: 132/500... Training loss: 0.1300\n",
      "Epoch: 132/500... Training loss: 0.0689\n",
      "Epoch: 132/500... Training loss: 0.0896\n",
      "Epoch: 132/500... Training loss: 0.0349\n",
      "Epoch: 132/500... Training loss: 0.1737\n",
      "Epoch: 132/500... Training loss: 0.1155\n",
      "Epoch: 132/500... Training loss: 0.1441\n",
      "Epoch: 132/500... Training loss: 0.0522\n",
      "Epoch: 132/500... Training loss: 0.0980\n",
      "Epoch: 132/500... Training loss: 0.0590\n",
      "Epoch: 132/500... Training loss: 0.0977\n",
      "Epoch: 132/500... Training loss: 0.1158\n",
      "Epoch: 132/500... Training loss: 0.1045\n",
      "Epoch: 132/500... Training loss: 0.1576\n",
      "Epoch: 132/500... Training loss: 0.1209\n",
      "Epoch: 132/500... Training loss: 0.0954\n",
      "Epoch: 132/500... Training loss: 0.0684\n",
      "Epoch: 132/500... Training loss: 0.0482\n",
      "Epoch: 132/500... Training loss: 0.0707\n",
      "Epoch: 132/500... Training loss: 0.1263\n",
      "Epoch: 132/500... Training loss: 0.0520\n",
      "Epoch: 132/500... Training loss: 0.0271\n",
      "Epoch: 132/500... Training loss: 0.0954\n",
      "Epoch: 132/500... Training loss: 0.0564\n",
      "Epoch: 132/500... Training loss: 0.0580\n",
      "Epoch: 133/500... Training loss: 0.0344\n",
      "Epoch: 133/500... Training loss: 0.0912\n",
      "Epoch: 133/500... Training loss: 0.0653\n",
      "Epoch: 133/500... Training loss: 0.1007\n",
      "Epoch: 133/500... Training loss: 0.1064\n",
      "Epoch: 133/500... Training loss: 0.0568\n",
      "Epoch: 133/500... Training loss: 0.1164\n",
      "Epoch: 133/500... Training loss: 0.0851\n",
      "Epoch: 133/500... Training loss: 0.0699\n",
      "Epoch: 133/500... Training loss: 0.0987\n",
      "Epoch: 133/500... Training loss: 0.1589\n",
      "Epoch: 133/500... Training loss: 0.2470\n",
      "Epoch: 133/500... Training loss: 0.0978\n",
      "Epoch: 133/500... Training loss: 0.0838\n",
      "Epoch: 133/500... Training loss: 0.1950\n",
      "Epoch: 133/500... Training loss: 0.0292\n",
      "Epoch: 133/500... Training loss: 0.1072\n",
      "Epoch: 133/500... Training loss: 0.1145\n",
      "Epoch: 133/500... Training loss: 0.1761\n",
      "Epoch: 133/500... Training loss: 0.0619\n",
      "Epoch: 133/500... Training loss: 0.1368\n",
      "Epoch: 133/500... Training loss: 0.1337\n",
      "Epoch: 133/500... Training loss: 0.0745\n",
      "Epoch: 133/500... Training loss: 0.0530\n",
      "Epoch: 133/500... Training loss: 0.0495\n",
      "Epoch: 133/500... Training loss: 0.2705\n",
      "Epoch: 133/500... Training loss: 0.0631\n",
      "Epoch: 133/500... Training loss: 0.1752\n",
      "Epoch: 133/500... Training loss: 0.0798\n",
      "Epoch: 133/500... Training loss: 0.1159\n",
      "Epoch: 133/500... Training loss: 0.0845\n",
      "Epoch: 134/500... Training loss: 0.1229\n",
      "Epoch: 134/500... Training loss: 0.1602\n",
      "Epoch: 134/500... Training loss: 0.0620\n",
      "Epoch: 134/500... Training loss: 0.0785\n",
      "Epoch: 134/500... Training loss: 0.0858\n",
      "Epoch: 134/500... Training loss: 0.0613\n",
      "Epoch: 134/500... Training loss: 0.2494\n",
      "Epoch: 134/500... Training loss: 0.0697\n",
      "Epoch: 134/500... Training loss: 0.0860\n",
      "Epoch: 134/500... Training loss: 0.1378\n",
      "Epoch: 134/500... Training loss: 0.1150\n",
      "Epoch: 134/500... Training loss: 0.1140\n",
      "Epoch: 134/500... Training loss: 0.1048\n",
      "Epoch: 134/500... Training loss: 0.0779\n",
      "Epoch: 134/500... Training loss: 0.1884\n",
      "Epoch: 134/500... Training loss: 0.0256\n",
      "Epoch: 134/500... Training loss: 0.0843\n",
      "Epoch: 134/500... Training loss: 0.0673\n",
      "Epoch: 134/500... Training loss: 0.1030\n",
      "Epoch: 134/500... Training loss: 0.0733\n",
      "Epoch: 134/500... Training loss: 0.1490\n",
      "Epoch: 134/500... Training loss: 0.1056\n",
      "Epoch: 134/500... Training loss: 0.1227\n",
      "Epoch: 134/500... Training loss: 0.0249\n",
      "Epoch: 134/500... Training loss: 0.0540\n",
      "Epoch: 134/500... Training loss: 0.1994\n",
      "Epoch: 134/500... Training loss: 0.0240\n",
      "Epoch: 134/500... Training loss: 0.0358\n",
      "Epoch: 134/500... Training loss: 0.0649\n",
      "Epoch: 134/500... Training loss: 0.1070\n",
      "Epoch: 134/500... Training loss: 0.1213\n",
      "Epoch: 135/500... Training loss: 0.0542\n",
      "Epoch: 135/500... Training loss: 0.1231\n",
      "Epoch: 135/500... Training loss: 0.0944\n",
      "Epoch: 135/500... Training loss: 0.1765\n",
      "Epoch: 135/500... Training loss: 0.1069\n",
      "Epoch: 135/500... Training loss: 0.0730\n",
      "Epoch: 135/500... Training loss: 0.0480\n",
      "Epoch: 135/500... Training loss: 0.2502\n",
      "Epoch: 135/500... Training loss: 0.0578\n",
      "Epoch: 135/500... Training loss: 0.0597\n",
      "Epoch: 135/500... Training loss: 0.1509\n",
      "Epoch: 135/500... Training loss: 0.0849\n",
      "Epoch: 135/500... Training loss: 0.0419\n",
      "Epoch: 135/500... Training loss: 0.0252\n",
      "Epoch: 135/500... Training loss: 0.1147\n",
      "Epoch: 135/500... Training loss: 0.1055\n",
      "Epoch: 135/500... Training loss: 0.0666\n",
      "Epoch: 135/500... Training loss: 0.0628\n",
      "Epoch: 135/500... Training loss: 0.0441\n",
      "Epoch: 135/500... Training loss: 0.0828\n",
      "Epoch: 135/500... Training loss: 0.1407\n",
      "Epoch: 135/500... Training loss: 0.0345\n",
      "Epoch: 135/500... Training loss: 0.1081\n",
      "Epoch: 135/500... Training loss: 0.0608\n",
      "Epoch: 135/500... Training loss: 0.0666\n",
      "Epoch: 135/500... Training loss: 0.0282\n",
      "Epoch: 135/500... Training loss: 0.0902\n",
      "Epoch: 135/500... Training loss: 0.0720\n",
      "Epoch: 135/500... Training loss: 0.0462\n",
      "Epoch: 135/500... Training loss: 0.0956\n",
      "Epoch: 135/500... Training loss: 0.0778\n",
      "Epoch: 136/500... Training loss: 0.2036\n",
      "Epoch: 136/500... Training loss: 0.1154\n",
      "Epoch: 136/500... Training loss: 0.0635\n",
      "Epoch: 136/500... Training loss: 0.0767\n",
      "Epoch: 136/500... Training loss: 0.0877\n",
      "Epoch: 136/500... Training loss: 0.0354\n",
      "Epoch: 136/500... Training loss: 0.1567\n",
      "Epoch: 136/500... Training loss: 0.0965\n",
      "Epoch: 136/500... Training loss: 0.1001\n",
      "Epoch: 136/500... Training loss: 0.0844\n",
      "Epoch: 136/500... Training loss: 0.1752\n",
      "Epoch: 136/500... Training loss: 0.1550\n",
      "Epoch: 136/500... Training loss: 0.1427\n",
      "Epoch: 136/500... Training loss: 0.0585\n",
      "Epoch: 136/500... Training loss: 0.0728\n",
      "Epoch: 136/500... Training loss: 0.0207\n",
      "Epoch: 136/500... Training loss: 0.1091\n",
      "Epoch: 136/500... Training loss: 0.0489\n",
      "Epoch: 136/500... Training loss: 0.0860\n",
      "Epoch: 136/500... Training loss: 0.0355\n",
      "Epoch: 136/500... Training loss: 0.0636\n",
      "Epoch: 136/500... Training loss: 0.0493\n",
      "Epoch: 136/500... Training loss: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/500... Training loss: 0.0837\n",
      "Epoch: 136/500... Training loss: 0.1227\n",
      "Epoch: 136/500... Training loss: 0.0271\n",
      "Epoch: 136/500... Training loss: 0.0608\n",
      "Epoch: 136/500... Training loss: 0.0403\n",
      "Epoch: 136/500... Training loss: 0.1046\n",
      "Epoch: 136/500... Training loss: 0.0941\n",
      "Epoch: 136/500... Training loss: 0.1046\n",
      "Epoch: 137/500... Training loss: 0.0462\n",
      "Epoch: 137/500... Training loss: 0.1467\n",
      "Epoch: 137/500... Training loss: 0.0521\n",
      "Epoch: 137/500... Training loss: 0.0750\n",
      "Epoch: 137/500... Training loss: 0.0377\n",
      "Epoch: 137/500... Training loss: 0.1238\n",
      "Epoch: 137/500... Training loss: 0.1341\n",
      "Epoch: 137/500... Training loss: 0.1196\n",
      "Epoch: 137/500... Training loss: 0.0592\n",
      "Epoch: 137/500... Training loss: 0.1083\n",
      "Epoch: 137/500... Training loss: 0.0513\n",
      "Epoch: 137/500... Training loss: 0.1052\n",
      "Epoch: 137/500... Training loss: 0.1714\n",
      "Epoch: 137/500... Training loss: 0.0347\n",
      "Epoch: 137/500... Training loss: 0.2300\n",
      "Epoch: 137/500... Training loss: 0.0909\n",
      "Epoch: 137/500... Training loss: 0.0399\n",
      "Epoch: 137/500... Training loss: 0.0793\n",
      "Epoch: 137/500... Training loss: 0.1308\n",
      "Epoch: 137/500... Training loss: 0.0156\n",
      "Epoch: 137/500... Training loss: 0.0667\n",
      "Epoch: 137/500... Training loss: 0.0421\n",
      "Epoch: 137/500... Training loss: 0.1804\n",
      "Epoch: 137/500... Training loss: 0.0601\n",
      "Epoch: 137/500... Training loss: 0.0607\n",
      "Epoch: 137/500... Training loss: 0.0143\n",
      "Epoch: 137/500... Training loss: 0.0934\n",
      "Epoch: 137/500... Training loss: 0.0532\n",
      "Epoch: 137/500... Training loss: 0.1938\n",
      "Epoch: 137/500... Training loss: 0.0788\n",
      "Epoch: 137/500... Training loss: 0.0986\n",
      "Epoch: 138/500... Training loss: 0.1661\n",
      "Epoch: 138/500... Training loss: 0.0575\n",
      "Epoch: 138/500... Training loss: 0.1054\n",
      "Epoch: 138/500... Training loss: 0.1117\n",
      "Epoch: 138/500... Training loss: 0.1262\n",
      "Epoch: 138/500... Training loss: 0.1196\n",
      "Epoch: 138/500... Training loss: 0.0472\n",
      "Epoch: 138/500... Training loss: 0.2017\n",
      "Epoch: 138/500... Training loss: 0.0778\n",
      "Epoch: 138/500... Training loss: 0.1668\n",
      "Epoch: 138/500... Training loss: 0.0859\n",
      "Epoch: 138/500... Training loss: 0.0751\n",
      "Epoch: 138/500... Training loss: 0.1207\n",
      "Epoch: 138/500... Training loss: 0.0758\n",
      "Epoch: 138/500... Training loss: 0.0495\n",
      "Epoch: 138/500... Training loss: 0.0995\n",
      "Epoch: 138/500... Training loss: 0.1340\n",
      "Epoch: 138/500... Training loss: 0.1605\n",
      "Epoch: 138/500... Training loss: 0.0677\n",
      "Epoch: 138/500... Training loss: 0.2153\n",
      "Epoch: 138/500... Training loss: 0.0361\n",
      "Epoch: 138/500... Training loss: 0.0595\n",
      "Epoch: 138/500... Training loss: 0.0775\n",
      "Epoch: 138/500... Training loss: 0.0526\n",
      "Epoch: 138/500... Training loss: 0.1808\n",
      "Epoch: 138/500... Training loss: 0.0482\n",
      "Epoch: 138/500... Training loss: 0.0673\n",
      "Epoch: 138/500... Training loss: 0.1884\n",
      "Epoch: 138/500... Training loss: 0.0842\n",
      "Epoch: 138/500... Training loss: 0.0650\n",
      "Epoch: 138/500... Training loss: 0.1275\n",
      "Epoch: 139/500... Training loss: 0.1686\n",
      "Epoch: 139/500... Training loss: 0.0734\n",
      "Epoch: 139/500... Training loss: 0.1030\n",
      "Epoch: 139/500... Training loss: 0.1042\n",
      "Epoch: 139/500... Training loss: 0.0956\n",
      "Epoch: 139/500... Training loss: 0.1128\n",
      "Epoch: 139/500... Training loss: 0.0544\n",
      "Epoch: 139/500... Training loss: 0.0711\n",
      "Epoch: 139/500... Training loss: 0.1241\n",
      "Epoch: 139/500... Training loss: 0.1599\n",
      "Epoch: 139/500... Training loss: 0.0920\n",
      "Epoch: 139/500... Training loss: 0.0886\n",
      "Epoch: 139/500... Training loss: 0.0685\n",
      "Epoch: 139/500... Training loss: 0.2024\n",
      "Epoch: 139/500... Training loss: 0.1321\n",
      "Epoch: 139/500... Training loss: 0.1084\n",
      "Epoch: 139/500... Training loss: 0.0631\n",
      "Epoch: 139/500... Training loss: 0.2116\n",
      "Epoch: 139/500... Training loss: 0.1828\n",
      "Epoch: 139/500... Training loss: 0.0295\n",
      "Epoch: 139/500... Training loss: 0.0684\n",
      "Epoch: 139/500... Training loss: 0.1177\n",
      "Epoch: 139/500... Training loss: 0.0622\n",
      "Epoch: 139/500... Training loss: 0.1003\n",
      "Epoch: 139/500... Training loss: 0.0874\n",
      "Epoch: 139/500... Training loss: 0.0774\n",
      "Epoch: 139/500... Training loss: 0.0863\n",
      "Epoch: 139/500... Training loss: 0.1332\n",
      "Epoch: 139/500... Training loss: 0.0675\n",
      "Epoch: 139/500... Training loss: 0.0805\n",
      "Epoch: 139/500... Training loss: 0.0346\n",
      "Epoch: 140/500... Training loss: 0.0624\n",
      "Epoch: 140/500... Training loss: 0.0677\n",
      "Epoch: 140/500... Training loss: 0.2193\n",
      "Epoch: 140/500... Training loss: 0.1190\n",
      "Epoch: 140/500... Training loss: 0.0613\n",
      "Epoch: 140/500... Training loss: 0.0993\n",
      "Epoch: 140/500... Training loss: 0.0790\n",
      "Epoch: 140/500... Training loss: 0.1818\n",
      "Epoch: 140/500... Training loss: 0.0732\n",
      "Epoch: 140/500... Training loss: 0.0694\n",
      "Epoch: 140/500... Training loss: 0.1182\n",
      "Epoch: 140/500... Training loss: 0.1164\n",
      "Epoch: 140/500... Training loss: 0.0829\n",
      "Epoch: 140/500... Training loss: 0.1031\n",
      "Epoch: 140/500... Training loss: 0.1185\n",
      "Epoch: 140/500... Training loss: 0.0425\n",
      "Epoch: 140/500... Training loss: 0.1223\n",
      "Epoch: 140/500... Training loss: 0.0658\n",
      "Epoch: 140/500... Training loss: 0.0253\n",
      "Epoch: 140/500... Training loss: 0.0720\n",
      "Epoch: 140/500... Training loss: 0.0512\n",
      "Epoch: 140/500... Training loss: 0.0374\n",
      "Epoch: 140/500... Training loss: 0.1542\n",
      "Epoch: 140/500... Training loss: 0.0564\n",
      "Epoch: 140/500... Training loss: 0.1097\n",
      "Epoch: 140/500... Training loss: 0.0994\n",
      "Epoch: 140/500... Training loss: 0.0622\n",
      "Epoch: 140/500... Training loss: 0.0294\n",
      "Epoch: 140/500... Training loss: 0.0687\n",
      "Epoch: 140/500... Training loss: 0.1229\n",
      "Epoch: 140/500... Training loss: 0.1397\n",
      "Epoch: 141/500... Training loss: 0.0383\n",
      "Epoch: 141/500... Training loss: 0.0661\n",
      "Epoch: 141/500... Training loss: 0.1100\n",
      "Epoch: 141/500... Training loss: 0.1222\n",
      "Epoch: 141/500... Training loss: 0.0865\n",
      "Epoch: 141/500... Training loss: 0.1733\n",
      "Epoch: 141/500... Training loss: 0.1022\n",
      "Epoch: 141/500... Training loss: 0.1186\n",
      "Epoch: 141/500... Training loss: 0.0697\n",
      "Epoch: 141/500... Training loss: 0.0787\n",
      "Epoch: 141/500... Training loss: 0.1183\n",
      "Epoch: 141/500... Training loss: 0.2319\n",
      "Epoch: 141/500... Training loss: 0.1748\n",
      "Epoch: 141/500... Training loss: 0.3589\n",
      "Epoch: 141/500... Training loss: 0.1353\n",
      "Epoch: 141/500... Training loss: 0.0301\n",
      "Epoch: 141/500... Training loss: 0.1154\n",
      "Epoch: 141/500... Training loss: 0.0255\n",
      "Epoch: 141/500... Training loss: 0.0823\n",
      "Epoch: 141/500... Training loss: 0.0747\n",
      "Epoch: 141/500... Training loss: 0.0754\n",
      "Epoch: 141/500... Training loss: 0.1174\n",
      "Epoch: 141/500... Training loss: 0.0815\n",
      "Epoch: 141/500... Training loss: 0.0967\n",
      "Epoch: 141/500... Training loss: 0.1656\n",
      "Epoch: 141/500... Training loss: 0.0476\n",
      "Epoch: 141/500... Training loss: 0.1678\n",
      "Epoch: 141/500... Training loss: 0.1032\n",
      "Epoch: 141/500... Training loss: 0.0344\n",
      "Epoch: 141/500... Training loss: 0.0931\n",
      "Epoch: 141/500... Training loss: 0.0408\n",
      "Epoch: 142/500... Training loss: 0.0238\n",
      "Epoch: 142/500... Training loss: 0.0470\n",
      "Epoch: 142/500... Training loss: 0.1294\n",
      "Epoch: 142/500... Training loss: 0.1372\n",
      "Epoch: 142/500... Training loss: 0.0586\n",
      "Epoch: 142/500... Training loss: 0.2443\n",
      "Epoch: 142/500... Training loss: 0.1519\n",
      "Epoch: 142/500... Training loss: 0.0978\n",
      "Epoch: 142/500... Training loss: 0.1030\n",
      "Epoch: 142/500... Training loss: 0.0701\n",
      "Epoch: 142/500... Training loss: 0.0778\n",
      "Epoch: 142/500... Training loss: 0.1714\n",
      "Epoch: 142/500... Training loss: 0.1112\n",
      "Epoch: 142/500... Training loss: 0.0803\n",
      "Epoch: 142/500... Training loss: 0.0917\n",
      "Epoch: 142/500... Training loss: 0.0807\n",
      "Epoch: 142/500... Training loss: 0.1056\n",
      "Epoch: 142/500... Training loss: 0.1897\n",
      "Epoch: 142/500... Training loss: 0.1005\n",
      "Epoch: 142/500... Training loss: 0.0750\n",
      "Epoch: 142/500... Training loss: 0.0940\n",
      "Epoch: 142/500... Training loss: 0.0594\n",
      "Epoch: 142/500... Training loss: 0.0909\n",
      "Epoch: 142/500... Training loss: 0.0933\n",
      "Epoch: 142/500... Training loss: 0.1366\n",
      "Epoch: 142/500... Training loss: 0.0897\n",
      "Epoch: 142/500... Training loss: 0.0518\n",
      "Epoch: 142/500... Training loss: 0.0519\n",
      "Epoch: 142/500... Training loss: 0.0368\n",
      "Epoch: 142/500... Training loss: 0.0602\n",
      "Epoch: 142/500... Training loss: 0.1690\n",
      "Epoch: 143/500... Training loss: 0.1785\n",
      "Epoch: 143/500... Training loss: 0.1055\n",
      "Epoch: 143/500... Training loss: 0.1105\n",
      "Epoch: 143/500... Training loss: 0.1282\n",
      "Epoch: 143/500... Training loss: 0.0720\n",
      "Epoch: 143/500... Training loss: 0.1553\n",
      "Epoch: 143/500... Training loss: 0.0576\n",
      "Epoch: 143/500... Training loss: 0.1879\n",
      "Epoch: 143/500... Training loss: 0.1026\n",
      "Epoch: 143/500... Training loss: 0.1155\n",
      "Epoch: 143/500... Training loss: 0.1455\n",
      "Epoch: 143/500... Training loss: 0.1257\n",
      "Epoch: 143/500... Training loss: 0.1594\n",
      "Epoch: 143/500... Training loss: 0.0902\n",
      "Epoch: 143/500... Training loss: 0.0655\n",
      "Epoch: 143/500... Training loss: 0.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143/500... Training loss: 0.1912\n",
      "Epoch: 143/500... Training loss: 0.0138\n",
      "Epoch: 143/500... Training loss: 0.1666\n",
      "Epoch: 143/500... Training loss: 0.0843\n",
      "Epoch: 143/500... Training loss: 0.0891\n",
      "Epoch: 143/500... Training loss: 0.0953\n",
      "Epoch: 143/500... Training loss: 0.1434\n",
      "Epoch: 143/500... Training loss: 0.0958\n",
      "Epoch: 143/500... Training loss: 0.0737\n",
      "Epoch: 143/500... Training loss: 0.1792\n",
      "Epoch: 143/500... Training loss: 0.1227\n",
      "Epoch: 143/500... Training loss: 0.1288\n",
      "Epoch: 143/500... Training loss: 0.0919\n",
      "Epoch: 143/500... Training loss: 0.0440\n",
      "Epoch: 143/500... Training loss: 0.1334\n",
      "Epoch: 144/500... Training loss: 0.0521\n",
      "Epoch: 144/500... Training loss: 0.0582\n",
      "Epoch: 144/500... Training loss: 0.0615\n",
      "Epoch: 144/500... Training loss: 0.1666\n",
      "Epoch: 144/500... Training loss: 0.1796\n",
      "Epoch: 144/500... Training loss: 0.1010\n",
      "Epoch: 144/500... Training loss: 0.0540\n",
      "Epoch: 144/500... Training loss: 0.0753\n",
      "Epoch: 144/500... Training loss: 0.0802\n",
      "Epoch: 144/500... Training loss: 0.1543\n",
      "Epoch: 144/500... Training loss: 0.0725\n",
      "Epoch: 144/500... Training loss: 0.1129\n",
      "Epoch: 144/500... Training loss: 0.2329\n",
      "Epoch: 144/500... Training loss: 0.1157\n",
      "Epoch: 144/500... Training loss: 0.0276\n",
      "Epoch: 144/500... Training loss: 0.0253\n",
      "Epoch: 144/500... Training loss: 0.1068\n",
      "Epoch: 144/500... Training loss: 0.0288\n",
      "Epoch: 144/500... Training loss: 0.0693\n",
      "Epoch: 144/500... Training loss: 0.0186\n",
      "Epoch: 144/500... Training loss: 0.0486\n",
      "Epoch: 144/500... Training loss: 0.1389\n",
      "Epoch: 144/500... Training loss: 0.0592\n",
      "Epoch: 144/500... Training loss: 0.1190\n",
      "Epoch: 144/500... Training loss: 0.0436\n",
      "Epoch: 144/500... Training loss: 0.0285\n",
      "Epoch: 144/500... Training loss: 0.0325\n",
      "Epoch: 144/500... Training loss: 0.1151\n",
      "Epoch: 144/500... Training loss: 0.0557\n",
      "Epoch: 144/500... Training loss: 0.0848\n",
      "Epoch: 144/500... Training loss: 0.1143\n",
      "Epoch: 145/500... Training loss: 0.0420\n",
      "Epoch: 145/500... Training loss: 0.0654\n",
      "Epoch: 145/500... Training loss: 0.1050\n",
      "Epoch: 145/500... Training loss: 0.0797\n",
      "Epoch: 145/500... Training loss: 0.1963\n",
      "Epoch: 145/500... Training loss: 0.0516\n",
      "Epoch: 145/500... Training loss: 0.0845\n",
      "Epoch: 145/500... Training loss: 0.0851\n",
      "Epoch: 145/500... Training loss: 0.1468\n",
      "Epoch: 145/500... Training loss: 0.0221\n",
      "Epoch: 145/500... Training loss: 0.1241\n",
      "Epoch: 145/500... Training loss: 0.1432\n",
      "Epoch: 145/500... Training loss: 0.1994\n",
      "Epoch: 145/500... Training loss: 0.0792\n",
      "Epoch: 145/500... Training loss: 0.0602\n",
      "Epoch: 145/500... Training loss: 0.0150\n",
      "Epoch: 145/500... Training loss: 0.1238\n",
      "Epoch: 145/500... Training loss: 0.0950\n",
      "Epoch: 145/500... Training loss: 0.1903\n",
      "Epoch: 145/500... Training loss: 0.0187\n",
      "Epoch: 145/500... Training loss: 0.0705\n",
      "Epoch: 145/500... Training loss: 0.1874\n",
      "Epoch: 145/500... Training loss: 0.0854\n",
      "Epoch: 145/500... Training loss: 0.0374\n",
      "Epoch: 145/500... Training loss: 0.0912\n",
      "Epoch: 145/500... Training loss: 0.0260\n",
      "Epoch: 145/500... Training loss: 0.0367\n",
      "Epoch: 145/500... Training loss: 0.0611\n",
      "Epoch: 145/500... Training loss: 0.0681\n",
      "Epoch: 145/500... Training loss: 0.0926\n",
      "Epoch: 145/500... Training loss: 0.0359\n",
      "Epoch: 146/500... Training loss: 0.0513\n",
      "Epoch: 146/500... Training loss: 0.0830\n",
      "Epoch: 146/500... Training loss: 0.0911\n",
      "Epoch: 146/500... Training loss: 0.0958\n",
      "Epoch: 146/500... Training loss: 0.1075\n",
      "Epoch: 146/500... Training loss: 0.0661\n",
      "Epoch: 146/500... Training loss: 0.0343\n",
      "Epoch: 146/500... Training loss: 0.0886\n",
      "Epoch: 146/500... Training loss: 0.0866\n",
      "Epoch: 146/500... Training loss: 0.0993\n",
      "Epoch: 146/500... Training loss: 0.0666\n",
      "Epoch: 146/500... Training loss: 0.1143\n",
      "Epoch: 146/500... Training loss: 0.2703\n",
      "Epoch: 146/500... Training loss: 0.1045\n",
      "Epoch: 146/500... Training loss: 0.0933\n",
      "Epoch: 146/500... Training loss: 0.0739\n",
      "Epoch: 146/500... Training loss: 0.0497\n",
      "Epoch: 146/500... Training loss: 0.0697\n",
      "Epoch: 146/500... Training loss: 0.0902\n",
      "Epoch: 146/500... Training loss: 0.0516\n",
      "Epoch: 146/500... Training loss: 0.0915\n",
      "Epoch: 146/500... Training loss: 0.1752\n",
      "Epoch: 146/500... Training loss: 0.0889\n",
      "Epoch: 146/500... Training loss: 0.0707\n",
      "Epoch: 146/500... Training loss: 0.0477\n",
      "Epoch: 146/500... Training loss: 0.1034\n",
      "Epoch: 146/500... Training loss: 0.1052\n",
      "Epoch: 146/500... Training loss: 0.1600\n",
      "Epoch: 146/500... Training loss: 0.0529\n",
      "Epoch: 146/500... Training loss: 0.2174\n",
      "Epoch: 146/500... Training loss: 0.0322\n",
      "Epoch: 147/500... Training loss: 0.0409\n",
      "Epoch: 147/500... Training loss: 0.1066\n",
      "Epoch: 147/500... Training loss: 0.1483\n",
      "Epoch: 147/500... Training loss: 0.0485\n",
      "Epoch: 147/500... Training loss: 0.2140\n",
      "Epoch: 147/500... Training loss: 0.1424\n",
      "Epoch: 147/500... Training loss: 0.0605\n",
      "Epoch: 147/500... Training loss: 0.1105\n",
      "Epoch: 147/500... Training loss: 0.0646\n",
      "Epoch: 147/500... Training loss: 0.0395\n",
      "Epoch: 147/500... Training loss: 0.1000\n",
      "Epoch: 147/500... Training loss: 0.1135\n",
      "Epoch: 147/500... Training loss: 0.1036\n",
      "Epoch: 147/500... Training loss: 0.0506\n",
      "Epoch: 147/500... Training loss: 0.0439\n",
      "Epoch: 147/500... Training loss: 0.0418\n",
      "Epoch: 147/500... Training loss: 0.0848\n",
      "Epoch: 147/500... Training loss: 0.0954\n",
      "Epoch: 147/500... Training loss: 0.0555\n",
      "Epoch: 147/500... Training loss: 0.0237\n",
      "Epoch: 147/500... Training loss: 0.0851\n",
      "Epoch: 147/500... Training loss: 0.1029\n",
      "Epoch: 147/500... Training loss: 0.0885\n",
      "Epoch: 147/500... Training loss: 0.1266\n",
      "Epoch: 147/500... Training loss: 0.0757\n",
      "Epoch: 147/500... Training loss: 0.0251\n",
      "Epoch: 147/500... Training loss: 0.0646\n",
      "Epoch: 147/500... Training loss: 0.0639\n",
      "Epoch: 147/500... Training loss: 0.2175\n",
      "Epoch: 147/500... Training loss: 0.0361\n",
      "Epoch: 147/500... Training loss: 0.1240\n",
      "Epoch: 148/500... Training loss: 0.0538\n",
      "Epoch: 148/500... Training loss: 0.0539\n",
      "Epoch: 148/500... Training loss: 0.2351\n",
      "Epoch: 148/500... Training loss: 0.2557\n",
      "Epoch: 148/500... Training loss: 0.0950\n",
      "Epoch: 148/500... Training loss: 0.1211\n",
      "Epoch: 148/500... Training loss: 0.0757\n",
      "Epoch: 148/500... Training loss: 0.0879\n",
      "Epoch: 148/500... Training loss: 0.0921\n",
      "Epoch: 148/500... Training loss: 0.1064\n",
      "Epoch: 148/500... Training loss: 0.0446\n",
      "Epoch: 148/500... Training loss: 0.0931\n",
      "Epoch: 148/500... Training loss: 0.0457\n",
      "Epoch: 148/500... Training loss: 0.0591\n",
      "Epoch: 148/500... Training loss: 0.0622\n",
      "Epoch: 148/500... Training loss: 0.1017\n",
      "Epoch: 148/500... Training loss: 0.0522\n",
      "Epoch: 148/500... Training loss: 0.0375\n",
      "Epoch: 148/500... Training loss: 0.1070\n",
      "Epoch: 148/500... Training loss: 0.0461\n",
      "Epoch: 148/500... Training loss: 0.2156\n",
      "Epoch: 148/500... Training loss: 0.0906\n",
      "Epoch: 148/500... Training loss: 0.0902\n",
      "Epoch: 148/500... Training loss: 0.0218\n",
      "Epoch: 148/500... Training loss: 0.1384\n",
      "Epoch: 148/500... Training loss: 0.0978\n",
      "Epoch: 148/500... Training loss: 0.0451\n",
      "Epoch: 148/500... Training loss: 0.1643\n",
      "Epoch: 148/500... Training loss: 0.0547\n",
      "Epoch: 148/500... Training loss: 0.0867\n",
      "Epoch: 148/500... Training loss: 0.0345\n",
      "Epoch: 149/500... Training loss: 0.1194\n",
      "Epoch: 149/500... Training loss: 0.0653\n",
      "Epoch: 149/500... Training loss: 0.0827\n",
      "Epoch: 149/500... Training loss: 0.1044\n",
      "Epoch: 149/500... Training loss: 0.0341\n",
      "Epoch: 149/500... Training loss: 0.0434\n",
      "Epoch: 149/500... Training loss: 0.1124\n",
      "Epoch: 149/500... Training loss: 0.0819\n",
      "Epoch: 149/500... Training loss: 0.0717\n",
      "Epoch: 149/500... Training loss: 0.0646\n",
      "Epoch: 149/500... Training loss: 0.1012\n",
      "Epoch: 149/500... Training loss: 0.1468\n",
      "Epoch: 149/500... Training loss: 0.0572\n",
      "Epoch: 149/500... Training loss: 0.0540\n",
      "Epoch: 149/500... Training loss: 0.0331\n",
      "Epoch: 149/500... Training loss: 0.1047\n",
      "Epoch: 149/500... Training loss: 0.0340\n",
      "Epoch: 149/500... Training loss: 0.1075\n",
      "Epoch: 149/500... Training loss: 0.0640\n",
      "Epoch: 149/500... Training loss: 0.0808\n",
      "Epoch: 149/500... Training loss: 0.0887\n",
      "Epoch: 149/500... Training loss: 0.1149\n",
      "Epoch: 149/500... Training loss: 0.0683\n",
      "Epoch: 149/500... Training loss: 0.0447\n",
      "Epoch: 149/500... Training loss: 0.0210\n",
      "Epoch: 149/500... Training loss: 0.0487\n",
      "Epoch: 149/500... Training loss: 0.1163\n",
      "Epoch: 149/500... Training loss: 0.0520\n",
      "Epoch: 149/500... Training loss: 0.0754\n",
      "Epoch: 149/500... Training loss: 0.0792\n",
      "Epoch: 149/500... Training loss: 0.0415\n",
      "Epoch: 150/500... Training loss: 0.2369\n",
      "Epoch: 150/500... Training loss: 0.0592\n",
      "Epoch: 150/500... Training loss: 0.1652\n",
      "Epoch: 150/500... Training loss: 0.1877\n",
      "Epoch: 150/500... Training loss: 0.0961\n",
      "Epoch: 150/500... Training loss: 0.0504\n",
      "Epoch: 150/500... Training loss: 0.0669\n",
      "Epoch: 150/500... Training loss: 0.0794\n",
      "Epoch: 150/500... Training loss: 0.0338\n",
      "Epoch: 150/500... Training loss: 0.0593\n",
      "Epoch: 150/500... Training loss: 0.2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/500... Training loss: 0.0816\n",
      "Epoch: 150/500... Training loss: 0.0475\n",
      "Epoch: 150/500... Training loss: 0.0658\n",
      "Epoch: 150/500... Training loss: 0.1417\n",
      "Epoch: 150/500... Training loss: 0.0264\n",
      "Epoch: 150/500... Training loss: 0.0825\n",
      "Epoch: 150/500... Training loss: 0.1204\n",
      "Epoch: 150/500... Training loss: 0.1203\n",
      "Epoch: 150/500... Training loss: 0.1243\n",
      "Epoch: 150/500... Training loss: 0.1748\n",
      "Epoch: 150/500... Training loss: 0.0363\n",
      "Epoch: 150/500... Training loss: 0.0692\n",
      "Epoch: 150/500... Training loss: 0.0312\n",
      "Epoch: 150/500... Training loss: 0.0325\n",
      "Epoch: 150/500... Training loss: 0.0299\n",
      "Epoch: 150/500... Training loss: 0.0663\n",
      "Epoch: 150/500... Training loss: 0.0363\n",
      "Epoch: 150/500... Training loss: 0.0993\n",
      "Epoch: 150/500... Training loss: 0.0381\n",
      "Epoch: 150/500... Training loss: 0.0519\n",
      "Epoch: 151/500... Training loss: 0.0678\n",
      "Epoch: 151/500... Training loss: 0.1970\n",
      "Epoch: 151/500... Training loss: 0.0909\n",
      "Epoch: 151/500... Training loss: 0.1172\n",
      "Epoch: 151/500... Training loss: 0.0644\n",
      "Epoch: 151/500... Training loss: 0.1499\n",
      "Epoch: 151/500... Training loss: 0.0649\n",
      "Epoch: 151/500... Training loss: 0.1745\n",
      "Epoch: 151/500... Training loss: 0.1233\n",
      "Epoch: 151/500... Training loss: 0.1221\n",
      "Epoch: 151/500... Training loss: 0.1498\n",
      "Epoch: 151/500... Training loss: 0.0336\n",
      "Epoch: 151/500... Training loss: 0.0506\n",
      "Epoch: 151/500... Training loss: 0.1302\n",
      "Epoch: 151/500... Training loss: 0.0827\n",
      "Epoch: 151/500... Training loss: 0.1178\n",
      "Epoch: 151/500... Training loss: 0.0306\n",
      "Epoch: 151/500... Training loss: 0.0793\n",
      "Epoch: 151/500... Training loss: 0.1310\n",
      "Epoch: 151/500... Training loss: 0.0363\n",
      "Epoch: 151/500... Training loss: 0.0376\n",
      "Epoch: 151/500... Training loss: 0.3654\n",
      "Epoch: 151/500... Training loss: 0.1136\n",
      "Epoch: 151/500... Training loss: 0.1602\n",
      "Epoch: 151/500... Training loss: 0.0478\n",
      "Epoch: 151/500... Training loss: 0.0970\n",
      "Epoch: 151/500... Training loss: 0.1384\n",
      "Epoch: 151/500... Training loss: 0.0932\n",
      "Epoch: 151/500... Training loss: 0.0142\n",
      "Epoch: 151/500... Training loss: 0.0304\n",
      "Epoch: 151/500... Training loss: 0.0556\n",
      "Epoch: 152/500... Training loss: 0.1509\n",
      "Epoch: 152/500... Training loss: 0.1076\n",
      "Epoch: 152/500... Training loss: 0.1194\n",
      "Epoch: 152/500... Training loss: 0.1590\n",
      "Epoch: 152/500... Training loss: 0.0308\n",
      "Epoch: 152/500... Training loss: 0.0420\n",
      "Epoch: 152/500... Training loss: 0.0483\n",
      "Epoch: 152/500... Training loss: 0.1424\n",
      "Epoch: 152/500... Training loss: 0.0380\n",
      "Epoch: 152/500... Training loss: 0.1395\n",
      "Epoch: 152/500... Training loss: 0.0999\n",
      "Epoch: 152/500... Training loss: 0.1050\n",
      "Epoch: 152/500... Training loss: 0.0585\n",
      "Epoch: 152/500... Training loss: 0.0884\n",
      "Epoch: 152/500... Training loss: 0.0649\n",
      "Epoch: 152/500... Training loss: 0.0140\n",
      "Epoch: 152/500... Training loss: 0.0426\n",
      "Epoch: 152/500... Training loss: 0.0587\n",
      "Epoch: 152/500... Training loss: 0.1772\n",
      "Epoch: 152/500... Training loss: 0.0341\n",
      "Epoch: 152/500... Training loss: 0.1122\n",
      "Epoch: 152/500... Training loss: 0.0804\n",
      "Epoch: 152/500... Training loss: 0.0891\n",
      "Epoch: 152/500... Training loss: 0.0430\n",
      "Epoch: 152/500... Training loss: 0.0505\n",
      "Epoch: 152/500... Training loss: 0.0534\n",
      "Epoch: 152/500... Training loss: 0.1373\n",
      "Epoch: 152/500... Training loss: 0.0141\n",
      "Epoch: 152/500... Training loss: 0.0770\n",
      "Epoch: 152/500... Training loss: 0.0698\n",
      "Epoch: 152/500... Training loss: 0.0529\n",
      "Epoch: 153/500... Training loss: 0.1392\n",
      "Epoch: 153/500... Training loss: 0.0529\n",
      "Epoch: 153/500... Training loss: 0.0180\n",
      "Epoch: 153/500... Training loss: 0.0544\n",
      "Epoch: 153/500... Training loss: 0.0411\n",
      "Epoch: 153/500... Training loss: 0.0458\n",
      "Epoch: 153/500... Training loss: 0.1208\n",
      "Epoch: 153/500... Training loss: 0.0520\n",
      "Epoch: 153/500... Training loss: 0.0580\n",
      "Epoch: 153/500... Training loss: 0.1958\n",
      "Epoch: 153/500... Training loss: 0.0458\n",
      "Epoch: 153/500... Training loss: 0.1220\n",
      "Epoch: 153/500... Training loss: 0.0650\n",
      "Epoch: 153/500... Training loss: 0.0333\n",
      "Epoch: 153/500... Training loss: 0.0747\n",
      "Epoch: 153/500... Training loss: 0.0341\n",
      "Epoch: 153/500... Training loss: 0.0208\n",
      "Epoch: 153/500... Training loss: 0.0952\n",
      "Epoch: 153/500... Training loss: 0.0634\n",
      "Epoch: 153/500... Training loss: 0.0835\n",
      "Epoch: 153/500... Training loss: 0.0512\n",
      "Epoch: 153/500... Training loss: 0.0507\n",
      "Epoch: 153/500... Training loss: 0.0486\n",
      "Epoch: 153/500... Training loss: 0.0587\n",
      "Epoch: 153/500... Training loss: 0.0451\n",
      "Epoch: 153/500... Training loss: 0.1293\n",
      "Epoch: 153/500... Training loss: 0.0779\n",
      "Epoch: 153/500... Training loss: 0.0606\n",
      "Epoch: 153/500... Training loss: 0.1594\n",
      "Epoch: 153/500... Training loss: 0.0753\n",
      "Epoch: 153/500... Training loss: 0.0423\n",
      "Epoch: 154/500... Training loss: 0.0204\n",
      "Epoch: 154/500... Training loss: 0.0415\n",
      "Epoch: 154/500... Training loss: 0.0407\n",
      "Epoch: 154/500... Training loss: 0.0490\n",
      "Epoch: 154/500... Training loss: 0.0363\n",
      "Epoch: 154/500... Training loss: 0.0299\n",
      "Epoch: 154/500... Training loss: 0.0321\n",
      "Epoch: 154/500... Training loss: 0.0739\n",
      "Epoch: 154/500... Training loss: 0.1228\n",
      "Epoch: 154/500... Training loss: 0.0833\n",
      "Epoch: 154/500... Training loss: 0.0701\n",
      "Epoch: 154/500... Training loss: 0.0717\n",
      "Epoch: 154/500... Training loss: 0.0757\n",
      "Epoch: 154/500... Training loss: 0.0431\n",
      "Epoch: 154/500... Training loss: 0.0561\n",
      "Epoch: 154/500... Training loss: 0.1174\n",
      "Epoch: 154/500... Training loss: 0.0948\n",
      "Epoch: 154/500... Training loss: 0.0733\n",
      "Epoch: 154/500... Training loss: 0.0750\n",
      "Epoch: 154/500... Training loss: 0.0244\n",
      "Epoch: 154/500... Training loss: 0.0660\n",
      "Epoch: 154/500... Training loss: 0.0188\n",
      "Epoch: 154/500... Training loss: 0.1369\n",
      "Epoch: 154/500... Training loss: 0.0555\n",
      "Epoch: 154/500... Training loss: 0.0239\n",
      "Epoch: 154/500... Training loss: 0.0371\n",
      "Epoch: 154/500... Training loss: 0.0118\n",
      "Epoch: 154/500... Training loss: 0.0732\n",
      "Epoch: 154/500... Training loss: 0.0562\n",
      "Epoch: 154/500... Training loss: 0.0714\n",
      "Epoch: 154/500... Training loss: 0.0183\n",
      "Epoch: 155/500... Training loss: 0.1820\n",
      "Epoch: 155/500... Training loss: 0.0181\n",
      "Epoch: 155/500... Training loss: 0.0353\n",
      "Epoch: 155/500... Training loss: 0.0683\n",
      "Epoch: 155/500... Training loss: 0.0706\n",
      "Epoch: 155/500... Training loss: 0.0442\n",
      "Epoch: 155/500... Training loss: 0.0501\n",
      "Epoch: 155/500... Training loss: 0.1059\n",
      "Epoch: 155/500... Training loss: 0.0882\n",
      "Epoch: 155/500... Training loss: 0.1154\n",
      "Epoch: 155/500... Training loss: 0.0849\n",
      "Epoch: 155/500... Training loss: 0.0551\n",
      "Epoch: 155/500... Training loss: 0.2137\n",
      "Epoch: 155/500... Training loss: 0.0178\n",
      "Epoch: 155/500... Training loss: 0.0937\n",
      "Epoch: 155/500... Training loss: 0.0241\n",
      "Epoch: 155/500... Training loss: 0.0768\n",
      "Epoch: 155/500... Training loss: 0.0249\n",
      "Epoch: 155/500... Training loss: 0.0941\n",
      "Epoch: 155/500... Training loss: 0.0550\n",
      "Epoch: 155/500... Training loss: 0.1301\n",
      "Epoch: 155/500... Training loss: 0.0237\n",
      "Epoch: 155/500... Training loss: 0.1219\n",
      "Epoch: 155/500... Training loss: 0.0394\n",
      "Epoch: 155/500... Training loss: 0.0477\n",
      "Epoch: 155/500... Training loss: 0.0856\n",
      "Epoch: 155/500... Training loss: 0.1091\n",
      "Epoch: 155/500... Training loss: 0.0764\n",
      "Epoch: 155/500... Training loss: 0.0156\n",
      "Epoch: 155/500... Training loss: 0.0164\n",
      "Epoch: 155/500... Training loss: 0.2077\n",
      "Epoch: 156/500... Training loss: 0.0434\n",
      "Epoch: 156/500... Training loss: 0.1071\n",
      "Epoch: 156/500... Training loss: 0.0215\n",
      "Epoch: 156/500... Training loss: 0.1265\n",
      "Epoch: 156/500... Training loss: 0.0277\n",
      "Epoch: 156/500... Training loss: 0.0408\n",
      "Epoch: 156/500... Training loss: 0.1436\n",
      "Epoch: 156/500... Training loss: 0.0483\n",
      "Epoch: 156/500... Training loss: 0.1933\n",
      "Epoch: 156/500... Training loss: 0.0305\n",
      "Epoch: 156/500... Training loss: 0.0667\n",
      "Epoch: 156/500... Training loss: 0.1028\n",
      "Epoch: 156/500... Training loss: 0.0650\n",
      "Epoch: 156/500... Training loss: 0.0822\n",
      "Epoch: 156/500... Training loss: 0.0942\n",
      "Epoch: 156/500... Training loss: 0.0948\n",
      "Epoch: 156/500... Training loss: 0.0556\n",
      "Epoch: 156/500... Training loss: 0.0208\n",
      "Epoch: 156/500... Training loss: 0.0666\n",
      "Epoch: 156/500... Training loss: 0.0304\n",
      "Epoch: 156/500... Training loss: 0.0723\n",
      "Epoch: 156/500... Training loss: 0.0849\n",
      "Epoch: 156/500... Training loss: 0.0496\n",
      "Epoch: 156/500... Training loss: 0.0566\n",
      "Epoch: 156/500... Training loss: 0.0831\n",
      "Epoch: 156/500... Training loss: 0.0987\n",
      "Epoch: 156/500... Training loss: 0.0144\n",
      "Epoch: 156/500... Training loss: 0.0310\n",
      "Epoch: 156/500... Training loss: 0.0230\n",
      "Epoch: 156/500... Training loss: 0.0964\n",
      "Epoch: 156/500... Training loss: 0.1333\n",
      "Epoch: 157/500... Training loss: 0.0695\n",
      "Epoch: 157/500... Training loss: 0.0201\n",
      "Epoch: 157/500... Training loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157/500... Training loss: 0.0634\n",
      "Epoch: 157/500... Training loss: 0.1292\n",
      "Epoch: 157/500... Training loss: 0.1060\n",
      "Epoch: 157/500... Training loss: 0.0288\n",
      "Epoch: 157/500... Training loss: 0.1551\n",
      "Epoch: 157/500... Training loss: 0.0429\n",
      "Epoch: 157/500... Training loss: 0.0398\n",
      "Epoch: 157/500... Training loss: 0.0913\n",
      "Epoch: 157/500... Training loss: 0.0279\n",
      "Epoch: 157/500... Training loss: 0.0847\n",
      "Epoch: 157/500... Training loss: 0.1545\n",
      "Epoch: 157/500... Training loss: 0.0870\n",
      "Epoch: 157/500... Training loss: 0.0632\n",
      "Epoch: 157/500... Training loss: 0.0426\n",
      "Epoch: 157/500... Training loss: 0.0355\n",
      "Epoch: 157/500... Training loss: 0.0360\n",
      "Epoch: 157/500... Training loss: 0.0244\n",
      "Epoch: 157/500... Training loss: 0.0649\n",
      "Epoch: 157/500... Training loss: 0.0810\n",
      "Epoch: 157/500... Training loss: 0.0180\n",
      "Epoch: 157/500... Training loss: 0.1380\n",
      "Epoch: 157/500... Training loss: 0.0421\n",
      "Epoch: 157/500... Training loss: 0.0989\n",
      "Epoch: 157/500... Training loss: 0.0139\n",
      "Epoch: 157/500... Training loss: 0.0667\n",
      "Epoch: 157/500... Training loss: 0.0284\n",
      "Epoch: 157/500... Training loss: 0.0315\n",
      "Epoch: 157/500... Training loss: 0.0295\n",
      "Epoch: 158/500... Training loss: 0.0608\n",
      "Epoch: 158/500... Training loss: 0.0296\n",
      "Epoch: 158/500... Training loss: 0.0423\n",
      "Epoch: 158/500... Training loss: 0.0692\n",
      "Epoch: 158/500... Training loss: 0.0408\n",
      "Epoch: 158/500... Training loss: 0.0679\n",
      "Epoch: 158/500... Training loss: 0.0726\n",
      "Epoch: 158/500... Training loss: 0.0469\n",
      "Epoch: 158/500... Training loss: 0.0490\n",
      "Epoch: 158/500... Training loss: 0.0399\n",
      "Epoch: 158/500... Training loss: 0.1283\n",
      "Epoch: 158/500... Training loss: 0.1725\n",
      "Epoch: 158/500... Training loss: 0.1363\n",
      "Epoch: 158/500... Training loss: 0.0600\n",
      "Epoch: 158/500... Training loss: 0.0334\n",
      "Epoch: 158/500... Training loss: 0.0218\n",
      "Epoch: 158/500... Training loss: 0.1929\n",
      "Epoch: 158/500... Training loss: 0.0347\n",
      "Epoch: 158/500... Training loss: 0.0239\n",
      "Epoch: 158/500... Training loss: 0.0147\n",
      "Epoch: 158/500... Training loss: 0.0345\n",
      "Epoch: 158/500... Training loss: 0.0579\n",
      "Epoch: 158/500... Training loss: 0.1078\n",
      "Epoch: 158/500... Training loss: 0.1090\n",
      "Epoch: 158/500... Training loss: 0.0387\n",
      "Epoch: 158/500... Training loss: 0.0683\n",
      "Epoch: 158/500... Training loss: 0.0750\n",
      "Epoch: 158/500... Training loss: 0.0432\n",
      "Epoch: 158/500... Training loss: 0.0433\n",
      "Epoch: 158/500... Training loss: 0.0599\n",
      "Epoch: 158/500... Training loss: 0.0210\n",
      "Epoch: 159/500... Training loss: 0.0419\n",
      "Epoch: 159/500... Training loss: 0.0419\n",
      "Epoch: 159/500... Training loss: 0.0494\n",
      "Epoch: 159/500... Training loss: 0.0674\n",
      "Epoch: 159/500... Training loss: 0.0763\n",
      "Epoch: 159/500... Training loss: 0.0608\n",
      "Epoch: 159/500... Training loss: 0.0218\n",
      "Epoch: 159/500... Training loss: 0.0946\n",
      "Epoch: 159/500... Training loss: 0.1733\n",
      "Epoch: 159/500... Training loss: 0.0263\n",
      "Epoch: 159/500... Training loss: 0.0523\n",
      "Epoch: 159/500... Training loss: 0.0875\n",
      "Epoch: 159/500... Training loss: 0.2290\n",
      "Epoch: 159/500... Training loss: 0.0491\n",
      "Epoch: 159/500... Training loss: 0.1337\n",
      "Epoch: 159/500... Training loss: 0.0341\n",
      "Epoch: 159/500... Training loss: 0.0856\n",
      "Epoch: 159/500... Training loss: 0.0498\n",
      "Epoch: 159/500... Training loss: 0.1611\n",
      "Epoch: 159/500... Training loss: 0.1171\n",
      "Epoch: 159/500... Training loss: 0.0338\n",
      "Epoch: 159/500... Training loss: 0.0883\n",
      "Epoch: 159/500... Training loss: 0.0703\n",
      "Epoch: 159/500... Training loss: 0.1167\n",
      "Epoch: 159/500... Training loss: 0.0300\n",
      "Epoch: 159/500... Training loss: 0.0446\n",
      "Epoch: 159/500... Training loss: 0.0663\n",
      "Epoch: 159/500... Training loss: 0.1068\n",
      "Epoch: 159/500... Training loss: 0.2103\n",
      "Epoch: 159/500... Training loss: 0.0812\n",
      "Epoch: 159/500... Training loss: 0.0321\n",
      "Epoch: 160/500... Training loss: 0.0776\n",
      "Epoch: 160/500... Training loss: 0.0603\n",
      "Epoch: 160/500... Training loss: 0.1174\n",
      "Epoch: 160/500... Training loss: 0.0824\n",
      "Epoch: 160/500... Training loss: 0.2425\n",
      "Epoch: 160/500... Training loss: 0.0705\n",
      "Epoch: 160/500... Training loss: 0.0320\n",
      "Epoch: 160/500... Training loss: 0.0511\n",
      "Epoch: 160/500... Training loss: 0.0378\n",
      "Epoch: 160/500... Training loss: 0.0428\n",
      "Epoch: 160/500... Training loss: 0.0522\n",
      "Epoch: 160/500... Training loss: 0.0673\n",
      "Epoch: 160/500... Training loss: 0.1106\n",
      "Epoch: 160/500... Training loss: 0.0824\n",
      "Epoch: 160/500... Training loss: 0.1001\n",
      "Epoch: 160/500... Training loss: 0.0201\n",
      "Epoch: 160/500... Training loss: 0.0342\n",
      "Epoch: 160/500... Training loss: 0.0959\n",
      "Epoch: 160/500... Training loss: 0.0969\n",
      "Epoch: 160/500... Training loss: 0.0150\n",
      "Epoch: 160/500... Training loss: 0.0505\n",
      "Epoch: 160/500... Training loss: 0.0122\n",
      "Epoch: 160/500... Training loss: 0.1675\n",
      "Epoch: 160/500... Training loss: 0.1361\n",
      "Epoch: 160/500... Training loss: 0.0910\n",
      "Epoch: 160/500... Training loss: 0.0858\n",
      "Epoch: 160/500... Training loss: 0.1153\n",
      "Epoch: 160/500... Training loss: 0.1069\n",
      "Epoch: 160/500... Training loss: 0.0148\n",
      "Epoch: 160/500... Training loss: 0.0491\n",
      "Epoch: 160/500... Training loss: 0.0700\n",
      "Epoch: 161/500... Training loss: 0.1103\n",
      "Epoch: 161/500... Training loss: 0.0346\n",
      "Epoch: 161/500... Training loss: 0.1208\n",
      "Epoch: 161/500... Training loss: 0.0377\n",
      "Epoch: 161/500... Training loss: 0.0561\n",
      "Epoch: 161/500... Training loss: 0.0228\n",
      "Epoch: 161/500... Training loss: 0.0750\n",
      "Epoch: 161/500... Training loss: 0.1357\n",
      "Epoch: 161/500... Training loss: 0.1504\n",
      "Epoch: 161/500... Training loss: 0.0458\n",
      "Epoch: 161/500... Training loss: 0.0395\n",
      "Epoch: 161/500... Training loss: 0.1072\n",
      "Epoch: 161/500... Training loss: 0.0745\n",
      "Epoch: 161/500... Training loss: 0.0364\n",
      "Epoch: 161/500... Training loss: 0.0955\n",
      "Epoch: 161/500... Training loss: 0.0367\n",
      "Epoch: 161/500... Training loss: 0.0910\n",
      "Epoch: 161/500... Training loss: 0.0257\n",
      "Epoch: 161/500... Training loss: 0.0780\n",
      "Epoch: 161/500... Training loss: 0.0879\n",
      "Epoch: 161/500... Training loss: 0.0953\n",
      "Epoch: 161/500... Training loss: 0.1215\n",
      "Epoch: 161/500... Training loss: 0.1101\n",
      "Epoch: 161/500... Training loss: 0.1330\n",
      "Epoch: 161/500... Training loss: 0.1155\n",
      "Epoch: 161/500... Training loss: 0.0751\n",
      "Epoch: 161/500... Training loss: 0.0927\n",
      "Epoch: 161/500... Training loss: 0.0707\n",
      "Epoch: 161/500... Training loss: 0.0349\n",
      "Epoch: 161/500... Training loss: 0.0821\n",
      "Epoch: 161/500... Training loss: 0.0525\n",
      "Epoch: 162/500... Training loss: 0.1311\n",
      "Epoch: 162/500... Training loss: 0.0477\n",
      "Epoch: 162/500... Training loss: 0.0364\n",
      "Epoch: 162/500... Training loss: 0.1309\n",
      "Epoch: 162/500... Training loss: 0.0288\n",
      "Epoch: 162/500... Training loss: 0.0636\n",
      "Epoch: 162/500... Training loss: 0.1866\n",
      "Epoch: 162/500... Training loss: 0.0328\n",
      "Epoch: 162/500... Training loss: 0.1134\n",
      "Epoch: 162/500... Training loss: 0.0166\n",
      "Epoch: 162/500... Training loss: 0.0398\n",
      "Epoch: 162/500... Training loss: 0.0537\n",
      "Epoch: 162/500... Training loss: 0.0908\n",
      "Epoch: 162/500... Training loss: 0.1128\n",
      "Epoch: 162/500... Training loss: 0.0373\n",
      "Epoch: 162/500... Training loss: 0.0675\n",
      "Epoch: 162/500... Training loss: 0.0594\n",
      "Epoch: 162/500... Training loss: 0.0217\n",
      "Epoch: 162/500... Training loss: 0.0501\n",
      "Epoch: 162/500... Training loss: 0.0376\n",
      "Epoch: 162/500... Training loss: 0.0323\n",
      "Epoch: 162/500... Training loss: 0.0270\n",
      "Epoch: 162/500... Training loss: 0.0403\n",
      "Epoch: 162/500... Training loss: 0.0931\n",
      "Epoch: 162/500... Training loss: 0.0157\n",
      "Epoch: 162/500... Training loss: 0.0215\n",
      "Epoch: 162/500... Training loss: 0.0894\n",
      "Epoch: 162/500... Training loss: 0.0623\n",
      "Epoch: 162/500... Training loss: 0.0083\n",
      "Epoch: 162/500... Training loss: 0.0673\n",
      "Epoch: 162/500... Training loss: 0.0199\n",
      "Epoch: 163/500... Training loss: 0.0437\n",
      "Epoch: 163/500... Training loss: 0.1227\n",
      "Epoch: 163/500... Training loss: 0.0656\n",
      "Epoch: 163/500... Training loss: 0.0948\n",
      "Epoch: 163/500... Training loss: 0.0439\n",
      "Epoch: 163/500... Training loss: 0.0490\n",
      "Epoch: 163/500... Training loss: 0.1469\n",
      "Epoch: 163/500... Training loss: 0.1177\n",
      "Epoch: 163/500... Training loss: 0.1557\n",
      "Epoch: 163/500... Training loss: 0.0208\n",
      "Epoch: 163/500... Training loss: 0.0439\n",
      "Epoch: 163/500... Training loss: 0.0908\n",
      "Epoch: 163/500... Training loss: 0.0534\n",
      "Epoch: 163/500... Training loss: 0.0132\n",
      "Epoch: 163/500... Training loss: 0.0836\n",
      "Epoch: 163/500... Training loss: 0.0314\n",
      "Epoch: 163/500... Training loss: 0.0870\n",
      "Epoch: 163/500... Training loss: 0.0152\n",
      "Epoch: 163/500... Training loss: 0.0812\n",
      "Epoch: 163/500... Training loss: 0.0458\n",
      "Epoch: 163/500... Training loss: 0.1823\n",
      "Epoch: 163/500... Training loss: 0.1065\n",
      "Epoch: 163/500... Training loss: 0.0710\n",
      "Epoch: 163/500... Training loss: 0.0169\n",
      "Epoch: 163/500... Training loss: 0.0318\n",
      "Epoch: 163/500... Training loss: 0.0286\n",
      "Epoch: 163/500... Training loss: 0.0163\n",
      "Epoch: 163/500... Training loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163/500... Training loss: 0.0117\n",
      "Epoch: 163/500... Training loss: 0.0897\n",
      "Epoch: 163/500... Training loss: 0.0331\n",
      "Epoch: 164/500... Training loss: 0.1189\n",
      "Epoch: 164/500... Training loss: 0.0987\n",
      "Epoch: 164/500... Training loss: 0.1291\n",
      "Epoch: 164/500... Training loss: 0.0601\n",
      "Epoch: 164/500... Training loss: 0.0667\n",
      "Epoch: 164/500... Training loss: 0.0629\n",
      "Epoch: 164/500... Training loss: 0.0798\n",
      "Epoch: 164/500... Training loss: 0.0829\n",
      "Epoch: 164/500... Training loss: 0.0764\n",
      "Epoch: 164/500... Training loss: 0.0562\n",
      "Epoch: 164/500... Training loss: 0.0221\n",
      "Epoch: 164/500... Training loss: 0.0676\n",
      "Epoch: 164/500... Training loss: 0.0636\n",
      "Epoch: 164/500... Training loss: 0.1003\n",
      "Epoch: 164/500... Training loss: 0.0668\n",
      "Epoch: 164/500... Training loss: 0.0313\n",
      "Epoch: 164/500... Training loss: 0.0217\n",
      "Epoch: 164/500... Training loss: 0.0263\n",
      "Epoch: 164/500... Training loss: 0.0195\n",
      "Epoch: 164/500... Training loss: 0.0149\n",
      "Epoch: 164/500... Training loss: 0.0496\n",
      "Epoch: 164/500... Training loss: 0.0710\n",
      "Epoch: 164/500... Training loss: 0.0646\n",
      "Epoch: 164/500... Training loss: 0.0749\n",
      "Epoch: 164/500... Training loss: 0.0567\n",
      "Epoch: 164/500... Training loss: 0.0276\n",
      "Epoch: 164/500... Training loss: 0.0377\n",
      "Epoch: 164/500... Training loss: 0.0267\n",
      "Epoch: 164/500... Training loss: 0.0251\n",
      "Epoch: 164/500... Training loss: 0.0432\n",
      "Epoch: 164/500... Training loss: 0.0351\n",
      "Epoch: 165/500... Training loss: 0.1005\n",
      "Epoch: 165/500... Training loss: 0.0730\n",
      "Epoch: 165/500... Training loss: 0.1371\n",
      "Epoch: 165/500... Training loss: 0.0212\n",
      "Epoch: 165/500... Training loss: 0.0488\n",
      "Epoch: 165/500... Training loss: 0.0466\n",
      "Epoch: 165/500... Training loss: 0.0934\n",
      "Epoch: 165/500... Training loss: 0.0399\n",
      "Epoch: 165/500... Training loss: 0.0272\n",
      "Epoch: 165/500... Training loss: 0.0501\n",
      "Epoch: 165/500... Training loss: 0.0482\n",
      "Epoch: 165/500... Training loss: 0.0454\n",
      "Epoch: 165/500... Training loss: 0.1348\n",
      "Epoch: 165/500... Training loss: 0.0985\n",
      "Epoch: 165/500... Training loss: 0.0638\n",
      "Epoch: 165/500... Training loss: 0.0164\n",
      "Epoch: 165/500... Training loss: 0.0972\n",
      "Epoch: 165/500... Training loss: 0.1197\n",
      "Epoch: 165/500... Training loss: 0.1811\n",
      "Epoch: 165/500... Training loss: 0.0376\n",
      "Epoch: 165/500... Training loss: 0.0569\n",
      "Epoch: 165/500... Training loss: 0.0488\n",
      "Epoch: 165/500... Training loss: 0.1135\n",
      "Epoch: 165/500... Training loss: 0.0362\n",
      "Epoch: 165/500... Training loss: 0.0235\n",
      "Epoch: 165/500... Training loss: 0.0179\n",
      "Epoch: 165/500... Training loss: 0.1293\n",
      "Epoch: 165/500... Training loss: 0.0430\n",
      "Epoch: 165/500... Training loss: 0.0841\n",
      "Epoch: 165/500... Training loss: 0.0621\n",
      "Epoch: 165/500... Training loss: 0.0528\n",
      "Epoch: 166/500... Training loss: 0.0365\n",
      "Epoch: 166/500... Training loss: 0.0207\n",
      "Epoch: 166/500... Training loss: 0.1019\n",
      "Epoch: 166/500... Training loss: 0.0508\n",
      "Epoch: 166/500... Training loss: 0.0412\n",
      "Epoch: 166/500... Training loss: 0.0203\n",
      "Epoch: 166/500... Training loss: 0.0666\n",
      "Epoch: 166/500... Training loss: 0.0529\n",
      "Epoch: 166/500... Training loss: 0.0359\n",
      "Epoch: 166/500... Training loss: 0.0967\n",
      "Epoch: 166/500... Training loss: 0.1413\n",
      "Epoch: 166/500... Training loss: 0.1826\n",
      "Epoch: 166/500... Training loss: 0.0550\n",
      "Epoch: 166/500... Training loss: 0.0821\n",
      "Epoch: 166/500... Training loss: 0.0783\n",
      "Epoch: 166/500... Training loss: 0.0174\n",
      "Epoch: 166/500... Training loss: 0.0897\n",
      "Epoch: 166/500... Training loss: 0.0514\n",
      "Epoch: 166/500... Training loss: 0.0919\n",
      "Epoch: 166/500... Training loss: 0.0160\n",
      "Epoch: 166/500... Training loss: 0.0662\n",
      "Epoch: 166/500... Training loss: 0.1636\n",
      "Epoch: 166/500... Training loss: 0.0386\n",
      "Epoch: 166/500... Training loss: 0.0240\n",
      "Epoch: 166/500... Training loss: 0.0450\n",
      "Epoch: 166/500... Training loss: 0.0199\n",
      "Epoch: 166/500... Training loss: 0.1228\n",
      "Epoch: 166/500... Training loss: 0.0610\n",
      "Epoch: 166/500... Training loss: 0.0782\n",
      "Epoch: 166/500... Training loss: 0.0526\n",
      "Epoch: 166/500... Training loss: 0.0540\n",
      "Epoch: 167/500... Training loss: 0.1869\n",
      "Epoch: 167/500... Training loss: 0.0190\n",
      "Epoch: 167/500... Training loss: 0.1132\n",
      "Epoch: 167/500... Training loss: 0.0357\n",
      "Epoch: 167/500... Training loss: 0.0208\n",
      "Epoch: 167/500... Training loss: 0.0368\n",
      "Epoch: 167/500... Training loss: 0.0313\n",
      "Epoch: 167/500... Training loss: 0.0767\n",
      "Epoch: 167/500... Training loss: 0.0242\n",
      "Epoch: 167/500... Training loss: 0.0713\n",
      "Epoch: 167/500... Training loss: 0.0736\n",
      "Epoch: 167/500... Training loss: 0.0397\n",
      "Epoch: 167/500... Training loss: 0.0821\n",
      "Epoch: 167/500... Training loss: 0.1053\n",
      "Epoch: 167/500... Training loss: 0.0294\n",
      "Epoch: 167/500... Training loss: 0.0409\n",
      "Epoch: 167/500... Training loss: 0.0398\n",
      "Epoch: 167/500... Training loss: 0.0844\n",
      "Epoch: 167/500... Training loss: 0.0847\n",
      "Epoch: 167/500... Training loss: 0.0214\n",
      "Epoch: 167/500... Training loss: 0.0723\n",
      "Epoch: 167/500... Training loss: 0.0917\n",
      "Epoch: 167/500... Training loss: 0.0081\n",
      "Epoch: 167/500... Training loss: 0.1466\n",
      "Epoch: 167/500... Training loss: 0.0528\n",
      "Epoch: 167/500... Training loss: 0.0269\n",
      "Epoch: 167/500... Training loss: 0.0796\n",
      "Epoch: 167/500... Training loss: 0.0526\n",
      "Epoch: 167/500... Training loss: 0.0946\n",
      "Epoch: 167/500... Training loss: 0.1074\n",
      "Epoch: 167/500... Training loss: 0.0663\n",
      "Epoch: 168/500... Training loss: 0.0499\n",
      "Epoch: 168/500... Training loss: 0.0400\n",
      "Epoch: 168/500... Training loss: 0.0320\n",
      "Epoch: 168/500... Training loss: 0.0384\n",
      "Epoch: 168/500... Training loss: 0.0445\n",
      "Epoch: 168/500... Training loss: 0.0977\n",
      "Epoch: 168/500... Training loss: 0.0532\n",
      "Epoch: 168/500... Training loss: 0.0858\n",
      "Epoch: 168/500... Training loss: 0.0763\n",
      "Epoch: 168/500... Training loss: 0.0286\n",
      "Epoch: 168/500... Training loss: 0.0570\n",
      "Epoch: 168/500... Training loss: 0.0737\n",
      "Epoch: 168/500... Training loss: 0.0461\n",
      "Epoch: 168/500... Training loss: 0.0592\n",
      "Epoch: 168/500... Training loss: 0.0585\n",
      "Epoch: 168/500... Training loss: 0.0466\n",
      "Epoch: 168/500... Training loss: 0.0638\n",
      "Epoch: 168/500... Training loss: 0.0656\n",
      "Epoch: 168/500... Training loss: 0.1036\n",
      "Epoch: 168/500... Training loss: 0.1027\n",
      "Epoch: 168/500... Training loss: 0.1266\n",
      "Epoch: 168/500... Training loss: 0.0832\n",
      "Epoch: 168/500... Training loss: 0.3158\n",
      "Epoch: 168/500... Training loss: 0.0210\n",
      "Epoch: 168/500... Training loss: 0.0585\n",
      "Epoch: 168/500... Training loss: 0.0137\n",
      "Epoch: 168/500... Training loss: 0.1208\n",
      "Epoch: 168/500... Training loss: 0.1164\n",
      "Epoch: 168/500... Training loss: 0.0132\n",
      "Epoch: 168/500... Training loss: 0.0635\n",
      "Epoch: 168/500... Training loss: 0.0152\n",
      "Epoch: 169/500... Training loss: 0.1395\n",
      "Epoch: 169/500... Training loss: 0.0916\n",
      "Epoch: 169/500... Training loss: 0.0514\n",
      "Epoch: 169/500... Training loss: 0.0128\n",
      "Epoch: 169/500... Training loss: 0.0362\n",
      "Epoch: 169/500... Training loss: 0.0450\n",
      "Epoch: 169/500... Training loss: 0.0398\n",
      "Epoch: 169/500... Training loss: 0.0586\n",
      "Epoch: 169/500... Training loss: 0.0295\n",
      "Epoch: 169/500... Training loss: 0.0353\n",
      "Epoch: 169/500... Training loss: 0.0839\n",
      "Epoch: 169/500... Training loss: 0.1950\n",
      "Epoch: 169/500... Training loss: 0.0524\n",
      "Epoch: 169/500... Training loss: 0.0242\n",
      "Epoch: 169/500... Training loss: 0.0196\n",
      "Epoch: 169/500... Training loss: 0.1465\n",
      "Epoch: 169/500... Training loss: 0.0893\n",
      "Epoch: 169/500... Training loss: 0.1482\n",
      "Epoch: 169/500... Training loss: 0.0458\n",
      "Epoch: 169/500... Training loss: 0.1250\n",
      "Epoch: 169/500... Training loss: 0.0773\n",
      "Epoch: 169/500... Training loss: 0.0637\n",
      "Epoch: 169/500... Training loss: 0.0437\n",
      "Epoch: 169/500... Training loss: 0.0544\n",
      "Epoch: 169/500... Training loss: 0.0244\n",
      "Epoch: 169/500... Training loss: 0.1387\n",
      "Epoch: 169/500... Training loss: 0.0699\n",
      "Epoch: 169/500... Training loss: 0.0833\n",
      "Epoch: 169/500... Training loss: 0.0690\n",
      "Epoch: 169/500... Training loss: 0.0882\n",
      "Epoch: 169/500... Training loss: 0.0979\n",
      "Epoch: 170/500... Training loss: 0.0445\n",
      "Epoch: 170/500... Training loss: 0.1922\n",
      "Epoch: 170/500... Training loss: 0.1169\n",
      "Epoch: 170/500... Training loss: 0.0735\n",
      "Epoch: 170/500... Training loss: 0.0347\n",
      "Epoch: 170/500... Training loss: 0.1676\n",
      "Epoch: 170/500... Training loss: 0.0571\n",
      "Epoch: 170/500... Training loss: 0.0478\n",
      "Epoch: 170/500... Training loss: 0.0307\n",
      "Epoch: 170/500... Training loss: 0.0231\n",
      "Epoch: 170/500... Training loss: 0.0667\n",
      "Epoch: 170/500... Training loss: 0.1732\n",
      "Epoch: 170/500... Training loss: 0.0701\n",
      "Epoch: 170/500... Training loss: 0.0615\n",
      "Epoch: 170/500... Training loss: 0.0521\n",
      "Epoch: 170/500... Training loss: 0.0486\n",
      "Epoch: 170/500... Training loss: 0.0721\n",
      "Epoch: 170/500... Training loss: 0.0267\n",
      "Epoch: 170/500... Training loss: 0.1115\n",
      "Epoch: 170/500... Training loss: 0.0619\n",
      "Epoch: 170/500... Training loss: 0.0500\n",
      "Epoch: 170/500... Training loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170/500... Training loss: 0.0695\n",
      "Epoch: 170/500... Training loss: 0.0423\n",
      "Epoch: 170/500... Training loss: 0.0941\n",
      "Epoch: 170/500... Training loss: 0.0337\n",
      "Epoch: 170/500... Training loss: 0.0779\n",
      "Epoch: 170/500... Training loss: 0.0166\n",
      "Epoch: 170/500... Training loss: 0.0228\n",
      "Epoch: 170/500... Training loss: 0.1235\n",
      "Epoch: 170/500... Training loss: 0.0585\n",
      "Epoch: 171/500... Training loss: 0.0635\n",
      "Epoch: 171/500... Training loss: 0.1146\n",
      "Epoch: 171/500... Training loss: 0.0605\n",
      "Epoch: 171/500... Training loss: 0.0448\n",
      "Epoch: 171/500... Training loss: 0.0465\n",
      "Epoch: 171/500... Training loss: 0.0502\n",
      "Epoch: 171/500... Training loss: 0.0669\n",
      "Epoch: 171/500... Training loss: 0.0905\n",
      "Epoch: 171/500... Training loss: 0.0518\n",
      "Epoch: 171/500... Training loss: 0.0932\n",
      "Epoch: 171/500... Training loss: 0.1661\n",
      "Epoch: 171/500... Training loss: 0.1682\n",
      "Epoch: 171/500... Training loss: 0.0439\n",
      "Epoch: 171/500... Training loss: 0.1045\n",
      "Epoch: 171/500... Training loss: 0.0202\n",
      "Epoch: 171/500... Training loss: 0.0357\n",
      "Epoch: 171/500... Training loss: 0.0425\n",
      "Epoch: 171/500... Training loss: 0.1506\n",
      "Epoch: 171/500... Training loss: 0.0873\n",
      "Epoch: 171/500... Training loss: 0.0441\n",
      "Epoch: 171/500... Training loss: 0.0568\n",
      "Epoch: 171/500... Training loss: 0.0451\n",
      "Epoch: 171/500... Training loss: 0.0463\n",
      "Epoch: 171/500... Training loss: 0.0892\n",
      "Epoch: 171/500... Training loss: 0.0838\n",
      "Epoch: 171/500... Training loss: 0.0126\n",
      "Epoch: 171/500... Training loss: 0.0300\n",
      "Epoch: 171/500... Training loss: 0.0838\n",
      "Epoch: 171/500... Training loss: 0.0341\n",
      "Epoch: 171/500... Training loss: 0.0334\n",
      "Epoch: 171/500... Training loss: 0.0299\n",
      "Epoch: 172/500... Training loss: 0.1661\n",
      "Epoch: 172/500... Training loss: 0.0439\n",
      "Epoch: 172/500... Training loss: 0.1166\n",
      "Epoch: 172/500... Training loss: 0.0532\n",
      "Epoch: 172/500... Training loss: 0.0756\n",
      "Epoch: 172/500... Training loss: 0.0609\n",
      "Epoch: 172/500... Training loss: 0.0640\n",
      "Epoch: 172/500... Training loss: 0.0634\n",
      "Epoch: 172/500... Training loss: 0.2230\n",
      "Epoch: 172/500... Training loss: 0.1071\n",
      "Epoch: 172/500... Training loss: 0.0544\n",
      "Epoch: 172/500... Training loss: 0.0653\n",
      "Epoch: 172/500... Training loss: 0.0877\n",
      "Epoch: 172/500... Training loss: 0.0277\n",
      "Epoch: 172/500... Training loss: 0.0824\n",
      "Epoch: 172/500... Training loss: 0.0399\n",
      "Epoch: 172/500... Training loss: 0.0233\n",
      "Epoch: 172/500... Training loss: 0.1105\n",
      "Epoch: 172/500... Training loss: 0.0809\n",
      "Epoch: 172/500... Training loss: 0.0268\n",
      "Epoch: 172/500... Training loss: 0.0713\n",
      "Epoch: 172/500... Training loss: 0.0264\n",
      "Epoch: 172/500... Training loss: 0.0311\n",
      "Epoch: 172/500... Training loss: 0.1280\n",
      "Epoch: 172/500... Training loss: 0.0934\n",
      "Epoch: 172/500... Training loss: 0.0133\n",
      "Epoch: 172/500... Training loss: 0.0662\n",
      "Epoch: 172/500... Training loss: 0.0175\n",
      "Epoch: 172/500... Training loss: 0.1043\n",
      "Epoch: 172/500... Training loss: 0.0301\n",
      "Epoch: 172/500... Training loss: 0.0621\n",
      "Epoch: 173/500... Training loss: 0.0317\n",
      "Epoch: 173/500... Training loss: 0.1132\n",
      "Epoch: 173/500... Training loss: 0.1993\n",
      "Epoch: 173/500... Training loss: 0.0246\n",
      "Epoch: 173/500... Training loss: 0.1119\n",
      "Epoch: 173/500... Training loss: 0.0232\n",
      "Epoch: 173/500... Training loss: 0.0612\n",
      "Epoch: 173/500... Training loss: 0.0298\n",
      "Epoch: 173/500... Training loss: 0.0434\n",
      "Epoch: 173/500... Training loss: 0.0563\n",
      "Epoch: 173/500... Training loss: 0.0928\n",
      "Epoch: 173/500... Training loss: 0.0610\n",
      "Epoch: 173/500... Training loss: 0.0522\n",
      "Epoch: 173/500... Training loss: 0.0420\n",
      "Epoch: 173/500... Training loss: 0.0323\n",
      "Epoch: 173/500... Training loss: 0.0449\n",
      "Epoch: 173/500... Training loss: 0.0875\n",
      "Epoch: 173/500... Training loss: 0.1206\n",
      "Epoch: 173/500... Training loss: 0.0112\n",
      "Epoch: 173/500... Training loss: 0.0468\n",
      "Epoch: 173/500... Training loss: 0.0325\n",
      "Epoch: 173/500... Training loss: 0.1203\n",
      "Epoch: 173/500... Training loss: 0.0451\n",
      "Epoch: 173/500... Training loss: 0.0393\n",
      "Epoch: 173/500... Training loss: 0.0509\n",
      "Epoch: 173/500... Training loss: 0.0361\n",
      "Epoch: 173/500... Training loss: 0.1538\n",
      "Epoch: 173/500... Training loss: 0.0482\n",
      "Epoch: 173/500... Training loss: 0.0469\n",
      "Epoch: 173/500... Training loss: 0.1378\n",
      "Epoch: 173/500... Training loss: 0.0603\n",
      "Epoch: 174/500... Training loss: 0.1736\n",
      "Epoch: 174/500... Training loss: 0.0269\n",
      "Epoch: 174/500... Training loss: 0.0106\n",
      "Epoch: 174/500... Training loss: 0.1109\n",
      "Epoch: 174/500... Training loss: 0.1601\n",
      "Epoch: 174/500... Training loss: 0.0383\n",
      "Epoch: 174/500... Training loss: 0.0993\n",
      "Epoch: 174/500... Training loss: 0.1580\n",
      "Epoch: 174/500... Training loss: 0.0624\n",
      "Epoch: 174/500... Training loss: 0.0846\n",
      "Epoch: 174/500... Training loss: 0.0328\n",
      "Epoch: 174/500... Training loss: 0.0365\n",
      "Epoch: 174/500... Training loss: 0.0299\n",
      "Epoch: 174/500... Training loss: 0.1740\n",
      "Epoch: 174/500... Training loss: 0.0613\n",
      "Epoch: 174/500... Training loss: 0.0199\n",
      "Epoch: 174/500... Training loss: 0.1464\n",
      "Epoch: 174/500... Training loss: 0.0419\n",
      "Epoch: 174/500... Training loss: 0.0783\n",
      "Epoch: 174/500... Training loss: 0.0533\n",
      "Epoch: 174/500... Training loss: 0.0681\n",
      "Epoch: 174/500... Training loss: 0.0437\n",
      "Epoch: 174/500... Training loss: 0.0106\n",
      "Epoch: 174/500... Training loss: 0.0618\n",
      "Epoch: 174/500... Training loss: 0.0276\n",
      "Epoch: 174/500... Training loss: 0.0342\n",
      "Epoch: 174/500... Training loss: 0.0878\n",
      "Epoch: 174/500... Training loss: 0.1113\n",
      "Epoch: 174/500... Training loss: 0.0126\n",
      "Epoch: 174/500... Training loss: 0.0392\n",
      "Epoch: 174/500... Training loss: 0.1595\n",
      "Epoch: 175/500... Training loss: 0.1840\n",
      "Epoch: 175/500... Training loss: 0.1373\n",
      "Epoch: 175/500... Training loss: 0.0929\n",
      "Epoch: 175/500... Training loss: 0.0831\n",
      "Epoch: 175/500... Training loss: 0.1360\n",
      "Epoch: 175/500... Training loss: 0.0834\n",
      "Epoch: 175/500... Training loss: 0.1794\n",
      "Epoch: 175/500... Training loss: 0.0358\n",
      "Epoch: 175/500... Training loss: 0.0897\n",
      "Epoch: 175/500... Training loss: 0.0219\n",
      "Epoch: 175/500... Training loss: 0.0996\n",
      "Epoch: 175/500... Training loss: 0.1124\n",
      "Epoch: 175/500... Training loss: 0.0452\n",
      "Epoch: 175/500... Training loss: 0.1591\n",
      "Epoch: 175/500... Training loss: 0.1024\n",
      "Epoch: 175/500... Training loss: 0.1638\n",
      "Epoch: 175/500... Training loss: 0.0339\n",
      "Epoch: 175/500... Training loss: 0.0681\n",
      "Epoch: 175/500... Training loss: 0.1462\n",
      "Epoch: 175/500... Training loss: 0.0045\n",
      "Epoch: 175/500... Training loss: 0.0510\n",
      "Epoch: 175/500... Training loss: 0.0552\n",
      "Epoch: 175/500... Training loss: 0.0375\n",
      "Epoch: 175/500... Training loss: 0.0468\n",
      "Epoch: 175/500... Training loss: 0.0564\n",
      "Epoch: 175/500... Training loss: 0.0316\n",
      "Epoch: 175/500... Training loss: 0.0806\n",
      "Epoch: 175/500... Training loss: 0.0250\n",
      "Epoch: 175/500... Training loss: 0.0363\n",
      "Epoch: 175/500... Training loss: 0.0870\n",
      "Epoch: 175/500... Training loss: 0.0910\n",
      "Epoch: 176/500... Training loss: 0.1456\n",
      "Epoch: 176/500... Training loss: 0.0893\n",
      "Epoch: 176/500... Training loss: 0.0474\n",
      "Epoch: 176/500... Training loss: 0.1373\n",
      "Epoch: 176/500... Training loss: 0.0385\n",
      "Epoch: 176/500... Training loss: 0.0234\n",
      "Epoch: 176/500... Training loss: 0.0266\n",
      "Epoch: 176/500... Training loss: 0.0231\n",
      "Epoch: 176/500... Training loss: 0.0245\n",
      "Epoch: 176/500... Training loss: 0.0646\n",
      "Epoch: 176/500... Training loss: 0.0300\n",
      "Epoch: 176/500... Training loss: 0.1051\n",
      "Epoch: 176/500... Training loss: 0.0433\n",
      "Epoch: 176/500... Training loss: 0.0479\n",
      "Epoch: 176/500... Training loss: 0.0574\n",
      "Epoch: 176/500... Training loss: 0.0413\n",
      "Epoch: 176/500... Training loss: 0.0509\n",
      "Epoch: 176/500... Training loss: 0.0874\n",
      "Epoch: 176/500... Training loss: 0.0651\n",
      "Epoch: 176/500... Training loss: 0.0194\n",
      "Epoch: 176/500... Training loss: 0.0378\n",
      "Epoch: 176/500... Training loss: 0.0491\n",
      "Epoch: 176/500... Training loss: 0.0880\n",
      "Epoch: 176/500... Training loss: 0.0912\n",
      "Epoch: 176/500... Training loss: 0.0247\n",
      "Epoch: 176/500... Training loss: 0.1092\n",
      "Epoch: 176/500... Training loss: 0.0319\n",
      "Epoch: 176/500... Training loss: 0.0957\n",
      "Epoch: 176/500... Training loss: 0.0785\n",
      "Epoch: 176/500... Training loss: 0.0588\n",
      "Epoch: 176/500... Training loss: 0.0965\n",
      "Epoch: 177/500... Training loss: 0.0592\n",
      "Epoch: 177/500... Training loss: 0.0288\n",
      "Epoch: 177/500... Training loss: 0.0482\n",
      "Epoch: 177/500... Training loss: 0.1245\n",
      "Epoch: 177/500... Training loss: 0.0372\n",
      "Epoch: 177/500... Training loss: 0.1042\n",
      "Epoch: 177/500... Training loss: 0.0626\n",
      "Epoch: 177/500... Training loss: 0.0174\n",
      "Epoch: 177/500... Training loss: 0.1303\n",
      "Epoch: 177/500... Training loss: 0.0912\n",
      "Epoch: 177/500... Training loss: 0.0662\n",
      "Epoch: 177/500... Training loss: 0.1446\n",
      "Epoch: 177/500... Training loss: 0.0416\n",
      "Epoch: 177/500... Training loss: 0.0976\n",
      "Epoch: 177/500... Training loss: 0.0629\n",
      "Epoch: 177/500... Training loss: 0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 177/500... Training loss: 0.2009\n",
      "Epoch: 177/500... Training loss: 0.0291\n",
      "Epoch: 177/500... Training loss: 0.0624\n",
      "Epoch: 177/500... Training loss: 0.0270\n",
      "Epoch: 177/500... Training loss: 0.0472\n",
      "Epoch: 177/500... Training loss: 0.0159\n",
      "Epoch: 177/500... Training loss: 0.0410\n",
      "Epoch: 177/500... Training loss: 0.0620\n",
      "Epoch: 177/500... Training loss: 0.1062\n",
      "Epoch: 177/500... Training loss: 0.0150\n",
      "Epoch: 177/500... Training loss: 0.0163\n",
      "Epoch: 177/500... Training loss: 0.0168\n",
      "Epoch: 177/500... Training loss: 0.0187\n",
      "Epoch: 177/500... Training loss: 0.0301\n",
      "Epoch: 177/500... Training loss: 0.0492\n",
      "Epoch: 178/500... Training loss: 0.0404\n",
      "Epoch: 178/500... Training loss: 0.0793\n",
      "Epoch: 178/500... Training loss: 0.0622\n",
      "Epoch: 178/500... Training loss: 0.0489\n",
      "Epoch: 178/500... Training loss: 0.0386\n",
      "Epoch: 178/500... Training loss: 0.0204\n",
      "Epoch: 178/500... Training loss: 0.0570\n",
      "Epoch: 178/500... Training loss: 0.0287\n",
      "Epoch: 178/500... Training loss: 0.0235\n",
      "Epoch: 178/500... Training loss: 0.0716\n",
      "Epoch: 178/500... Training loss: 0.0733\n",
      "Epoch: 178/500... Training loss: 0.1607\n",
      "Epoch: 178/500... Training loss: 0.0687\n",
      "Epoch: 178/500... Training loss: 0.0774\n",
      "Epoch: 178/500... Training loss: 0.0461\n",
      "Epoch: 178/500... Training loss: 0.0959\n",
      "Epoch: 178/500... Training loss: 0.0126\n",
      "Epoch: 178/500... Training loss: 0.1068\n",
      "Epoch: 178/500... Training loss: 0.0415\n",
      "Epoch: 178/500... Training loss: 0.0588\n",
      "Epoch: 178/500... Training loss: 0.0471\n",
      "Epoch: 178/500... Training loss: 0.1657\n",
      "Epoch: 178/500... Training loss: 0.0193\n",
      "Epoch: 178/500... Training loss: 0.0182\n",
      "Epoch: 178/500... Training loss: 0.0423\n",
      "Epoch: 178/500... Training loss: 0.0480\n",
      "Epoch: 178/500... Training loss: 0.0558\n",
      "Epoch: 178/500... Training loss: 0.1092\n",
      "Epoch: 178/500... Training loss: 0.0241\n",
      "Epoch: 178/500... Training loss: 0.1424\n",
      "Epoch: 178/500... Training loss: 0.0327\n",
      "Epoch: 179/500... Training loss: 0.0839\n",
      "Epoch: 179/500... Training loss: 0.0383\n",
      "Epoch: 179/500... Training loss: 0.0580\n",
      "Epoch: 179/500... Training loss: 0.1056\n",
      "Epoch: 179/500... Training loss: 0.0392\n",
      "Epoch: 179/500... Training loss: 0.0182\n",
      "Epoch: 179/500... Training loss: 0.0726\n",
      "Epoch: 179/500... Training loss: 0.0586\n",
      "Epoch: 179/500... Training loss: 0.1391\n",
      "Epoch: 179/500... Training loss: 0.0556\n",
      "Epoch: 179/500... Training loss: 0.0860\n",
      "Epoch: 179/500... Training loss: 0.0565\n",
      "Epoch: 179/500... Training loss: 0.0292\n",
      "Epoch: 179/500... Training loss: 0.0621\n",
      "Epoch: 179/500... Training loss: 0.0377\n",
      "Epoch: 179/500... Training loss: 0.0103\n",
      "Epoch: 179/500... Training loss: 0.0143\n",
      "Epoch: 179/500... Training loss: 0.0552\n",
      "Epoch: 179/500... Training loss: 0.0755\n",
      "Epoch: 179/500... Training loss: 0.0708\n",
      "Epoch: 179/500... Training loss: 0.0156\n",
      "Epoch: 179/500... Training loss: 0.1269\n",
      "Epoch: 179/500... Training loss: 0.0292\n",
      "Epoch: 179/500... Training loss: 0.0461\n",
      "Epoch: 179/500... Training loss: 0.0216\n",
      "Epoch: 179/500... Training loss: 0.0496\n",
      "Epoch: 179/500... Training loss: 0.0242\n",
      "Epoch: 179/500... Training loss: 0.0438\n",
      "Epoch: 179/500... Training loss: 0.0207\n",
      "Epoch: 179/500... Training loss: 0.0306\n",
      "Epoch: 179/500... Training loss: 0.0589\n",
      "Epoch: 180/500... Training loss: 0.0450\n",
      "Epoch: 180/500... Training loss: 0.1019\n",
      "Epoch: 180/500... Training loss: 0.0504\n",
      "Epoch: 180/500... Training loss: 0.0209\n",
      "Epoch: 180/500... Training loss: 0.0652\n",
      "Epoch: 180/500... Training loss: 0.0289\n",
      "Epoch: 180/500... Training loss: 0.0764\n",
      "Epoch: 180/500... Training loss: 0.0161\n",
      "Epoch: 180/500... Training loss: 0.0284\n",
      "Epoch: 180/500... Training loss: 0.0420\n",
      "Epoch: 180/500... Training loss: 0.0579\n",
      "Epoch: 180/500... Training loss: 0.0830\n",
      "Epoch: 180/500... Training loss: 0.0527\n",
      "Epoch: 180/500... Training loss: 0.0175\n",
      "Epoch: 180/500... Training loss: 0.0715\n",
      "Epoch: 180/500... Training loss: 0.0555\n",
      "Epoch: 180/500... Training loss: 0.0324\n",
      "Epoch: 180/500... Training loss: 0.0683\n",
      "Epoch: 180/500... Training loss: 0.0689\n",
      "Epoch: 180/500... Training loss: 0.0506\n",
      "Epoch: 180/500... Training loss: 0.2113\n",
      "Epoch: 180/500... Training loss: 0.0989\n",
      "Epoch: 180/500... Training loss: 0.0208\n",
      "Epoch: 180/500... Training loss: 0.0138\n",
      "Epoch: 180/500... Training loss: 0.0324\n",
      "Epoch: 180/500... Training loss: 0.0136\n",
      "Epoch: 180/500... Training loss: 0.1007\n",
      "Epoch: 180/500... Training loss: 0.0222\n",
      "Epoch: 180/500... Training loss: 0.0854\n",
      "Epoch: 180/500... Training loss: 0.0346\n",
      "Epoch: 180/500... Training loss: 0.0174\n",
      "Epoch: 181/500... Training loss: 0.1292\n",
      "Epoch: 181/500... Training loss: 0.0211\n",
      "Epoch: 181/500... Training loss: 0.0419\n",
      "Epoch: 181/500... Training loss: 0.0557\n",
      "Epoch: 181/500... Training loss: 0.2256\n",
      "Epoch: 181/500... Training loss: 0.0230\n",
      "Epoch: 181/500... Training loss: 0.0576\n",
      "Epoch: 181/500... Training loss: 0.1253\n",
      "Epoch: 181/500... Training loss: 0.0532\n",
      "Epoch: 181/500... Training loss: 0.0367\n",
      "Epoch: 181/500... Training loss: 0.0839\n",
      "Epoch: 181/500... Training loss: 0.0363\n",
      "Epoch: 181/500... Training loss: 0.0287\n",
      "Epoch: 181/500... Training loss: 0.1418\n",
      "Epoch: 181/500... Training loss: 0.0656\n",
      "Epoch: 181/500... Training loss: 0.0725\n",
      "Epoch: 181/500... Training loss: 0.0202\n",
      "Epoch: 181/500... Training loss: 0.0297\n",
      "Epoch: 181/500... Training loss: 0.1004\n",
      "Epoch: 181/500... Training loss: 0.0634\n",
      "Epoch: 181/500... Training loss: 0.0196\n",
      "Epoch: 181/500... Training loss: 0.0855\n",
      "Epoch: 181/500... Training loss: 0.0379\n",
      "Epoch: 181/500... Training loss: 0.0444\n",
      "Epoch: 181/500... Training loss: 0.0530\n",
      "Epoch: 181/500... Training loss: 0.0269\n",
      "Epoch: 181/500... Training loss: 0.0762\n",
      "Epoch: 181/500... Training loss: 0.0517\n",
      "Epoch: 181/500... Training loss: 0.1174\n",
      "Epoch: 181/500... Training loss: 0.0161\n",
      "Epoch: 181/500... Training loss: 0.0884\n",
      "Epoch: 182/500... Training loss: 0.0942\n",
      "Epoch: 182/500... Training loss: 0.0557\n",
      "Epoch: 182/500... Training loss: 0.0902\n",
      "Epoch: 182/500... Training loss: 0.1369\n",
      "Epoch: 182/500... Training loss: 0.0681\n",
      "Epoch: 182/500... Training loss: 0.0470\n",
      "Epoch: 182/500... Training loss: 0.0501\n",
      "Epoch: 182/500... Training loss: 0.1263\n",
      "Epoch: 182/500... Training loss: 0.0210\n",
      "Epoch: 182/500... Training loss: 0.0109\n",
      "Epoch: 182/500... Training loss: 0.0927\n",
      "Epoch: 182/500... Training loss: 0.0777\n",
      "Epoch: 182/500... Training loss: 0.1150\n",
      "Epoch: 182/500... Training loss: 0.0234\n",
      "Epoch: 182/500... Training loss: 0.0248\n",
      "Epoch: 182/500... Training loss: 0.0123\n",
      "Epoch: 182/500... Training loss: 0.0598\n",
      "Epoch: 182/500... Training loss: 0.0123\n",
      "Epoch: 182/500... Training loss: 0.0419\n",
      "Epoch: 182/500... Training loss: 0.0198\n",
      "Epoch: 182/500... Training loss: 0.0246\n",
      "Epoch: 182/500... Training loss: 0.0429\n",
      "Epoch: 182/500... Training loss: 0.0251\n",
      "Epoch: 182/500... Training loss: 0.1094\n",
      "Epoch: 182/500... Training loss: 0.0588\n",
      "Epoch: 182/500... Training loss: 0.1086\n",
      "Epoch: 182/500... Training loss: 0.0398\n",
      "Epoch: 182/500... Training loss: 0.0540\n",
      "Epoch: 182/500... Training loss: 0.0499\n",
      "Epoch: 182/500... Training loss: 0.0324\n",
      "Epoch: 182/500... Training loss: 0.0409\n",
      "Epoch: 183/500... Training loss: 0.0793\n",
      "Epoch: 183/500... Training loss: 0.1917\n",
      "Epoch: 183/500... Training loss: 0.0160\n",
      "Epoch: 183/500... Training loss: 0.1545\n",
      "Epoch: 183/500... Training loss: 0.0387\n",
      "Epoch: 183/500... Training loss: 0.0393\n",
      "Epoch: 183/500... Training loss: 0.0615\n",
      "Epoch: 183/500... Training loss: 0.0587\n",
      "Epoch: 183/500... Training loss: 0.0460\n",
      "Epoch: 183/500... Training loss: 0.0328\n",
      "Epoch: 183/500... Training loss: 0.0605\n",
      "Epoch: 183/500... Training loss: 0.0535\n",
      "Epoch: 183/500... Training loss: 0.1028\n",
      "Epoch: 183/500... Training loss: 0.0466\n",
      "Epoch: 183/500... Training loss: 0.1407\n",
      "Epoch: 183/500... Training loss: 0.0491\n",
      "Epoch: 183/500... Training loss: 0.1373\n",
      "Epoch: 183/500... Training loss: 0.0725\n",
      "Epoch: 183/500... Training loss: 0.0184\n",
      "Epoch: 183/500... Training loss: 0.0558\n",
      "Epoch: 183/500... Training loss: 0.0594\n",
      "Epoch: 183/500... Training loss: 0.1297\n",
      "Epoch: 183/500... Training loss: 0.0496\n",
      "Epoch: 183/500... Training loss: 0.1243\n",
      "Epoch: 183/500... Training loss: 0.1007\n",
      "Epoch: 183/500... Training loss: 0.1999\n",
      "Epoch: 183/500... Training loss: 0.0771\n",
      "Epoch: 183/500... Training loss: 0.0637\n",
      "Epoch: 183/500... Training loss: 0.0270\n",
      "Epoch: 183/500... Training loss: 0.0348\n",
      "Epoch: 183/500... Training loss: 0.0518\n",
      "Epoch: 184/500... Training loss: 0.1014\n",
      "Epoch: 184/500... Training loss: 0.0815\n",
      "Epoch: 184/500... Training loss: 0.0247\n",
      "Epoch: 184/500... Training loss: 0.0930\n",
      "Epoch: 184/500... Training loss: 0.0121\n",
      "Epoch: 184/500... Training loss: 0.1426\n",
      "Epoch: 184/500... Training loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184/500... Training loss: 0.0915\n",
      "Epoch: 184/500... Training loss: 0.0250\n",
      "Epoch: 184/500... Training loss: 0.0433\n",
      "Epoch: 184/500... Training loss: 0.0171\n",
      "Epoch: 184/500... Training loss: 0.0497\n",
      "Epoch: 184/500... Training loss: 0.0267\n",
      "Epoch: 184/500... Training loss: 0.1429\n",
      "Epoch: 184/500... Training loss: 0.0832\n",
      "Epoch: 184/500... Training loss: 0.0196\n",
      "Epoch: 184/500... Training loss: 0.0565\n",
      "Epoch: 184/500... Training loss: 0.0673\n",
      "Epoch: 184/500... Training loss: 0.0946\n",
      "Epoch: 184/500... Training loss: 0.0325\n",
      "Epoch: 184/500... Training loss: 0.0833\n",
      "Epoch: 184/500... Training loss: 0.0203\n",
      "Epoch: 184/500... Training loss: 0.0331\n",
      "Epoch: 184/500... Training loss: 0.2091\n",
      "Epoch: 184/500... Training loss: 0.0972\n",
      "Epoch: 184/500... Training loss: 0.0517\n",
      "Epoch: 184/500... Training loss: 0.0161\n",
      "Epoch: 184/500... Training loss: 0.0419\n",
      "Epoch: 184/500... Training loss: 0.0166\n",
      "Epoch: 184/500... Training loss: 0.0470\n",
      "Epoch: 184/500... Training loss: 0.0128\n",
      "Epoch: 185/500... Training loss: 0.0390\n",
      "Epoch: 185/500... Training loss: 0.0627\n",
      "Epoch: 185/500... Training loss: 0.0247\n",
      "Epoch: 185/500... Training loss: 0.0332\n",
      "Epoch: 185/500... Training loss: 0.1026\n",
      "Epoch: 185/500... Training loss: 0.0523\n",
      "Epoch: 185/500... Training loss: 0.1091\n",
      "Epoch: 185/500... Training loss: 0.0541\n",
      "Epoch: 185/500... Training loss: 0.0462\n",
      "Epoch: 185/500... Training loss: 0.0440\n",
      "Epoch: 185/500... Training loss: 0.0355\n",
      "Epoch: 185/500... Training loss: 0.0542\n",
      "Epoch: 185/500... Training loss: 0.0835\n",
      "Epoch: 185/500... Training loss: 0.0794\n",
      "Epoch: 185/500... Training loss: 0.0465\n",
      "Epoch: 185/500... Training loss: 0.0271\n",
      "Epoch: 185/500... Training loss: 0.0057\n",
      "Epoch: 185/500... Training loss: 0.0083\n",
      "Epoch: 185/500... Training loss: 0.0147\n",
      "Epoch: 185/500... Training loss: 0.0344\n",
      "Epoch: 185/500... Training loss: 0.0789\n",
      "Epoch: 185/500... Training loss: 0.0703\n",
      "Epoch: 185/500... Training loss: 0.0156\n",
      "Epoch: 185/500... Training loss: 0.0689\n",
      "Epoch: 185/500... Training loss: 0.0530\n",
      "Epoch: 185/500... Training loss: 0.0161\n",
      "Epoch: 185/500... Training loss: 0.0448\n",
      "Epoch: 185/500... Training loss: 0.0613\n",
      "Epoch: 185/500... Training loss: 0.0307\n",
      "Epoch: 185/500... Training loss: 0.0159\n",
      "Epoch: 185/500... Training loss: 0.0220\n",
      "Epoch: 186/500... Training loss: 0.1047\n",
      "Epoch: 186/500... Training loss: 0.0080\n",
      "Epoch: 186/500... Training loss: 0.0304\n",
      "Epoch: 186/500... Training loss: 0.0428\n",
      "Epoch: 186/500... Training loss: 0.0160\n",
      "Epoch: 186/500... Training loss: 0.0474\n",
      "Epoch: 186/500... Training loss: 0.0221\n",
      "Epoch: 186/500... Training loss: 0.0292\n",
      "Epoch: 186/500... Training loss: 0.0311\n",
      "Epoch: 186/500... Training loss: 0.0131\n",
      "Epoch: 186/500... Training loss: 0.0285\n",
      "Epoch: 186/500... Training loss: 0.0702\n",
      "Epoch: 186/500... Training loss: 0.0432\n",
      "Epoch: 186/500... Training loss: 0.0344\n",
      "Epoch: 186/500... Training loss: 0.0359\n",
      "Epoch: 186/500... Training loss: 0.0797\n",
      "Epoch: 186/500... Training loss: 0.0583\n",
      "Epoch: 186/500... Training loss: 0.0804\n",
      "Epoch: 186/500... Training loss: 0.0455\n",
      "Epoch: 186/500... Training loss: 0.0072\n",
      "Epoch: 186/500... Training loss: 0.0466\n",
      "Epoch: 186/500... Training loss: 0.0330\n",
      "Epoch: 186/500... Training loss: 0.0083\n",
      "Epoch: 186/500... Training loss: 0.0155\n",
      "Epoch: 186/500... Training loss: 0.0362\n",
      "Epoch: 186/500... Training loss: 0.0737\n",
      "Epoch: 186/500... Training loss: 0.1221\n",
      "Epoch: 186/500... Training loss: 0.1161\n",
      "Epoch: 186/500... Training loss: 0.0466\n",
      "Epoch: 186/500... Training loss: 0.0298\n",
      "Epoch: 186/500... Training loss: 0.1319\n",
      "Epoch: 187/500... Training loss: 0.1227\n",
      "Epoch: 187/500... Training loss: 0.0505\n",
      "Epoch: 187/500... Training loss: 0.0417\n",
      "Epoch: 187/500... Training loss: 0.1036\n",
      "Epoch: 187/500... Training loss: 0.0373\n",
      "Epoch: 187/500... Training loss: 0.0882\n",
      "Epoch: 187/500... Training loss: 0.0352\n",
      "Epoch: 187/500... Training loss: 0.0633\n",
      "Epoch: 187/500... Training loss: 0.0299\n",
      "Epoch: 187/500... Training loss: 0.0351\n",
      "Epoch: 187/500... Training loss: 0.0281\n",
      "Epoch: 187/500... Training loss: 0.1606\n",
      "Epoch: 187/500... Training loss: 0.1292\n",
      "Epoch: 187/500... Training loss: 0.0272\n",
      "Epoch: 187/500... Training loss: 0.0081\n",
      "Epoch: 187/500... Training loss: 0.0532\n",
      "Epoch: 187/500... Training loss: 0.0491\n",
      "Epoch: 187/500... Training loss: 0.0725\n",
      "Epoch: 187/500... Training loss: 0.0494\n",
      "Epoch: 187/500... Training loss: 0.0416\n",
      "Epoch: 187/500... Training loss: 0.0559\n",
      "Epoch: 187/500... Training loss: 0.0807\n",
      "Epoch: 187/500... Training loss: 0.0552\n",
      "Epoch: 187/500... Training loss: 0.0221\n",
      "Epoch: 187/500... Training loss: 0.0074\n",
      "Epoch: 187/500... Training loss: 0.1242\n",
      "Epoch: 187/500... Training loss: 0.0748\n",
      "Epoch: 187/500... Training loss: 0.0300\n",
      "Epoch: 187/500... Training loss: 0.0683\n",
      "Epoch: 187/500... Training loss: 0.0816\n",
      "Epoch: 187/500... Training loss: 0.0088\n",
      "Epoch: 188/500... Training loss: 0.0110\n",
      "Epoch: 188/500... Training loss: 0.0717\n",
      "Epoch: 188/500... Training loss: 0.0467\n",
      "Epoch: 188/500... Training loss: 0.0350\n",
      "Epoch: 188/500... Training loss: 0.1219\n",
      "Epoch: 188/500... Training loss: 0.0550\n",
      "Epoch: 188/500... Training loss: 0.1266\n",
      "Epoch: 188/500... Training loss: 0.1159\n",
      "Epoch: 188/500... Training loss: 0.0198\n",
      "Epoch: 188/500... Training loss: 0.0162\n",
      "Epoch: 188/500... Training loss: 0.0444\n",
      "Epoch: 188/500... Training loss: 0.0268\n",
      "Epoch: 188/500... Training loss: 0.0134\n",
      "Epoch: 188/500... Training loss: 0.0296\n",
      "Epoch: 188/500... Training loss: 0.1108\n",
      "Epoch: 188/500... Training loss: 0.0180\n",
      "Epoch: 188/500... Training loss: 0.0112\n",
      "Epoch: 188/500... Training loss: 0.0109\n",
      "Epoch: 188/500... Training loss: 0.0796\n",
      "Epoch: 188/500... Training loss: 0.0420\n",
      "Epoch: 188/500... Training loss: 0.0321\n",
      "Epoch: 188/500... Training loss: 0.0149\n",
      "Epoch: 188/500... Training loss: 0.0194\n",
      "Epoch: 188/500... Training loss: 0.0381\n",
      "Epoch: 188/500... Training loss: 0.0282\n",
      "Epoch: 188/500... Training loss: 0.0385\n",
      "Epoch: 188/500... Training loss: 0.0736\n",
      "Epoch: 188/500... Training loss: 0.0596\n",
      "Epoch: 188/500... Training loss: 0.0283\n",
      "Epoch: 188/500... Training loss: 0.0471\n",
      "Epoch: 188/500... Training loss: 0.0491\n",
      "Epoch: 189/500... Training loss: 0.1260\n",
      "Epoch: 189/500... Training loss: 0.0120\n",
      "Epoch: 189/500... Training loss: 0.0261\n",
      "Epoch: 189/500... Training loss: 0.0177\n",
      "Epoch: 189/500... Training loss: 0.0775\n",
      "Epoch: 189/500... Training loss: 0.0713\n",
      "Epoch: 189/500... Training loss: 0.0496\n",
      "Epoch: 189/500... Training loss: 0.0261\n",
      "Epoch: 189/500... Training loss: 0.0296\n",
      "Epoch: 189/500... Training loss: 0.0551\n",
      "Epoch: 189/500... Training loss: 0.0558\n",
      "Epoch: 189/500... Training loss: 0.0274\n",
      "Epoch: 189/500... Training loss: 0.0713\n",
      "Epoch: 189/500... Training loss: 0.0256\n",
      "Epoch: 189/500... Training loss: 0.0244\n",
      "Epoch: 189/500... Training loss: 0.0616\n",
      "Epoch: 189/500... Training loss: 0.0307\n",
      "Epoch: 189/500... Training loss: 0.0367\n",
      "Epoch: 189/500... Training loss: 0.0629\n",
      "Epoch: 189/500... Training loss: 0.0365\n",
      "Epoch: 189/500... Training loss: 0.0526\n",
      "Epoch: 189/500... Training loss: 0.0798\n",
      "Epoch: 189/500... Training loss: 0.0269\n",
      "Epoch: 189/500... Training loss: 0.0198\n",
      "Epoch: 189/500... Training loss: 0.0106\n",
      "Epoch: 189/500... Training loss: 0.0274\n",
      "Epoch: 189/500... Training loss: 0.0102\n",
      "Epoch: 189/500... Training loss: 0.0086\n",
      "Epoch: 189/500... Training loss: 0.0169\n",
      "Epoch: 189/500... Training loss: 0.0926\n",
      "Epoch: 189/500... Training loss: 0.0298\n",
      "Epoch: 190/500... Training loss: 0.0327\n",
      "Epoch: 190/500... Training loss: 0.0082\n",
      "Epoch: 190/500... Training loss: 0.0593\n",
      "Epoch: 190/500... Training loss: 0.0174\n",
      "Epoch: 190/500... Training loss: 0.0361\n",
      "Epoch: 190/500... Training loss: 0.0504\n",
      "Epoch: 190/500... Training loss: 0.0533\n",
      "Epoch: 190/500... Training loss: 0.0289\n",
      "Epoch: 190/500... Training loss: 0.0175\n",
      "Epoch: 190/500... Training loss: 0.0192\n",
      "Epoch: 190/500... Training loss: 0.0339\n",
      "Epoch: 190/500... Training loss: 0.0109\n",
      "Epoch: 190/500... Training loss: 0.0273\n",
      "Epoch: 190/500... Training loss: 0.0091\n",
      "Epoch: 190/500... Training loss: 0.0634\n",
      "Epoch: 190/500... Training loss: 0.1026\n",
      "Epoch: 190/500... Training loss: 0.0105\n",
      "Epoch: 190/500... Training loss: 0.0085\n",
      "Epoch: 190/500... Training loss: 0.0399\n",
      "Epoch: 190/500... Training loss: 0.0383\n",
      "Epoch: 190/500... Training loss: 0.0171\n",
      "Epoch: 190/500... Training loss: 0.0259\n",
      "Epoch: 190/500... Training loss: 0.0318\n",
      "Epoch: 190/500... Training loss: 0.0940\n",
      "Epoch: 190/500... Training loss: 0.0236\n",
      "Epoch: 190/500... Training loss: 0.1401\n",
      "Epoch: 190/500... Training loss: 0.0169\n",
      "Epoch: 190/500... Training loss: 0.0566\n",
      "Epoch: 190/500... Training loss: 0.0313\n",
      "Epoch: 190/500... Training loss: 0.0225\n",
      "Epoch: 190/500... Training loss: 0.0160\n",
      "Epoch: 191/500... Training loss: 0.0122\n",
      "Epoch: 191/500... Training loss: 0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191/500... Training loss: 0.0638\n",
      "Epoch: 191/500... Training loss: 0.1465\n",
      "Epoch: 191/500... Training loss: 0.0180\n",
      "Epoch: 191/500... Training loss: 0.0149\n",
      "Epoch: 191/500... Training loss: 0.0191\n",
      "Epoch: 191/500... Training loss: 0.0415\n",
      "Epoch: 191/500... Training loss: 0.0109\n",
      "Epoch: 191/500... Training loss: 0.0960\n",
      "Epoch: 191/500... Training loss: 0.0258\n",
      "Epoch: 191/500... Training loss: 0.1149\n",
      "Epoch: 191/500... Training loss: 0.0224\n",
      "Epoch: 191/500... Training loss: 0.0112\n",
      "Epoch: 191/500... Training loss: 0.0142\n",
      "Epoch: 191/500... Training loss: 0.0144\n",
      "Epoch: 191/500... Training loss: 0.0047\n",
      "Epoch: 191/500... Training loss: 0.0620\n",
      "Epoch: 191/500... Training loss: 0.0356\n",
      "Epoch: 191/500... Training loss: 0.0850\n",
      "Epoch: 191/500... Training loss: 0.0132\n",
      "Epoch: 191/500... Training loss: 0.0555\n",
      "Epoch: 191/500... Training loss: 0.0197\n",
      "Epoch: 191/500... Training loss: 0.0315\n",
      "Epoch: 191/500... Training loss: 0.0391\n",
      "Epoch: 191/500... Training loss: 0.0389\n",
      "Epoch: 191/500... Training loss: 0.0605\n",
      "Epoch: 191/500... Training loss: 0.1263\n",
      "Epoch: 191/500... Training loss: 0.0406\n",
      "Epoch: 191/500... Training loss: 0.0328\n",
      "Epoch: 191/500... Training loss: 0.0370\n",
      "Epoch: 192/500... Training loss: 0.0778\n",
      "Epoch: 192/500... Training loss: 0.0103\n",
      "Epoch: 192/500... Training loss: 0.0430\n",
      "Epoch: 192/500... Training loss: 0.0592\n",
      "Epoch: 192/500... Training loss: 0.0188\n",
      "Epoch: 192/500... Training loss: 0.0838\n",
      "Epoch: 192/500... Training loss: 0.0211\n",
      "Epoch: 192/500... Training loss: 0.0310\n",
      "Epoch: 192/500... Training loss: 0.0477\n",
      "Epoch: 192/500... Training loss: 0.0536\n",
      "Epoch: 192/500... Training loss: 0.1344\n",
      "Epoch: 192/500... Training loss: 0.0640\n",
      "Epoch: 192/500... Training loss: 0.1304\n",
      "Epoch: 192/500... Training loss: 0.0193\n",
      "Epoch: 192/500... Training loss: 0.2188\n",
      "Epoch: 192/500... Training loss: 0.0326\n",
      "Epoch: 192/500... Training loss: 0.0729\n",
      "Epoch: 192/500... Training loss: 0.0178\n",
      "Epoch: 192/500... Training loss: 0.0432\n",
      "Epoch: 192/500... Training loss: 0.0767\n",
      "Epoch: 192/500... Training loss: 0.0358\n",
      "Epoch: 192/500... Training loss: 0.0119\n",
      "Epoch: 192/500... Training loss: 0.0552\n",
      "Epoch: 192/500... Training loss: 0.0066\n",
      "Epoch: 192/500... Training loss: 0.0436\n",
      "Epoch: 192/500... Training loss: 0.0168\n",
      "Epoch: 192/500... Training loss: 0.0354\n",
      "Epoch: 192/500... Training loss: 0.1415\n",
      "Epoch: 192/500... Training loss: 0.0084\n",
      "Epoch: 192/500... Training loss: 0.0506\n",
      "Epoch: 192/500... Training loss: 0.0224\n",
      "Epoch: 193/500... Training loss: 0.0473\n",
      "Epoch: 193/500... Training loss: 0.2112\n",
      "Epoch: 193/500... Training loss: 0.0253\n",
      "Epoch: 193/500... Training loss: 0.0131\n",
      "Epoch: 193/500... Training loss: 0.0127\n",
      "Epoch: 193/500... Training loss: 0.0315\n",
      "Epoch: 193/500... Training loss: 0.0145\n",
      "Epoch: 193/500... Training loss: 0.0136\n",
      "Epoch: 193/500... Training loss: 0.0552\n",
      "Epoch: 193/500... Training loss: 0.0205\n",
      "Epoch: 193/500... Training loss: 0.0381\n",
      "Epoch: 193/500... Training loss: 0.0930\n",
      "Epoch: 193/500... Training loss: 0.0823\n",
      "Epoch: 193/500... Training loss: 0.0327\n",
      "Epoch: 193/500... Training loss: 0.0759\n",
      "Epoch: 193/500... Training loss: 0.0657\n",
      "Epoch: 193/500... Training loss: 0.1419\n",
      "Epoch: 193/500... Training loss: 0.0181\n",
      "Epoch: 193/500... Training loss: 0.0709\n",
      "Epoch: 193/500... Training loss: 0.0341\n",
      "Epoch: 193/500... Training loss: 0.0948\n",
      "Epoch: 193/500... Training loss: 0.0377\n",
      "Epoch: 193/500... Training loss: 0.0086\n",
      "Epoch: 193/500... Training loss: 0.0833\n",
      "Epoch: 193/500... Training loss: 0.0287\n",
      "Epoch: 193/500... Training loss: 0.0256\n",
      "Epoch: 193/500... Training loss: 0.0970\n",
      "Epoch: 193/500... Training loss: 0.0634\n",
      "Epoch: 193/500... Training loss: 0.0623\n",
      "Epoch: 193/500... Training loss: 0.0209\n",
      "Epoch: 193/500... Training loss: 0.0631\n",
      "Epoch: 194/500... Training loss: 0.0964\n",
      "Epoch: 194/500... Training loss: 0.0647\n",
      "Epoch: 194/500... Training loss: 0.0404\n",
      "Epoch: 194/500... Training loss: 0.0282\n",
      "Epoch: 194/500... Training loss: 0.0480\n",
      "Epoch: 194/500... Training loss: 0.1043\n",
      "Epoch: 194/500... Training loss: 0.0495\n",
      "Epoch: 194/500... Training loss: 0.0292\n",
      "Epoch: 194/500... Training loss: 0.0298\n",
      "Epoch: 194/500... Training loss: 0.0168\n",
      "Epoch: 194/500... Training loss: 0.1902\n",
      "Epoch: 194/500... Training loss: 0.0558\n",
      "Epoch: 194/500... Training loss: 0.0065\n",
      "Epoch: 194/500... Training loss: 0.0292\n",
      "Epoch: 194/500... Training loss: 0.0591\n",
      "Epoch: 194/500... Training loss: 0.0116\n",
      "Epoch: 194/500... Training loss: 0.0215\n",
      "Epoch: 194/500... Training loss: 0.0304\n",
      "Epoch: 194/500... Training loss: 0.0874\n",
      "Epoch: 194/500... Training loss: 0.0717\n",
      "Epoch: 194/500... Training loss: 0.0331\n",
      "Epoch: 194/500... Training loss: 0.1570\n",
      "Epoch: 194/500... Training loss: 0.0384\n",
      "Epoch: 194/500... Training loss: 0.0694\n",
      "Epoch: 194/500... Training loss: 0.0360\n",
      "Epoch: 194/500... Training loss: 0.0148\n",
      "Epoch: 194/500... Training loss: 0.0434\n",
      "Epoch: 194/500... Training loss: 0.0098\n",
      "Epoch: 194/500... Training loss: 0.0409\n",
      "Epoch: 194/500... Training loss: 0.0586\n",
      "Epoch: 194/500... Training loss: 0.0225\n",
      "Epoch: 195/500... Training loss: 0.1671\n",
      "Epoch: 195/500... Training loss: 0.1293\n",
      "Epoch: 195/500... Training loss: 0.0069\n",
      "Epoch: 195/500... Training loss: 0.0234\n",
      "Epoch: 195/500... Training loss: 0.1324\n",
      "Epoch: 195/500... Training loss: 0.0322\n",
      "Epoch: 195/500... Training loss: 0.0260\n",
      "Epoch: 195/500... Training loss: 0.0379\n",
      "Epoch: 195/500... Training loss: 0.0845\n",
      "Epoch: 195/500... Training loss: 0.0333\n",
      "Epoch: 195/500... Training loss: 0.0632\n",
      "Epoch: 195/500... Training loss: 0.0930\n",
      "Epoch: 195/500... Training loss: 0.0787\n",
      "Epoch: 195/500... Training loss: 0.0872\n",
      "Epoch: 195/500... Training loss: 0.0497\n",
      "Epoch: 195/500... Training loss: 0.0387\n",
      "Epoch: 195/500... Training loss: 0.0584\n",
      "Epoch: 195/500... Training loss: 0.0290\n",
      "Epoch: 195/500... Training loss: 0.0619\n",
      "Epoch: 195/500... Training loss: 0.1437\n",
      "Epoch: 195/500... Training loss: 0.0258\n",
      "Epoch: 195/500... Training loss: 0.0903\n",
      "Epoch: 195/500... Training loss: 0.0604\n",
      "Epoch: 195/500... Training loss: 0.0134\n",
      "Epoch: 195/500... Training loss: 0.0349\n",
      "Epoch: 195/500... Training loss: 0.0811\n",
      "Epoch: 195/500... Training loss: 0.0146\n",
      "Epoch: 195/500... Training loss: 0.1161\n",
      "Epoch: 195/500... Training loss: 0.0071\n",
      "Epoch: 195/500... Training loss: 0.0215\n",
      "Epoch: 195/500... Training loss: 0.0329\n",
      "Epoch: 196/500... Training loss: 0.0080\n",
      "Epoch: 196/500... Training loss: 0.0511\n",
      "Epoch: 196/500... Training loss: 0.0649\n",
      "Epoch: 196/500... Training loss: 0.0191\n",
      "Epoch: 196/500... Training loss: 0.0730\n",
      "Epoch: 196/500... Training loss: 0.0697\n",
      "Epoch: 196/500... Training loss: 0.0273\n",
      "Epoch: 196/500... Training loss: 0.1178\n",
      "Epoch: 196/500... Training loss: 0.1035\n",
      "Epoch: 196/500... Training loss: 0.0201\n",
      "Epoch: 196/500... Training loss: 0.0105\n",
      "Epoch: 196/500... Training loss: 0.2178\n",
      "Epoch: 196/500... Training loss: 0.0075\n",
      "Epoch: 196/500... Training loss: 0.0222\n",
      "Epoch: 196/500... Training loss: 0.0266\n",
      "Epoch: 196/500... Training loss: 0.0125\n",
      "Epoch: 196/500... Training loss: 0.0124\n",
      "Epoch: 196/500... Training loss: 0.0779\n",
      "Epoch: 196/500... Training loss: 0.0199\n",
      "Epoch: 196/500... Training loss: 0.0256\n",
      "Epoch: 196/500... Training loss: 0.0579\n",
      "Epoch: 196/500... Training loss: 0.0070\n",
      "Epoch: 196/500... Training loss: 0.0467\n",
      "Epoch: 196/500... Training loss: 0.0319\n",
      "Epoch: 196/500... Training loss: 0.0356\n",
      "Epoch: 196/500... Training loss: 0.0392\n",
      "Epoch: 196/500... Training loss: 0.0992\n",
      "Epoch: 196/500... Training loss: 0.0330\n",
      "Epoch: 196/500... Training loss: 0.0190\n",
      "Epoch: 196/500... Training loss: 0.0605\n",
      "Epoch: 196/500... Training loss: 0.0937\n",
      "Epoch: 197/500... Training loss: 0.0436\n",
      "Epoch: 197/500... Training loss: 0.0589\n",
      "Epoch: 197/500... Training loss: 0.1395\n",
      "Epoch: 197/500... Training loss: 0.0903\n",
      "Epoch: 197/500... Training loss: 0.0593\n",
      "Epoch: 197/500... Training loss: 0.0213\n",
      "Epoch: 197/500... Training loss: 0.1215\n",
      "Epoch: 197/500... Training loss: 0.0571\n",
      "Epoch: 197/500... Training loss: 0.0468\n",
      "Epoch: 197/500... Training loss: 0.0326\n",
      "Epoch: 197/500... Training loss: 0.0879\n",
      "Epoch: 197/500... Training loss: 0.0117\n",
      "Epoch: 197/500... Training loss: 0.0966\n",
      "Epoch: 197/500... Training loss: 0.0624\n",
      "Epoch: 197/500... Training loss: 0.0144\n",
      "Epoch: 197/500... Training loss: 0.0190\n",
      "Epoch: 197/500... Training loss: 0.0104\n",
      "Epoch: 197/500... Training loss: 0.0362\n",
      "Epoch: 197/500... Training loss: 0.0439\n",
      "Epoch: 197/500... Training loss: 0.0161\n",
      "Epoch: 197/500... Training loss: 0.0363\n",
      "Epoch: 197/500... Training loss: 0.0065\n",
      "Epoch: 197/500... Training loss: 0.0587\n",
      "Epoch: 197/500... Training loss: 0.0056\n",
      "Epoch: 197/500... Training loss: 0.0110\n",
      "Epoch: 197/500... Training loss: 0.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 197/500... Training loss: 0.0769\n",
      "Epoch: 197/500... Training loss: 0.0397\n",
      "Epoch: 197/500... Training loss: 0.0121\n",
      "Epoch: 197/500... Training loss: 0.0415\n",
      "Epoch: 197/500... Training loss: 0.0522\n",
      "Epoch: 198/500... Training loss: 0.0612\n",
      "Epoch: 198/500... Training loss: 0.0200\n",
      "Epoch: 198/500... Training loss: 0.0291\n",
      "Epoch: 198/500... Training loss: 0.0447\n",
      "Epoch: 198/500... Training loss: 0.2606\n",
      "Epoch: 198/500... Training loss: 0.0471\n",
      "Epoch: 198/500... Training loss: 0.0528\n",
      "Epoch: 198/500... Training loss: 0.0118\n",
      "Epoch: 198/500... Training loss: 0.0589\n",
      "Epoch: 198/500... Training loss: 0.0907\n",
      "Epoch: 198/500... Training loss: 0.1363\n",
      "Epoch: 198/500... Training loss: 0.0157\n",
      "Epoch: 198/500... Training loss: 0.0783\n",
      "Epoch: 198/500... Training loss: 0.0263\n",
      "Epoch: 198/500... Training loss: 0.0415\n",
      "Epoch: 198/500... Training loss: 0.0235\n",
      "Epoch: 198/500... Training loss: 0.0088\n",
      "Epoch: 198/500... Training loss: 0.0288\n",
      "Epoch: 198/500... Training loss: 0.0116\n",
      "Epoch: 198/500... Training loss: 0.0198\n",
      "Epoch: 198/500... Training loss: 0.0152\n",
      "Epoch: 198/500... Training loss: 0.0507\n",
      "Epoch: 198/500... Training loss: 0.0307\n",
      "Epoch: 198/500... Training loss: 0.0104\n",
      "Epoch: 198/500... Training loss: 0.0230\n",
      "Epoch: 198/500... Training loss: 0.0085\n",
      "Epoch: 198/500... Training loss: 0.0218\n",
      "Epoch: 198/500... Training loss: 0.0266\n",
      "Epoch: 198/500... Training loss: 0.0123\n",
      "Epoch: 198/500... Training loss: 0.0326\n",
      "Epoch: 198/500... Training loss: 0.0925\n",
      "Epoch: 199/500... Training loss: 0.0296\n",
      "Epoch: 199/500... Training loss: 0.1050\n",
      "Epoch: 199/500... Training loss: 0.0734\n",
      "Epoch: 199/500... Training loss: 0.0557\n",
      "Epoch: 199/500... Training loss: 0.0223\n",
      "Epoch: 199/500... Training loss: 0.0660\n",
      "Epoch: 199/500... Training loss: 0.0425\n",
      "Epoch: 199/500... Training loss: 0.0150\n",
      "Epoch: 199/500... Training loss: 0.0097\n",
      "Epoch: 199/500... Training loss: 0.0259\n",
      "Epoch: 199/500... Training loss: 0.1763\n",
      "Epoch: 199/500... Training loss: 0.0374\n",
      "Epoch: 199/500... Training loss: 0.1237\n",
      "Epoch: 199/500... Training loss: 0.0957\n",
      "Epoch: 199/500... Training loss: 0.1126\n",
      "Epoch: 199/500... Training loss: 0.0232\n",
      "Epoch: 199/500... Training loss: 0.0169\n",
      "Epoch: 199/500... Training loss: 0.0146\n",
      "Epoch: 199/500... Training loss: 0.0190\n",
      "Epoch: 199/500... Training loss: 0.0161\n",
      "Epoch: 199/500... Training loss: 0.0247\n",
      "Epoch: 199/500... Training loss: 0.0168\n",
      "Epoch: 199/500... Training loss: 0.0466\n",
      "Epoch: 199/500... Training loss: 0.0379\n",
      "Epoch: 199/500... Training loss: 0.0242\n",
      "Epoch: 199/500... Training loss: 0.1665\n",
      "Epoch: 199/500... Training loss: 0.0070\n",
      "Epoch: 199/500... Training loss: 0.0118\n",
      "Epoch: 199/500... Training loss: 0.0537\n",
      "Epoch: 199/500... Training loss: 0.0491\n",
      "Epoch: 199/500... Training loss: 0.0071\n",
      "Epoch: 200/500... Training loss: 0.0830\n",
      "Epoch: 200/500... Training loss: 0.0055\n",
      "Epoch: 200/500... Training loss: 0.0086\n",
      "Epoch: 200/500... Training loss: 0.0670\n",
      "Epoch: 200/500... Training loss: 0.0501\n",
      "Epoch: 200/500... Training loss: 0.0174\n",
      "Epoch: 200/500... Training loss: 0.1195\n",
      "Epoch: 200/500... Training loss: 0.1136\n",
      "Epoch: 200/500... Training loss: 0.0961\n",
      "Epoch: 200/500... Training loss: 0.0262\n",
      "Epoch: 200/500... Training loss: 0.1303\n",
      "Epoch: 200/500... Training loss: 0.0258\n",
      "Epoch: 200/500... Training loss: 0.0514\n",
      "Epoch: 200/500... Training loss: 0.0211\n",
      "Epoch: 200/500... Training loss: 0.0727\n",
      "Epoch: 200/500... Training loss: 0.0088\n",
      "Epoch: 200/500... Training loss: 0.0778\n",
      "Epoch: 200/500... Training loss: 0.0119\n",
      "Epoch: 200/500... Training loss: 0.0320\n",
      "Epoch: 200/500... Training loss: 0.0075\n",
      "Epoch: 200/500... Training loss: 0.1983\n",
      "Epoch: 200/500... Training loss: 0.0360\n",
      "Epoch: 200/500... Training loss: 0.0308\n",
      "Epoch: 200/500... Training loss: 0.1576\n",
      "Epoch: 200/500... Training loss: 0.0090\n",
      "Epoch: 200/500... Training loss: 0.0059\n",
      "Epoch: 200/500... Training loss: 0.0444\n",
      "Epoch: 200/500... Training loss: 0.0154\n",
      "Epoch: 200/500... Training loss: 0.0434\n",
      "Epoch: 200/500... Training loss: 0.0452\n",
      "Epoch: 200/500... Training loss: 0.0265\n",
      "Epoch: 201/500... Training loss: 0.0145\n",
      "Epoch: 201/500... Training loss: 0.0359\n",
      "Epoch: 201/500... Training loss: 0.0282\n",
      "Epoch: 201/500... Training loss: 0.0585\n",
      "Epoch: 201/500... Training loss: 0.0420\n",
      "Epoch: 201/500... Training loss: 0.0429\n",
      "Epoch: 201/500... Training loss: 0.1012\n",
      "Epoch: 201/500... Training loss: 0.0238\n",
      "Epoch: 201/500... Training loss: 0.1072\n",
      "Epoch: 201/500... Training loss: 0.0504\n",
      "Epoch: 201/500... Training loss: 0.0991\n",
      "Epoch: 201/500... Training loss: 0.0246\n",
      "Epoch: 201/500... Training loss: 0.0954\n",
      "Epoch: 201/500... Training loss: 0.0164\n",
      "Epoch: 201/500... Training loss: 0.0819\n",
      "Epoch: 201/500... Training loss: 0.0576\n",
      "Epoch: 201/500... Training loss: 0.0525\n",
      "Epoch: 201/500... Training loss: 0.0257\n",
      "Epoch: 201/500... Training loss: 0.0119\n",
      "Epoch: 201/500... Training loss: 0.0214\n",
      "Epoch: 201/500... Training loss: 0.0157\n",
      "Epoch: 201/500... Training loss: 0.0202\n",
      "Epoch: 201/500... Training loss: 0.1703\n",
      "Epoch: 201/500... Training loss: 0.0428\n",
      "Epoch: 201/500... Training loss: 0.0333\n",
      "Epoch: 201/500... Training loss: 0.0836\n",
      "Epoch: 201/500... Training loss: 0.0149\n",
      "Epoch: 201/500... Training loss: 0.0540\n",
      "Epoch: 201/500... Training loss: 0.1030\n",
      "Epoch: 201/500... Training loss: 0.0466\n",
      "Epoch: 201/500... Training loss: 0.0662\n",
      "Epoch: 202/500... Training loss: 0.0059\n",
      "Epoch: 202/500... Training loss: 0.0212\n",
      "Epoch: 202/500... Training loss: 0.0969\n",
      "Epoch: 202/500... Training loss: 0.0770\n",
      "Epoch: 202/500... Training loss: 0.0545\n",
      "Epoch: 202/500... Training loss: 0.0236\n",
      "Epoch: 202/500... Training loss: 0.0341\n",
      "Epoch: 202/500... Training loss: 0.0251\n",
      "Epoch: 202/500... Training loss: 0.0477\n",
      "Epoch: 202/500... Training loss: 0.0310\n",
      "Epoch: 202/500... Training loss: 0.0509\n",
      "Epoch: 202/500... Training loss: 0.0101\n",
      "Epoch: 202/500... Training loss: 0.1164\n",
      "Epoch: 202/500... Training loss: 0.0558\n",
      "Epoch: 202/500... Training loss: 0.0566\n",
      "Epoch: 202/500... Training loss: 0.0236\n",
      "Epoch: 202/500... Training loss: 0.0089\n",
      "Epoch: 202/500... Training loss: 0.0440\n",
      "Epoch: 202/500... Training loss: 0.0167\n",
      "Epoch: 202/500... Training loss: 0.0454\n",
      "Epoch: 202/500... Training loss: 0.0427\n",
      "Epoch: 202/500... Training loss: 0.0102\n",
      "Epoch: 202/500... Training loss: 0.0175\n",
      "Epoch: 202/500... Training loss: 0.0384\n",
      "Epoch: 202/500... Training loss: 0.0733\n",
      "Epoch: 202/500... Training loss: 0.0648\n",
      "Epoch: 202/500... Training loss: 0.0761\n",
      "Epoch: 202/500... Training loss: 0.0086\n",
      "Epoch: 202/500... Training loss: 0.0475\n",
      "Epoch: 202/500... Training loss: 0.0625\n",
      "Epoch: 202/500... Training loss: 0.0673\n",
      "Epoch: 203/500... Training loss: 0.1137\n",
      "Epoch: 203/500... Training loss: 0.0077\n",
      "Epoch: 203/500... Training loss: 0.0491\n",
      "Epoch: 203/500... Training loss: 0.0394\n",
      "Epoch: 203/500... Training loss: 0.0074\n",
      "Epoch: 203/500... Training loss: 0.0080\n",
      "Epoch: 203/500... Training loss: 0.0185\n",
      "Epoch: 203/500... Training loss: 0.0342\n",
      "Epoch: 203/500... Training loss: 0.0625\n",
      "Epoch: 203/500... Training loss: 0.1629\n",
      "Epoch: 203/500... Training loss: 0.0136\n",
      "Epoch: 203/500... Training loss: 0.0403\n",
      "Epoch: 203/500... Training loss: 0.0040\n",
      "Epoch: 203/500... Training loss: 0.0165\n",
      "Epoch: 203/500... Training loss: 0.0635\n",
      "Epoch: 203/500... Training loss: 0.0267\n",
      "Epoch: 203/500... Training loss: 0.2289\n",
      "Epoch: 203/500... Training loss: 0.0097\n",
      "Epoch: 203/500... Training loss: 0.0442\n",
      "Epoch: 203/500... Training loss: 0.0478\n",
      "Epoch: 203/500... Training loss: 0.0120\n",
      "Epoch: 203/500... Training loss: 0.0373\n",
      "Epoch: 203/500... Training loss: 0.1154\n",
      "Epoch: 203/500... Training loss: 0.0345\n",
      "Epoch: 203/500... Training loss: 0.0438\n",
      "Epoch: 203/500... Training loss: 0.0122\n",
      "Epoch: 203/500... Training loss: 0.0346\n",
      "Epoch: 203/500... Training loss: 0.0179\n",
      "Epoch: 203/500... Training loss: 0.0333\n",
      "Epoch: 203/500... Training loss: 0.0311\n",
      "Epoch: 203/500... Training loss: 0.0237\n",
      "Epoch: 204/500... Training loss: 0.1527\n",
      "Epoch: 204/500... Training loss: 0.0126\n",
      "Epoch: 204/500... Training loss: 0.0127\n",
      "Epoch: 204/500... Training loss: 0.0295\n",
      "Epoch: 204/500... Training loss: 0.0131\n",
      "Epoch: 204/500... Training loss: 0.0308\n",
      "Epoch: 204/500... Training loss: 0.0294\n",
      "Epoch: 204/500... Training loss: 0.0378\n",
      "Epoch: 204/500... Training loss: 0.0368\n",
      "Epoch: 204/500... Training loss: 0.0278\n",
      "Epoch: 204/500... Training loss: 0.0311\n",
      "Epoch: 204/500... Training loss: 0.0140\n",
      "Epoch: 204/500... Training loss: 0.0123\n",
      "Epoch: 204/500... Training loss: 0.0568\n",
      "Epoch: 204/500... Training loss: 0.0242\n",
      "Epoch: 204/500... Training loss: 0.0340\n",
      "Epoch: 204/500... Training loss: 0.0113\n",
      "Epoch: 204/500... Training loss: 0.0076\n",
      "Epoch: 204/500... Training loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204/500... Training loss: 0.0281\n",
      "Epoch: 204/500... Training loss: 0.0155\n",
      "Epoch: 204/500... Training loss: 0.0637\n",
      "Epoch: 204/500... Training loss: 0.0824\n",
      "Epoch: 204/500... Training loss: 0.0058\n",
      "Epoch: 204/500... Training loss: 0.0550\n",
      "Epoch: 204/500... Training loss: 0.0405\n",
      "Epoch: 204/500... Training loss: 0.0278\n",
      "Epoch: 204/500... Training loss: 0.0312\n",
      "Epoch: 204/500... Training loss: 0.0084\n",
      "Epoch: 204/500... Training loss: 0.0372\n",
      "Epoch: 204/500... Training loss: 0.0435\n",
      "Epoch: 205/500... Training loss: 0.0331\n",
      "Epoch: 205/500... Training loss: 0.0066\n",
      "Epoch: 205/500... Training loss: 0.0320\n",
      "Epoch: 205/500... Training loss: 0.0474\n",
      "Epoch: 205/500... Training loss: 0.0441\n",
      "Epoch: 205/500... Training loss: 0.0540\n",
      "Epoch: 205/500... Training loss: 0.1057\n",
      "Epoch: 205/500... Training loss: 0.0142\n",
      "Epoch: 205/500... Training loss: 0.0625\n",
      "Epoch: 205/500... Training loss: 0.0374\n",
      "Epoch: 205/500... Training loss: 0.0449\n",
      "Epoch: 205/500... Training loss: 0.0563\n",
      "Epoch: 205/500... Training loss: 0.0478\n",
      "Epoch: 205/500... Training loss: 0.1363\n",
      "Epoch: 205/500... Training loss: 0.0966\n",
      "Epoch: 205/500... Training loss: 0.0269\n",
      "Epoch: 205/500... Training loss: 0.0341\n",
      "Epoch: 205/500... Training loss: 0.0344\n",
      "Epoch: 205/500... Training loss: 0.0178\n",
      "Epoch: 205/500... Training loss: 0.0796\n",
      "Epoch: 205/500... Training loss: 0.0855\n",
      "Epoch: 205/500... Training loss: 0.0990\n",
      "Epoch: 205/500... Training loss: 0.0432\n",
      "Epoch: 205/500... Training loss: 0.0247\n",
      "Epoch: 205/500... Training loss: 0.0196\n",
      "Epoch: 205/500... Training loss: 0.0287\n",
      "Epoch: 205/500... Training loss: 0.0083\n",
      "Epoch: 205/500... Training loss: 0.0514\n",
      "Epoch: 205/500... Training loss: 0.0277\n",
      "Epoch: 205/500... Training loss: 0.0611\n",
      "Epoch: 205/500... Training loss: 0.0236\n",
      "Epoch: 206/500... Training loss: 0.0702\n",
      "Epoch: 206/500... Training loss: 0.0260\n",
      "Epoch: 206/500... Training loss: 0.1104\n",
      "Epoch: 206/500... Training loss: 0.0950\n",
      "Epoch: 206/500... Training loss: 0.0596\n",
      "Epoch: 206/500... Training loss: 0.0743\n",
      "Epoch: 206/500... Training loss: 0.0675\n",
      "Epoch: 206/500... Training loss: 0.0181\n",
      "Epoch: 206/500... Training loss: 0.0189\n",
      "Epoch: 206/500... Training loss: 0.0290\n",
      "Epoch: 206/500... Training loss: 0.0464\n",
      "Epoch: 206/500... Training loss: 0.0791\n",
      "Epoch: 206/500... Training loss: 0.0400\n",
      "Epoch: 206/500... Training loss: 0.0645\n",
      "Epoch: 206/500... Training loss: 0.0269\n",
      "Epoch: 206/500... Training loss: 0.0171\n",
      "Epoch: 206/500... Training loss: 0.1122\n",
      "Epoch: 206/500... Training loss: 0.1021\n",
      "Epoch: 206/500... Training loss: 0.0305\n",
      "Epoch: 206/500... Training loss: 0.0375\n",
      "Epoch: 206/500... Training loss: 0.0237\n",
      "Epoch: 206/500... Training loss: 0.0201\n",
      "Epoch: 206/500... Training loss: 0.0951\n",
      "Epoch: 206/500... Training loss: 0.0790\n",
      "Epoch: 206/500... Training loss: 0.0800\n",
      "Epoch: 206/500... Training loss: 0.0391\n",
      "Epoch: 206/500... Training loss: 0.0064\n",
      "Epoch: 206/500... Training loss: 0.0273\n",
      "Epoch: 206/500... Training loss: 0.1022\n",
      "Epoch: 206/500... Training loss: 0.0079\n",
      "Epoch: 206/500... Training loss: 0.0070\n",
      "Epoch: 207/500... Training loss: 0.0606\n",
      "Epoch: 207/500... Training loss: 0.0375\n",
      "Epoch: 207/500... Training loss: 0.0215\n",
      "Epoch: 207/500... Training loss: 0.0163\n",
      "Epoch: 207/500... Training loss: 0.0341\n",
      "Epoch: 207/500... Training loss: 0.0593\n",
      "Epoch: 207/500... Training loss: 0.0473\n",
      "Epoch: 207/500... Training loss: 0.0630\n",
      "Epoch: 207/500... Training loss: 0.0812\n",
      "Epoch: 207/500... Training loss: 0.1178\n",
      "Epoch: 207/500... Training loss: 0.0769\n",
      "Epoch: 207/500... Training loss: 0.0669\n",
      "Epoch: 207/500... Training loss: 0.0250\n",
      "Epoch: 207/500... Training loss: 0.1178\n",
      "Epoch: 207/500... Training loss: 0.0861\n",
      "Epoch: 207/500... Training loss: 0.0230\n",
      "Epoch: 207/500... Training loss: 0.0467\n",
      "Epoch: 207/500... Training loss: 0.0175\n",
      "Epoch: 207/500... Training loss: 0.0128\n",
      "Epoch: 207/500... Training loss: 0.0088\n",
      "Epoch: 207/500... Training loss: 0.0463\n",
      "Epoch: 207/500... Training loss: 0.0147\n",
      "Epoch: 207/500... Training loss: 0.0574\n",
      "Epoch: 207/500... Training loss: 0.0200\n",
      "Epoch: 207/500... Training loss: 0.0875\n",
      "Epoch: 207/500... Training loss: 0.0644\n",
      "Epoch: 207/500... Training loss: 0.0736\n",
      "Epoch: 207/500... Training loss: 0.0160\n",
      "Epoch: 207/500... Training loss: 0.0383\n",
      "Epoch: 207/500... Training loss: 0.0184\n",
      "Epoch: 207/500... Training loss: 0.0356\n",
      "Epoch: 208/500... Training loss: 0.0899\n",
      "Epoch: 208/500... Training loss: 0.0659\n",
      "Epoch: 208/500... Training loss: 0.0112\n",
      "Epoch: 208/500... Training loss: 0.0820\n",
      "Epoch: 208/500... Training loss: 0.0577\n",
      "Epoch: 208/500... Training loss: 0.0379\n",
      "Epoch: 208/500... Training loss: 0.0293\n",
      "Epoch: 208/500... Training loss: 0.1434\n",
      "Epoch: 208/500... Training loss: 0.0990\n",
      "Epoch: 208/500... Training loss: 0.0317\n",
      "Epoch: 208/500... Training loss: 0.0792\n",
      "Epoch: 208/500... Training loss: 0.1375\n",
      "Epoch: 208/500... Training loss: 0.0134\n",
      "Epoch: 208/500... Training loss: 0.0768\n",
      "Epoch: 208/500... Training loss: 0.0354\n",
      "Epoch: 208/500... Training loss: 0.0113\n",
      "Epoch: 208/500... Training loss: 0.0585\n",
      "Epoch: 208/500... Training loss: 0.0890\n",
      "Epoch: 208/500... Training loss: 0.0561\n",
      "Epoch: 208/500... Training loss: 0.0289\n",
      "Epoch: 208/500... Training loss: 0.0086\n",
      "Epoch: 208/500... Training loss: 0.0152\n",
      "Epoch: 208/500... Training loss: 0.3133\n",
      "Epoch: 208/500... Training loss: 0.1129\n",
      "Epoch: 208/500... Training loss: 0.0237\n",
      "Epoch: 208/500... Training loss: 0.0784\n",
      "Epoch: 208/500... Training loss: 0.0152\n",
      "Epoch: 208/500... Training loss: 0.1280\n",
      "Epoch: 208/500... Training loss: 0.1529\n",
      "Epoch: 208/500... Training loss: 0.0045\n",
      "Epoch: 208/500... Training loss: 0.0786\n",
      "Epoch: 209/500... Training loss: 0.0129\n",
      "Epoch: 209/500... Training loss: 0.0378\n",
      "Epoch: 209/500... Training loss: 0.0323\n",
      "Epoch: 209/500... Training loss: 0.1166\n",
      "Epoch: 209/500... Training loss: 0.0188\n",
      "Epoch: 209/500... Training loss: 0.0900\n",
      "Epoch: 209/500... Training loss: 0.0223\n",
      "Epoch: 209/500... Training loss: 0.0741\n",
      "Epoch: 209/500... Training loss: 0.0163\n",
      "Epoch: 209/500... Training loss: 0.0428\n",
      "Epoch: 209/500... Training loss: 0.0228\n",
      "Epoch: 209/500... Training loss: 0.0989\n",
      "Epoch: 209/500... Training loss: 0.0240\n",
      "Epoch: 209/500... Training loss: 0.0103\n",
      "Epoch: 209/500... Training loss: 0.0617\n",
      "Epoch: 209/500... Training loss: 0.0124\n",
      "Epoch: 209/500... Training loss: 0.0683\n",
      "Epoch: 209/500... Training loss: 0.0279\n",
      "Epoch: 209/500... Training loss: 0.0220\n",
      "Epoch: 209/500... Training loss: 0.0281\n",
      "Epoch: 209/500... Training loss: 0.0251\n",
      "Epoch: 209/500... Training loss: 0.0167\n",
      "Epoch: 209/500... Training loss: 0.0231\n",
      "Epoch: 209/500... Training loss: 0.0104\n",
      "Epoch: 209/500... Training loss: 0.0396\n",
      "Epoch: 209/500... Training loss: 0.0754\n",
      "Epoch: 209/500... Training loss: 0.0842\n",
      "Epoch: 209/500... Training loss: 0.2108\n",
      "Epoch: 209/500... Training loss: 0.0720\n",
      "Epoch: 209/500... Training loss: 0.0245\n",
      "Epoch: 209/500... Training loss: 0.0233\n",
      "Epoch: 210/500... Training loss: 0.0785\n",
      "Epoch: 210/500... Training loss: 0.0366\n",
      "Epoch: 210/500... Training loss: 0.0115\n",
      "Epoch: 210/500... Training loss: 0.0249\n",
      "Epoch: 210/500... Training loss: 0.0134\n",
      "Epoch: 210/500... Training loss: 0.0891\n",
      "Epoch: 210/500... Training loss: 0.0516\n",
      "Epoch: 210/500... Training loss: 0.0799\n",
      "Epoch: 210/500... Training loss: 0.0562\n",
      "Epoch: 210/500... Training loss: 0.0193\n",
      "Epoch: 210/500... Training loss: 0.0851\n",
      "Epoch: 210/500... Training loss: 0.1011\n",
      "Epoch: 210/500... Training loss: 0.0303\n",
      "Epoch: 210/500... Training loss: 0.0231\n",
      "Epoch: 210/500... Training loss: 0.0955\n",
      "Epoch: 210/500... Training loss: 0.0252\n",
      "Epoch: 210/500... Training loss: 0.0278\n",
      "Epoch: 210/500... Training loss: 0.0157\n",
      "Epoch: 210/500... Training loss: 0.0381\n",
      "Epoch: 210/500... Training loss: 0.0538\n",
      "Epoch: 210/500... Training loss: 0.0945\n",
      "Epoch: 210/500... Training loss: 0.1064\n",
      "Epoch: 210/500... Training loss: 0.0733\n",
      "Epoch: 210/500... Training loss: 0.0517\n",
      "Epoch: 210/500... Training loss: 0.0433\n",
      "Epoch: 210/500... Training loss: 0.0096\n",
      "Epoch: 210/500... Training loss: 0.0385\n",
      "Epoch: 210/500... Training loss: 0.0499\n",
      "Epoch: 210/500... Training loss: 0.0262\n",
      "Epoch: 210/500... Training loss: 0.0418\n",
      "Epoch: 210/500... Training loss: 0.0246\n",
      "Epoch: 211/500... Training loss: 0.1856\n",
      "Epoch: 211/500... Training loss: 0.0150\n",
      "Epoch: 211/500... Training loss: 0.0286\n",
      "Epoch: 211/500... Training loss: 0.0365\n",
      "Epoch: 211/500... Training loss: 0.0606\n",
      "Epoch: 211/500... Training loss: 0.0172\n",
      "Epoch: 211/500... Training loss: 0.0225\n",
      "Epoch: 211/500... Training loss: 0.0411\n",
      "Epoch: 211/500... Training loss: 0.0263\n",
      "Epoch: 211/500... Training loss: 0.0570\n",
      "Epoch: 211/500... Training loss: 0.0893\n",
      "Epoch: 211/500... Training loss: 0.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 211/500... Training loss: 0.0491\n",
      "Epoch: 211/500... Training loss: 0.0516\n",
      "Epoch: 211/500... Training loss: 0.0512\n",
      "Epoch: 211/500... Training loss: 0.0167\n",
      "Epoch: 211/500... Training loss: 0.0612\n",
      "Epoch: 211/500... Training loss: 0.0052\n",
      "Epoch: 211/500... Training loss: 0.0389\n",
      "Epoch: 211/500... Training loss: 0.0043\n",
      "Epoch: 211/500... Training loss: 0.0478\n",
      "Epoch: 211/500... Training loss: 0.0801\n",
      "Epoch: 211/500... Training loss: 0.1496\n",
      "Epoch: 211/500... Training loss: 0.0355\n",
      "Epoch: 211/500... Training loss: 0.0182\n",
      "Epoch: 211/500... Training loss: 0.0543\n",
      "Epoch: 211/500... Training loss: 0.0193\n",
      "Epoch: 211/500... Training loss: 0.0186\n",
      "Epoch: 211/500... Training loss: 0.0111\n",
      "Epoch: 211/500... Training loss: 0.0967\n",
      "Epoch: 211/500... Training loss: 0.0655\n",
      "Epoch: 212/500... Training loss: 0.0248\n",
      "Epoch: 212/500... Training loss: 0.1242\n",
      "Epoch: 212/500... Training loss: 0.0208\n",
      "Epoch: 212/500... Training loss: 0.0473\n",
      "Epoch: 212/500... Training loss: 0.0253\n",
      "Epoch: 212/500... Training loss: 0.0322\n",
      "Epoch: 212/500... Training loss: 0.0357\n",
      "Epoch: 212/500... Training loss: 0.0484\n",
      "Epoch: 212/500... Training loss: 0.0213\n",
      "Epoch: 212/500... Training loss: 0.0121\n",
      "Epoch: 212/500... Training loss: 0.0221\n",
      "Epoch: 212/500... Training loss: 0.1005\n",
      "Epoch: 212/500... Training loss: 0.0136\n",
      "Epoch: 212/500... Training loss: 0.0326\n",
      "Epoch: 212/500... Training loss: 0.1447\n",
      "Epoch: 212/500... Training loss: 0.0512\n",
      "Epoch: 212/500... Training loss: 0.0183\n",
      "Epoch: 212/500... Training loss: 0.0218\n",
      "Epoch: 212/500... Training loss: 0.0081\n",
      "Epoch: 212/500... Training loss: 0.0221\n",
      "Epoch: 212/500... Training loss: 0.0248\n",
      "Epoch: 212/500... Training loss: 0.1273\n",
      "Epoch: 212/500... Training loss: 0.0351\n",
      "Epoch: 212/500... Training loss: 0.0480\n",
      "Epoch: 212/500... Training loss: 0.0597\n",
      "Epoch: 212/500... Training loss: 0.0233\n",
      "Epoch: 212/500... Training loss: 0.0090\n",
      "Epoch: 212/500... Training loss: 0.0154\n",
      "Epoch: 212/500... Training loss: 0.0090\n",
      "Epoch: 212/500... Training loss: 0.0173\n",
      "Epoch: 212/500... Training loss: 0.0941\n",
      "Epoch: 213/500... Training loss: 0.0878\n",
      "Epoch: 213/500... Training loss: 0.0299\n",
      "Epoch: 213/500... Training loss: 0.0743\n",
      "Epoch: 213/500... Training loss: 0.0818\n",
      "Epoch: 213/500... Training loss: 0.0749\n",
      "Epoch: 213/500... Training loss: 0.0495\n",
      "Epoch: 213/500... Training loss: 0.0582\n",
      "Epoch: 213/500... Training loss: 0.0305\n",
      "Epoch: 213/500... Training loss: 0.0281\n",
      "Epoch: 213/500... Training loss: 0.0509\n",
      "Epoch: 213/500... Training loss: 0.0134\n",
      "Epoch: 213/500... Training loss: 0.0428\n",
      "Epoch: 213/500... Training loss: 0.0573\n",
      "Epoch: 213/500... Training loss: 0.0561\n",
      "Epoch: 213/500... Training loss: 0.0407\n",
      "Epoch: 213/500... Training loss: 0.1287\n",
      "Epoch: 213/500... Training loss: 0.1389\n",
      "Epoch: 213/500... Training loss: 0.0156\n",
      "Epoch: 213/500... Training loss: 0.0219\n",
      "Epoch: 213/500... Training loss: 0.0418\n",
      "Epoch: 213/500... Training loss: 0.0098\n",
      "Epoch: 213/500... Training loss: 0.0151\n",
      "Epoch: 213/500... Training loss: 0.1168\n",
      "Epoch: 213/500... Training loss: 0.0353\n",
      "Epoch: 213/500... Training loss: 0.0574\n",
      "Epoch: 213/500... Training loss: 0.0175\n",
      "Epoch: 213/500... Training loss: 0.0860\n",
      "Epoch: 213/500... Training loss: 0.0501\n",
      "Epoch: 213/500... Training loss: 0.0286\n",
      "Epoch: 213/500... Training loss: 0.0272\n",
      "Epoch: 213/500... Training loss: 0.0159\n",
      "Epoch: 214/500... Training loss: 0.1141\n",
      "Epoch: 214/500... Training loss: 0.2267\n",
      "Epoch: 214/500... Training loss: 0.0076\n",
      "Epoch: 214/500... Training loss: 0.0139\n",
      "Epoch: 214/500... Training loss: 0.0709\n",
      "Epoch: 214/500... Training loss: 0.0357\n",
      "Epoch: 214/500... Training loss: 0.0132\n",
      "Epoch: 214/500... Training loss: 0.0103\n",
      "Epoch: 214/500... Training loss: 0.0076\n",
      "Epoch: 214/500... Training loss: 0.0090\n",
      "Epoch: 214/500... Training loss: 0.2376\n",
      "Epoch: 214/500... Training loss: 0.0640\n",
      "Epoch: 214/500... Training loss: 0.0232\n",
      "Epoch: 214/500... Training loss: 0.0710\n",
      "Epoch: 214/500... Training loss: 0.0979\n",
      "Epoch: 214/500... Training loss: 0.0451\n",
      "Epoch: 214/500... Training loss: 0.1112\n",
      "Epoch: 214/500... Training loss: 0.0275\n",
      "Epoch: 214/500... Training loss: 0.0493\n",
      "Epoch: 214/500... Training loss: 0.0072\n",
      "Epoch: 214/500... Training loss: 0.0286\n",
      "Epoch: 214/500... Training loss: 0.0402\n",
      "Epoch: 214/500... Training loss: 0.0743\n",
      "Epoch: 214/500... Training loss: 0.0682\n",
      "Epoch: 214/500... Training loss: 0.0090\n",
      "Epoch: 214/500... Training loss: 0.0247\n",
      "Epoch: 214/500... Training loss: 0.0266\n",
      "Epoch: 214/500... Training loss: 0.0161\n",
      "Epoch: 214/500... Training loss: 0.0063\n",
      "Epoch: 214/500... Training loss: 0.0329\n",
      "Epoch: 214/500... Training loss: 0.0391\n",
      "Epoch: 215/500... Training loss: 0.2670\n",
      "Epoch: 215/500... Training loss: 0.0381\n",
      "Epoch: 215/500... Training loss: 0.0159\n",
      "Epoch: 215/500... Training loss: 0.1651\n",
      "Epoch: 215/500... Training loss: 0.0279\n",
      "Epoch: 215/500... Training loss: 0.0540\n",
      "Epoch: 215/500... Training loss: 0.0264\n",
      "Epoch: 215/500... Training loss: 0.0539\n",
      "Epoch: 215/500... Training loss: 0.0928\n",
      "Epoch: 215/500... Training loss: 0.0387\n",
      "Epoch: 215/500... Training loss: 0.0157\n",
      "Epoch: 215/500... Training loss: 0.0570\n",
      "Epoch: 215/500... Training loss: 0.0095\n",
      "Epoch: 215/500... Training loss: 0.0355\n",
      "Epoch: 215/500... Training loss: 0.0166\n",
      "Epoch: 215/500... Training loss: 0.0653\n",
      "Epoch: 215/500... Training loss: 0.0364\n",
      "Epoch: 215/500... Training loss: 0.0607\n",
      "Epoch: 215/500... Training loss: 0.0892\n",
      "Epoch: 215/500... Training loss: 0.0480\n",
      "Epoch: 215/500... Training loss: 0.0125\n",
      "Epoch: 215/500... Training loss: 0.1275\n",
      "Epoch: 215/500... Training loss: 0.0593\n",
      "Epoch: 215/500... Training loss: 0.0086\n",
      "Epoch: 215/500... Training loss: 0.0227\n",
      "Epoch: 215/500... Training loss: 0.0353\n",
      "Epoch: 215/500... Training loss: 0.0300\n",
      "Epoch: 215/500... Training loss: 0.0111\n",
      "Epoch: 215/500... Training loss: 0.0382\n",
      "Epoch: 215/500... Training loss: 0.0175\n",
      "Epoch: 215/500... Training loss: 0.0260\n",
      "Epoch: 216/500... Training loss: 0.0487\n",
      "Epoch: 216/500... Training loss: 0.0157\n",
      "Epoch: 216/500... Training loss: 0.0559\n",
      "Epoch: 216/500... Training loss: 0.0190\n",
      "Epoch: 216/500... Training loss: 0.0179\n",
      "Epoch: 216/500... Training loss: 0.0393\n",
      "Epoch: 216/500... Training loss: 0.0238\n",
      "Epoch: 216/500... Training loss: 0.1726\n",
      "Epoch: 216/500... Training loss: 0.0590\n",
      "Epoch: 216/500... Training loss: 0.0935\n",
      "Epoch: 216/500... Training loss: 0.0358\n",
      "Epoch: 216/500... Training loss: 0.1023\n",
      "Epoch: 216/500... Training loss: 0.0899\n",
      "Epoch: 216/500... Training loss: 0.0509\n",
      "Epoch: 216/500... Training loss: 0.1097\n",
      "Epoch: 216/500... Training loss: 0.0161\n",
      "Epoch: 216/500... Training loss: 0.0440\n",
      "Epoch: 216/500... Training loss: 0.0649\n",
      "Epoch: 216/500... Training loss: 0.0289\n",
      "Epoch: 216/500... Training loss: 0.0536\n",
      "Epoch: 216/500... Training loss: 0.0471\n",
      "Epoch: 216/500... Training loss: 0.0586\n",
      "Epoch: 216/500... Training loss: 0.0196\n",
      "Epoch: 216/500... Training loss: 0.0267\n",
      "Epoch: 216/500... Training loss: 0.0346\n",
      "Epoch: 216/500... Training loss: 0.0284\n",
      "Epoch: 216/500... Training loss: 0.1422\n",
      "Epoch: 216/500... Training loss: 0.0437\n",
      "Epoch: 216/500... Training loss: 0.1583\n",
      "Epoch: 216/500... Training loss: 0.0685\n",
      "Epoch: 216/500... Training loss: 0.0672\n",
      "Epoch: 217/500... Training loss: 0.0072\n",
      "Epoch: 217/500... Training loss: 0.0418\n",
      "Epoch: 217/500... Training loss: 0.0597\n",
      "Epoch: 217/500... Training loss: 0.0639\n",
      "Epoch: 217/500... Training loss: 0.0948\n",
      "Epoch: 217/500... Training loss: 0.0391\n",
      "Epoch: 217/500... Training loss: 0.0549\n",
      "Epoch: 217/500... Training loss: 0.0505\n",
      "Epoch: 217/500... Training loss: 0.0837\n",
      "Epoch: 217/500... Training loss: 0.0320\n",
      "Epoch: 217/500... Training loss: 0.0115\n",
      "Epoch: 217/500... Training loss: 0.0728\n",
      "Epoch: 217/500... Training loss: 0.0594\n",
      "Epoch: 217/500... Training loss: 0.0532\n",
      "Epoch: 217/500... Training loss: 0.0574\n",
      "Epoch: 217/500... Training loss: 0.0933\n",
      "Epoch: 217/500... Training loss: 0.0402\n",
      "Epoch: 217/500... Training loss: 0.0390\n",
      "Epoch: 217/500... Training loss: 0.0891\n",
      "Epoch: 217/500... Training loss: 0.0269\n",
      "Epoch: 217/500... Training loss: 0.0674\n",
      "Epoch: 217/500... Training loss: 0.0306\n",
      "Epoch: 217/500... Training loss: 0.1728\n",
      "Epoch: 217/500... Training loss: 0.0779\n",
      "Epoch: 217/500... Training loss: 0.0254\n",
      "Epoch: 217/500... Training loss: 0.0178\n",
      "Epoch: 217/500... Training loss: 0.0303\n",
      "Epoch: 217/500... Training loss: 0.0540\n",
      "Epoch: 217/500... Training loss: 0.0645\n",
      "Epoch: 217/500... Training loss: 0.0208\n",
      "Epoch: 217/500... Training loss: 0.0165\n",
      "Epoch: 218/500... Training loss: 0.0581\n",
      "Epoch: 218/500... Training loss: 0.0085\n",
      "Epoch: 218/500... Training loss: 0.0183\n",
      "Epoch: 218/500... Training loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 218/500... Training loss: 0.0476\n",
      "Epoch: 218/500... Training loss: 0.0269\n",
      "Epoch: 218/500... Training loss: 0.0385\n",
      "Epoch: 218/500... Training loss: 0.0548\n",
      "Epoch: 218/500... Training loss: 0.0499\n",
      "Epoch: 218/500... Training loss: 0.1046\n",
      "Epoch: 218/500... Training loss: 0.0646\n",
      "Epoch: 218/500... Training loss: 0.0981\n",
      "Epoch: 218/500... Training loss: 0.0813\n",
      "Epoch: 218/500... Training loss: 0.0316\n",
      "Epoch: 218/500... Training loss: 0.1175\n",
      "Epoch: 218/500... Training loss: 0.0522\n",
      "Epoch: 218/500... Training loss: 0.0229\n",
      "Epoch: 218/500... Training loss: 0.1152\n",
      "Epoch: 218/500... Training loss: 0.0391\n",
      "Epoch: 218/500... Training loss: 0.0202\n",
      "Epoch: 218/500... Training loss: 0.0521\n",
      "Epoch: 218/500... Training loss: 0.1093\n",
      "Epoch: 218/500... Training loss: 0.2319\n",
      "Epoch: 218/500... Training loss: 0.0161\n",
      "Epoch: 218/500... Training loss: 0.0950\n",
      "Epoch: 218/500... Training loss: 0.0219\n",
      "Epoch: 218/500... Training loss: 0.0478\n",
      "Epoch: 218/500... Training loss: 0.0539\n",
      "Epoch: 218/500... Training loss: 0.0794\n",
      "Epoch: 218/500... Training loss: 0.0446\n",
      "Epoch: 218/500... Training loss: 0.0229\n",
      "Epoch: 219/500... Training loss: 0.0470\n",
      "Epoch: 219/500... Training loss: 0.0098\n",
      "Epoch: 219/500... Training loss: 0.0736\n",
      "Epoch: 219/500... Training loss: 0.0299\n",
      "Epoch: 219/500... Training loss: 0.0350\n",
      "Epoch: 219/500... Training loss: 0.0651\n",
      "Epoch: 219/500... Training loss: 0.0358\n",
      "Epoch: 219/500... Training loss: 0.0703\n",
      "Epoch: 219/500... Training loss: 0.0736\n",
      "Epoch: 219/500... Training loss: 0.0605\n",
      "Epoch: 219/500... Training loss: 0.0690\n",
      "Epoch: 219/500... Training loss: 0.0119\n",
      "Epoch: 219/500... Training loss: 0.0970\n",
      "Epoch: 219/500... Training loss: 0.0206\n",
      "Epoch: 219/500... Training loss: 0.1359\n",
      "Epoch: 219/500... Training loss: 0.0155\n",
      "Epoch: 219/500... Training loss: 0.0319\n",
      "Epoch: 219/500... Training loss: 0.0225\n",
      "Epoch: 219/500... Training loss: 0.0370\n",
      "Epoch: 219/500... Training loss: 0.2473\n",
      "Epoch: 219/500... Training loss: 0.0151\n",
      "Epoch: 219/500... Training loss: 0.0544\n",
      "Epoch: 219/500... Training loss: 0.1013\n",
      "Epoch: 219/500... Training loss: 0.0278\n",
      "Epoch: 219/500... Training loss: 0.0177\n",
      "Epoch: 219/500... Training loss: 0.0832\n",
      "Epoch: 219/500... Training loss: 0.0349\n",
      "Epoch: 219/500... Training loss: 0.0552\n",
      "Epoch: 219/500... Training loss: 0.0616\n",
      "Epoch: 219/500... Training loss: 0.0186\n",
      "Epoch: 219/500... Training loss: 0.0843\n",
      "Epoch: 220/500... Training loss: 0.0074\n",
      "Epoch: 220/500... Training loss: 0.0389\n",
      "Epoch: 220/500... Training loss: 0.0233\n",
      "Epoch: 220/500... Training loss: 0.0739\n",
      "Epoch: 220/500... Training loss: 0.0096\n",
      "Epoch: 220/500... Training loss: 0.0122\n",
      "Epoch: 220/500... Training loss: 0.0212\n",
      "Epoch: 220/500... Training loss: 0.0222\n",
      "Epoch: 220/500... Training loss: 0.1531\n",
      "Epoch: 220/500... Training loss: 0.0331\n",
      "Epoch: 220/500... Training loss: 0.0173\n",
      "Epoch: 220/500... Training loss: 0.0274\n",
      "Epoch: 220/500... Training loss: 0.0490\n",
      "Epoch: 220/500... Training loss: 0.1186\n",
      "Epoch: 220/500... Training loss: 0.0400\n",
      "Epoch: 220/500... Training loss: 0.0583\n",
      "Epoch: 220/500... Training loss: 0.0336\n",
      "Epoch: 220/500... Training loss: 0.0900\n",
      "Epoch: 220/500... Training loss: 0.0154\n",
      "Epoch: 220/500... Training loss: 0.0776\n",
      "Epoch: 220/500... Training loss: 0.0471\n",
      "Epoch: 220/500... Training loss: 0.0646\n",
      "Epoch: 220/500... Training loss: 0.0124\n",
      "Epoch: 220/500... Training loss: 0.0123\n",
      "Epoch: 220/500... Training loss: 0.0131\n",
      "Epoch: 220/500... Training loss: 0.0993\n",
      "Epoch: 220/500... Training loss: 0.0443\n",
      "Epoch: 220/500... Training loss: 0.0647\n",
      "Epoch: 220/500... Training loss: 0.1068\n",
      "Epoch: 220/500... Training loss: 0.0131\n",
      "Epoch: 220/500... Training loss: 0.0557\n",
      "Epoch: 221/500... Training loss: 0.0285\n",
      "Epoch: 221/500... Training loss: 0.0266\n",
      "Epoch: 221/500... Training loss: 0.0272\n",
      "Epoch: 221/500... Training loss: 0.0655\n",
      "Epoch: 221/500... Training loss: 0.0174\n",
      "Epoch: 221/500... Training loss: 0.1245\n",
      "Epoch: 221/500... Training loss: 0.0593\n",
      "Epoch: 221/500... Training loss: 0.0645\n",
      "Epoch: 221/500... Training loss: 0.0517\n",
      "Epoch: 221/500... Training loss: 0.0122\n",
      "Epoch: 221/500... Training loss: 0.1160\n",
      "Epoch: 221/500... Training loss: 0.0355\n",
      "Epoch: 221/500... Training loss: 0.0516\n",
      "Epoch: 221/500... Training loss: 0.0362\n",
      "Epoch: 221/500... Training loss: 0.0621\n",
      "Epoch: 221/500... Training loss: 0.1148\n",
      "Epoch: 221/500... Training loss: 0.0622\n",
      "Epoch: 221/500... Training loss: 0.0151\n",
      "Epoch: 221/500... Training loss: 0.0438\n",
      "Epoch: 221/500... Training loss: 0.0387\n",
      "Epoch: 221/500... Training loss: 0.1604\n",
      "Epoch: 221/500... Training loss: 0.0120\n",
      "Epoch: 221/500... Training loss: 0.1180\n",
      "Epoch: 221/500... Training loss: 0.0173\n",
      "Epoch: 221/500... Training loss: 0.0137\n",
      "Epoch: 221/500... Training loss: 0.0231\n",
      "Epoch: 221/500... Training loss: 0.0539\n",
      "Epoch: 221/500... Training loss: 0.0533\n",
      "Epoch: 221/500... Training loss: 0.0493\n",
      "Epoch: 221/500... Training loss: 0.0269\n",
      "Epoch: 221/500... Training loss: 0.0114\n",
      "Epoch: 222/500... Training loss: 0.0132\n",
      "Epoch: 222/500... Training loss: 0.1068\n",
      "Epoch: 222/500... Training loss: 0.0416\n",
      "Epoch: 222/500... Training loss: 0.1006\n",
      "Epoch: 222/500... Training loss: 0.0304\n",
      "Epoch: 222/500... Training loss: 0.0504\n",
      "Epoch: 222/500... Training loss: 0.0748\n",
      "Epoch: 222/500... Training loss: 0.0654\n",
      "Epoch: 222/500... Training loss: 0.0191\n",
      "Epoch: 222/500... Training loss: 0.0236\n",
      "Epoch: 222/500... Training loss: 0.1247\n",
      "Epoch: 222/500... Training loss: 0.0239\n",
      "Epoch: 222/500... Training loss: 0.0582\n",
      "Epoch: 222/500... Training loss: 0.0875\n",
      "Epoch: 222/500... Training loss: 0.0420\n",
      "Epoch: 222/500... Training loss: 0.0671\n",
      "Epoch: 222/500... Training loss: 0.0089\n",
      "Epoch: 222/500... Training loss: 0.0737\n",
      "Epoch: 222/500... Training loss: 0.0435\n",
      "Epoch: 222/500... Training loss: 0.0101\n",
      "Epoch: 222/500... Training loss: 0.0456\n",
      "Epoch: 222/500... Training loss: 0.0290\n",
      "Epoch: 222/500... Training loss: 0.0330\n",
      "Epoch: 222/500... Training loss: 0.0393\n",
      "Epoch: 222/500... Training loss: 0.0436\n",
      "Epoch: 222/500... Training loss: 0.0123\n",
      "Epoch: 222/500... Training loss: 0.0221\n",
      "Epoch: 222/500... Training loss: 0.0458\n",
      "Epoch: 222/500... Training loss: 0.0827\n",
      "Epoch: 222/500... Training loss: 0.1372\n",
      "Epoch: 222/500... Training loss: 0.0755\n",
      "Epoch: 223/500... Training loss: 0.0581\n",
      "Epoch: 223/500... Training loss: 0.0233\n",
      "Epoch: 223/500... Training loss: 0.0223\n",
      "Epoch: 223/500... Training loss: 0.0905\n",
      "Epoch: 223/500... Training loss: 0.0532\n",
      "Epoch: 223/500... Training loss: 0.0268\n",
      "Epoch: 223/500... Training loss: 0.1969\n",
      "Epoch: 223/500... Training loss: 0.0525\n",
      "Epoch: 223/500... Training loss: 0.0231\n",
      "Epoch: 223/500... Training loss: 0.0467\n",
      "Epoch: 223/500... Training loss: 0.0338\n",
      "Epoch: 223/500... Training loss: 0.0193\n",
      "Epoch: 223/500... Training loss: 0.0542\n",
      "Epoch: 223/500... Training loss: 0.0584\n",
      "Epoch: 223/500... Training loss: 0.0287\n",
      "Epoch: 223/500... Training loss: 0.0111\n",
      "Epoch: 223/500... Training loss: 0.0081\n",
      "Epoch: 223/500... Training loss: 0.0232\n",
      "Epoch: 223/500... Training loss: 0.0685\n",
      "Epoch: 223/500... Training loss: 0.0314\n",
      "Epoch: 223/500... Training loss: 0.0136\n",
      "Epoch: 223/500... Training loss: 0.0137\n",
      "Epoch: 223/500... Training loss: 0.0030\n",
      "Epoch: 223/500... Training loss: 0.1493\n",
      "Epoch: 223/500... Training loss: 0.0138\n",
      "Epoch: 223/500... Training loss: 0.0372\n",
      "Epoch: 223/500... Training loss: 0.0518\n",
      "Epoch: 223/500... Training loss: 0.0225\n",
      "Epoch: 223/500... Training loss: 0.0260\n",
      "Epoch: 223/500... Training loss: 0.0160\n",
      "Epoch: 223/500... Training loss: 0.0074\n",
      "Epoch: 224/500... Training loss: 0.0089\n",
      "Epoch: 224/500... Training loss: 0.0850\n",
      "Epoch: 224/500... Training loss: 0.0148\n",
      "Epoch: 224/500... Training loss: 0.1110\n",
      "Epoch: 224/500... Training loss: 0.0650\n",
      "Epoch: 224/500... Training loss: 0.0229\n",
      "Epoch: 224/500... Training loss: 0.1525\n",
      "Epoch: 224/500... Training loss: 0.1470\n",
      "Epoch: 224/500... Training loss: 0.0078\n",
      "Epoch: 224/500... Training loss: 0.0433\n",
      "Epoch: 224/500... Training loss: 0.0399\n",
      "Epoch: 224/500... Training loss: 0.0073\n",
      "Epoch: 224/500... Training loss: 0.0063\n",
      "Epoch: 224/500... Training loss: 0.0141\n",
      "Epoch: 224/500... Training loss: 0.0778\n",
      "Epoch: 224/500... Training loss: 0.0145\n",
      "Epoch: 224/500... Training loss: 0.0481\n",
      "Epoch: 224/500... Training loss: 0.0096\n",
      "Epoch: 224/500... Training loss: 0.0205\n",
      "Epoch: 224/500... Training loss: 0.0159\n",
      "Epoch: 224/500... Training loss: 0.0603\n",
      "Epoch: 224/500... Training loss: 0.1475\n",
      "Epoch: 224/500... Training loss: 0.0117\n",
      "Epoch: 224/500... Training loss: 0.0219\n",
      "Epoch: 224/500... Training loss: 0.0900\n",
      "Epoch: 224/500... Training loss: 0.0089\n",
      "Epoch: 224/500... Training loss: 0.0133\n",
      "Epoch: 224/500... Training loss: 0.0147\n",
      "Epoch: 224/500... Training loss: 0.0823\n",
      "Epoch: 224/500... Training loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224/500... Training loss: 0.0225\n",
      "Epoch: 225/500... Training loss: 0.0542\n",
      "Epoch: 225/500... Training loss: 0.0298\n",
      "Epoch: 225/500... Training loss: 0.0595\n",
      "Epoch: 225/500... Training loss: 0.0081\n",
      "Epoch: 225/500... Training loss: 0.0852\n",
      "Epoch: 225/500... Training loss: 0.0868\n",
      "Epoch: 225/500... Training loss: 0.0315\n",
      "Epoch: 225/500... Training loss: 0.0266\n",
      "Epoch: 225/500... Training loss: 0.0652\n",
      "Epoch: 225/500... Training loss: 0.0684\n",
      "Epoch: 225/500... Training loss: 0.0554\n",
      "Epoch: 225/500... Training loss: 0.0620\n",
      "Epoch: 225/500... Training loss: 0.1332\n",
      "Epoch: 225/500... Training loss: 0.0276\n",
      "Epoch: 225/500... Training loss: 0.0630\n",
      "Epoch: 225/500... Training loss: 0.0367\n",
      "Epoch: 225/500... Training loss: 0.0124\n",
      "Epoch: 225/500... Training loss: 0.0088\n",
      "Epoch: 225/500... Training loss: 0.0120\n",
      "Epoch: 225/500... Training loss: 0.0861\n",
      "Epoch: 225/500... Training loss: 0.0388\n",
      "Epoch: 225/500... Training loss: 0.0081\n",
      "Epoch: 225/500... Training loss: 0.0078\n",
      "Epoch: 225/500... Training loss: 0.0563\n",
      "Epoch: 225/500... Training loss: 0.0633\n",
      "Epoch: 225/500... Training loss: 0.0094\n",
      "Epoch: 225/500... Training loss: 0.0485\n",
      "Epoch: 225/500... Training loss: 0.0955\n",
      "Epoch: 225/500... Training loss: 0.0231\n",
      "Epoch: 225/500... Training loss: 0.0582\n",
      "Epoch: 225/500... Training loss: 0.1136\n",
      "Epoch: 226/500... Training loss: 0.0551\n",
      "Epoch: 226/500... Training loss: 0.0911\n",
      "Epoch: 226/500... Training loss: 0.0697\n",
      "Epoch: 226/500... Training loss: 0.0981\n",
      "Epoch: 226/500... Training loss: 0.0123\n",
      "Epoch: 226/500... Training loss: 0.0209\n",
      "Epoch: 226/500... Training loss: 0.0419\n",
      "Epoch: 226/500... Training loss: 0.0602\n",
      "Epoch: 226/500... Training loss: 0.0359\n",
      "Epoch: 226/500... Training loss: 0.0106\n",
      "Epoch: 226/500... Training loss: 0.0126\n",
      "Epoch: 226/500... Training loss: 0.2025\n",
      "Epoch: 226/500... Training loss: 0.0057\n",
      "Epoch: 226/500... Training loss: 0.0822\n",
      "Epoch: 226/500... Training loss: 0.1017\n",
      "Epoch: 226/500... Training loss: 0.0065\n",
      "Epoch: 226/500... Training loss: 0.0377\n",
      "Epoch: 226/500... Training loss: 0.0527\n",
      "Epoch: 226/500... Training loss: 0.0075\n",
      "Epoch: 226/500... Training loss: 0.0188\n",
      "Epoch: 226/500... Training loss: 0.0588\n",
      "Epoch: 226/500... Training loss: 0.0305\n",
      "Epoch: 226/500... Training loss: 0.0416\n",
      "Epoch: 226/500... Training loss: 0.0263\n",
      "Epoch: 226/500... Training loss: 0.0100\n",
      "Epoch: 226/500... Training loss: 0.0126\n",
      "Epoch: 226/500... Training loss: 0.0058\n",
      "Epoch: 226/500... Training loss: 0.1407\n",
      "Epoch: 226/500... Training loss: 0.0249\n",
      "Epoch: 226/500... Training loss: 0.0187\n",
      "Epoch: 226/500... Training loss: 0.0323\n",
      "Epoch: 227/500... Training loss: 0.0705\n",
      "Epoch: 227/500... Training loss: 0.0083\n",
      "Epoch: 227/500... Training loss: 0.0079\n",
      "Epoch: 227/500... Training loss: 0.0084\n",
      "Epoch: 227/500... Training loss: 0.0228\n",
      "Epoch: 227/500... Training loss: 0.0648\n",
      "Epoch: 227/500... Training loss: 0.0897\n",
      "Epoch: 227/500... Training loss: 0.0323\n",
      "Epoch: 227/500... Training loss: 0.0154\n",
      "Epoch: 227/500... Training loss: 0.0102\n",
      "Epoch: 227/500... Training loss: 0.0189\n",
      "Epoch: 227/500... Training loss: 0.1137\n",
      "Epoch: 227/500... Training loss: 0.0536\n",
      "Epoch: 227/500... Training loss: 0.0292\n",
      "Epoch: 227/500... Training loss: 0.0082\n",
      "Epoch: 227/500... Training loss: 0.0299\n",
      "Epoch: 227/500... Training loss: 0.0184\n",
      "Epoch: 227/500... Training loss: 0.0324\n",
      "Epoch: 227/500... Training loss: 0.0661\n",
      "Epoch: 227/500... Training loss: 0.0219\n",
      "Epoch: 227/500... Training loss: 0.0151\n",
      "Epoch: 227/500... Training loss: 0.0181\n",
      "Epoch: 227/500... Training loss: 0.0599\n",
      "Epoch: 227/500... Training loss: 0.0178\n",
      "Epoch: 227/500... Training loss: 0.0458\n",
      "Epoch: 227/500... Training loss: 0.1302\n",
      "Epoch: 227/500... Training loss: 0.0625\n",
      "Epoch: 227/500... Training loss: 0.0399\n",
      "Epoch: 227/500... Training loss: 0.0120\n",
      "Epoch: 227/500... Training loss: 0.0589\n",
      "Epoch: 227/500... Training loss: 0.0211\n",
      "Epoch: 228/500... Training loss: 0.0128\n",
      "Epoch: 228/500... Training loss: 0.0370\n",
      "Epoch: 228/500... Training loss: 0.0214\n",
      "Epoch: 228/500... Training loss: 0.0222\n",
      "Epoch: 228/500... Training loss: 0.0053\n",
      "Epoch: 228/500... Training loss: 0.0470\n",
      "Epoch: 228/500... Training loss: 0.1174\n",
      "Epoch: 228/500... Training loss: 0.0544\n",
      "Epoch: 228/500... Training loss: 0.0100\n",
      "Epoch: 228/500... Training loss: 0.0166\n",
      "Epoch: 228/500... Training loss: 0.0310\n",
      "Epoch: 228/500... Training loss: 0.0393\n",
      "Epoch: 228/500... Training loss: 0.0189\n",
      "Epoch: 228/500... Training loss: 0.0423\n",
      "Epoch: 228/500... Training loss: 0.0438\n",
      "Epoch: 228/500... Training loss: 0.0039\n",
      "Epoch: 228/500... Training loss: 0.0070\n",
      "Epoch: 228/500... Training loss: 0.0637\n",
      "Epoch: 228/500... Training loss: 0.0649\n",
      "Epoch: 228/500... Training loss: 0.0220\n",
      "Epoch: 228/500... Training loss: 0.0067\n",
      "Epoch: 228/500... Training loss: 0.0117\n",
      "Epoch: 228/500... Training loss: 0.1786\n",
      "Epoch: 228/500... Training loss: 0.0163\n",
      "Epoch: 228/500... Training loss: 0.0159\n",
      "Epoch: 228/500... Training loss: 0.0251\n",
      "Epoch: 228/500... Training loss: 0.0107\n",
      "Epoch: 228/500... Training loss: 0.0057\n",
      "Epoch: 228/500... Training loss: 0.0103\n",
      "Epoch: 228/500... Training loss: 0.0562\n",
      "Epoch: 228/500... Training loss: 0.0849\n",
      "Epoch: 229/500... Training loss: 0.0411\n",
      "Epoch: 229/500... Training loss: 0.0404\n",
      "Epoch: 229/500... Training loss: 0.0376\n",
      "Epoch: 229/500... Training loss: 0.0196\n",
      "Epoch: 229/500... Training loss: 0.0186\n",
      "Epoch: 229/500... Training loss: 0.0674\n",
      "Epoch: 229/500... Training loss: 0.0498\n",
      "Epoch: 229/500... Training loss: 0.0277\n",
      "Epoch: 229/500... Training loss: 0.0231\n",
      "Epoch: 229/500... Training loss: 0.0100\n",
      "Epoch: 229/500... Training loss: 0.0172\n",
      "Epoch: 229/500... Training loss: 0.0497\n",
      "Epoch: 229/500... Training loss: 0.0295\n",
      "Epoch: 229/500... Training loss: 0.0116\n",
      "Epoch: 229/500... Training loss: 0.0696\n",
      "Epoch: 229/500... Training loss: 0.0799\n",
      "Epoch: 229/500... Training loss: 0.0092\n",
      "Epoch: 229/500... Training loss: 0.0417\n",
      "Epoch: 229/500... Training loss: 0.0813\n",
      "Epoch: 229/500... Training loss: 0.0106\n",
      "Epoch: 229/500... Training loss: 0.0052\n",
      "Epoch: 229/500... Training loss: 0.0169\n",
      "Epoch: 229/500... Training loss: 0.0793\n",
      "Epoch: 229/500... Training loss: 0.0953\n",
      "Epoch: 229/500... Training loss: 0.0209\n",
      "Epoch: 229/500... Training loss: 0.0900\n",
      "Epoch: 229/500... Training loss: 0.0423\n",
      "Epoch: 229/500... Training loss: 0.0481\n",
      "Epoch: 229/500... Training loss: 0.1064\n",
      "Epoch: 229/500... Training loss: 0.0228\n",
      "Epoch: 229/500... Training loss: 0.0410\n",
      "Epoch: 230/500... Training loss: 0.0844\n",
      "Epoch: 230/500... Training loss: 0.0539\n",
      "Epoch: 230/500... Training loss: 0.0268\n",
      "Epoch: 230/500... Training loss: 0.0316\n",
      "Epoch: 230/500... Training loss: 0.0854\n",
      "Epoch: 230/500... Training loss: 0.0531\n",
      "Epoch: 230/500... Training loss: 0.0252\n",
      "Epoch: 230/500... Training loss: 0.0242\n",
      "Epoch: 230/500... Training loss: 0.0138\n",
      "Epoch: 230/500... Training loss: 0.0086\n",
      "Epoch: 230/500... Training loss: 0.1244\n",
      "Epoch: 230/500... Training loss: 0.1340\n",
      "Epoch: 230/500... Training loss: 0.0063\n",
      "Epoch: 230/500... Training loss: 0.0535\n",
      "Epoch: 230/500... Training loss: 0.0097\n",
      "Epoch: 230/500... Training loss: 0.0457\n",
      "Epoch: 230/500... Training loss: 0.0244\n",
      "Epoch: 230/500... Training loss: 0.0281\n",
      "Epoch: 230/500... Training loss: 0.0269\n",
      "Epoch: 230/500... Training loss: 0.0489\n",
      "Epoch: 230/500... Training loss: 0.0740\n",
      "Epoch: 230/500... Training loss: 0.0212\n",
      "Epoch: 230/500... Training loss: 0.0192\n",
      "Epoch: 230/500... Training loss: 0.0268\n",
      "Epoch: 230/500... Training loss: 0.0639\n",
      "Epoch: 230/500... Training loss: 0.0039\n",
      "Epoch: 230/500... Training loss: 0.0268\n",
      "Epoch: 230/500... Training loss: 0.0161\n",
      "Epoch: 230/500... Training loss: 0.0141\n",
      "Epoch: 230/500... Training loss: 0.0341\n",
      "Epoch: 230/500... Training loss: 0.0247\n",
      "Epoch: 231/500... Training loss: 0.3040\n",
      "Epoch: 231/500... Training loss: 0.0071\n",
      "Epoch: 231/500... Training loss: 0.0229\n",
      "Epoch: 231/500... Training loss: 0.0091\n",
      "Epoch: 231/500... Training loss: 0.0206\n",
      "Epoch: 231/500... Training loss: 0.0362\n",
      "Epoch: 231/500... Training loss: 0.1262\n",
      "Epoch: 231/500... Training loss: 0.0082\n",
      "Epoch: 231/500... Training loss: 0.1523\n",
      "Epoch: 231/500... Training loss: 0.0998\n",
      "Epoch: 231/500... Training loss: 0.1093\n",
      "Epoch: 231/500... Training loss: 0.1207\n",
      "Epoch: 231/500... Training loss: 0.0043\n",
      "Epoch: 231/500... Training loss: 0.0418\n",
      "Epoch: 231/500... Training loss: 0.0072\n",
      "Epoch: 231/500... Training loss: 0.0826\n",
      "Epoch: 231/500... Training loss: 0.0050\n",
      "Epoch: 231/500... Training loss: 0.0189\n",
      "Epoch: 231/500... Training loss: 0.1339\n",
      "Epoch: 231/500... Training loss: 0.0091\n",
      "Epoch: 231/500... Training loss: 0.0614\n",
      "Epoch: 231/500... Training loss: 0.0338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 231/500... Training loss: 0.0340\n",
      "Epoch: 231/500... Training loss: 0.0081\n",
      "Epoch: 231/500... Training loss: 0.1090\n",
      "Epoch: 231/500... Training loss: 0.0175\n",
      "Epoch: 231/500... Training loss: 0.0328\n",
      "Epoch: 231/500... Training loss: 0.0215\n",
      "Epoch: 231/500... Training loss: 0.0101\n",
      "Epoch: 231/500... Training loss: 0.0184\n",
      "Epoch: 231/500... Training loss: 0.0210\n",
      "Epoch: 232/500... Training loss: 0.1196\n",
      "Epoch: 232/500... Training loss: 0.1438\n",
      "Epoch: 232/500... Training loss: 0.1540\n",
      "Epoch: 232/500... Training loss: 0.0174\n",
      "Epoch: 232/500... Training loss: 0.0244\n",
      "Epoch: 232/500... Training loss: 0.0169\n",
      "Epoch: 232/500... Training loss: 0.0219\n",
      "Epoch: 232/500... Training loss: 0.0159\n",
      "Epoch: 232/500... Training loss: 0.0371\n",
      "Epoch: 232/500... Training loss: 0.0215\n",
      "Epoch: 232/500... Training loss: 0.0991\n",
      "Epoch: 232/500... Training loss: 0.0423\n",
      "Epoch: 232/500... Training loss: 0.0082\n",
      "Epoch: 232/500... Training loss: 0.0183\n",
      "Epoch: 232/500... Training loss: 0.0420\n",
      "Epoch: 232/500... Training loss: 0.0163\n",
      "Epoch: 232/500... Training loss: 0.0259\n",
      "Epoch: 232/500... Training loss: 0.0181\n",
      "Epoch: 232/500... Training loss: 0.0092\n",
      "Epoch: 232/500... Training loss: 0.0178\n",
      "Epoch: 232/500... Training loss: 0.0089\n",
      "Epoch: 232/500... Training loss: 0.0840\n",
      "Epoch: 232/500... Training loss: 0.0594\n",
      "Epoch: 232/500... Training loss: 0.0646\n",
      "Epoch: 232/500... Training loss: 0.0084\n",
      "Epoch: 232/500... Training loss: 0.0387\n",
      "Epoch: 232/500... Training loss: 0.0512\n",
      "Epoch: 232/500... Training loss: 0.0255\n",
      "Epoch: 232/500... Training loss: 0.0257\n",
      "Epoch: 232/500... Training loss: 0.0378\n",
      "Epoch: 232/500... Training loss: 0.0176\n",
      "Epoch: 233/500... Training loss: 0.0481\n",
      "Epoch: 233/500... Training loss: 0.0275\n",
      "Epoch: 233/500... Training loss: 0.1087\n",
      "Epoch: 233/500... Training loss: 0.0250\n",
      "Epoch: 233/500... Training loss: 0.0059\n",
      "Epoch: 233/500... Training loss: 0.0117\n",
      "Epoch: 233/500... Training loss: 0.1346\n",
      "Epoch: 233/500... Training loss: 0.0707\n",
      "Epoch: 233/500... Training loss: 0.1050\n",
      "Epoch: 233/500... Training loss: 0.0086\n",
      "Epoch: 233/500... Training loss: 0.0731\n",
      "Epoch: 233/500... Training loss: 0.0077\n",
      "Epoch: 233/500... Training loss: 0.0234\n",
      "Epoch: 233/500... Training loss: 0.0517\n",
      "Epoch: 233/500... Training loss: 0.0119\n",
      "Epoch: 233/500... Training loss: 0.0210\n",
      "Epoch: 233/500... Training loss: 0.0109\n",
      "Epoch: 233/500... Training loss: 0.0762\n",
      "Epoch: 233/500... Training loss: 0.0192\n",
      "Epoch: 233/500... Training loss: 0.0522\n",
      "Epoch: 233/500... Training loss: 0.0096\n",
      "Epoch: 233/500... Training loss: 0.0169\n",
      "Epoch: 233/500... Training loss: 0.0130\n",
      "Epoch: 233/500... Training loss: 0.0130\n",
      "Epoch: 233/500... Training loss: 0.2224\n",
      "Epoch: 233/500... Training loss: 0.0574\n",
      "Epoch: 233/500... Training loss: 0.0602\n",
      "Epoch: 233/500... Training loss: 0.0070\n",
      "Epoch: 233/500... Training loss: 0.0232\n",
      "Epoch: 233/500... Training loss: 0.0597\n",
      "Epoch: 233/500... Training loss: 0.0449\n",
      "Epoch: 234/500... Training loss: 0.0245\n",
      "Epoch: 234/500... Training loss: 0.0374\n",
      "Epoch: 234/500... Training loss: 0.0139\n",
      "Epoch: 234/500... Training loss: 0.0184\n",
      "Epoch: 234/500... Training loss: 0.0565\n",
      "Epoch: 234/500... Training loss: 0.1598\n",
      "Epoch: 234/500... Training loss: 0.0337\n",
      "Epoch: 234/500... Training loss: 0.0716\n",
      "Epoch: 234/500... Training loss: 0.0076\n",
      "Epoch: 234/500... Training loss: 0.0098\n",
      "Epoch: 234/500... Training loss: 0.1919\n",
      "Epoch: 234/500... Training loss: 0.0568\n",
      "Epoch: 234/500... Training loss: 0.0332\n",
      "Epoch: 234/500... Training loss: 0.0337\n",
      "Epoch: 234/500... Training loss: 0.0945\n",
      "Epoch: 234/500... Training loss: 0.0167\n",
      "Epoch: 234/500... Training loss: 0.0226\n",
      "Epoch: 234/500... Training loss: 0.0099\n",
      "Epoch: 234/500... Training loss: 0.0122\n",
      "Epoch: 234/500... Training loss: 0.0270\n",
      "Epoch: 234/500... Training loss: 0.0309\n",
      "Epoch: 234/500... Training loss: 0.0213\n",
      "Epoch: 234/500... Training loss: 0.0470\n",
      "Epoch: 234/500... Training loss: 0.0832\n",
      "Epoch: 234/500... Training loss: 0.0777\n",
      "Epoch: 234/500... Training loss: 0.0464\n",
      "Epoch: 234/500... Training loss: 0.2151\n",
      "Epoch: 234/500... Training loss: 0.0896\n",
      "Epoch: 234/500... Training loss: 0.0121\n",
      "Epoch: 234/500... Training loss: 0.0089\n",
      "Epoch: 234/500... Training loss: 0.0147\n",
      "Epoch: 235/500... Training loss: 0.0056\n",
      "Epoch: 235/500... Training loss: 0.1054\n",
      "Epoch: 235/500... Training loss: 0.0179\n",
      "Epoch: 235/500... Training loss: 0.0950\n",
      "Epoch: 235/500... Training loss: 0.0667\n",
      "Epoch: 235/500... Training loss: 0.0261\n",
      "Epoch: 235/500... Training loss: 0.0047\n",
      "Epoch: 235/500... Training loss: 0.0538\n",
      "Epoch: 235/500... Training loss: 0.0921\n",
      "Epoch: 235/500... Training loss: 0.0581\n",
      "Epoch: 235/500... Training loss: 0.0106\n",
      "Epoch: 235/500... Training loss: 0.0110\n",
      "Epoch: 235/500... Training loss: 0.0495\n",
      "Epoch: 235/500... Training loss: 0.0074\n",
      "Epoch: 235/500... Training loss: 0.0088\n",
      "Epoch: 235/500... Training loss: 0.0065\n",
      "Epoch: 235/500... Training loss: 0.0227\n",
      "Epoch: 235/500... Training loss: 0.0989\n",
      "Epoch: 235/500... Training loss: 0.0231\n",
      "Epoch: 235/500... Training loss: 0.0144\n",
      "Epoch: 235/500... Training loss: 0.0061\n",
      "Epoch: 235/500... Training loss: 0.0380\n",
      "Epoch: 235/500... Training loss: 0.0070\n",
      "Epoch: 235/500... Training loss: 0.0122\n",
      "Epoch: 235/500... Training loss: 0.0260\n",
      "Epoch: 235/500... Training loss: 0.0298\n",
      "Epoch: 235/500... Training loss: 0.0184\n",
      "Epoch: 235/500... Training loss: 0.0425\n",
      "Epoch: 235/500... Training loss: 0.0298\n",
      "Epoch: 235/500... Training loss: 0.0420\n",
      "Epoch: 235/500... Training loss: 0.0169\n",
      "Epoch: 236/500... Training loss: 0.0232\n",
      "Epoch: 236/500... Training loss: 0.0092\n",
      "Epoch: 236/500... Training loss: 0.0385\n",
      "Epoch: 236/500... Training loss: 0.0248\n",
      "Epoch: 236/500... Training loss: 0.0109\n",
      "Epoch: 236/500... Training loss: 0.0356\n",
      "Epoch: 236/500... Training loss: 0.0055\n",
      "Epoch: 236/500... Training loss: 0.0522\n",
      "Epoch: 236/500... Training loss: 0.0143\n",
      "Epoch: 236/500... Training loss: 0.0077\n",
      "Epoch: 236/500... Training loss: 0.0193\n",
      "Epoch: 236/500... Training loss: 0.0725\n",
      "Epoch: 236/500... Training loss: 0.0845\n",
      "Epoch: 236/500... Training loss: 0.0109\n",
      "Epoch: 236/500... Training loss: 0.0056\n",
      "Epoch: 236/500... Training loss: 0.0677\n",
      "Epoch: 236/500... Training loss: 0.0092\n",
      "Epoch: 236/500... Training loss: 0.0297\n",
      "Epoch: 236/500... Training loss: 0.0184\n",
      "Epoch: 236/500... Training loss: 0.0073\n",
      "Epoch: 236/500... Training loss: 0.0235\n",
      "Epoch: 236/500... Training loss: 0.0121\n",
      "Epoch: 236/500... Training loss: 0.0041\n",
      "Epoch: 236/500... Training loss: 0.0561\n",
      "Epoch: 236/500... Training loss: 0.0542\n",
      "Epoch: 236/500... Training loss: 0.0532\n",
      "Epoch: 236/500... Training loss: 0.0176\n",
      "Epoch: 236/500... Training loss: 0.0546\n",
      "Epoch: 236/500... Training loss: 0.0473\n",
      "Epoch: 236/500... Training loss: 0.0257\n",
      "Epoch: 236/500... Training loss: 0.0109\n",
      "Epoch: 237/500... Training loss: 0.0182\n",
      "Epoch: 237/500... Training loss: 0.0156\n",
      "Epoch: 237/500... Training loss: 0.0367\n",
      "Epoch: 237/500... Training loss: 0.0177\n",
      "Epoch: 237/500... Training loss: 0.0683\n",
      "Epoch: 237/500... Training loss: 0.0353\n",
      "Epoch: 237/500... Training loss: 0.0069\n",
      "Epoch: 237/500... Training loss: 0.0072\n",
      "Epoch: 237/500... Training loss: 0.0061\n",
      "Epoch: 237/500... Training loss: 0.0392\n",
      "Epoch: 237/500... Training loss: 0.0090\n",
      "Epoch: 237/500... Training loss: 0.0242\n",
      "Epoch: 237/500... Training loss: 0.0096\n",
      "Epoch: 237/500... Training loss: 0.0096\n",
      "Epoch: 237/500... Training loss: 0.0170\n",
      "Epoch: 237/500... Training loss: 0.0030\n",
      "Epoch: 237/500... Training loss: 0.0177\n",
      "Epoch: 237/500... Training loss: 0.0436\n",
      "Epoch: 237/500... Training loss: 0.0930\n",
      "Epoch: 237/500... Training loss: 0.0187\n",
      "Epoch: 237/500... Training loss: 0.0117\n",
      "Epoch: 237/500... Training loss: 0.0189\n",
      "Epoch: 237/500... Training loss: 0.0265\n",
      "Epoch: 237/500... Training loss: 0.0032\n",
      "Epoch: 237/500... Training loss: 0.0441\n",
      "Epoch: 237/500... Training loss: 0.0404\n",
      "Epoch: 237/500... Training loss: 0.0058\n",
      "Epoch: 237/500... Training loss: 0.1134\n",
      "Epoch: 237/500... Training loss: 0.0658\n",
      "Epoch: 237/500... Training loss: 0.0458\n",
      "Epoch: 237/500... Training loss: 0.0068\n",
      "Epoch: 238/500... Training loss: 0.0289\n",
      "Epoch: 238/500... Training loss: 0.0106\n",
      "Epoch: 238/500... Training loss: 0.0093\n",
      "Epoch: 238/500... Training loss: 0.0100\n",
      "Epoch: 238/500... Training loss: 0.0112\n",
      "Epoch: 238/500... Training loss: 0.0055\n",
      "Epoch: 238/500... Training loss: 0.0092\n",
      "Epoch: 238/500... Training loss: 0.0156\n",
      "Epoch: 238/500... Training loss: 0.0127\n",
      "Epoch: 238/500... Training loss: 0.0436\n",
      "Epoch: 238/500... Training loss: 0.0216\n",
      "Epoch: 238/500... Training loss: 0.0339\n",
      "Epoch: 238/500... Training loss: 0.0705\n",
      "Epoch: 238/500... Training loss: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 238/500... Training loss: 0.0610\n",
      "Epoch: 238/500... Training loss: 0.0150\n",
      "Epoch: 238/500... Training loss: 0.0113\n",
      "Epoch: 238/500... Training loss: 0.0059\n",
      "Epoch: 238/500... Training loss: 0.0250\n",
      "Epoch: 238/500... Training loss: 0.0111\n",
      "Epoch: 238/500... Training loss: 0.0080\n",
      "Epoch: 238/500... Training loss: 0.0379\n",
      "Epoch: 238/500... Training loss: 0.0416\n",
      "Epoch: 238/500... Training loss: 0.1307\n",
      "Epoch: 238/500... Training loss: 0.0056\n",
      "Epoch: 238/500... Training loss: 0.0103\n",
      "Epoch: 238/500... Training loss: 0.0213\n",
      "Epoch: 238/500... Training loss: 0.0324\n",
      "Epoch: 238/500... Training loss: 0.0236\n",
      "Epoch: 238/500... Training loss: 0.0055\n",
      "Epoch: 238/500... Training loss: 0.0140\n",
      "Epoch: 239/500... Training loss: 0.0493\n",
      "Epoch: 239/500... Training loss: 0.0220\n",
      "Epoch: 239/500... Training loss: 0.0049\n",
      "Epoch: 239/500... Training loss: 0.0174\n",
      "Epoch: 239/500... Training loss: 0.0215\n",
      "Epoch: 239/500... Training loss: 0.0072\n",
      "Epoch: 239/500... Training loss: 0.0664\n",
      "Epoch: 239/500... Training loss: 0.0914\n",
      "Epoch: 239/500... Training loss: 0.0051\n",
      "Epoch: 239/500... Training loss: 0.1393\n",
      "Epoch: 239/500... Training loss: 0.0933\n",
      "Epoch: 239/500... Training loss: 0.0079\n",
      "Epoch: 239/500... Training loss: 0.0543\n",
      "Epoch: 239/500... Training loss: 0.0263\n",
      "Epoch: 239/500... Training loss: 0.0234\n",
      "Epoch: 239/500... Training loss: 0.0112\n",
      "Epoch: 239/500... Training loss: 0.1240\n",
      "Epoch: 239/500... Training loss: 0.0259\n",
      "Epoch: 239/500... Training loss: 0.0366\n",
      "Epoch: 239/500... Training loss: 0.0310\n",
      "Epoch: 239/500... Training loss: 0.0025\n",
      "Epoch: 239/500... Training loss: 0.0341\n",
      "Epoch: 239/500... Training loss: 0.0211\n",
      "Epoch: 239/500... Training loss: 0.0370\n",
      "Epoch: 239/500... Training loss: 0.0189\n",
      "Epoch: 239/500... Training loss: 0.0658\n",
      "Epoch: 239/500... Training loss: 0.0209\n",
      "Epoch: 239/500... Training loss: 0.0225\n",
      "Epoch: 239/500... Training loss: 0.0420\n",
      "Epoch: 239/500... Training loss: 0.0272\n",
      "Epoch: 239/500... Training loss: 0.0115\n",
      "Epoch: 240/500... Training loss: 0.0197\n",
      "Epoch: 240/500... Training loss: 0.0062\n",
      "Epoch: 240/500... Training loss: 0.0108\n",
      "Epoch: 240/500... Training loss: 0.0061\n",
      "Epoch: 240/500... Training loss: 0.0300\n",
      "Epoch: 240/500... Training loss: 0.0226\n",
      "Epoch: 240/500... Training loss: 0.0399\n",
      "Epoch: 240/500... Training loss: 0.0225\n",
      "Epoch: 240/500... Training loss: 0.0053\n",
      "Epoch: 240/500... Training loss: 0.0140\n",
      "Epoch: 240/500... Training loss: 0.0690\n",
      "Epoch: 240/500... Training loss: 0.0732\n",
      "Epoch: 240/500... Training loss: 0.0859\n",
      "Epoch: 240/500... Training loss: 0.1030\n",
      "Epoch: 240/500... Training loss: 0.0378\n",
      "Epoch: 240/500... Training loss: 0.0049\n",
      "Epoch: 240/500... Training loss: 0.0043\n",
      "Epoch: 240/500... Training loss: 0.0123\n",
      "Epoch: 240/500... Training loss: 0.0156\n",
      "Epoch: 240/500... Training loss: 0.0085\n",
      "Epoch: 240/500... Training loss: 0.0665\n",
      "Epoch: 240/500... Training loss: 0.0388\n",
      "Epoch: 240/500... Training loss: 0.0693\n",
      "Epoch: 240/500... Training loss: 0.0044\n",
      "Epoch: 240/500... Training loss: 0.1327\n",
      "Epoch: 240/500... Training loss: 0.0571\n",
      "Epoch: 240/500... Training loss: 0.0736\n",
      "Epoch: 240/500... Training loss: 0.0842\n",
      "Epoch: 240/500... Training loss: 0.0042\n",
      "Epoch: 240/500... Training loss: 0.0331\n",
      "Epoch: 240/500... Training loss: 0.0153\n",
      "Epoch: 241/500... Training loss: 0.0225\n",
      "Epoch: 241/500... Training loss: 0.0072\n",
      "Epoch: 241/500... Training loss: 0.0158\n",
      "Epoch: 241/500... Training loss: 0.0323\n",
      "Epoch: 241/500... Training loss: 0.0240\n",
      "Epoch: 241/500... Training loss: 0.0193\n",
      "Epoch: 241/500... Training loss: 0.0186\n",
      "Epoch: 241/500... Training loss: 0.1379\n",
      "Epoch: 241/500... Training loss: 0.0058\n",
      "Epoch: 241/500... Training loss: 0.0109\n",
      "Epoch: 241/500... Training loss: 0.0556\n",
      "Epoch: 241/500... Training loss: 0.2718\n",
      "Epoch: 241/500... Training loss: 0.1645\n",
      "Epoch: 241/500... Training loss: 0.0054\n",
      "Epoch: 241/500... Training loss: 0.0285\n",
      "Epoch: 241/500... Training loss: 0.0342\n",
      "Epoch: 241/500... Training loss: 0.1047\n",
      "Epoch: 241/500... Training loss: 0.0571\n",
      "Epoch: 241/500... Training loss: 0.0054\n",
      "Epoch: 241/500... Training loss: 0.0028\n",
      "Epoch: 241/500... Training loss: 0.0211\n",
      "Epoch: 241/500... Training loss: 0.0304\n",
      "Epoch: 241/500... Training loss: 0.0574\n",
      "Epoch: 241/500... Training loss: 0.0251\n",
      "Epoch: 241/500... Training loss: 0.0085\n",
      "Epoch: 241/500... Training loss: 0.0230\n",
      "Epoch: 241/500... Training loss: 0.0309\n",
      "Epoch: 241/500... Training loss: 0.0151\n",
      "Epoch: 241/500... Training loss: 0.0047\n",
      "Epoch: 241/500... Training loss: 0.0236\n",
      "Epoch: 241/500... Training loss: 0.0069\n",
      "Epoch: 242/500... Training loss: 0.0087\n",
      "Epoch: 242/500... Training loss: 0.0075\n",
      "Epoch: 242/500... Training loss: 0.0155\n",
      "Epoch: 242/500... Training loss: 0.0110\n",
      "Epoch: 242/500... Training loss: 0.0067\n",
      "Epoch: 242/500... Training loss: 0.0465\n",
      "Epoch: 242/500... Training loss: 0.0645\n",
      "Epoch: 242/500... Training loss: 0.1041\n",
      "Epoch: 242/500... Training loss: 0.0905\n",
      "Epoch: 242/500... Training loss: 0.0295\n",
      "Epoch: 242/500... Training loss: 0.0525\n",
      "Epoch: 242/500... Training loss: 0.0218\n",
      "Epoch: 242/500... Training loss: 0.0182\n",
      "Epoch: 242/500... Training loss: 0.0859\n",
      "Epoch: 242/500... Training loss: 0.0308\n",
      "Epoch: 242/500... Training loss: 0.0493\n",
      "Epoch: 242/500... Training loss: 0.0233\n",
      "Epoch: 242/500... Training loss: 0.0021\n",
      "Epoch: 242/500... Training loss: 0.0201\n",
      "Epoch: 242/500... Training loss: 0.0584\n",
      "Epoch: 242/500... Training loss: 0.0158\n",
      "Epoch: 242/500... Training loss: 0.0580\n",
      "Epoch: 242/500... Training loss: 0.0566\n",
      "Epoch: 242/500... Training loss: 0.0840\n",
      "Epoch: 242/500... Training loss: 0.0085\n",
      "Epoch: 242/500... Training loss: 0.0064\n",
      "Epoch: 242/500... Training loss: 0.2809\n",
      "Epoch: 242/500... Training loss: 0.0315\n",
      "Epoch: 242/500... Training loss: 0.0498\n",
      "Epoch: 242/500... Training loss: 0.0501\n",
      "Epoch: 242/500... Training loss: 0.0123\n",
      "Epoch: 243/500... Training loss: 0.0776\n",
      "Epoch: 243/500... Training loss: 0.0114\n",
      "Epoch: 243/500... Training loss: 0.0168\n",
      "Epoch: 243/500... Training loss: 0.0882\n",
      "Epoch: 243/500... Training loss: 0.0633\n",
      "Epoch: 243/500... Training loss: 0.0575\n",
      "Epoch: 243/500... Training loss: 0.0246\n",
      "Epoch: 243/500... Training loss: 0.0176\n",
      "Epoch: 243/500... Training loss: 0.0329\n",
      "Epoch: 243/500... Training loss: 0.0042\n",
      "Epoch: 243/500... Training loss: 0.0797\n",
      "Epoch: 243/500... Training loss: 0.0129\n",
      "Epoch: 243/500... Training loss: 0.0126\n",
      "Epoch: 243/500... Training loss: 0.1118\n",
      "Epoch: 243/500... Training loss: 0.1175\n",
      "Epoch: 243/500... Training loss: 0.0029\n",
      "Epoch: 243/500... Training loss: 0.0264\n",
      "Epoch: 243/500... Training loss: 0.0175\n",
      "Epoch: 243/500... Training loss: 0.0250\n",
      "Epoch: 243/500... Training loss: 0.0921\n",
      "Epoch: 243/500... Training loss: 0.0883\n",
      "Epoch: 243/500... Training loss: 0.0079\n",
      "Epoch: 243/500... Training loss: 0.0466\n",
      "Epoch: 243/500... Training loss: 0.0579\n",
      "Epoch: 243/500... Training loss: 0.0489\n",
      "Epoch: 243/500... Training loss: 0.0530\n",
      "Epoch: 243/500... Training loss: 0.0259\n",
      "Epoch: 243/500... Training loss: 0.0182\n",
      "Epoch: 243/500... Training loss: 0.0070\n",
      "Epoch: 243/500... Training loss: 0.0122\n",
      "Epoch: 243/500... Training loss: 0.0251\n",
      "Epoch: 244/500... Training loss: 0.0339\n",
      "Epoch: 244/500... Training loss: 0.0476\n",
      "Epoch: 244/500... Training loss: 0.0204\n",
      "Epoch: 244/500... Training loss: 0.0367\n",
      "Epoch: 244/500... Training loss: 0.0180\n",
      "Epoch: 244/500... Training loss: 0.0151\n",
      "Epoch: 244/500... Training loss: 0.0537\n",
      "Epoch: 244/500... Training loss: 0.0836\n",
      "Epoch: 244/500... Training loss: 0.0320\n",
      "Epoch: 244/500... Training loss: 0.0268\n",
      "Epoch: 244/500... Training loss: 0.0274\n",
      "Epoch: 244/500... Training loss: 0.0152\n",
      "Epoch: 244/500... Training loss: 0.0198\n",
      "Epoch: 244/500... Training loss: 0.0368\n",
      "Epoch: 244/500... Training loss: 0.0199\n",
      "Epoch: 244/500... Training loss: 0.0103\n",
      "Epoch: 244/500... Training loss: 0.0422\n",
      "Epoch: 244/500... Training loss: 0.0283\n",
      "Epoch: 244/500... Training loss: 0.0125\n",
      "Epoch: 244/500... Training loss: 0.0161\n",
      "Epoch: 244/500... Training loss: 0.0095\n",
      "Epoch: 244/500... Training loss: 0.0176\n",
      "Epoch: 244/500... Training loss: 0.0145\n",
      "Epoch: 244/500... Training loss: 0.0914\n",
      "Epoch: 244/500... Training loss: 0.0206\n",
      "Epoch: 244/500... Training loss: 0.1775\n",
      "Epoch: 244/500... Training loss: 0.0482\n",
      "Epoch: 244/500... Training loss: 0.0571\n",
      "Epoch: 244/500... Training loss: 0.0049\n",
      "Epoch: 244/500... Training loss: 0.0163\n",
      "Epoch: 244/500... Training loss: 0.0182\n",
      "Epoch: 245/500... Training loss: 0.0154\n",
      "Epoch: 245/500... Training loss: 0.0387\n",
      "Epoch: 245/500... Training loss: 0.0042\n",
      "Epoch: 245/500... Training loss: 0.0626\n",
      "Epoch: 245/500... Training loss: 0.0395\n",
      "Epoch: 245/500... Training loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 245/500... Training loss: 0.0183\n",
      "Epoch: 245/500... Training loss: 0.0260\n",
      "Epoch: 245/500... Training loss: 0.0402\n",
      "Epoch: 245/500... Training loss: 0.0230\n",
      "Epoch: 245/500... Training loss: 0.0136\n",
      "Epoch: 245/500... Training loss: 0.1530\n",
      "Epoch: 245/500... Training loss: 0.0920\n",
      "Epoch: 245/500... Training loss: 0.0478\n",
      "Epoch: 245/500... Training loss: 0.0458\n",
      "Epoch: 245/500... Training loss: 0.0662\n",
      "Epoch: 245/500... Training loss: 0.0270\n",
      "Epoch: 245/500... Training loss: 0.0604\n",
      "Epoch: 245/500... Training loss: 0.1311\n",
      "Epoch: 245/500... Training loss: 0.1249\n",
      "Epoch: 245/500... Training loss: 0.0136\n",
      "Epoch: 245/500... Training loss: 0.0493\n",
      "Epoch: 245/500... Training loss: 0.0053\n",
      "Epoch: 245/500... Training loss: 0.0404\n",
      "Epoch: 245/500... Training loss: 0.0141\n",
      "Epoch: 245/500... Training loss: 0.0940\n",
      "Epoch: 245/500... Training loss: 0.0144\n",
      "Epoch: 245/500... Training loss: 0.0250\n",
      "Epoch: 245/500... Training loss: 0.0232\n",
      "Epoch: 245/500... Training loss: 0.0378\n",
      "Epoch: 245/500... Training loss: 0.0452\n",
      "Epoch: 246/500... Training loss: 0.1296\n",
      "Epoch: 246/500... Training loss: 0.0604\n",
      "Epoch: 246/500... Training loss: 0.0125\n",
      "Epoch: 246/500... Training loss: 0.1092\n",
      "Epoch: 246/500... Training loss: 0.2275\n",
      "Epoch: 246/500... Training loss: 0.1307\n",
      "Epoch: 246/500... Training loss: 0.0194\n",
      "Epoch: 246/500... Training loss: 0.0167\n",
      "Epoch: 246/500... Training loss: 0.0248\n",
      "Epoch: 246/500... Training loss: 0.0287\n",
      "Epoch: 246/500... Training loss: 0.0039\n",
      "Epoch: 246/500... Training loss: 0.0185\n",
      "Epoch: 246/500... Training loss: 0.0460\n",
      "Epoch: 246/500... Training loss: 0.0660\n",
      "Epoch: 246/500... Training loss: 0.0304\n",
      "Epoch: 246/500... Training loss: 0.0137\n",
      "Epoch: 246/500... Training loss: 0.0567\n",
      "Epoch: 246/500... Training loss: 0.0435\n",
      "Epoch: 246/500... Training loss: 0.0133\n",
      "Epoch: 246/500... Training loss: 0.0145\n",
      "Epoch: 246/500... Training loss: 0.0482\n",
      "Epoch: 246/500... Training loss: 0.0436\n",
      "Epoch: 246/500... Training loss: 0.0524\n",
      "Epoch: 246/500... Training loss: 0.0590\n",
      "Epoch: 246/500... Training loss: 0.1062\n",
      "Epoch: 246/500... Training loss: 0.0435\n",
      "Epoch: 246/500... Training loss: 0.0378\n",
      "Epoch: 246/500... Training loss: 0.0268\n",
      "Epoch: 246/500... Training loss: 0.0430\n",
      "Epoch: 246/500... Training loss: 0.0236\n",
      "Epoch: 246/500... Training loss: 0.0068\n",
      "Epoch: 247/500... Training loss: 0.0134\n",
      "Epoch: 247/500... Training loss: 0.0682\n",
      "Epoch: 247/500... Training loss: 0.0168\n",
      "Epoch: 247/500... Training loss: 0.0198\n",
      "Epoch: 247/500... Training loss: 0.0218\n",
      "Epoch: 247/500... Training loss: 0.0557\n",
      "Epoch: 247/500... Training loss: 0.0271\n",
      "Epoch: 247/500... Training loss: 0.0862\n",
      "Epoch: 247/500... Training loss: 0.0263\n",
      "Epoch: 247/500... Training loss: 0.0222\n",
      "Epoch: 247/500... Training loss: 0.0282\n",
      "Epoch: 247/500... Training loss: 0.0401\n",
      "Epoch: 247/500... Training loss: 0.0636\n",
      "Epoch: 247/500... Training loss: 0.0214\n",
      "Epoch: 247/500... Training loss: 0.0096\n",
      "Epoch: 247/500... Training loss: 0.0173\n",
      "Epoch: 247/500... Training loss: 0.0150\n",
      "Epoch: 247/500... Training loss: 0.0322\n",
      "Epoch: 247/500... Training loss: 0.0649\n",
      "Epoch: 247/500... Training loss: 0.0580\n",
      "Epoch: 247/500... Training loss: 0.0554\n",
      "Epoch: 247/500... Training loss: 0.0157\n",
      "Epoch: 247/500... Training loss: 0.0633\n",
      "Epoch: 247/500... Training loss: 0.1544\n",
      "Epoch: 247/500... Training loss: 0.0251\n",
      "Epoch: 247/500... Training loss: 0.1731\n",
      "Epoch: 247/500... Training loss: 0.0243\n",
      "Epoch: 247/500... Training loss: 0.0911\n",
      "Epoch: 247/500... Training loss: 0.0181\n",
      "Epoch: 247/500... Training loss: 0.0333\n",
      "Epoch: 247/500... Training loss: 0.0768\n",
      "Epoch: 248/500... Training loss: 0.1186\n",
      "Epoch: 248/500... Training loss: 0.0229\n",
      "Epoch: 248/500... Training loss: 0.0150\n",
      "Epoch: 248/500... Training loss: 0.0140\n",
      "Epoch: 248/500... Training loss: 0.0453\n",
      "Epoch: 248/500... Training loss: 0.0285\n",
      "Epoch: 248/500... Training loss: 0.0167\n",
      "Epoch: 248/500... Training loss: 0.0214\n",
      "Epoch: 248/500... Training loss: 0.0281\n",
      "Epoch: 248/500... Training loss: 0.0137\n",
      "Epoch: 248/500... Training loss: 0.0129\n",
      "Epoch: 248/500... Training loss: 0.0346\n",
      "Epoch: 248/500... Training loss: 0.0563\n",
      "Epoch: 248/500... Training loss: 0.0518\n",
      "Epoch: 248/500... Training loss: 0.0818\n",
      "Epoch: 248/500... Training loss: 0.0098\n",
      "Epoch: 248/500... Training loss: 0.0075\n",
      "Epoch: 248/500... Training loss: 0.0157\n",
      "Epoch: 248/500... Training loss: 0.0444\n",
      "Epoch: 248/500... Training loss: 0.0204\n",
      "Epoch: 248/500... Training loss: 0.0209\n",
      "Epoch: 248/500... Training loss: 0.0639\n",
      "Epoch: 248/500... Training loss: 0.0308\n",
      "Epoch: 248/500... Training loss: 0.1088\n",
      "Epoch: 248/500... Training loss: 0.0663\n",
      "Epoch: 248/500... Training loss: 0.0280\n",
      "Epoch: 248/500... Training loss: 0.0213\n",
      "Epoch: 248/500... Training loss: 0.0447\n",
      "Epoch: 248/500... Training loss: 0.0133\n",
      "Epoch: 248/500... Training loss: 0.0131\n",
      "Epoch: 248/500... Training loss: 0.0747\n",
      "Epoch: 249/500... Training loss: 0.0168\n",
      "Epoch: 249/500... Training loss: 0.0254\n",
      "Epoch: 249/500... Training loss: 0.0105\n",
      "Epoch: 249/500... Training loss: 0.0141\n",
      "Epoch: 249/500... Training loss: 0.0326\n",
      "Epoch: 249/500... Training loss: 0.0092\n",
      "Epoch: 249/500... Training loss: 0.0242\n",
      "Epoch: 249/500... Training loss: 0.0258\n",
      "Epoch: 249/500... Training loss: 0.0098\n",
      "Epoch: 249/500... Training loss: 0.0487\n",
      "Epoch: 249/500... Training loss: 0.0414\n",
      "Epoch: 249/500... Training loss: 0.1453\n",
      "Epoch: 249/500... Training loss: 0.0131\n",
      "Epoch: 249/500... Training loss: 0.0049\n",
      "Epoch: 249/500... Training loss: 0.0163\n",
      "Epoch: 249/500... Training loss: 0.0198\n",
      "Epoch: 249/500... Training loss: 0.1444\n",
      "Epoch: 249/500... Training loss: 0.0494\n",
      "Epoch: 249/500... Training loss: 0.0052\n",
      "Epoch: 249/500... Training loss: 0.0283\n",
      "Epoch: 249/500... Training loss: 0.0054\n",
      "Epoch: 249/500... Training loss: 0.0047\n",
      "Epoch: 249/500... Training loss: 0.0202\n",
      "Epoch: 249/500... Training loss: 0.0071\n",
      "Epoch: 249/500... Training loss: 0.0110\n",
      "Epoch: 249/500... Training loss: 0.0254\n",
      "Epoch: 249/500... Training loss: 0.0568\n",
      "Epoch: 249/500... Training loss: 0.0346\n",
      "Epoch: 249/500... Training loss: 0.0299\n",
      "Epoch: 249/500... Training loss: 0.0828\n",
      "Epoch: 249/500... Training loss: 0.0236\n",
      "Epoch: 250/500... Training loss: 0.0175\n",
      "Epoch: 250/500... Training loss: 0.0037\n",
      "Epoch: 250/500... Training loss: 0.0045\n",
      "Epoch: 250/500... Training loss: 0.0243\n",
      "Epoch: 250/500... Training loss: 0.0105\n",
      "Epoch: 250/500... Training loss: 0.0251\n",
      "Epoch: 250/500... Training loss: 0.0110\n",
      "Epoch: 250/500... Training loss: 0.1329\n",
      "Epoch: 250/500... Training loss: 0.0424\n",
      "Epoch: 250/500... Training loss: 0.0169\n",
      "Epoch: 250/500... Training loss: 0.0920\n",
      "Epoch: 250/500... Training loss: 0.0228\n",
      "Epoch: 250/500... Training loss: 0.0128\n",
      "Epoch: 250/500... Training loss: 0.0169\n",
      "Epoch: 250/500... Training loss: 0.0109\n",
      "Epoch: 250/500... Training loss: 0.0622\n",
      "Epoch: 250/500... Training loss: 0.0417\n",
      "Epoch: 250/500... Training loss: 0.0219\n",
      "Epoch: 250/500... Training loss: 0.1145\n",
      "Epoch: 250/500... Training loss: 0.0093\n",
      "Epoch: 250/500... Training loss: 0.0197\n",
      "Epoch: 250/500... Training loss: 0.0704\n",
      "Epoch: 250/500... Training loss: 0.0081\n",
      "Epoch: 250/500... Training loss: 0.0363\n",
      "Epoch: 250/500... Training loss: 0.0325\n",
      "Epoch: 250/500... Training loss: 0.0217\n",
      "Epoch: 250/500... Training loss: 0.0168\n",
      "Epoch: 250/500... Training loss: 0.0666\n",
      "Epoch: 250/500... Training loss: 0.0051\n",
      "Epoch: 250/500... Training loss: 0.0334\n",
      "Epoch: 250/500... Training loss: 0.0066\n",
      "Epoch: 251/500... Training loss: 0.0320\n",
      "Epoch: 251/500... Training loss: 0.0241\n",
      "Epoch: 251/500... Training loss: 0.0308\n",
      "Epoch: 251/500... Training loss: 0.0096\n",
      "Epoch: 251/500... Training loss: 0.0654\n",
      "Epoch: 251/500... Training loss: 0.0232\n",
      "Epoch: 251/500... Training loss: 0.1040\n",
      "Epoch: 251/500... Training loss: 0.0174\n",
      "Epoch: 251/500... Training loss: 0.0074\n",
      "Epoch: 251/500... Training loss: 0.0088\n",
      "Epoch: 251/500... Training loss: 0.0338\n",
      "Epoch: 251/500... Training loss: 0.0107\n",
      "Epoch: 251/500... Training loss: 0.0357\n",
      "Epoch: 251/500... Training loss: 0.0093\n",
      "Epoch: 251/500... Training loss: 0.0139\n",
      "Epoch: 251/500... Training loss: 0.0192\n",
      "Epoch: 251/500... Training loss: 0.0377\n",
      "Epoch: 251/500... Training loss: 0.0123\n",
      "Epoch: 251/500... Training loss: 0.0746\n",
      "Epoch: 251/500... Training loss: 0.0105\n",
      "Epoch: 251/500... Training loss: 0.0269\n",
      "Epoch: 251/500... Training loss: 0.0147\n",
      "Epoch: 251/500... Training loss: 0.0740\n",
      "Epoch: 251/500... Training loss: 0.0406\n",
      "Epoch: 251/500... Training loss: 0.0158\n",
      "Epoch: 251/500... Training loss: 0.0552\n",
      "Epoch: 251/500... Training loss: 0.0175\n",
      "Epoch: 251/500... Training loss: 0.0303\n",
      "Epoch: 251/500... Training loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251/500... Training loss: 0.0048\n",
      "Epoch: 251/500... Training loss: 0.0176\n",
      "Epoch: 252/500... Training loss: 0.0321\n",
      "Epoch: 252/500... Training loss: 0.0371\n",
      "Epoch: 252/500... Training loss: 0.0417\n",
      "Epoch: 252/500... Training loss: 0.0160\n",
      "Epoch: 252/500... Training loss: 0.0231\n",
      "Epoch: 252/500... Training loss: 0.0601\n",
      "Epoch: 252/500... Training loss: 0.0049\n",
      "Epoch: 252/500... Training loss: 0.0465\n",
      "Epoch: 252/500... Training loss: 0.0655\n",
      "Epoch: 252/500... Training loss: 0.0219\n",
      "Epoch: 252/500... Training loss: 0.0101\n",
      "Epoch: 252/500... Training loss: 0.0094\n",
      "Epoch: 252/500... Training loss: 0.0283\n",
      "Epoch: 252/500... Training loss: 0.0595\n",
      "Epoch: 252/500... Training loss: 0.0358\n",
      "Epoch: 252/500... Training loss: 0.0604\n",
      "Epoch: 252/500... Training loss: 0.0058\n",
      "Epoch: 252/500... Training loss: 0.0148\n",
      "Epoch: 252/500... Training loss: 0.1772\n",
      "Epoch: 252/500... Training loss: 0.0017\n",
      "Epoch: 252/500... Training loss: 0.0282\n",
      "Epoch: 252/500... Training loss: 0.0785\n",
      "Epoch: 252/500... Training loss: 0.0379\n",
      "Epoch: 252/500... Training loss: 0.0213\n",
      "Epoch: 252/500... Training loss: 0.0077\n",
      "Epoch: 252/500... Training loss: 0.0408\n",
      "Epoch: 252/500... Training loss: 0.0313\n",
      "Epoch: 252/500... Training loss: 0.0089\n",
      "Epoch: 252/500... Training loss: 0.0390\n",
      "Epoch: 252/500... Training loss: 0.0133\n",
      "Epoch: 252/500... Training loss: 0.0242\n",
      "Epoch: 253/500... Training loss: 0.0814\n",
      "Epoch: 253/500... Training loss: 0.0146\n",
      "Epoch: 253/500... Training loss: 0.0142\n",
      "Epoch: 253/500... Training loss: 0.0283\n",
      "Epoch: 253/500... Training loss: 0.0134\n",
      "Epoch: 253/500... Training loss: 0.0168\n",
      "Epoch: 253/500... Training loss: 0.0149\n",
      "Epoch: 253/500... Training loss: 0.0407\n",
      "Epoch: 253/500... Training loss: 0.0604\n",
      "Epoch: 253/500... Training loss: 0.0385\n",
      "Epoch: 253/500... Training loss: 0.0810\n",
      "Epoch: 253/500... Training loss: 0.0241\n",
      "Epoch: 253/500... Training loss: 0.0266\n",
      "Epoch: 253/500... Training loss: 0.0096\n",
      "Epoch: 253/500... Training loss: 0.0246\n",
      "Epoch: 253/500... Training loss: 0.0179\n",
      "Epoch: 253/500... Training loss: 0.0302\n",
      "Epoch: 253/500... Training loss: 0.0657\n",
      "Epoch: 253/500... Training loss: 0.0576\n",
      "Epoch: 253/500... Training loss: 0.0070\n",
      "Epoch: 253/500... Training loss: 0.0101\n",
      "Epoch: 253/500... Training loss: 0.0190\n",
      "Epoch: 253/500... Training loss: 0.0959\n",
      "Epoch: 253/500... Training loss: 0.0035\n",
      "Epoch: 253/500... Training loss: 0.0106\n",
      "Epoch: 253/500... Training loss: 0.0336\n",
      "Epoch: 253/500... Training loss: 0.0211\n",
      "Epoch: 253/500... Training loss: 0.1070\n",
      "Epoch: 253/500... Training loss: 0.0271\n",
      "Epoch: 253/500... Training loss: 0.0224\n",
      "Epoch: 253/500... Training loss: 0.0249\n",
      "Epoch: 254/500... Training loss: 0.0245\n",
      "Epoch: 254/500... Training loss: 0.0597\n",
      "Epoch: 254/500... Training loss: 0.0970\n",
      "Epoch: 254/500... Training loss: 0.1479\n",
      "Epoch: 254/500... Training loss: 0.0313\n",
      "Epoch: 254/500... Training loss: 0.0183\n",
      "Epoch: 254/500... Training loss: 0.1741\n",
      "Epoch: 254/500... Training loss: 0.0298\n",
      "Epoch: 254/500... Training loss: 0.1026\n",
      "Epoch: 254/500... Training loss: 0.0168\n",
      "Epoch: 254/500... Training loss: 0.0317\n",
      "Epoch: 254/500... Training loss: 0.0900\n",
      "Epoch: 254/500... Training loss: 0.0059\n",
      "Epoch: 254/500... Training loss: 0.0215\n",
      "Epoch: 254/500... Training loss: 0.0097\n",
      "Epoch: 254/500... Training loss: 0.0507\n",
      "Epoch: 254/500... Training loss: 0.0047\n",
      "Epoch: 254/500... Training loss: 0.0253\n",
      "Epoch: 254/500... Training loss: 0.0062\n",
      "Epoch: 254/500... Training loss: 0.0575\n",
      "Epoch: 254/500... Training loss: 0.0256\n",
      "Epoch: 254/500... Training loss: 0.0236\n",
      "Epoch: 254/500... Training loss: 0.0688\n",
      "Epoch: 254/500... Training loss: 0.0185\n",
      "Epoch: 254/500... Training loss: 0.0096\n",
      "Epoch: 254/500... Training loss: 0.0138\n",
      "Epoch: 254/500... Training loss: 0.0641\n",
      "Epoch: 254/500... Training loss: 0.0534\n",
      "Epoch: 254/500... Training loss: 0.0258\n",
      "Epoch: 254/500... Training loss: 0.0218\n",
      "Epoch: 254/500... Training loss: 0.0228\n",
      "Epoch: 255/500... Training loss: 0.0092\n",
      "Epoch: 255/500... Training loss: 0.0106\n",
      "Epoch: 255/500... Training loss: 0.0143\n",
      "Epoch: 255/500... Training loss: 0.0171\n",
      "Epoch: 255/500... Training loss: 0.0392\n",
      "Epoch: 255/500... Training loss: 0.0538\n",
      "Epoch: 255/500... Training loss: 0.0074\n",
      "Epoch: 255/500... Training loss: 0.0721\n",
      "Epoch: 255/500... Training loss: 0.0091\n",
      "Epoch: 255/500... Training loss: 0.0169\n",
      "Epoch: 255/500... Training loss: 0.0027\n",
      "Epoch: 255/500... Training loss: 0.0487\n",
      "Epoch: 255/500... Training loss: 0.1034\n",
      "Epoch: 255/500... Training loss: 0.1679\n",
      "Epoch: 255/500... Training loss: 0.0279\n",
      "Epoch: 255/500... Training loss: 0.0035\n",
      "Epoch: 255/500... Training loss: 0.0180\n",
      "Epoch: 255/500... Training loss: 0.0148\n",
      "Epoch: 255/500... Training loss: 0.0148\n",
      "Epoch: 255/500... Training loss: 0.0144\n",
      "Epoch: 255/500... Training loss: 0.0673\n",
      "Epoch: 255/500... Training loss: 0.0021\n",
      "Epoch: 255/500... Training loss: 0.0986\n",
      "Epoch: 255/500... Training loss: 0.0114\n",
      "Epoch: 255/500... Training loss: 0.0332\n",
      "Epoch: 255/500... Training loss: 0.0819\n",
      "Epoch: 255/500... Training loss: 0.0079\n",
      "Epoch: 255/500... Training loss: 0.0149\n",
      "Epoch: 255/500... Training loss: 0.0628\n",
      "Epoch: 255/500... Training loss: 0.0886\n",
      "Epoch: 255/500... Training loss: 0.0076\n",
      "Epoch: 256/500... Training loss: 0.0511\n",
      "Epoch: 256/500... Training loss: 0.0172\n",
      "Epoch: 256/500... Training loss: 0.0044\n",
      "Epoch: 256/500... Training loss: 0.0022\n",
      "Epoch: 256/500... Training loss: 0.0708\n",
      "Epoch: 256/500... Training loss: 0.0282\n",
      "Epoch: 256/500... Training loss: 0.0560\n",
      "Epoch: 256/500... Training loss: 0.0338\n",
      "Epoch: 256/500... Training loss: 0.0531\n",
      "Epoch: 256/500... Training loss: 0.0085\n",
      "Epoch: 256/500... Training loss: 0.0422\n",
      "Epoch: 256/500... Training loss: 0.0575\n",
      "Epoch: 256/500... Training loss: 0.0188\n",
      "Epoch: 256/500... Training loss: 0.1476\n",
      "Epoch: 256/500... Training loss: 0.0170\n",
      "Epoch: 256/500... Training loss: 0.0249\n",
      "Epoch: 256/500... Training loss: 0.0518\n",
      "Epoch: 256/500... Training loss: 0.0136\n",
      "Epoch: 256/500... Training loss: 0.0129\n",
      "Epoch: 256/500... Training loss: 0.1828\n",
      "Epoch: 256/500... Training loss: 0.1227\n",
      "Epoch: 256/500... Training loss: 0.0302\n",
      "Epoch: 256/500... Training loss: 0.0316\n",
      "Epoch: 256/500... Training loss: 0.0064\n",
      "Epoch: 256/500... Training loss: 0.0056\n",
      "Epoch: 256/500... Training loss: 0.0102\n",
      "Epoch: 256/500... Training loss: 0.0664\n",
      "Epoch: 256/500... Training loss: 0.0204\n",
      "Epoch: 256/500... Training loss: 0.0099\n",
      "Epoch: 256/500... Training loss: 0.0052\n",
      "Epoch: 256/500... Training loss: 0.0102\n",
      "Epoch: 257/500... Training loss: 0.0303\n",
      "Epoch: 257/500... Training loss: 0.0232\n",
      "Epoch: 257/500... Training loss: 0.0606\n",
      "Epoch: 257/500... Training loss: 0.0908\n",
      "Epoch: 257/500... Training loss: 0.0077\n",
      "Epoch: 257/500... Training loss: 0.0819\n",
      "Epoch: 257/500... Training loss: 0.0207\n",
      "Epoch: 257/500... Training loss: 0.0217\n",
      "Epoch: 257/500... Training loss: 0.0547\n",
      "Epoch: 257/500... Training loss: 0.0863\n",
      "Epoch: 257/500... Training loss: 0.0235\n",
      "Epoch: 257/500... Training loss: 0.0798\n",
      "Epoch: 257/500... Training loss: 0.0755\n",
      "Epoch: 257/500... Training loss: 0.0411\n",
      "Epoch: 257/500... Training loss: 0.0722\n",
      "Epoch: 257/500... Training loss: 0.0277\n",
      "Epoch: 257/500... Training loss: 0.0106\n",
      "Epoch: 257/500... Training loss: 0.0218\n",
      "Epoch: 257/500... Training loss: 0.0520\n",
      "Epoch: 257/500... Training loss: 0.0068\n",
      "Epoch: 257/500... Training loss: 0.0196\n",
      "Epoch: 257/500... Training loss: 0.0441\n",
      "Epoch: 257/500... Training loss: 0.0405\n",
      "Epoch: 257/500... Training loss: 0.0574\n",
      "Epoch: 257/500... Training loss: 0.0689\n",
      "Epoch: 257/500... Training loss: 0.0459\n",
      "Epoch: 257/500... Training loss: 0.0321\n",
      "Epoch: 257/500... Training loss: 0.0641\n",
      "Epoch: 257/500... Training loss: 0.1616\n",
      "Epoch: 257/500... Training loss: 0.0560\n",
      "Epoch: 257/500... Training loss: 0.0081\n",
      "Epoch: 258/500... Training loss: 0.0636\n",
      "Epoch: 258/500... Training loss: 0.0142\n",
      "Epoch: 258/500... Training loss: 0.2499\n",
      "Epoch: 258/500... Training loss: 0.0047\n",
      "Epoch: 258/500... Training loss: 0.0465\n",
      "Epoch: 258/500... Training loss: 0.0072\n",
      "Epoch: 258/500... Training loss: 0.0428\n",
      "Epoch: 258/500... Training loss: 0.0321\n",
      "Epoch: 258/500... Training loss: 0.0297\n",
      "Epoch: 258/500... Training loss: 0.0342\n",
      "Epoch: 258/500... Training loss: 0.0160\n",
      "Epoch: 258/500... Training loss: 0.0688\n",
      "Epoch: 258/500... Training loss: 0.0228\n",
      "Epoch: 258/500... Training loss: 0.0093\n",
      "Epoch: 258/500... Training loss: 0.0948\n",
      "Epoch: 258/500... Training loss: 0.0906\n",
      "Epoch: 258/500... Training loss: 0.0174\n",
      "Epoch: 258/500... Training loss: 0.0048\n",
      "Epoch: 258/500... Training loss: 0.0235\n",
      "Epoch: 258/500... Training loss: 0.0087\n",
      "Epoch: 258/500... Training loss: 0.0289\n",
      "Epoch: 258/500... Training loss: 0.0447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/500... Training loss: 0.0269\n",
      "Epoch: 258/500... Training loss: 0.0116\n",
      "Epoch: 258/500... Training loss: 0.0073\n",
      "Epoch: 258/500... Training loss: 0.0313\n",
      "Epoch: 258/500... Training loss: 0.0122\n",
      "Epoch: 258/500... Training loss: 0.0302\n",
      "Epoch: 258/500... Training loss: 0.0058\n",
      "Epoch: 258/500... Training loss: 0.0141\n",
      "Epoch: 258/500... Training loss: 0.0123\n",
      "Epoch: 259/500... Training loss: 0.0864\n",
      "Epoch: 259/500... Training loss: 0.0082\n",
      "Epoch: 259/500... Training loss: 0.0730\n",
      "Epoch: 259/500... Training loss: 0.0402\n",
      "Epoch: 259/500... Training loss: 0.0451\n",
      "Epoch: 259/500... Training loss: 0.1210\n",
      "Epoch: 259/500... Training loss: 0.0325\n",
      "Epoch: 259/500... Training loss: 0.0182\n",
      "Epoch: 259/500... Training loss: 0.0167\n",
      "Epoch: 259/500... Training loss: 0.0056\n",
      "Epoch: 259/500... Training loss: 0.0311\n",
      "Epoch: 259/500... Training loss: 0.0113\n",
      "Epoch: 259/500... Training loss: 0.0194\n",
      "Epoch: 259/500... Training loss: 0.0111\n",
      "Epoch: 259/500... Training loss: 0.0048\n",
      "Epoch: 259/500... Training loss: 0.0105\n",
      "Epoch: 259/500... Training loss: 0.0143\n",
      "Epoch: 259/500... Training loss: 0.0123\n",
      "Epoch: 259/500... Training loss: 0.0069\n",
      "Epoch: 259/500... Training loss: 0.0309\n",
      "Epoch: 259/500... Training loss: 0.0197\n",
      "Epoch: 259/500... Training loss: 0.0503\n",
      "Epoch: 259/500... Training loss: 0.0085\n",
      "Epoch: 259/500... Training loss: 0.0037\n",
      "Epoch: 259/500... Training loss: 0.0314\n",
      "Epoch: 259/500... Training loss: 0.0066\n",
      "Epoch: 259/500... Training loss: 0.0169\n",
      "Epoch: 259/500... Training loss: 0.0404\n",
      "Epoch: 259/500... Training loss: 0.0488\n",
      "Epoch: 259/500... Training loss: 0.0125\n",
      "Epoch: 259/500... Training loss: 0.0169\n",
      "Epoch: 260/500... Training loss: 0.1729\n",
      "Epoch: 260/500... Training loss: 0.0356\n",
      "Epoch: 260/500... Training loss: 0.0952\n",
      "Epoch: 260/500... Training loss: 0.0075\n",
      "Epoch: 260/500... Training loss: 0.0059\n",
      "Epoch: 260/500... Training loss: 0.0228\n",
      "Epoch: 260/500... Training loss: 0.0090\n",
      "Epoch: 260/500... Training loss: 0.0068\n",
      "Epoch: 260/500... Training loss: 0.0881\n",
      "Epoch: 260/500... Training loss: 0.0224\n",
      "Epoch: 260/500... Training loss: 0.0034\n",
      "Epoch: 260/500... Training loss: 0.0918\n",
      "Epoch: 260/500... Training loss: 0.1527\n",
      "Epoch: 260/500... Training loss: 0.0427\n",
      "Epoch: 260/500... Training loss: 0.0110\n",
      "Epoch: 260/500... Training loss: 0.0262\n",
      "Epoch: 260/500... Training loss: 0.0141\n",
      "Epoch: 260/500... Training loss: 0.0826\n",
      "Epoch: 260/500... Training loss: 0.0131\n",
      "Epoch: 260/500... Training loss: 0.0151\n",
      "Epoch: 260/500... Training loss: 0.0066\n",
      "Epoch: 260/500... Training loss: 0.0397\n",
      "Epoch: 260/500... Training loss: 0.0720\n",
      "Epoch: 260/500... Training loss: 0.0100\n",
      "Epoch: 260/500... Training loss: 0.0599\n",
      "Epoch: 260/500... Training loss: 0.1256\n",
      "Epoch: 260/500... Training loss: 0.0194\n",
      "Epoch: 260/500... Training loss: 0.0096\n",
      "Epoch: 260/500... Training loss: 0.0137\n",
      "Epoch: 260/500... Training loss: 0.0742\n",
      "Epoch: 260/500... Training loss: 0.0769\n",
      "Epoch: 261/500... Training loss: 0.1973\n",
      "Epoch: 261/500... Training loss: 0.0046\n",
      "Epoch: 261/500... Training loss: 0.0186\n",
      "Epoch: 261/500... Training loss: 0.0281\n",
      "Epoch: 261/500... Training loss: 0.0416\n",
      "Epoch: 261/500... Training loss: 0.0067\n",
      "Epoch: 261/500... Training loss: 0.0083\n",
      "Epoch: 261/500... Training loss: 0.1822\n",
      "Epoch: 261/500... Training loss: 0.0295\n",
      "Epoch: 261/500... Training loss: 0.0145\n",
      "Epoch: 261/500... Training loss: 0.0312\n",
      "Epoch: 261/500... Training loss: 0.0383\n",
      "Epoch: 261/500... Training loss: 0.0223\n",
      "Epoch: 261/500... Training loss: 0.0076\n",
      "Epoch: 261/500... Training loss: 0.0152\n",
      "Epoch: 261/500... Training loss: 0.0567\n",
      "Epoch: 261/500... Training loss: 0.0122\n",
      "Epoch: 261/500... Training loss: 0.0328\n",
      "Epoch: 261/500... Training loss: 0.0137\n",
      "Epoch: 261/500... Training loss: 0.0201\n",
      "Epoch: 261/500... Training loss: 0.0149\n",
      "Epoch: 261/500... Training loss: 0.0133\n",
      "Epoch: 261/500... Training loss: 0.0062\n",
      "Epoch: 261/500... Training loss: 0.0158\n",
      "Epoch: 261/500... Training loss: 0.0048\n",
      "Epoch: 261/500... Training loss: 0.0604\n",
      "Epoch: 261/500... Training loss: 0.0065\n",
      "Epoch: 261/500... Training loss: 0.0156\n",
      "Epoch: 261/500... Training loss: 0.0114\n",
      "Epoch: 261/500... Training loss: 0.0675\n",
      "Epoch: 261/500... Training loss: 0.0411\n",
      "Epoch: 262/500... Training loss: 0.0315\n",
      "Epoch: 262/500... Training loss: 0.0076\n",
      "Epoch: 262/500... Training loss: 0.0151\n",
      "Epoch: 262/500... Training loss: 0.0106\n",
      "Epoch: 262/500... Training loss: 0.1045\n",
      "Epoch: 262/500... Training loss: 0.0304\n",
      "Epoch: 262/500... Training loss: 0.0139\n",
      "Epoch: 262/500... Training loss: 0.0067\n",
      "Epoch: 262/500... Training loss: 0.0181\n",
      "Epoch: 262/500... Training loss: 0.0068\n",
      "Epoch: 262/500... Training loss: 0.0097\n",
      "Epoch: 262/500... Training loss: 0.0243\n",
      "Epoch: 262/500... Training loss: 0.0517\n",
      "Epoch: 262/500... Training loss: 0.0129\n",
      "Epoch: 262/500... Training loss: 0.0446\n",
      "Epoch: 262/500... Training loss: 0.0132\n",
      "Epoch: 262/500... Training loss: 0.0081\n",
      "Epoch: 262/500... Training loss: 0.0783\n",
      "Epoch: 262/500... Training loss: 0.0500\n",
      "Epoch: 262/500... Training loss: 0.0377\n",
      "Epoch: 262/500... Training loss: 0.0053\n",
      "Epoch: 262/500... Training loss: 0.0123\n",
      "Epoch: 262/500... Training loss: 0.0061\n",
      "Epoch: 262/500... Training loss: 0.0044\n",
      "Epoch: 262/500... Training loss: 0.0216\n",
      "Epoch: 262/500... Training loss: 0.0126\n",
      "Epoch: 262/500... Training loss: 0.1216\n",
      "Epoch: 262/500... Training loss: 0.0085\n",
      "Epoch: 262/500... Training loss: 0.0113\n",
      "Epoch: 262/500... Training loss: 0.0117\n",
      "Epoch: 262/500... Training loss: 0.1101\n",
      "Epoch: 263/500... Training loss: 0.0469\n",
      "Epoch: 263/500... Training loss: 0.0193\n",
      "Epoch: 263/500... Training loss: 0.0192\n",
      "Epoch: 263/500... Training loss: 0.0173\n",
      "Epoch: 263/500... Training loss: 0.0025\n",
      "Epoch: 263/500... Training loss: 0.0265\n",
      "Epoch: 263/500... Training loss: 0.0209\n",
      "Epoch: 263/500... Training loss: 0.0536\n",
      "Epoch: 263/500... Training loss: 0.1376\n",
      "Epoch: 263/500... Training loss: 0.0588\n",
      "Epoch: 263/500... Training loss: 0.0602\n",
      "Epoch: 263/500... Training loss: 0.1057\n",
      "Epoch: 263/500... Training loss: 0.0723\n",
      "Epoch: 263/500... Training loss: 0.0243\n",
      "Epoch: 263/500... Training loss: 0.0108\n",
      "Epoch: 263/500... Training loss: 0.0110\n",
      "Epoch: 263/500... Training loss: 0.0445\n",
      "Epoch: 263/500... Training loss: 0.0095\n",
      "Epoch: 263/500... Training loss: 0.0839\n",
      "Epoch: 263/500... Training loss: 0.0140\n",
      "Epoch: 263/500... Training loss: 0.0190\n",
      "Epoch: 263/500... Training loss: 0.1051\n",
      "Epoch: 263/500... Training loss: 0.0353\n",
      "Epoch: 263/500... Training loss: 0.0241\n",
      "Epoch: 263/500... Training loss: 0.0200\n",
      "Epoch: 263/500... Training loss: 0.0090\n",
      "Epoch: 263/500... Training loss: 0.0079\n",
      "Epoch: 263/500... Training loss: 0.0442\n",
      "Epoch: 263/500... Training loss: 0.0037\n",
      "Epoch: 263/500... Training loss: 0.0627\n",
      "Epoch: 263/500... Training loss: 0.0055\n",
      "Epoch: 264/500... Training loss: 0.0719\n",
      "Epoch: 264/500... Training loss: 0.0134\n",
      "Epoch: 264/500... Training loss: 0.0353\n",
      "Epoch: 264/500... Training loss: 0.0104\n",
      "Epoch: 264/500... Training loss: 0.0069\n",
      "Epoch: 264/500... Training loss: 0.0466\n",
      "Epoch: 264/500... Training loss: 0.1104\n",
      "Epoch: 264/500... Training loss: 0.0187\n",
      "Epoch: 264/500... Training loss: 0.0243\n",
      "Epoch: 264/500... Training loss: 0.0188\n",
      "Epoch: 264/500... Training loss: 0.0392\n",
      "Epoch: 264/500... Training loss: 0.0959\n",
      "Epoch: 264/500... Training loss: 0.0306\n",
      "Epoch: 264/500... Training loss: 0.0041\n",
      "Epoch: 264/500... Training loss: 0.0191\n",
      "Epoch: 264/500... Training loss: 0.0214\n",
      "Epoch: 264/500... Training loss: 0.0049\n",
      "Epoch: 264/500... Training loss: 0.0036\n",
      "Epoch: 264/500... Training loss: 0.0097\n",
      "Epoch: 264/500... Training loss: 0.0145\n",
      "Epoch: 264/500... Training loss: 0.0319\n",
      "Epoch: 264/500... Training loss: 0.0711\n",
      "Epoch: 264/500... Training loss: 0.0105\n",
      "Epoch: 264/500... Training loss: 0.0098\n",
      "Epoch: 264/500... Training loss: 0.0661\n",
      "Epoch: 264/500... Training loss: 0.1121\n",
      "Epoch: 264/500... Training loss: 0.0712\n",
      "Epoch: 264/500... Training loss: 0.0171\n",
      "Epoch: 264/500... Training loss: 0.0136\n",
      "Epoch: 264/500... Training loss: 0.0183\n",
      "Epoch: 264/500... Training loss: 0.0531\n",
      "Epoch: 265/500... Training loss: 0.0078\n",
      "Epoch: 265/500... Training loss: 0.0473\n",
      "Epoch: 265/500... Training loss: 0.0405\n",
      "Epoch: 265/500... Training loss: 0.0954\n",
      "Epoch: 265/500... Training loss: 0.0180\n",
      "Epoch: 265/500... Training loss: 0.0296\n",
      "Epoch: 265/500... Training loss: 0.0321\n",
      "Epoch: 265/500... Training loss: 0.0174\n",
      "Epoch: 265/500... Training loss: 0.0172\n",
      "Epoch: 265/500... Training loss: 0.0382\n",
      "Epoch: 265/500... Training loss: 0.0480\n",
      "Epoch: 265/500... Training loss: 0.0149\n",
      "Epoch: 265/500... Training loss: 0.0177\n",
      "Epoch: 265/500... Training loss: 0.0109\n",
      "Epoch: 265/500... Training loss: 0.0225\n",
      "Epoch: 265/500... Training loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 265/500... Training loss: 0.0419\n",
      "Epoch: 265/500... Training loss: 0.0141\n",
      "Epoch: 265/500... Training loss: 0.0152\n",
      "Epoch: 265/500... Training loss: 0.0062\n",
      "Epoch: 265/500... Training loss: 0.0065\n",
      "Epoch: 265/500... Training loss: 0.0073\n",
      "Epoch: 265/500... Training loss: 0.0074\n",
      "Epoch: 265/500... Training loss: 0.0087\n",
      "Epoch: 265/500... Training loss: 0.0249\n",
      "Epoch: 265/500... Training loss: 0.0811\n",
      "Epoch: 265/500... Training loss: 0.0953\n",
      "Epoch: 265/500... Training loss: 0.0799\n",
      "Epoch: 265/500... Training loss: 0.0106\n",
      "Epoch: 265/500... Training loss: 0.0141\n",
      "Epoch: 265/500... Training loss: 0.0205\n",
      "Epoch: 266/500... Training loss: 0.0573\n",
      "Epoch: 266/500... Training loss: 0.0187\n",
      "Epoch: 266/500... Training loss: 0.0069\n",
      "Epoch: 266/500... Training loss: 0.0440\n",
      "Epoch: 266/500... Training loss: 0.0129\n",
      "Epoch: 266/500... Training loss: 0.0272\n",
      "Epoch: 266/500... Training loss: 0.0560\n",
      "Epoch: 266/500... Training loss: 0.0711\n",
      "Epoch: 266/500... Training loss: 0.0094\n",
      "Epoch: 266/500... Training loss: 0.0477\n",
      "Epoch: 266/500... Training loss: 0.0137\n",
      "Epoch: 266/500... Training loss: 0.0501\n",
      "Epoch: 266/500... Training loss: 0.0681\n",
      "Epoch: 266/500... Training loss: 0.0716\n",
      "Epoch: 266/500... Training loss: 0.0290\n",
      "Epoch: 266/500... Training loss: 0.0067\n",
      "Epoch: 266/500... Training loss: 0.0319\n",
      "Epoch: 266/500... Training loss: 0.0091\n",
      "Epoch: 266/500... Training loss: 0.0049\n",
      "Epoch: 266/500... Training loss: 0.0166\n",
      "Epoch: 266/500... Training loss: 0.0361\n",
      "Epoch: 266/500... Training loss: 0.0535\n",
      "Epoch: 266/500... Training loss: 0.0323\n",
      "Epoch: 266/500... Training loss: 0.0303\n",
      "Epoch: 266/500... Training loss: 0.0528\n",
      "Epoch: 266/500... Training loss: 0.0073\n",
      "Epoch: 266/500... Training loss: 0.0459\n",
      "Epoch: 266/500... Training loss: 0.2250\n",
      "Epoch: 266/500... Training loss: 0.0030\n",
      "Epoch: 266/500... Training loss: 0.0308\n",
      "Epoch: 266/500... Training loss: 0.0043\n",
      "Epoch: 267/500... Training loss: 0.1215\n",
      "Epoch: 267/500... Training loss: 0.0275\n",
      "Epoch: 267/500... Training loss: 0.0253\n",
      "Epoch: 267/500... Training loss: 0.0495\n",
      "Epoch: 267/500... Training loss: 0.0113\n",
      "Epoch: 267/500... Training loss: 0.0069\n",
      "Epoch: 267/500... Training loss: 0.0188\n",
      "Epoch: 267/500... Training loss: 0.1717\n",
      "Epoch: 267/500... Training loss: 0.0127\n",
      "Epoch: 267/500... Training loss: 0.0071\n",
      "Epoch: 267/500... Training loss: 0.0105\n",
      "Epoch: 267/500... Training loss: 0.0318\n",
      "Epoch: 267/500... Training loss: 0.0135\n",
      "Epoch: 267/500... Training loss: 0.0704\n",
      "Epoch: 267/500... Training loss: 0.0131\n",
      "Epoch: 267/500... Training loss: 0.0079\n",
      "Epoch: 267/500... Training loss: 0.0226\n",
      "Epoch: 267/500... Training loss: 0.0082\n",
      "Epoch: 267/500... Training loss: 0.0132\n",
      "Epoch: 267/500... Training loss: 0.0054\n",
      "Epoch: 267/500... Training loss: 0.0034\n",
      "Epoch: 267/500... Training loss: 0.0141\n",
      "Epoch: 267/500... Training loss: 0.0049\n",
      "Epoch: 267/500... Training loss: 0.0532\n",
      "Epoch: 267/500... Training loss: 0.0049\n",
      "Epoch: 267/500... Training loss: 0.0442\n",
      "Epoch: 267/500... Training loss: 0.0081\n",
      "Epoch: 267/500... Training loss: 0.0514\n",
      "Epoch: 267/500... Training loss: 0.0047\n",
      "Epoch: 267/500... Training loss: 0.0610\n",
      "Epoch: 267/500... Training loss: 0.0231\n",
      "Epoch: 268/500... Training loss: 0.0172\n",
      "Epoch: 268/500... Training loss: 0.0423\n",
      "Epoch: 268/500... Training loss: 0.0208\n",
      "Epoch: 268/500... Training loss: 0.0080\n",
      "Epoch: 268/500... Training loss: 0.0028\n",
      "Epoch: 268/500... Training loss: 0.0161\n",
      "Epoch: 268/500... Training loss: 0.0133\n",
      "Epoch: 268/500... Training loss: 0.0125\n",
      "Epoch: 268/500... Training loss: 0.1996\n",
      "Epoch: 268/500... Training loss: 0.0154\n",
      "Epoch: 268/500... Training loss: 0.0102\n",
      "Epoch: 268/500... Training loss: 0.0079\n",
      "Epoch: 268/500... Training loss: 0.0697\n",
      "Epoch: 268/500... Training loss: 0.0219\n",
      "Epoch: 268/500... Training loss: 0.0882\n",
      "Epoch: 268/500... Training loss: 0.0056\n",
      "Epoch: 268/500... Training loss: 0.0598\n",
      "Epoch: 268/500... Training loss: 0.0382\n",
      "Epoch: 268/500... Training loss: 0.0099\n",
      "Epoch: 268/500... Training loss: 0.0052\n",
      "Epoch: 268/500... Training loss: 0.0094\n",
      "Epoch: 268/500... Training loss: 0.0110\n",
      "Epoch: 268/500... Training loss: 0.0157\n",
      "Epoch: 268/500... Training loss: 0.1326\n",
      "Epoch: 268/500... Training loss: 0.0136\n",
      "Epoch: 268/500... Training loss: 0.0199\n",
      "Epoch: 268/500... Training loss: 0.0183\n",
      "Epoch: 268/500... Training loss: 0.0074\n",
      "Epoch: 268/500... Training loss: 0.0146\n",
      "Epoch: 268/500... Training loss: 0.0207\n",
      "Epoch: 268/500... Training loss: 0.0052\n",
      "Epoch: 269/500... Training loss: 0.0265\n",
      "Epoch: 269/500... Training loss: 0.0224\n",
      "Epoch: 269/500... Training loss: 0.0246\n",
      "Epoch: 269/500... Training loss: 0.0068\n",
      "Epoch: 269/500... Training loss: 0.0280\n",
      "Epoch: 269/500... Training loss: 0.0233\n",
      "Epoch: 269/500... Training loss: 0.0035\n",
      "Epoch: 269/500... Training loss: 0.0095\n",
      "Epoch: 269/500... Training loss: 0.0254\n",
      "Epoch: 269/500... Training loss: 0.1036\n",
      "Epoch: 269/500... Training loss: 0.0301\n",
      "Epoch: 269/500... Training loss: 0.0037\n",
      "Epoch: 269/500... Training loss: 0.1110\n",
      "Epoch: 269/500... Training loss: 0.0615\n",
      "Epoch: 269/500... Training loss: 0.0124\n",
      "Epoch: 269/500... Training loss: 0.0046\n",
      "Epoch: 269/500... Training loss: 0.0302\n",
      "Epoch: 269/500... Training loss: 0.0651\n",
      "Epoch: 269/500... Training loss: 0.0128\n",
      "Epoch: 269/500... Training loss: 0.0280\n",
      "Epoch: 269/500... Training loss: 0.0137\n",
      "Epoch: 269/500... Training loss: 0.0458\n",
      "Epoch: 269/500... Training loss: 0.0154\n",
      "Epoch: 269/500... Training loss: 0.0129\n",
      "Epoch: 269/500... Training loss: 0.0149\n",
      "Epoch: 269/500... Training loss: 0.0818\n",
      "Epoch: 269/500... Training loss: 0.0488\n",
      "Epoch: 269/500... Training loss: 0.0129\n",
      "Epoch: 269/500... Training loss: 0.0845\n",
      "Epoch: 269/500... Training loss: 0.0118\n",
      "Epoch: 269/500... Training loss: 0.0083\n",
      "Epoch: 270/500... Training loss: 0.0654\n",
      "Epoch: 270/500... Training loss: 0.0061\n",
      "Epoch: 270/500... Training loss: 0.0753\n",
      "Epoch: 270/500... Training loss: 0.0502\n",
      "Epoch: 270/500... Training loss: 0.0071\n",
      "Epoch: 270/500... Training loss: 0.0178\n",
      "Epoch: 270/500... Training loss: 0.0419\n",
      "Epoch: 270/500... Training loss: 0.0193\n",
      "Epoch: 270/500... Training loss: 0.0226\n",
      "Epoch: 270/500... Training loss: 0.0494\n",
      "Epoch: 270/500... Training loss: 0.0442\n",
      "Epoch: 270/500... Training loss: 0.0848\n",
      "Epoch: 270/500... Training loss: 0.1759\n",
      "Epoch: 270/500... Training loss: 0.0111\n",
      "Epoch: 270/500... Training loss: 0.0150\n",
      "Epoch: 270/500... Training loss: 0.0298\n",
      "Epoch: 270/500... Training loss: 0.0242\n",
      "Epoch: 270/500... Training loss: 0.0236\n",
      "Epoch: 270/500... Training loss: 0.0256\n",
      "Epoch: 270/500... Training loss: 0.0129\n",
      "Epoch: 270/500... Training loss: 0.0470\n",
      "Epoch: 270/500... Training loss: 0.0416\n",
      "Epoch: 270/500... Training loss: 0.0507\n",
      "Epoch: 270/500... Training loss: 0.0818\n",
      "Epoch: 270/500... Training loss: 0.0080\n",
      "Epoch: 270/500... Training loss: 0.0216\n",
      "Epoch: 270/500... Training loss: 0.0684\n",
      "Epoch: 270/500... Training loss: 0.0284\n",
      "Epoch: 270/500... Training loss: 0.0174\n",
      "Epoch: 270/500... Training loss: 0.0131\n",
      "Epoch: 270/500... Training loss: 0.0153\n",
      "Epoch: 271/500... Training loss: 0.0246\n",
      "Epoch: 271/500... Training loss: 0.1400\n",
      "Epoch: 271/500... Training loss: 0.0174\n",
      "Epoch: 271/500... Training loss: 0.0188\n",
      "Epoch: 271/500... Training loss: 0.0414\n",
      "Epoch: 271/500... Training loss: 0.0242\n",
      "Epoch: 271/500... Training loss: 0.0367\n",
      "Epoch: 271/500... Training loss: 0.0071\n",
      "Epoch: 271/500... Training loss: 0.0331\n",
      "Epoch: 271/500... Training loss: 0.2100\n",
      "Epoch: 271/500... Training loss: 0.0129\n",
      "Epoch: 271/500... Training loss: 0.0042\n",
      "Epoch: 271/500... Training loss: 0.0721\n",
      "Epoch: 271/500... Training loss: 0.0123\n",
      "Epoch: 271/500... Training loss: 0.0199\n",
      "Epoch: 271/500... Training loss: 0.0059\n",
      "Epoch: 271/500... Training loss: 0.0362\n",
      "Epoch: 271/500... Training loss: 0.0656\n",
      "Epoch: 271/500... Training loss: 0.0208\n",
      "Epoch: 271/500... Training loss: 0.0450\n",
      "Epoch: 271/500... Training loss: 0.0275\n",
      "Epoch: 271/500... Training loss: 0.0755\n",
      "Epoch: 271/500... Training loss: 0.0252\n",
      "Epoch: 271/500... Training loss: 0.0384\n",
      "Epoch: 271/500... Training loss: 0.0179\n",
      "Epoch: 271/500... Training loss: 0.0099\n",
      "Epoch: 271/500... Training loss: 0.0063\n",
      "Epoch: 271/500... Training loss: 0.0114\n",
      "Epoch: 271/500... Training loss: 0.0039\n",
      "Epoch: 271/500... Training loss: 0.0425\n",
      "Epoch: 271/500... Training loss: 0.0120\n",
      "Epoch: 272/500... Training loss: 0.0212\n",
      "Epoch: 272/500... Training loss: 0.0079\n",
      "Epoch: 272/500... Training loss: 0.0249\n",
      "Epoch: 272/500... Training loss: 0.0321\n",
      "Epoch: 272/500... Training loss: 0.0070\n",
      "Epoch: 272/500... Training loss: 0.1172\n",
      "Epoch: 272/500... Training loss: 0.0563\n",
      "Epoch: 272/500... Training loss: 0.0510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 272/500... Training loss: 0.0298\n",
      "Epoch: 272/500... Training loss: 0.0157\n",
      "Epoch: 272/500... Training loss: 0.0282\n",
      "Epoch: 272/500... Training loss: 0.0192\n",
      "Epoch: 272/500... Training loss: 0.0310\n",
      "Epoch: 272/500... Training loss: 0.0371\n",
      "Epoch: 272/500... Training loss: 0.0073\n",
      "Epoch: 272/500... Training loss: 0.0049\n",
      "Epoch: 272/500... Training loss: 0.0143\n",
      "Epoch: 272/500... Training loss: 0.0054\n",
      "Epoch: 272/500... Training loss: 0.0508\n",
      "Epoch: 272/500... Training loss: 0.0110\n",
      "Epoch: 272/500... Training loss: 0.0069\n",
      "Epoch: 272/500... Training loss: 0.0255\n",
      "Epoch: 272/500... Training loss: 0.0140\n",
      "Epoch: 272/500... Training loss: 0.0761\n",
      "Epoch: 272/500... Training loss: 0.0031\n",
      "Epoch: 272/500... Training loss: 0.0189\n",
      "Epoch: 272/500... Training loss: 0.0424\n",
      "Epoch: 272/500... Training loss: 0.0512\n",
      "Epoch: 272/500... Training loss: 0.0328\n",
      "Epoch: 272/500... Training loss: 0.0241\n",
      "Epoch: 272/500... Training loss: 0.0197\n",
      "Epoch: 273/500... Training loss: 0.0367\n",
      "Epoch: 273/500... Training loss: 0.0149\n",
      "Epoch: 273/500... Training loss: 0.1179\n",
      "Epoch: 273/500... Training loss: 0.0046\n",
      "Epoch: 273/500... Training loss: 0.0061\n",
      "Epoch: 273/500... Training loss: 0.0181\n",
      "Epoch: 273/500... Training loss: 0.1046\n",
      "Epoch: 273/500... Training loss: 0.0106\n",
      "Epoch: 273/500... Training loss: 0.0058\n",
      "Epoch: 273/500... Training loss: 0.0669\n",
      "Epoch: 273/500... Training loss: 0.0088\n",
      "Epoch: 273/500... Training loss: 0.0129\n",
      "Epoch: 273/500... Training loss: 0.0235\n",
      "Epoch: 273/500... Training loss: 0.0245\n",
      "Epoch: 273/500... Training loss: 0.0103\n",
      "Epoch: 273/500... Training loss: 0.0160\n",
      "Epoch: 273/500... Training loss: 0.0160\n",
      "Epoch: 273/500... Training loss: 0.0314\n",
      "Epoch: 273/500... Training loss: 0.0251\n",
      "Epoch: 273/500... Training loss: 0.0023\n",
      "Epoch: 273/500... Training loss: 0.0109\n",
      "Epoch: 273/500... Training loss: 0.0019\n",
      "Epoch: 273/500... Training loss: 0.0448\n",
      "Epoch: 273/500... Training loss: 0.0667\n",
      "Epoch: 273/500... Training loss: 0.0028\n",
      "Epoch: 273/500... Training loss: 0.0794\n",
      "Epoch: 273/500... Training loss: 0.0113\n",
      "Epoch: 273/500... Training loss: 0.0121\n",
      "Epoch: 273/500... Training loss: 0.0143\n",
      "Epoch: 273/500... Training loss: 0.0116\n",
      "Epoch: 273/500... Training loss: 0.0085\n",
      "Epoch: 274/500... Training loss: 0.0209\n",
      "Epoch: 274/500... Training loss: 0.0337\n",
      "Epoch: 274/500... Training loss: 0.0446\n",
      "Epoch: 274/500... Training loss: 0.0108\n",
      "Epoch: 274/500... Training loss: 0.0160\n",
      "Epoch: 274/500... Training loss: 0.0433\n",
      "Epoch: 274/500... Training loss: 0.0442\n",
      "Epoch: 274/500... Training loss: 0.0071\n",
      "Epoch: 274/500... Training loss: 0.0295\n",
      "Epoch: 274/500... Training loss: 0.0842\n",
      "Epoch: 274/500... Training loss: 0.0053\n",
      "Epoch: 274/500... Training loss: 0.1079\n",
      "Epoch: 274/500... Training loss: 0.0477\n",
      "Epoch: 274/500... Training loss: 0.0518\n",
      "Epoch: 274/500... Training loss: 0.0521\n",
      "Epoch: 274/500... Training loss: 0.0336\n",
      "Epoch: 274/500... Training loss: 0.0606\n",
      "Epoch: 274/500... Training loss: 0.0055\n",
      "Epoch: 274/500... Training loss: 0.0446\n",
      "Epoch: 274/500... Training loss: 0.0096\n",
      "Epoch: 274/500... Training loss: 0.0059\n",
      "Epoch: 274/500... Training loss: 0.0649\n",
      "Epoch: 274/500... Training loss: 0.0093\n",
      "Epoch: 274/500... Training loss: 0.0068\n",
      "Epoch: 274/500... Training loss: 0.0063\n",
      "Epoch: 274/500... Training loss: 0.0290\n",
      "Epoch: 274/500... Training loss: 0.0107\n",
      "Epoch: 274/500... Training loss: 0.0622\n",
      "Epoch: 274/500... Training loss: 0.0065\n",
      "Epoch: 274/500... Training loss: 0.0466\n",
      "Epoch: 274/500... Training loss: 0.0063\n",
      "Epoch: 275/500... Training loss: 0.0106\n",
      "Epoch: 275/500... Training loss: 0.0098\n",
      "Epoch: 275/500... Training loss: 0.0402\n",
      "Epoch: 275/500... Training loss: 0.0220\n",
      "Epoch: 275/500... Training loss: 0.0052\n",
      "Epoch: 275/500... Training loss: 0.0076\n",
      "Epoch: 275/500... Training loss: 0.0752\n",
      "Epoch: 275/500... Training loss: 0.0931\n",
      "Epoch: 275/500... Training loss: 0.0867\n",
      "Epoch: 275/500... Training loss: 0.0597\n",
      "Epoch: 275/500... Training loss: 0.0408\n",
      "Epoch: 275/500... Training loss: 0.0346\n",
      "Epoch: 275/500... Training loss: 0.0214\n",
      "Epoch: 275/500... Training loss: 0.0069\n",
      "Epoch: 275/500... Training loss: 0.0415\n",
      "Epoch: 275/500... Training loss: 0.0391\n",
      "Epoch: 275/500... Training loss: 0.0067\n",
      "Epoch: 275/500... Training loss: 0.0239\n",
      "Epoch: 275/500... Training loss: 0.0767\n",
      "Epoch: 275/500... Training loss: 0.0337\n",
      "Epoch: 275/500... Training loss: 0.0060\n",
      "Epoch: 275/500... Training loss: 0.1599\n",
      "Epoch: 275/500... Training loss: 0.0203\n",
      "Epoch: 275/500... Training loss: 0.0249\n",
      "Epoch: 275/500... Training loss: 0.0144\n",
      "Epoch: 275/500... Training loss: 0.0207\n",
      "Epoch: 275/500... Training loss: 0.0093\n",
      "Epoch: 275/500... Training loss: 0.0141\n",
      "Epoch: 275/500... Training loss: 0.0086\n",
      "Epoch: 275/500... Training loss: 0.0062\n",
      "Epoch: 275/500... Training loss: 0.0285\n",
      "Epoch: 276/500... Training loss: 0.0037\n",
      "Epoch: 276/500... Training loss: 0.0095\n",
      "Epoch: 276/500... Training loss: 0.0135\n",
      "Epoch: 276/500... Training loss: 0.0450\n",
      "Epoch: 276/500... Training loss: 0.0094\n",
      "Epoch: 276/500... Training loss: 0.0408\n",
      "Epoch: 276/500... Training loss: 0.0157\n",
      "Epoch: 276/500... Training loss: 0.0663\n",
      "Epoch: 276/500... Training loss: 0.1080\n",
      "Epoch: 276/500... Training loss: 0.0294\n",
      "Epoch: 276/500... Training loss: 0.0099\n",
      "Epoch: 276/500... Training loss: 0.0397\n",
      "Epoch: 276/500... Training loss: 0.0680\n",
      "Epoch: 276/500... Training loss: 0.0120\n",
      "Epoch: 276/500... Training loss: 0.0220\n",
      "Epoch: 276/500... Training loss: 0.0097\n",
      "Epoch: 276/500... Training loss: 0.0024\n",
      "Epoch: 276/500... Training loss: 0.0043\n",
      "Epoch: 276/500... Training loss: 0.0276\n",
      "Epoch: 276/500... Training loss: 0.0096\n",
      "Epoch: 276/500... Training loss: 0.0181\n",
      "Epoch: 276/500... Training loss: 0.0054\n",
      "Epoch: 276/500... Training loss: 0.0388\n",
      "Epoch: 276/500... Training loss: 0.0229\n",
      "Epoch: 276/500... Training loss: 0.0181\n",
      "Epoch: 276/500... Training loss: 0.0084\n",
      "Epoch: 276/500... Training loss: 0.0687\n",
      "Epoch: 276/500... Training loss: 0.0161\n",
      "Epoch: 276/500... Training loss: 0.0073\n",
      "Epoch: 276/500... Training loss: 0.0619\n",
      "Epoch: 276/500... Training loss: 0.0091\n",
      "Epoch: 277/500... Training loss: 0.0348\n",
      "Epoch: 277/500... Training loss: 0.0089\n",
      "Epoch: 277/500... Training loss: 0.0982\n",
      "Epoch: 277/500... Training loss: 0.0270\n",
      "Epoch: 277/500... Training loss: 0.0805\n",
      "Epoch: 277/500... Training loss: 0.0081\n",
      "Epoch: 277/500... Training loss: 0.0637\n",
      "Epoch: 277/500... Training loss: 0.0128\n",
      "Epoch: 277/500... Training loss: 0.0095\n",
      "Epoch: 277/500... Training loss: 0.1369\n",
      "Epoch: 277/500... Training loss: 0.0041\n",
      "Epoch: 277/500... Training loss: 0.0770\n",
      "Epoch: 277/500... Training loss: 0.0084\n",
      "Epoch: 277/500... Training loss: 0.0093\n",
      "Epoch: 277/500... Training loss: 0.0118\n",
      "Epoch: 277/500... Training loss: 0.0102\n",
      "Epoch: 277/500... Training loss: 0.0351\n",
      "Epoch: 277/500... Training loss: 0.0054\n",
      "Epoch: 277/500... Training loss: 0.0304\n",
      "Epoch: 277/500... Training loss: 0.0138\n",
      "Epoch: 277/500... Training loss: 0.0025\n",
      "Epoch: 277/500... Training loss: 0.0047\n",
      "Epoch: 277/500... Training loss: 0.0163\n",
      "Epoch: 277/500... Training loss: 0.0045\n",
      "Epoch: 277/500... Training loss: 0.0319\n",
      "Epoch: 277/500... Training loss: 0.0741\n",
      "Epoch: 277/500... Training loss: 0.0139\n",
      "Epoch: 277/500... Training loss: 0.0425\n",
      "Epoch: 277/500... Training loss: 0.0023\n",
      "Epoch: 277/500... Training loss: 0.0045\n",
      "Epoch: 277/500... Training loss: 0.0023\n",
      "Epoch: 278/500... Training loss: 0.0138\n",
      "Epoch: 278/500... Training loss: 0.0095\n",
      "Epoch: 278/500... Training loss: 0.0122\n",
      "Epoch: 278/500... Training loss: 0.0069\n",
      "Epoch: 278/500... Training loss: 0.0709\n",
      "Epoch: 278/500... Training loss: 0.0113\n",
      "Epoch: 278/500... Training loss: 0.0190\n",
      "Epoch: 278/500... Training loss: 0.0300\n",
      "Epoch: 278/500... Training loss: 0.0054\n",
      "Epoch: 278/500... Training loss: 0.0764\n",
      "Epoch: 278/500... Training loss: 0.0238\n",
      "Epoch: 278/500... Training loss: 0.0220\n",
      "Epoch: 278/500... Training loss: 0.0040\n",
      "Epoch: 278/500... Training loss: 0.0665\n",
      "Epoch: 278/500... Training loss: 0.0386\n",
      "Epoch: 278/500... Training loss: 0.0019\n",
      "Epoch: 278/500... Training loss: 0.0171\n",
      "Epoch: 278/500... Training loss: 0.0019\n",
      "Epoch: 278/500... Training loss: 0.0402\n",
      "Epoch: 278/500... Training loss: 0.0069\n",
      "Epoch: 278/500... Training loss: 0.0227\n",
      "Epoch: 278/500... Training loss: 0.0017\n",
      "Epoch: 278/500... Training loss: 0.0580\n",
      "Epoch: 278/500... Training loss: 0.0242\n",
      "Epoch: 278/500... Training loss: 0.0030\n",
      "Epoch: 278/500... Training loss: 0.0029\n",
      "Epoch: 278/500... Training loss: 0.0045\n",
      "Epoch: 278/500... Training loss: 0.0257\n",
      "Epoch: 278/500... Training loss: 0.0102\n",
      "Epoch: 278/500... Training loss: 0.0036\n",
      "Epoch: 278/500... Training loss: 0.0046\n",
      "Epoch: 279/500... Training loss: 0.0358\n",
      "Epoch: 279/500... Training loss: 0.0129\n",
      "Epoch: 279/500... Training loss: 0.0882\n",
      "Epoch: 279/500... Training loss: 0.2264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 279/500... Training loss: 0.0467\n",
      "Epoch: 279/500... Training loss: 0.0064\n",
      "Epoch: 279/500... Training loss: 0.0335\n",
      "Epoch: 279/500... Training loss: 0.0278\n",
      "Epoch: 279/500... Training loss: 0.0531\n",
      "Epoch: 279/500... Training loss: 0.0104\n",
      "Epoch: 279/500... Training loss: 0.0238\n",
      "Epoch: 279/500... Training loss: 0.0055\n",
      "Epoch: 279/500... Training loss: 0.0575\n",
      "Epoch: 279/500... Training loss: 0.0067\n",
      "Epoch: 279/500... Training loss: 0.0078\n",
      "Epoch: 279/500... Training loss: 0.0026\n",
      "Epoch: 279/500... Training loss: 0.0528\n",
      "Epoch: 279/500... Training loss: 0.0929\n",
      "Epoch: 279/500... Training loss: 0.0318\n",
      "Epoch: 279/500... Training loss: 0.0054\n",
      "Epoch: 279/500... Training loss: 0.0058\n",
      "Epoch: 279/500... Training loss: 0.0113\n",
      "Epoch: 279/500... Training loss: 0.0283\n",
      "Epoch: 279/500... Training loss: 0.0948\n",
      "Epoch: 279/500... Training loss: 0.0041\n",
      "Epoch: 279/500... Training loss: 0.0183\n",
      "Epoch: 279/500... Training loss: 0.0142\n",
      "Epoch: 279/500... Training loss: 0.0708\n",
      "Epoch: 279/500... Training loss: 0.0393\n",
      "Epoch: 279/500... Training loss: 0.0138\n",
      "Epoch: 279/500... Training loss: 0.0174\n",
      "Epoch: 280/500... Training loss: 0.0040\n",
      "Epoch: 280/500... Training loss: 0.0995\n",
      "Epoch: 280/500... Training loss: 0.2038\n",
      "Epoch: 280/500... Training loss: 0.0460\n",
      "Epoch: 280/500... Training loss: 0.1356\n",
      "Epoch: 280/500... Training loss: 0.0062\n",
      "Epoch: 280/500... Training loss: 0.0246\n",
      "Epoch: 280/500... Training loss: 0.0049\n",
      "Epoch: 280/500... Training loss: 0.0139\n",
      "Epoch: 280/500... Training loss: 0.0161\n",
      "Epoch: 280/500... Training loss: 0.0111\n",
      "Epoch: 280/500... Training loss: 0.0177\n",
      "Epoch: 280/500... Training loss: 0.0408\n",
      "Epoch: 280/500... Training loss: 0.0584\n",
      "Epoch: 280/500... Training loss: 0.0468\n",
      "Epoch: 280/500... Training loss: 0.0345\n",
      "Epoch: 280/500... Training loss: 0.0114\n",
      "Epoch: 280/500... Training loss: 0.0277\n",
      "Epoch: 280/500... Training loss: 0.0106\n",
      "Epoch: 280/500... Training loss: 0.0185\n",
      "Epoch: 280/500... Training loss: 0.0170\n",
      "Epoch: 280/500... Training loss: 0.0191\n",
      "Epoch: 280/500... Training loss: 0.0571\n",
      "Epoch: 280/500... Training loss: 0.0043\n",
      "Epoch: 280/500... Training loss: 0.0114\n",
      "Epoch: 280/500... Training loss: 0.0133\n",
      "Epoch: 280/500... Training loss: 0.0425\n",
      "Epoch: 280/500... Training loss: 0.0545\n",
      "Epoch: 280/500... Training loss: 0.0048\n",
      "Epoch: 280/500... Training loss: 0.0224\n",
      "Epoch: 280/500... Training loss: 0.0116\n",
      "Epoch: 281/500... Training loss: 0.0396\n",
      "Epoch: 281/500... Training loss: 0.0087\n",
      "Epoch: 281/500... Training loss: 0.0249\n",
      "Epoch: 281/500... Training loss: 0.0965\n",
      "Epoch: 281/500... Training loss: 0.0113\n",
      "Epoch: 281/500... Training loss: 0.0352\n",
      "Epoch: 281/500... Training loss: 0.0821\n",
      "Epoch: 281/500... Training loss: 0.0273\n",
      "Epoch: 281/500... Training loss: 0.0168\n",
      "Epoch: 281/500... Training loss: 0.0131\n",
      "Epoch: 281/500... Training loss: 0.0118\n",
      "Epoch: 281/500... Training loss: 0.0270\n",
      "Epoch: 281/500... Training loss: 0.0520\n",
      "Epoch: 281/500... Training loss: 0.0341\n",
      "Epoch: 281/500... Training loss: 0.0234\n",
      "Epoch: 281/500... Training loss: 0.0108\n",
      "Epoch: 281/500... Training loss: 0.0057\n",
      "Epoch: 281/500... Training loss: 0.0523\n",
      "Epoch: 281/500... Training loss: 0.0668\n",
      "Epoch: 281/500... Training loss: 0.0558\n",
      "Epoch: 281/500... Training loss: 0.0149\n",
      "Epoch: 281/500... Training loss: 0.0170\n",
      "Epoch: 281/500... Training loss: 0.1514\n",
      "Epoch: 281/500... Training loss: 0.0108\n",
      "Epoch: 281/500... Training loss: 0.0285\n",
      "Epoch: 281/500... Training loss: 0.0315\n",
      "Epoch: 281/500... Training loss: 0.0017\n",
      "Epoch: 281/500... Training loss: 0.1099\n",
      "Epoch: 281/500... Training loss: 0.0059\n",
      "Epoch: 281/500... Training loss: 0.0880\n",
      "Epoch: 281/500... Training loss: 0.1976\n",
      "Epoch: 282/500... Training loss: 0.0288\n",
      "Epoch: 282/500... Training loss: 0.0062\n",
      "Epoch: 282/500... Training loss: 0.0185\n",
      "Epoch: 282/500... Training loss: 0.0547\n",
      "Epoch: 282/500... Training loss: 0.0331\n",
      "Epoch: 282/500... Training loss: 0.0070\n",
      "Epoch: 282/500... Training loss: 0.0080\n",
      "Epoch: 282/500... Training loss: 0.0421\n",
      "Epoch: 282/500... Training loss: 0.0193\n",
      "Epoch: 282/500... Training loss: 0.0232\n",
      "Epoch: 282/500... Training loss: 0.0266\n",
      "Epoch: 282/500... Training loss: 0.0074\n",
      "Epoch: 282/500... Training loss: 0.0367\n",
      "Epoch: 282/500... Training loss: 0.1511\n",
      "Epoch: 282/500... Training loss: 0.0120\n",
      "Epoch: 282/500... Training loss: 0.0214\n",
      "Epoch: 282/500... Training loss: 0.0081\n",
      "Epoch: 282/500... Training loss: 0.0012\n",
      "Epoch: 282/500... Training loss: 0.0201\n",
      "Epoch: 282/500... Training loss: 0.0452\n",
      "Epoch: 282/500... Training loss: 0.0082\n",
      "Epoch: 282/500... Training loss: 0.0092\n",
      "Epoch: 282/500... Training loss: 0.0101\n",
      "Epoch: 282/500... Training loss: 0.0225\n",
      "Epoch: 282/500... Training loss: 0.0016\n",
      "Epoch: 282/500... Training loss: 0.1140\n",
      "Epoch: 282/500... Training loss: 0.0117\n",
      "Epoch: 282/500... Training loss: 0.0043\n",
      "Epoch: 282/500... Training loss: 0.0538\n",
      "Epoch: 282/500... Training loss: 0.0057\n",
      "Epoch: 282/500... Training loss: 0.0193\n",
      "Epoch: 283/500... Training loss: 0.0043\n",
      "Epoch: 283/500... Training loss: 0.0057\n",
      "Epoch: 283/500... Training loss: 0.0349\n",
      "Epoch: 283/500... Training loss: 0.0162\n",
      "Epoch: 283/500... Training loss: 0.0255\n",
      "Epoch: 283/500... Training loss: 0.0048\n",
      "Epoch: 283/500... Training loss: 0.0727\n",
      "Epoch: 283/500... Training loss: 0.0167\n",
      "Epoch: 283/500... Training loss: 0.0078\n",
      "Epoch: 283/500... Training loss: 0.0229\n",
      "Epoch: 283/500... Training loss: 0.0684\n",
      "Epoch: 283/500... Training loss: 0.0221\n",
      "Epoch: 283/500... Training loss: 0.0130\n",
      "Epoch: 283/500... Training loss: 0.0109\n",
      "Epoch: 283/500... Training loss: 0.0111\n",
      "Epoch: 283/500... Training loss: 0.0226\n",
      "Epoch: 283/500... Training loss: 0.0074\n",
      "Epoch: 283/500... Training loss: 0.0107\n",
      "Epoch: 283/500... Training loss: 0.0076\n",
      "Epoch: 283/500... Training loss: 0.0020\n",
      "Epoch: 283/500... Training loss: 0.0463\n",
      "Epoch: 283/500... Training loss: 0.0086\n",
      "Epoch: 283/500... Training loss: 0.0833\n",
      "Epoch: 283/500... Training loss: 0.0212\n",
      "Epoch: 283/500... Training loss: 0.0478\n",
      "Epoch: 283/500... Training loss: 0.0814\n",
      "Epoch: 283/500... Training loss: 0.0064\n",
      "Epoch: 283/500... Training loss: 0.0029\n",
      "Epoch: 283/500... Training loss: 0.0265\n",
      "Epoch: 283/500... Training loss: 0.0752\n",
      "Epoch: 283/500... Training loss: 0.1028\n",
      "Epoch: 284/500... Training loss: 0.0091\n",
      "Epoch: 284/500... Training loss: 0.0128\n",
      "Epoch: 284/500... Training loss: 0.0273\n",
      "Epoch: 284/500... Training loss: 0.0638\n",
      "Epoch: 284/500... Training loss: 0.0109\n",
      "Epoch: 284/500... Training loss: 0.0168\n",
      "Epoch: 284/500... Training loss: 0.0124\n",
      "Epoch: 284/500... Training loss: 0.0679\n",
      "Epoch: 284/500... Training loss: 0.0271\n",
      "Epoch: 284/500... Training loss: 0.1021\n",
      "Epoch: 284/500... Training loss: 0.0070\n",
      "Epoch: 284/500... Training loss: 0.0197\n",
      "Epoch: 284/500... Training loss: 0.0150\n",
      "Epoch: 284/500... Training loss: 0.0106\n",
      "Epoch: 284/500... Training loss: 0.0281\n",
      "Epoch: 284/500... Training loss: 0.0119\n",
      "Epoch: 284/500... Training loss: 0.0079\n",
      "Epoch: 284/500... Training loss: 0.0121\n",
      "Epoch: 284/500... Training loss: 0.1372\n",
      "Epoch: 284/500... Training loss: 0.0313\n",
      "Epoch: 284/500... Training loss: 0.0344\n",
      "Epoch: 284/500... Training loss: 0.0072\n",
      "Epoch: 284/500... Training loss: 0.0352\n",
      "Epoch: 284/500... Training loss: 0.0709\n",
      "Epoch: 284/500... Training loss: 0.0458\n",
      "Epoch: 284/500... Training loss: 0.0041\n",
      "Epoch: 284/500... Training loss: 0.0287\n",
      "Epoch: 284/500... Training loss: 0.0431\n",
      "Epoch: 284/500... Training loss: 0.0506\n",
      "Epoch: 284/500... Training loss: 0.0092\n",
      "Epoch: 284/500... Training loss: 0.0066\n",
      "Epoch: 285/500... Training loss: 0.0086\n",
      "Epoch: 285/500... Training loss: 0.0166\n",
      "Epoch: 285/500... Training loss: 0.0225\n",
      "Epoch: 285/500... Training loss: 0.0635\n",
      "Epoch: 285/500... Training loss: 0.1577\n",
      "Epoch: 285/500... Training loss: 0.0179\n",
      "Epoch: 285/500... Training loss: 0.0330\n",
      "Epoch: 285/500... Training loss: 0.0077\n",
      "Epoch: 285/500... Training loss: 0.0113\n",
      "Epoch: 285/500... Training loss: 0.0057\n",
      "Epoch: 285/500... Training loss: 0.0613\n",
      "Epoch: 285/500... Training loss: 0.0799\n",
      "Epoch: 285/500... Training loss: 0.0043\n",
      "Epoch: 285/500... Training loss: 0.0044\n",
      "Epoch: 285/500... Training loss: 0.0182\n",
      "Epoch: 285/500... Training loss: 0.0311\n",
      "Epoch: 285/500... Training loss: 0.0396\n",
      "Epoch: 285/500... Training loss: 0.0137\n",
      "Epoch: 285/500... Training loss: 0.0158\n",
      "Epoch: 285/500... Training loss: 0.0022\n",
      "Epoch: 285/500... Training loss: 0.0090\n",
      "Epoch: 285/500... Training loss: 0.0102\n",
      "Epoch: 285/500... Training loss: 0.0911\n",
      "Epoch: 285/500... Training loss: 0.0200\n",
      "Epoch: 285/500... Training loss: 0.0705\n",
      "Epoch: 285/500... Training loss: 0.0377\n",
      "Epoch: 285/500... Training loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285/500... Training loss: 0.0325\n",
      "Epoch: 285/500... Training loss: 0.0655\n",
      "Epoch: 285/500... Training loss: 0.0174\n",
      "Epoch: 285/500... Training loss: 0.0070\n",
      "Epoch: 286/500... Training loss: 0.0037\n",
      "Epoch: 286/500... Training loss: 0.0292\n",
      "Epoch: 286/500... Training loss: 0.0124\n",
      "Epoch: 286/500... Training loss: 0.2347\n",
      "Epoch: 286/500... Training loss: 0.0560\n",
      "Epoch: 286/500... Training loss: 0.0080\n",
      "Epoch: 286/500... Training loss: 0.0033\n",
      "Epoch: 286/500... Training loss: 0.0530\n",
      "Epoch: 286/500... Training loss: 0.0298\n",
      "Epoch: 286/500... Training loss: 0.0505\n",
      "Epoch: 286/500... Training loss: 0.0462\n",
      "Epoch: 286/500... Training loss: 0.0448\n",
      "Epoch: 286/500... Training loss: 0.0180\n",
      "Epoch: 286/500... Training loss: 0.0173\n",
      "Epoch: 286/500... Training loss: 0.0143\n",
      "Epoch: 286/500... Training loss: 0.0131\n",
      "Epoch: 286/500... Training loss: 0.0121\n",
      "Epoch: 286/500... Training loss: 0.0277\n",
      "Epoch: 286/500... Training loss: 0.1771\n",
      "Epoch: 286/500... Training loss: 0.0230\n",
      "Epoch: 286/500... Training loss: 0.0055\n",
      "Epoch: 286/500... Training loss: 0.0101\n",
      "Epoch: 286/500... Training loss: 0.0054\n",
      "Epoch: 286/500... Training loss: 0.0255\n",
      "Epoch: 286/500... Training loss: 0.1269\n",
      "Epoch: 286/500... Training loss: 0.0069\n",
      "Epoch: 286/500... Training loss: 0.0121\n",
      "Epoch: 286/500... Training loss: 0.0654\n",
      "Epoch: 286/500... Training loss: 0.0080\n",
      "Epoch: 286/500... Training loss: 0.0058\n",
      "Epoch: 286/500... Training loss: 0.0233\n",
      "Epoch: 287/500... Training loss: 0.0015\n",
      "Epoch: 287/500... Training loss: 0.0113\n",
      "Epoch: 287/500... Training loss: 0.0034\n",
      "Epoch: 287/500... Training loss: 0.0211\n",
      "Epoch: 287/500... Training loss: 0.0155\n",
      "Epoch: 287/500... Training loss: 0.0459\n",
      "Epoch: 287/500... Training loss: 0.0756\n",
      "Epoch: 287/500... Training loss: 0.0068\n",
      "Epoch: 287/500... Training loss: 0.1419\n",
      "Epoch: 287/500... Training loss: 0.0095\n",
      "Epoch: 287/500... Training loss: 0.0069\n",
      "Epoch: 287/500... Training loss: 0.0944\n",
      "Epoch: 287/500... Training loss: 0.0309\n",
      "Epoch: 287/500... Training loss: 0.0195\n",
      "Epoch: 287/500... Training loss: 0.0522\n",
      "Epoch: 287/500... Training loss: 0.0319\n",
      "Epoch: 287/500... Training loss: 0.0228\n",
      "Epoch: 287/500... Training loss: 0.0058\n",
      "Epoch: 287/500... Training loss: 0.0473\n",
      "Epoch: 287/500... Training loss: 0.0138\n",
      "Epoch: 287/500... Training loss: 0.0072\n",
      "Epoch: 287/500... Training loss: 0.0183\n",
      "Epoch: 287/500... Training loss: 0.0201\n",
      "Epoch: 287/500... Training loss: 0.0068\n",
      "Epoch: 287/500... Training loss: 0.0180\n",
      "Epoch: 287/500... Training loss: 0.0623\n",
      "Epoch: 287/500... Training loss: 0.0741\n",
      "Epoch: 287/500... Training loss: 0.0059\n",
      "Epoch: 287/500... Training loss: 0.0076\n",
      "Epoch: 287/500... Training loss: 0.0153\n",
      "Epoch: 287/500... Training loss: 0.1191\n",
      "Epoch: 288/500... Training loss: 0.1129\n",
      "Epoch: 288/500... Training loss: 0.0241\n",
      "Epoch: 288/500... Training loss: 0.0044\n",
      "Epoch: 288/500... Training loss: 0.0529\n",
      "Epoch: 288/500... Training loss: 0.0051\n",
      "Epoch: 288/500... Training loss: 0.0231\n",
      "Epoch: 288/500... Training loss: 0.0046\n",
      "Epoch: 288/500... Training loss: 0.0594\n",
      "Epoch: 288/500... Training loss: 0.0251\n",
      "Epoch: 288/500... Training loss: 0.0063\n",
      "Epoch: 288/500... Training loss: 0.0232\n",
      "Epoch: 288/500... Training loss: 0.0617\n",
      "Epoch: 288/500... Training loss: 0.0328\n",
      "Epoch: 288/500... Training loss: 0.0196\n",
      "Epoch: 288/500... Training loss: 0.0557\n",
      "Epoch: 288/500... Training loss: 0.0050\n",
      "Epoch: 288/500... Training loss: 0.0048\n",
      "Epoch: 288/500... Training loss: 0.0401\n",
      "Epoch: 288/500... Training loss: 0.0529\n",
      "Epoch: 288/500... Training loss: 0.0231\n",
      "Epoch: 288/500... Training loss: 0.0253\n",
      "Epoch: 288/500... Training loss: 0.0783\n",
      "Epoch: 288/500... Training loss: 0.0181\n",
      "Epoch: 288/500... Training loss: 0.0077\n",
      "Epoch: 288/500... Training loss: 0.0178\n",
      "Epoch: 288/500... Training loss: 0.0405\n",
      "Epoch: 288/500... Training loss: 0.0172\n",
      "Epoch: 288/500... Training loss: 0.0326\n",
      "Epoch: 288/500... Training loss: 0.0178\n",
      "Epoch: 288/500... Training loss: 0.0415\n",
      "Epoch: 288/500... Training loss: 0.0613\n",
      "Epoch: 289/500... Training loss: 0.0092\n",
      "Epoch: 289/500... Training loss: 0.0172\n",
      "Epoch: 289/500... Training loss: 0.0111\n",
      "Epoch: 289/500... Training loss: 0.0215\n",
      "Epoch: 289/500... Training loss: 0.0360\n",
      "Epoch: 289/500... Training loss: 0.0040\n",
      "Epoch: 289/500... Training loss: 0.0088\n",
      "Epoch: 289/500... Training loss: 0.0157\n",
      "Epoch: 289/500... Training loss: 0.0553\n",
      "Epoch: 289/500... Training loss: 0.0212\n",
      "Epoch: 289/500... Training loss: 0.0059\n",
      "Epoch: 289/500... Training loss: 0.0320\n",
      "Epoch: 289/500... Training loss: 0.0103\n",
      "Epoch: 289/500... Training loss: 0.0098\n",
      "Epoch: 289/500... Training loss: 0.0320\n",
      "Epoch: 289/500... Training loss: 0.0053\n",
      "Epoch: 289/500... Training loss: 0.0163\n",
      "Epoch: 289/500... Training loss: 0.1464\n",
      "Epoch: 289/500... Training loss: 0.0502\n",
      "Epoch: 289/500... Training loss: 0.0076\n",
      "Epoch: 289/500... Training loss: 0.0533\n",
      "Epoch: 289/500... Training loss: 0.0443\n",
      "Epoch: 289/500... Training loss: 0.0205\n",
      "Epoch: 289/500... Training loss: 0.0212\n",
      "Epoch: 289/500... Training loss: 0.0120\n",
      "Epoch: 289/500... Training loss: 0.0270\n",
      "Epoch: 289/500... Training loss: 0.0189\n",
      "Epoch: 289/500... Training loss: 0.0041\n",
      "Epoch: 289/500... Training loss: 0.0152\n",
      "Epoch: 289/500... Training loss: 0.0442\n",
      "Epoch: 289/500... Training loss: 0.1833\n",
      "Epoch: 290/500... Training loss: 0.0066\n",
      "Epoch: 290/500... Training loss: 0.0050\n",
      "Epoch: 290/500... Training loss: 0.0042\n",
      "Epoch: 290/500... Training loss: 0.0080\n",
      "Epoch: 290/500... Training loss: 0.0287\n",
      "Epoch: 290/500... Training loss: 0.0066\n",
      "Epoch: 290/500... Training loss: 0.0084\n",
      "Epoch: 290/500... Training loss: 0.0395\n",
      "Epoch: 290/500... Training loss: 0.0207\n",
      "Epoch: 290/500... Training loss: 0.2024\n",
      "Epoch: 290/500... Training loss: 0.0088\n",
      "Epoch: 290/500... Training loss: 0.0328\n",
      "Epoch: 290/500... Training loss: 0.0023\n",
      "Epoch: 290/500... Training loss: 0.0363\n",
      "Epoch: 290/500... Training loss: 0.0038\n",
      "Epoch: 290/500... Training loss: 0.0043\n",
      "Epoch: 290/500... Training loss: 0.0424\n",
      "Epoch: 290/500... Training loss: 0.0314\n",
      "Epoch: 290/500... Training loss: 0.0138\n",
      "Epoch: 290/500... Training loss: 0.0078\n",
      "Epoch: 290/500... Training loss: 0.0144\n",
      "Epoch: 290/500... Training loss: 0.0073\n",
      "Epoch: 290/500... Training loss: 0.0171\n",
      "Epoch: 290/500... Training loss: 0.0029\n",
      "Epoch: 290/500... Training loss: 0.0054\n",
      "Epoch: 290/500... Training loss: 0.0587\n",
      "Epoch: 290/500... Training loss: 0.0220\n",
      "Epoch: 290/500... Training loss: 0.0367\n",
      "Epoch: 290/500... Training loss: 0.0028\n",
      "Epoch: 290/500... Training loss: 0.0549\n",
      "Epoch: 290/500... Training loss: 0.0101\n",
      "Epoch: 291/500... Training loss: 0.0037\n",
      "Epoch: 291/500... Training loss: 0.1322\n",
      "Epoch: 291/500... Training loss: 0.0083\n",
      "Epoch: 291/500... Training loss: 0.0110\n",
      "Epoch: 291/500... Training loss: 0.0035\n",
      "Epoch: 291/500... Training loss: 0.0086\n",
      "Epoch: 291/500... Training loss: 0.0583\n",
      "Epoch: 291/500... Training loss: 0.0891\n",
      "Epoch: 291/500... Training loss: 0.0203\n",
      "Epoch: 291/500... Training loss: 0.0375\n",
      "Epoch: 291/500... Training loss: 0.0077\n",
      "Epoch: 291/500... Training loss: 0.0331\n",
      "Epoch: 291/500... Training loss: 0.0038\n",
      "Epoch: 291/500... Training loss: 0.0748\n",
      "Epoch: 291/500... Training loss: 0.0068\n",
      "Epoch: 291/500... Training loss: 0.0081\n",
      "Epoch: 291/500... Training loss: 0.0074\n",
      "Epoch: 291/500... Training loss: 0.0177\n",
      "Epoch: 291/500... Training loss: 0.1124\n",
      "Epoch: 291/500... Training loss: 0.0204\n",
      "Epoch: 291/500... Training loss: 0.0172\n",
      "Epoch: 291/500... Training loss: 0.0055\n",
      "Epoch: 291/500... Training loss: 0.0404\n",
      "Epoch: 291/500... Training loss: 0.0347\n",
      "Epoch: 291/500... Training loss: 0.1217\n",
      "Epoch: 291/500... Training loss: 0.0206\n",
      "Epoch: 291/500... Training loss: 0.0064\n",
      "Epoch: 291/500... Training loss: 0.0130\n",
      "Epoch: 291/500... Training loss: 0.0130\n",
      "Epoch: 291/500... Training loss: 0.0055\n",
      "Epoch: 291/500... Training loss: 0.0049\n",
      "Epoch: 292/500... Training loss: 0.0126\n",
      "Epoch: 292/500... Training loss: 0.0074\n",
      "Epoch: 292/500... Training loss: 0.0159\n",
      "Epoch: 292/500... Training loss: 0.0237\n",
      "Epoch: 292/500... Training loss: 0.0072\n",
      "Epoch: 292/500... Training loss: 0.0115\n",
      "Epoch: 292/500... Training loss: 0.0228\n",
      "Epoch: 292/500... Training loss: 0.0277\n",
      "Epoch: 292/500... Training loss: 0.0839\n",
      "Epoch: 292/500... Training loss: 0.0042\n",
      "Epoch: 292/500... Training loss: 0.0064\n",
      "Epoch: 292/500... Training loss: 0.0318\n",
      "Epoch: 292/500... Training loss: 0.0258\n",
      "Epoch: 292/500... Training loss: 0.0556\n",
      "Epoch: 292/500... Training loss: 0.0223\n",
      "Epoch: 292/500... Training loss: 0.0037\n",
      "Epoch: 292/500... Training loss: 0.0138\n",
      "Epoch: 292/500... Training loss: 0.1148\n",
      "Epoch: 292/500... Training loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 292/500... Training loss: 0.0053\n",
      "Epoch: 292/500... Training loss: 0.0037\n",
      "Epoch: 292/500... Training loss: 0.0112\n",
      "Epoch: 292/500... Training loss: 0.0413\n",
      "Epoch: 292/500... Training loss: 0.0080\n",
      "Epoch: 292/500... Training loss: 0.0089\n",
      "Epoch: 292/500... Training loss: 0.0041\n",
      "Epoch: 292/500... Training loss: 0.0820\n",
      "Epoch: 292/500... Training loss: 0.0698\n",
      "Epoch: 292/500... Training loss: 0.0051\n",
      "Epoch: 292/500... Training loss: 0.0344\n",
      "Epoch: 292/500... Training loss: 0.0127\n",
      "Epoch: 293/500... Training loss: 0.0043\n",
      "Epoch: 293/500... Training loss: 0.0008\n",
      "Epoch: 293/500... Training loss: 0.0291\n",
      "Epoch: 293/500... Training loss: 0.0127\n",
      "Epoch: 293/500... Training loss: 0.0052\n",
      "Epoch: 293/500... Training loss: 0.0159\n",
      "Epoch: 293/500... Training loss: 0.0055\n",
      "Epoch: 293/500... Training loss: 0.0783\n",
      "Epoch: 293/500... Training loss: 0.0043\n",
      "Epoch: 293/500... Training loss: 0.0479\n",
      "Epoch: 293/500... Training loss: 0.0809\n",
      "Epoch: 293/500... Training loss: 0.0117\n",
      "Epoch: 293/500... Training loss: 0.0313\n",
      "Epoch: 293/500... Training loss: 0.0054\n",
      "Epoch: 293/500... Training loss: 0.0130\n",
      "Epoch: 293/500... Training loss: 0.0049\n",
      "Epoch: 293/500... Training loss: 0.0568\n",
      "Epoch: 293/500... Training loss: 0.0050\n",
      "Epoch: 293/500... Training loss: 0.0398\n",
      "Epoch: 293/500... Training loss: 0.0183\n",
      "Epoch: 293/500... Training loss: 0.0640\n",
      "Epoch: 293/500... Training loss: 0.0561\n",
      "Epoch: 293/500... Training loss: 0.0471\n",
      "Epoch: 293/500... Training loss: 0.0103\n",
      "Epoch: 293/500... Training loss: 0.0123\n",
      "Epoch: 293/500... Training loss: 0.0064\n",
      "Epoch: 293/500... Training loss: 0.0422\n",
      "Epoch: 293/500... Training loss: 0.0039\n",
      "Epoch: 293/500... Training loss: 0.0024\n",
      "Epoch: 293/500... Training loss: 0.0409\n",
      "Epoch: 293/500... Training loss: 0.0078\n",
      "Epoch: 294/500... Training loss: 0.0834\n",
      "Epoch: 294/500... Training loss: 0.0226\n",
      "Epoch: 294/500... Training loss: 0.0482\n",
      "Epoch: 294/500... Training loss: 0.0173\n",
      "Epoch: 294/500... Training loss: 0.0112\n",
      "Epoch: 294/500... Training loss: 0.0079\n",
      "Epoch: 294/500... Training loss: 0.0089\n",
      "Epoch: 294/500... Training loss: 0.0577\n",
      "Epoch: 294/500... Training loss: 0.0073\n",
      "Epoch: 294/500... Training loss: 0.0128\n",
      "Epoch: 294/500... Training loss: 0.0372\n",
      "Epoch: 294/500... Training loss: 0.0094\n",
      "Epoch: 294/500... Training loss: 0.0473\n",
      "Epoch: 294/500... Training loss: 0.1377\n",
      "Epoch: 294/500... Training loss: 0.0535\n",
      "Epoch: 294/500... Training loss: 0.0334\n",
      "Epoch: 294/500... Training loss: 0.0527\n",
      "Epoch: 294/500... Training loss: 0.0069\n",
      "Epoch: 294/500... Training loss: 0.0346\n",
      "Epoch: 294/500... Training loss: 0.0505\n",
      "Epoch: 294/500... Training loss: 0.0170\n",
      "Epoch: 294/500... Training loss: 0.0090\n",
      "Epoch: 294/500... Training loss: 0.0359\n",
      "Epoch: 294/500... Training loss: 0.0127\n",
      "Epoch: 294/500... Training loss: 0.0147\n",
      "Epoch: 294/500... Training loss: 0.0113\n",
      "Epoch: 294/500... Training loss: 0.0048\n",
      "Epoch: 294/500... Training loss: 0.0141\n",
      "Epoch: 294/500... Training loss: 0.0138\n",
      "Epoch: 294/500... Training loss: 0.0406\n",
      "Epoch: 294/500... Training loss: 0.0138\n",
      "Epoch: 295/500... Training loss: 0.0150\n",
      "Epoch: 295/500... Training loss: 0.0016\n",
      "Epoch: 295/500... Training loss: 0.0164\n",
      "Epoch: 295/500... Training loss: 0.0135\n",
      "Epoch: 295/500... Training loss: 0.0111\n",
      "Epoch: 295/500... Training loss: 0.0108\n",
      "Epoch: 295/500... Training loss: 0.0298\n",
      "Epoch: 295/500... Training loss: 0.0658\n",
      "Epoch: 295/500... Training loss: 0.0082\n",
      "Epoch: 295/500... Training loss: 0.1551\n",
      "Epoch: 295/500... Training loss: 0.0307\n",
      "Epoch: 295/500... Training loss: 0.0067\n",
      "Epoch: 295/500... Training loss: 0.0931\n",
      "Epoch: 295/500... Training loss: 0.0072\n",
      "Epoch: 295/500... Training loss: 0.0037\n",
      "Epoch: 295/500... Training loss: 0.0160\n",
      "Epoch: 295/500... Training loss: 0.0200\n",
      "Epoch: 295/500... Training loss: 0.0103\n",
      "Epoch: 295/500... Training loss: 0.0062\n",
      "Epoch: 295/500... Training loss: 0.0771\n",
      "Epoch: 295/500... Training loss: 0.0185\n",
      "Epoch: 295/500... Training loss: 0.0055\n",
      "Epoch: 295/500... Training loss: 0.0051\n",
      "Epoch: 295/500... Training loss: 0.0169\n",
      "Epoch: 295/500... Training loss: 0.0316\n",
      "Epoch: 295/500... Training loss: 0.0181\n",
      "Epoch: 295/500... Training loss: 0.0957\n",
      "Epoch: 295/500... Training loss: 0.0023\n",
      "Epoch: 295/500... Training loss: 0.0112\n",
      "Epoch: 295/500... Training loss: 0.0539\n",
      "Epoch: 295/500... Training loss: 0.0310\n",
      "Epoch: 296/500... Training loss: 0.0222\n",
      "Epoch: 296/500... Training loss: 0.0062\n",
      "Epoch: 296/500... Training loss: 0.0109\n",
      "Epoch: 296/500... Training loss: 0.0057\n",
      "Epoch: 296/500... Training loss: 0.0150\n",
      "Epoch: 296/500... Training loss: 0.0257\n",
      "Epoch: 296/500... Training loss: 0.0351\n",
      "Epoch: 296/500... Training loss: 0.0046\n",
      "Epoch: 296/500... Training loss: 0.0870\n",
      "Epoch: 296/500... Training loss: 0.0035\n",
      "Epoch: 296/500... Training loss: 0.0156\n",
      "Epoch: 296/500... Training loss: 0.0134\n",
      "Epoch: 296/500... Training loss: 0.0885\n",
      "Epoch: 296/500... Training loss: 0.0303\n",
      "Epoch: 296/500... Training loss: 0.0148\n",
      "Epoch: 296/500... Training loss: 0.0134\n",
      "Epoch: 296/500... Training loss: 0.0047\n",
      "Epoch: 296/500... Training loss: 0.0292\n",
      "Epoch: 296/500... Training loss: 0.1235\n",
      "Epoch: 296/500... Training loss: 0.0379\n",
      "Epoch: 296/500... Training loss: 0.0048\n",
      "Epoch: 296/500... Training loss: 0.0098\n",
      "Epoch: 296/500... Training loss: 0.0199\n",
      "Epoch: 296/500... Training loss: 0.0497\n",
      "Epoch: 296/500... Training loss: 0.0079\n",
      "Epoch: 296/500... Training loss: 0.0076\n",
      "Epoch: 296/500... Training loss: 0.0405\n",
      "Epoch: 296/500... Training loss: 0.0176\n",
      "Epoch: 296/500... Training loss: 0.0260\n",
      "Epoch: 296/500... Training loss: 0.0068\n",
      "Epoch: 296/500... Training loss: 0.0411\n",
      "Epoch: 297/500... Training loss: 0.0095\n",
      "Epoch: 297/500... Training loss: 0.0087\n",
      "Epoch: 297/500... Training loss: 0.0330\n",
      "Epoch: 297/500... Training loss: 0.0237\n",
      "Epoch: 297/500... Training loss: 0.0045\n",
      "Epoch: 297/500... Training loss: 0.0265\n",
      "Epoch: 297/500... Training loss: 0.0175\n",
      "Epoch: 297/500... Training loss: 0.0169\n",
      "Epoch: 297/500... Training loss: 0.0241\n",
      "Epoch: 297/500... Training loss: 0.0665\n",
      "Epoch: 297/500... Training loss: 0.0057\n",
      "Epoch: 297/500... Training loss: 0.0097\n",
      "Epoch: 297/500... Training loss: 0.0693\n",
      "Epoch: 297/500... Training loss: 0.0124\n",
      "Epoch: 297/500... Training loss: 0.0168\n",
      "Epoch: 297/500... Training loss: 0.0149\n",
      "Epoch: 297/500... Training loss: 0.0030\n",
      "Epoch: 297/500... Training loss: 0.1271\n",
      "Epoch: 297/500... Training loss: 0.0547\n",
      "Epoch: 297/500... Training loss: 0.0294\n",
      "Epoch: 297/500... Training loss: 0.0085\n",
      "Epoch: 297/500... Training loss: 0.0372\n",
      "Epoch: 297/500... Training loss: 0.0705\n",
      "Epoch: 297/500... Training loss: 0.0085\n",
      "Epoch: 297/500... Training loss: 0.0096\n",
      "Epoch: 297/500... Training loss: 0.0049\n",
      "Epoch: 297/500... Training loss: 0.0031\n",
      "Epoch: 297/500... Training loss: 0.0020\n",
      "Epoch: 297/500... Training loss: 0.0552\n",
      "Epoch: 297/500... Training loss: 0.0144\n",
      "Epoch: 297/500... Training loss: 0.0090\n",
      "Epoch: 298/500... Training loss: 0.0033\n",
      "Epoch: 298/500... Training loss: 0.0065\n",
      "Epoch: 298/500... Training loss: 0.0107\n",
      "Epoch: 298/500... Training loss: 0.0143\n",
      "Epoch: 298/500... Training loss: 0.0041\n",
      "Epoch: 298/500... Training loss: 0.0137\n",
      "Epoch: 298/500... Training loss: 0.0160\n",
      "Epoch: 298/500... Training loss: 0.0057\n",
      "Epoch: 298/500... Training loss: 0.0802\n",
      "Epoch: 298/500... Training loss: 0.0159\n",
      "Epoch: 298/500... Training loss: 0.0230\n",
      "Epoch: 298/500... Training loss: 0.0208\n",
      "Epoch: 298/500... Training loss: 0.0176\n",
      "Epoch: 298/500... Training loss: 0.0194\n",
      "Epoch: 298/500... Training loss: 0.0068\n",
      "Epoch: 298/500... Training loss: 0.0376\n",
      "Epoch: 298/500... Training loss: 0.0358\n",
      "Epoch: 298/500... Training loss: 0.0122\n",
      "Epoch: 298/500... Training loss: 0.0047\n",
      "Epoch: 298/500... Training loss: 0.0373\n",
      "Epoch: 298/500... Training loss: 0.0356\n",
      "Epoch: 298/500... Training loss: 0.0036\n",
      "Epoch: 298/500... Training loss: 0.0812\n",
      "Epoch: 298/500... Training loss: 0.0064\n",
      "Epoch: 298/500... Training loss: 0.0276\n",
      "Epoch: 298/500... Training loss: 0.0370\n",
      "Epoch: 298/500... Training loss: 0.0222\n",
      "Epoch: 298/500... Training loss: 0.1088\n",
      "Epoch: 298/500... Training loss: 0.0805\n",
      "Epoch: 298/500... Training loss: 0.0320\n",
      "Epoch: 298/500... Training loss: 0.0091\n",
      "Epoch: 299/500... Training loss: 0.0014\n",
      "Epoch: 299/500... Training loss: 0.0051\n",
      "Epoch: 299/500... Training loss: 0.0813\n",
      "Epoch: 299/500... Training loss: 0.0071\n",
      "Epoch: 299/500... Training loss: 0.0023\n",
      "Epoch: 299/500... Training loss: 0.0305\n",
      "Epoch: 299/500... Training loss: 0.0301\n",
      "Epoch: 299/500... Training loss: 0.0265\n",
      "Epoch: 299/500... Training loss: 0.0085\n",
      "Epoch: 299/500... Training loss: 0.0060\n",
      "Epoch: 299/500... Training loss: 0.0212\n",
      "Epoch: 299/500... Training loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/500... Training loss: 0.0267\n",
      "Epoch: 299/500... Training loss: 0.0064\n",
      "Epoch: 299/500... Training loss: 0.0152\n",
      "Epoch: 299/500... Training loss: 0.0283\n",
      "Epoch: 299/500... Training loss: 0.0042\n",
      "Epoch: 299/500... Training loss: 0.0310\n",
      "Epoch: 299/500... Training loss: 0.1521\n",
      "Epoch: 299/500... Training loss: 0.0264\n",
      "Epoch: 299/500... Training loss: 0.0334\n",
      "Epoch: 299/500... Training loss: 0.0716\n",
      "Epoch: 299/500... Training loss: 0.1058\n",
      "Epoch: 299/500... Training loss: 0.0083\n",
      "Epoch: 299/500... Training loss: 0.0072\n",
      "Epoch: 299/500... Training loss: 0.0216\n",
      "Epoch: 299/500... Training loss: 0.0816\n",
      "Epoch: 299/500... Training loss: 0.0032\n",
      "Epoch: 299/500... Training loss: 0.0040\n",
      "Epoch: 299/500... Training loss: 0.0427\n",
      "Epoch: 299/500... Training loss: 0.0209\n",
      "Epoch: 300/500... Training loss: 0.0224\n",
      "Epoch: 300/500... Training loss: 0.1408\n",
      "Epoch: 300/500... Training loss: 0.0446\n",
      "Epoch: 300/500... Training loss: 0.1166\n",
      "Epoch: 300/500... Training loss: 0.0086\n",
      "Epoch: 300/500... Training loss: 0.0141\n",
      "Epoch: 300/500... Training loss: 0.0134\n",
      "Epoch: 300/500... Training loss: 0.0215\n",
      "Epoch: 300/500... Training loss: 0.0789\n",
      "Epoch: 300/500... Training loss: 0.0055\n",
      "Epoch: 300/500... Training loss: 0.0049\n",
      "Epoch: 300/500... Training loss: 0.0145\n",
      "Epoch: 300/500... Training loss: 0.0194\n",
      "Epoch: 300/500... Training loss: 0.0083\n",
      "Epoch: 300/500... Training loss: 0.0505\n",
      "Epoch: 300/500... Training loss: 0.0073\n",
      "Epoch: 300/500... Training loss: 0.0039\n",
      "Epoch: 300/500... Training loss: 0.0079\n",
      "Epoch: 300/500... Training loss: 0.0264\n",
      "Epoch: 300/500... Training loss: 0.0025\n",
      "Epoch: 300/500... Training loss: 0.0326\n",
      "Epoch: 300/500... Training loss: 0.0186\n",
      "Epoch: 300/500... Training loss: 0.0338\n",
      "Epoch: 300/500... Training loss: 0.0086\n",
      "Epoch: 300/500... Training loss: 0.0146\n",
      "Epoch: 300/500... Training loss: 0.0049\n",
      "Epoch: 300/500... Training loss: 0.0091\n",
      "Epoch: 300/500... Training loss: 0.0028\n",
      "Epoch: 300/500... Training loss: 0.0090\n",
      "Epoch: 300/500... Training loss: 0.0125\n",
      "Epoch: 300/500... Training loss: 0.0163\n",
      "Epoch: 301/500... Training loss: 0.0151\n",
      "Epoch: 301/500... Training loss: 0.0350\n",
      "Epoch: 301/500... Training loss: 0.0359\n",
      "Epoch: 301/500... Training loss: 0.0030\n",
      "Epoch: 301/500... Training loss: 0.0029\n",
      "Epoch: 301/500... Training loss: 0.0293\n",
      "Epoch: 301/500... Training loss: 0.0497\n",
      "Epoch: 301/500... Training loss: 0.0125\n",
      "Epoch: 301/500... Training loss: 0.0085\n",
      "Epoch: 301/500... Training loss: 0.0472\n",
      "Epoch: 301/500... Training loss: 0.0092\n",
      "Epoch: 301/500... Training loss: 0.0346\n",
      "Epoch: 301/500... Training loss: 0.0537\n",
      "Epoch: 301/500... Training loss: 0.0125\n",
      "Epoch: 301/500... Training loss: 0.0030\n",
      "Epoch: 301/500... Training loss: 0.0065\n",
      "Epoch: 301/500... Training loss: 0.0234\n",
      "Epoch: 301/500... Training loss: 0.0029\n",
      "Epoch: 301/500... Training loss: 0.0251\n",
      "Epoch: 301/500... Training loss: 0.0241\n",
      "Epoch: 301/500... Training loss: 0.0069\n",
      "Epoch: 301/500... Training loss: 0.0904\n",
      "Epoch: 301/500... Training loss: 0.0408\n",
      "Epoch: 301/500... Training loss: 0.0386\n",
      "Epoch: 301/500... Training loss: 0.0010\n",
      "Epoch: 301/500... Training loss: 0.0047\n",
      "Epoch: 301/500... Training loss: 0.0582\n",
      "Epoch: 301/500... Training loss: 0.0143\n",
      "Epoch: 301/500... Training loss: 0.0223\n",
      "Epoch: 301/500... Training loss: 0.0574\n",
      "Epoch: 301/500... Training loss: 0.0054\n",
      "Epoch: 302/500... Training loss: 0.0469\n",
      "Epoch: 302/500... Training loss: 0.0482\n",
      "Epoch: 302/500... Training loss: 0.0226\n",
      "Epoch: 302/500... Training loss: 0.0060\n",
      "Epoch: 302/500... Training loss: 0.0124\n",
      "Epoch: 302/500... Training loss: 0.0179\n",
      "Epoch: 302/500... Training loss: 0.0238\n",
      "Epoch: 302/500... Training loss: 0.0200\n",
      "Epoch: 302/500... Training loss: 0.0845\n",
      "Epoch: 302/500... Training loss: 0.0672\n",
      "Epoch: 302/500... Training loss: 0.0655\n",
      "Epoch: 302/500... Training loss: 0.0067\n",
      "Epoch: 302/500... Training loss: 0.0338\n",
      "Epoch: 302/500... Training loss: 0.0367\n",
      "Epoch: 302/500... Training loss: 0.0339\n",
      "Epoch: 302/500... Training loss: 0.0090\n",
      "Epoch: 302/500... Training loss: 0.0196\n",
      "Epoch: 302/500... Training loss: 0.0034\n",
      "Epoch: 302/500... Training loss: 0.0188\n",
      "Epoch: 302/500... Training loss: 0.1006\n",
      "Epoch: 302/500... Training loss: 0.1205\n",
      "Epoch: 302/500... Training loss: 0.0131\n",
      "Epoch: 302/500... Training loss: 0.0229\n",
      "Epoch: 302/500... Training loss: 0.0108\n",
      "Epoch: 302/500... Training loss: 0.0382\n",
      "Epoch: 302/500... Training loss: 0.0039\n",
      "Epoch: 302/500... Training loss: 0.0165\n",
      "Epoch: 302/500... Training loss: 0.0775\n",
      "Epoch: 302/500... Training loss: 0.0334\n",
      "Epoch: 302/500... Training loss: 0.0205\n",
      "Epoch: 302/500... Training loss: 0.0266\n",
      "Epoch: 303/500... Training loss: 0.0064\n",
      "Epoch: 303/500... Training loss: 0.0448\n",
      "Epoch: 303/500... Training loss: 0.0632\n",
      "Epoch: 303/500... Training loss: 0.0102\n",
      "Epoch: 303/500... Training loss: 0.0518\n",
      "Epoch: 303/500... Training loss: 0.0075\n",
      "Epoch: 303/500... Training loss: 0.0166\n",
      "Epoch: 303/500... Training loss: 0.0133\n",
      "Epoch: 303/500... Training loss: 0.0222\n",
      "Epoch: 303/500... Training loss: 0.0418\n",
      "Epoch: 303/500... Training loss: 0.0569\n",
      "Epoch: 303/500... Training loss: 0.0338\n",
      "Epoch: 303/500... Training loss: 0.0832\n",
      "Epoch: 303/500... Training loss: 0.0082\n",
      "Epoch: 303/500... Training loss: 0.0026\n",
      "Epoch: 303/500... Training loss: 0.0032\n",
      "Epoch: 303/500... Training loss: 0.0095\n",
      "Epoch: 303/500... Training loss: 0.0105\n",
      "Epoch: 303/500... Training loss: 0.0472\n",
      "Epoch: 303/500... Training loss: 0.0114\n",
      "Epoch: 303/500... Training loss: 0.0228\n",
      "Epoch: 303/500... Training loss: 0.0201\n",
      "Epoch: 303/500... Training loss: 0.0751\n",
      "Epoch: 303/500... Training loss: 0.0502\n",
      "Epoch: 303/500... Training loss: 0.0319\n",
      "Epoch: 303/500... Training loss: 0.0028\n",
      "Epoch: 303/500... Training loss: 0.0085\n",
      "Epoch: 303/500... Training loss: 0.0560\n",
      "Epoch: 303/500... Training loss: 0.0028\n",
      "Epoch: 303/500... Training loss: 0.0055\n",
      "Epoch: 303/500... Training loss: 0.0166\n",
      "Epoch: 304/500... Training loss: 0.0579\n",
      "Epoch: 304/500... Training loss: 0.0122\n",
      "Epoch: 304/500... Training loss: 0.0693\n",
      "Epoch: 304/500... Training loss: 0.0038\n",
      "Epoch: 304/500... Training loss: 0.0522\n",
      "Epoch: 304/500... Training loss: 0.0067\n",
      "Epoch: 304/500... Training loss: 0.0155\n",
      "Epoch: 304/500... Training loss: 0.0054\n",
      "Epoch: 304/500... Training loss: 0.0038\n",
      "Epoch: 304/500... Training loss: 0.0271\n",
      "Epoch: 304/500... Training loss: 0.2332\n",
      "Epoch: 304/500... Training loss: 0.0163\n",
      "Epoch: 304/500... Training loss: 0.0401\n",
      "Epoch: 304/500... Training loss: 0.0042\n",
      "Epoch: 304/500... Training loss: 0.0020\n",
      "Epoch: 304/500... Training loss: 0.0064\n",
      "Epoch: 304/500... Training loss: 0.0079\n",
      "Epoch: 304/500... Training loss: 0.0125\n",
      "Epoch: 304/500... Training loss: 0.0514\n",
      "Epoch: 304/500... Training loss: 0.0040\n",
      "Epoch: 304/500... Training loss: 0.0231\n",
      "Epoch: 304/500... Training loss: 0.0736\n",
      "Epoch: 304/500... Training loss: 0.0095\n",
      "Epoch: 304/500... Training loss: 0.0366\n",
      "Epoch: 304/500... Training loss: 0.0067\n",
      "Epoch: 304/500... Training loss: 0.0886\n",
      "Epoch: 304/500... Training loss: 0.0602\n",
      "Epoch: 304/500... Training loss: 0.0046\n",
      "Epoch: 304/500... Training loss: 0.0075\n",
      "Epoch: 304/500... Training loss: 0.0310\n",
      "Epoch: 304/500... Training loss: 0.0693\n",
      "Epoch: 305/500... Training loss: 0.0039\n",
      "Epoch: 305/500... Training loss: 0.0089\n",
      "Epoch: 305/500... Training loss: 0.0208\n",
      "Epoch: 305/500... Training loss: 0.0079\n",
      "Epoch: 305/500... Training loss: 0.0095\n",
      "Epoch: 305/500... Training loss: 0.0120\n",
      "Epoch: 305/500... Training loss: 0.0412\n",
      "Epoch: 305/500... Training loss: 0.0026\n",
      "Epoch: 305/500... Training loss: 0.0783\n",
      "Epoch: 305/500... Training loss: 0.0652\n",
      "Epoch: 305/500... Training loss: 0.0210\n",
      "Epoch: 305/500... Training loss: 0.0096\n",
      "Epoch: 305/500... Training loss: 0.0417\n",
      "Epoch: 305/500... Training loss: 0.0219\n",
      "Epoch: 305/500... Training loss: 0.0053\n",
      "Epoch: 305/500... Training loss: 0.0161\n",
      "Epoch: 305/500... Training loss: 0.0046\n",
      "Epoch: 305/500... Training loss: 0.0014\n",
      "Epoch: 305/500... Training loss: 0.0249\n",
      "Epoch: 305/500... Training loss: 0.0649\n",
      "Epoch: 305/500... Training loss: 0.0217\n",
      "Epoch: 305/500... Training loss: 0.0246\n",
      "Epoch: 305/500... Training loss: 0.0788\n",
      "Epoch: 305/500... Training loss: 0.0080\n",
      "Epoch: 305/500... Training loss: 0.0180\n",
      "Epoch: 305/500... Training loss: 0.0202\n",
      "Epoch: 305/500... Training loss: 0.0094\n",
      "Epoch: 305/500... Training loss: 0.0206\n",
      "Epoch: 305/500... Training loss: 0.0196\n",
      "Epoch: 305/500... Training loss: 0.0146\n",
      "Epoch: 305/500... Training loss: 0.0068\n",
      "Epoch: 306/500... Training loss: 0.0411\n",
      "Epoch: 306/500... Training loss: 0.0016\n",
      "Epoch: 306/500... Training loss: 0.0153\n",
      "Epoch: 306/500... Training loss: 0.0052\n",
      "Epoch: 306/500... Training loss: 0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 306/500... Training loss: 0.0063\n",
      "Epoch: 306/500... Training loss: 0.0172\n",
      "Epoch: 306/500... Training loss: 0.0632\n",
      "Epoch: 306/500... Training loss: 0.0067\n",
      "Epoch: 306/500... Training loss: 0.0948\n",
      "Epoch: 306/500... Training loss: 0.0586\n",
      "Epoch: 306/500... Training loss: 0.0099\n",
      "Epoch: 306/500... Training loss: 0.0508\n",
      "Epoch: 306/500... Training loss: 0.0786\n",
      "Epoch: 306/500... Training loss: 0.0118\n",
      "Epoch: 306/500... Training loss: 0.0107\n",
      "Epoch: 306/500... Training loss: 0.0107\n",
      "Epoch: 306/500... Training loss: 0.0114\n",
      "Epoch: 306/500... Training loss: 0.0805\n",
      "Epoch: 306/500... Training loss: 0.0147\n",
      "Epoch: 306/500... Training loss: 0.0093\n",
      "Epoch: 306/500... Training loss: 0.0564\n",
      "Epoch: 306/500... Training loss: 0.0020\n",
      "Epoch: 306/500... Training loss: 0.0425\n",
      "Epoch: 306/500... Training loss: 0.0343\n",
      "Epoch: 306/500... Training loss: 0.0085\n",
      "Epoch: 306/500... Training loss: 0.0062\n",
      "Epoch: 306/500... Training loss: 0.0134\n",
      "Epoch: 306/500... Training loss: 0.0353\n",
      "Epoch: 306/500... Training loss: 0.0160\n",
      "Epoch: 306/500... Training loss: 0.0067\n",
      "Epoch: 307/500... Training loss: 0.0449\n",
      "Epoch: 307/500... Training loss: 0.0193\n",
      "Epoch: 307/500... Training loss: 0.0215\n",
      "Epoch: 307/500... Training loss: 0.0091\n",
      "Epoch: 307/500... Training loss: 0.0024\n",
      "Epoch: 307/500... Training loss: 0.0383\n",
      "Epoch: 307/500... Training loss: 0.0086\n",
      "Epoch: 307/500... Training loss: 0.0044\n",
      "Epoch: 307/500... Training loss: 0.0038\n",
      "Epoch: 307/500... Training loss: 0.0104\n",
      "Epoch: 307/500... Training loss: 0.0402\n",
      "Epoch: 307/500... Training loss: 0.0180\n",
      "Epoch: 307/500... Training loss: 0.0502\n",
      "Epoch: 307/500... Training loss: 0.0074\n",
      "Epoch: 307/500... Training loss: 0.0330\n",
      "Epoch: 307/500... Training loss: 0.0028\n",
      "Epoch: 307/500... Training loss: 0.0050\n",
      "Epoch: 307/500... Training loss: 0.0149\n",
      "Epoch: 307/500... Training loss: 0.0322\n",
      "Epoch: 307/500... Training loss: 0.0425\n",
      "Epoch: 307/500... Training loss: 0.0026\n",
      "Epoch: 307/500... Training loss: 0.0120\n",
      "Epoch: 307/500... Training loss: 0.0073\n",
      "Epoch: 307/500... Training loss: 0.0052\n",
      "Epoch: 307/500... Training loss: 0.0451\n",
      "Epoch: 307/500... Training loss: 0.0116\n",
      "Epoch: 307/500... Training loss: 0.0105\n",
      "Epoch: 307/500... Training loss: 0.0043\n",
      "Epoch: 307/500... Training loss: 0.0152\n",
      "Epoch: 307/500... Training loss: 0.0342\n",
      "Epoch: 307/500... Training loss: 0.0075\n",
      "Epoch: 308/500... Training loss: 0.0047\n",
      "Epoch: 308/500... Training loss: 0.0319\n",
      "Epoch: 308/500... Training loss: 0.0788\n",
      "Epoch: 308/500... Training loss: 0.0332\n",
      "Epoch: 308/500... Training loss: 0.0261\n",
      "Epoch: 308/500... Training loss: 0.0046\n",
      "Epoch: 308/500... Training loss: 0.0015\n",
      "Epoch: 308/500... Training loss: 0.0190\n",
      "Epoch: 308/500... Training loss: 0.0385\n",
      "Epoch: 308/500... Training loss: 0.0146\n",
      "Epoch: 308/500... Training loss: 0.0481\n",
      "Epoch: 308/500... Training loss: 0.0101\n",
      "Epoch: 308/500... Training loss: 0.0239\n",
      "Epoch: 308/500... Training loss: 0.0095\n",
      "Epoch: 308/500... Training loss: 0.0397\n",
      "Epoch: 308/500... Training loss: 0.0019\n",
      "Epoch: 308/500... Training loss: 0.0007\n",
      "Epoch: 308/500... Training loss: 0.0144\n",
      "Epoch: 308/500... Training loss: 0.0068\n",
      "Epoch: 308/500... Training loss: 0.0781\n",
      "Epoch: 308/500... Training loss: 0.0242\n",
      "Epoch: 308/500... Training loss: 0.0040\n",
      "Epoch: 308/500... Training loss: 0.0845\n",
      "Epoch: 308/500... Training loss: 0.0015\n",
      "Epoch: 308/500... Training loss: 0.0214\n",
      "Epoch: 308/500... Training loss: 0.0046\n",
      "Epoch: 308/500... Training loss: 0.0060\n",
      "Epoch: 308/500... Training loss: 0.0150\n",
      "Epoch: 308/500... Training loss: 0.0091\n",
      "Epoch: 308/500... Training loss: 0.0201\n",
      "Epoch: 308/500... Training loss: 0.0083\n",
      "Epoch: 309/500... Training loss: 0.0987\n",
      "Epoch: 309/500... Training loss: 0.0292\n",
      "Epoch: 309/500... Training loss: 0.0158\n",
      "Epoch: 309/500... Training loss: 0.0240\n",
      "Epoch: 309/500... Training loss: 0.0672\n",
      "Epoch: 309/500... Training loss: 0.0381\n",
      "Epoch: 309/500... Training loss: 0.0223\n",
      "Epoch: 309/500... Training loss: 0.0259\n",
      "Epoch: 309/500... Training loss: 0.0287\n",
      "Epoch: 309/500... Training loss: 0.0099\n",
      "Epoch: 309/500... Training loss: 0.1062\n",
      "Epoch: 309/500... Training loss: 0.0111\n",
      "Epoch: 309/500... Training loss: 0.0741\n",
      "Epoch: 309/500... Training loss: 0.0201\n",
      "Epoch: 309/500... Training loss: 0.0372\n",
      "Epoch: 309/500... Training loss: 0.0124\n",
      "Epoch: 309/500... Training loss: 0.0143\n",
      "Epoch: 309/500... Training loss: 0.0048\n",
      "Epoch: 309/500... Training loss: 0.0453\n",
      "Epoch: 309/500... Training loss: 0.0174\n",
      "Epoch: 309/500... Training loss: 0.0033\n",
      "Epoch: 309/500... Training loss: 0.0206\n",
      "Epoch: 309/500... Training loss: 0.0517\n",
      "Epoch: 309/500... Training loss: 0.0226\n",
      "Epoch: 309/500... Training loss: 0.0136\n",
      "Epoch: 309/500... Training loss: 0.0068\n",
      "Epoch: 309/500... Training loss: 0.1001\n",
      "Epoch: 309/500... Training loss: 0.0250\n",
      "Epoch: 309/500... Training loss: 0.0609\n",
      "Epoch: 309/500... Training loss: 0.0669\n",
      "Epoch: 309/500... Training loss: 0.0363\n",
      "Epoch: 310/500... Training loss: 0.0074\n",
      "Epoch: 310/500... Training loss: 0.0115\n",
      "Epoch: 310/500... Training loss: 0.0625\n",
      "Epoch: 310/500... Training loss: 0.0032\n",
      "Epoch: 310/500... Training loss: 0.0039\n",
      "Epoch: 310/500... Training loss: 0.0045\n",
      "Epoch: 310/500... Training loss: 0.0150\n",
      "Epoch: 310/500... Training loss: 0.0030\n",
      "Epoch: 310/500... Training loss: 0.0099\n",
      "Epoch: 310/500... Training loss: 0.0101\n",
      "Epoch: 310/500... Training loss: 0.0340\n",
      "Epoch: 310/500... Training loss: 0.0557\n",
      "Epoch: 310/500... Training loss: 0.0926\n",
      "Epoch: 310/500... Training loss: 0.0161\n",
      "Epoch: 310/500... Training loss: 0.0116\n",
      "Epoch: 310/500... Training loss: 0.0024\n",
      "Epoch: 310/500... Training loss: 0.0208\n",
      "Epoch: 310/500... Training loss: 0.0853\n",
      "Epoch: 310/500... Training loss: 0.0084\n",
      "Epoch: 310/500... Training loss: 0.0023\n",
      "Epoch: 310/500... Training loss: 0.0064\n",
      "Epoch: 310/500... Training loss: 0.0541\n",
      "Epoch: 310/500... Training loss: 0.0619\n",
      "Epoch: 310/500... Training loss: 0.0368\n",
      "Epoch: 310/500... Training loss: 0.0101\n",
      "Epoch: 310/500... Training loss: 0.0097\n",
      "Epoch: 310/500... Training loss: 0.0246\n",
      "Epoch: 310/500... Training loss: 0.0097\n",
      "Epoch: 310/500... Training loss: 0.0048\n",
      "Epoch: 310/500... Training loss: 0.0260\n",
      "Epoch: 310/500... Training loss: 0.0125\n",
      "Epoch: 311/500... Training loss: 0.0311\n",
      "Epoch: 311/500... Training loss: 0.0036\n",
      "Epoch: 311/500... Training loss: 0.0307\n",
      "Epoch: 311/500... Training loss: 0.0754\n",
      "Epoch: 311/500... Training loss: 0.0045\n",
      "Epoch: 311/500... Training loss: 0.0234\n",
      "Epoch: 311/500... Training loss: 0.0237\n",
      "Epoch: 311/500... Training loss: 0.0188\n",
      "Epoch: 311/500... Training loss: 0.0217\n",
      "Epoch: 311/500... Training loss: 0.0357\n",
      "Epoch: 311/500... Training loss: 0.0316\n",
      "Epoch: 311/500... Training loss: 0.0037\n",
      "Epoch: 311/500... Training loss: 0.0916\n",
      "Epoch: 311/500... Training loss: 0.0068\n",
      "Epoch: 311/500... Training loss: 0.0213\n",
      "Epoch: 311/500... Training loss: 0.0049\n",
      "Epoch: 311/500... Training loss: 0.0088\n",
      "Epoch: 311/500... Training loss: 0.0042\n",
      "Epoch: 311/500... Training loss: 0.0092\n",
      "Epoch: 311/500... Training loss: 0.0041\n",
      "Epoch: 311/500... Training loss: 0.0044\n",
      "Epoch: 311/500... Training loss: 0.0093\n",
      "Epoch: 311/500... Training loss: 0.0031\n",
      "Epoch: 311/500... Training loss: 0.0053\n",
      "Epoch: 311/500... Training loss: 0.0114\n",
      "Epoch: 311/500... Training loss: 0.0038\n",
      "Epoch: 311/500... Training loss: 0.0360\n",
      "Epoch: 311/500... Training loss: 0.0104\n",
      "Epoch: 311/500... Training loss: 0.0153\n",
      "Epoch: 311/500... Training loss: 0.0169\n",
      "Epoch: 311/500... Training loss: 0.0174\n",
      "Epoch: 312/500... Training loss: 0.0055\n",
      "Epoch: 312/500... Training loss: 0.0067\n",
      "Epoch: 312/500... Training loss: 0.0492\n",
      "Epoch: 312/500... Training loss: 0.0051\n",
      "Epoch: 312/500... Training loss: 0.0538\n",
      "Epoch: 312/500... Training loss: 0.0531\n",
      "Epoch: 312/500... Training loss: 0.0091\n",
      "Epoch: 312/500... Training loss: 0.0363\n",
      "Epoch: 312/500... Training loss: 0.0195\n",
      "Epoch: 312/500... Training loss: 0.0205\n",
      "Epoch: 312/500... Training loss: 0.0167\n",
      "Epoch: 312/500... Training loss: 0.0035\n",
      "Epoch: 312/500... Training loss: 0.0793\n",
      "Epoch: 312/500... Training loss: 0.0440\n",
      "Epoch: 312/500... Training loss: 0.0197\n",
      "Epoch: 312/500... Training loss: 0.0039\n",
      "Epoch: 312/500... Training loss: 0.0890\n",
      "Epoch: 312/500... Training loss: 0.0318\n",
      "Epoch: 312/500... Training loss: 0.0118\n",
      "Epoch: 312/500... Training loss: 0.0255\n",
      "Epoch: 312/500... Training loss: 0.0107\n",
      "Epoch: 312/500... Training loss: 0.0083\n",
      "Epoch: 312/500... Training loss: 0.0592\n",
      "Epoch: 312/500... Training loss: 0.0170\n",
      "Epoch: 312/500... Training loss: 0.0041\n",
      "Epoch: 312/500... Training loss: 0.0190\n",
      "Epoch: 312/500... Training loss: 0.0275\n",
      "Epoch: 312/500... Training loss: 0.0046\n",
      "Epoch: 312/500... Training loss: 0.0025\n",
      "Epoch: 312/500... Training loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 312/500... Training loss: 0.0600\n",
      "Epoch: 313/500... Training loss: 0.0303\n",
      "Epoch: 313/500... Training loss: 0.0445\n",
      "Epoch: 313/500... Training loss: 0.0233\n",
      "Epoch: 313/500... Training loss: 0.0039\n",
      "Epoch: 313/500... Training loss: 0.0095\n",
      "Epoch: 313/500... Training loss: 0.0831\n",
      "Epoch: 313/500... Training loss: 0.0126\n",
      "Epoch: 313/500... Training loss: 0.0236\n",
      "Epoch: 313/500... Training loss: 0.0048\n",
      "Epoch: 313/500... Training loss: 0.0062\n",
      "Epoch: 313/500... Training loss: 0.0060\n",
      "Epoch: 313/500... Training loss: 0.0090\n",
      "Epoch: 313/500... Training loss: 0.0208\n",
      "Epoch: 313/500... Training loss: 0.0524\n",
      "Epoch: 313/500... Training loss: 0.0444\n",
      "Epoch: 313/500... Training loss: 0.0024\n",
      "Epoch: 313/500... Training loss: 0.0047\n",
      "Epoch: 313/500... Training loss: 0.0120\n",
      "Epoch: 313/500... Training loss: 0.0443\n",
      "Epoch: 313/500... Training loss: 0.0161\n",
      "Epoch: 313/500... Training loss: 0.0063\n",
      "Epoch: 313/500... Training loss: 0.0170\n",
      "Epoch: 313/500... Training loss: 0.1180\n",
      "Epoch: 313/500... Training loss: 0.0027\n",
      "Epoch: 313/500... Training loss: 0.0066\n",
      "Epoch: 313/500... Training loss: 0.0057\n",
      "Epoch: 313/500... Training loss: 0.0068\n",
      "Epoch: 313/500... Training loss: 0.0014\n",
      "Epoch: 313/500... Training loss: 0.0251\n",
      "Epoch: 313/500... Training loss: 0.1056\n",
      "Epoch: 313/500... Training loss: 0.0503\n",
      "Epoch: 314/500... Training loss: 0.0111\n",
      "Epoch: 314/500... Training loss: 0.0588\n",
      "Epoch: 314/500... Training loss: 0.0209\n",
      "Epoch: 314/500... Training loss: 0.0547\n",
      "Epoch: 314/500... Training loss: 0.0495\n",
      "Epoch: 314/500... Training loss: 0.0121\n",
      "Epoch: 314/500... Training loss: 0.0494\n",
      "Epoch: 314/500... Training loss: 0.0452\n",
      "Epoch: 314/500... Training loss: 0.0047\n",
      "Epoch: 314/500... Training loss: 0.0206\n",
      "Epoch: 314/500... Training loss: 0.0069\n",
      "Epoch: 314/500... Training loss: 0.0241\n",
      "Epoch: 314/500... Training loss: 0.0218\n",
      "Epoch: 314/500... Training loss: 0.0108\n",
      "Epoch: 314/500... Training loss: 0.0101\n",
      "Epoch: 314/500... Training loss: 0.0392\n",
      "Epoch: 314/500... Training loss: 0.0012\n",
      "Epoch: 314/500... Training loss: 0.0069\n",
      "Epoch: 314/500... Training loss: 0.0194\n",
      "Epoch: 314/500... Training loss: 0.0458\n",
      "Epoch: 314/500... Training loss: 0.0386\n",
      "Epoch: 314/500... Training loss: 0.0114\n",
      "Epoch: 314/500... Training loss: 0.0105\n",
      "Epoch: 314/500... Training loss: 0.0063\n",
      "Epoch: 314/500... Training loss: 0.0530\n",
      "Epoch: 314/500... Training loss: 0.0023\n",
      "Epoch: 314/500... Training loss: 0.0033\n",
      "Epoch: 314/500... Training loss: 0.0275\n",
      "Epoch: 314/500... Training loss: 0.0315\n",
      "Epoch: 314/500... Training loss: 0.0439\n",
      "Epoch: 314/500... Training loss: 0.0227\n",
      "Epoch: 315/500... Training loss: 0.0065\n",
      "Epoch: 315/500... Training loss: 0.0192\n",
      "Epoch: 315/500... Training loss: 0.0039\n",
      "Epoch: 315/500... Training loss: 0.0031\n",
      "Epoch: 315/500... Training loss: 0.0053\n",
      "Epoch: 315/500... Training loss: 0.0087\n",
      "Epoch: 315/500... Training loss: 0.0331\n",
      "Epoch: 315/500... Training loss: 0.0112\n",
      "Epoch: 315/500... Training loss: 0.0097\n",
      "Epoch: 315/500... Training loss: 0.0087\n",
      "Epoch: 315/500... Training loss: 0.0836\n",
      "Epoch: 315/500... Training loss: 0.0103\n",
      "Epoch: 315/500... Training loss: 0.0513\n",
      "Epoch: 315/500... Training loss: 0.0184\n",
      "Epoch: 315/500... Training loss: 0.0134\n",
      "Epoch: 315/500... Training loss: 0.0094\n",
      "Epoch: 315/500... Training loss: 0.0380\n",
      "Epoch: 315/500... Training loss: 0.0056\n",
      "Epoch: 315/500... Training loss: 0.0108\n",
      "Epoch: 315/500... Training loss: 0.0041\n",
      "Epoch: 315/500... Training loss: 0.0088\n",
      "Epoch: 315/500... Training loss: 0.0057\n",
      "Epoch: 315/500... Training loss: 0.0519\n",
      "Epoch: 315/500... Training loss: 0.0415\n",
      "Epoch: 315/500... Training loss: 0.0826\n",
      "Epoch: 315/500... Training loss: 0.0040\n",
      "Epoch: 315/500... Training loss: 0.0447\n",
      "Epoch: 315/500... Training loss: 0.0242\n",
      "Epoch: 315/500... Training loss: 0.0056\n",
      "Epoch: 315/500... Training loss: 0.0042\n",
      "Epoch: 315/500... Training loss: 0.0016\n",
      "Epoch: 316/500... Training loss: 0.0329\n",
      "Epoch: 316/500... Training loss: 0.0480\n",
      "Epoch: 316/500... Training loss: 0.0105\n",
      "Epoch: 316/500... Training loss: 0.0854\n",
      "Epoch: 316/500... Training loss: 0.0273\n",
      "Epoch: 316/500... Training loss: 0.0701\n",
      "Epoch: 316/500... Training loss: 0.0147\n",
      "Epoch: 316/500... Training loss: 0.0020\n",
      "Epoch: 316/500... Training loss: 0.0025\n",
      "Epoch: 316/500... Training loss: 0.0086\n",
      "Epoch: 316/500... Training loss: 0.0068\n",
      "Epoch: 316/500... Training loss: 0.0094\n",
      "Epoch: 316/500... Training loss: 0.0071\n",
      "Epoch: 316/500... Training loss: 0.0164\n",
      "Epoch: 316/500... Training loss: 0.0534\n",
      "Epoch: 316/500... Training loss: 0.0229\n",
      "Epoch: 316/500... Training loss: 0.0206\n",
      "Epoch: 316/500... Training loss: 0.0028\n",
      "Epoch: 316/500... Training loss: 0.0127\n",
      "Epoch: 316/500... Training loss: 0.0055\n",
      "Epoch: 316/500... Training loss: 0.0466\n",
      "Epoch: 316/500... Training loss: 0.0072\n",
      "Epoch: 316/500... Training loss: 0.0084\n",
      "Epoch: 316/500... Training loss: 0.0154\n",
      "Epoch: 316/500... Training loss: 0.0024\n",
      "Epoch: 316/500... Training loss: 0.0103\n",
      "Epoch: 316/500... Training loss: 0.0356\n",
      "Epoch: 316/500... Training loss: 0.0341\n",
      "Epoch: 316/500... Training loss: 0.0424\n",
      "Epoch: 316/500... Training loss: 0.0537\n",
      "Epoch: 316/500... Training loss: 0.0128\n",
      "Epoch: 317/500... Training loss: 0.0397\n",
      "Epoch: 317/500... Training loss: 0.0097\n",
      "Epoch: 317/500... Training loss: 0.0191\n",
      "Epoch: 317/500... Training loss: 0.0223\n",
      "Epoch: 317/500... Training loss: 0.0497\n",
      "Epoch: 317/500... Training loss: 0.0290\n",
      "Epoch: 317/500... Training loss: 0.0057\n",
      "Epoch: 317/500... Training loss: 0.2068\n",
      "Epoch: 317/500... Training loss: 0.0111\n",
      "Epoch: 317/500... Training loss: 0.0122\n",
      "Epoch: 317/500... Training loss: 0.0479\n",
      "Epoch: 317/500... Training loss: 0.0038\n",
      "Epoch: 317/500... Training loss: 0.0023\n",
      "Epoch: 317/500... Training loss: 0.0059\n",
      "Epoch: 317/500... Training loss: 0.0068\n",
      "Epoch: 317/500... Training loss: 0.0035\n",
      "Epoch: 317/500... Training loss: 0.0076\n",
      "Epoch: 317/500... Training loss: 0.0093\n",
      "Epoch: 317/500... Training loss: 0.0031\n",
      "Epoch: 317/500... Training loss: 0.0710\n",
      "Epoch: 317/500... Training loss: 0.0085\n",
      "Epoch: 317/500... Training loss: 0.2265\n",
      "Epoch: 317/500... Training loss: 0.0124\n",
      "Epoch: 317/500... Training loss: 0.0046\n",
      "Epoch: 317/500... Training loss: 0.0168\n",
      "Epoch: 317/500... Training loss: 0.0037\n",
      "Epoch: 317/500... Training loss: 0.0437\n",
      "Epoch: 317/500... Training loss: 0.0089\n",
      "Epoch: 317/500... Training loss: 0.0031\n",
      "Epoch: 317/500... Training loss: 0.0027\n",
      "Epoch: 317/500... Training loss: 0.0393\n",
      "Epoch: 318/500... Training loss: 0.0141\n",
      "Epoch: 318/500... Training loss: 0.0062\n",
      "Epoch: 318/500... Training loss: 0.0104\n",
      "Epoch: 318/500... Training loss: 0.0135\n",
      "Epoch: 318/500... Training loss: 0.0045\n",
      "Epoch: 318/500... Training loss: 0.0075\n",
      "Epoch: 318/500... Training loss: 0.0421\n",
      "Epoch: 318/500... Training loss: 0.0219\n",
      "Epoch: 318/500... Training loss: 0.0251\n",
      "Epoch: 318/500... Training loss: 0.0743\n",
      "Epoch: 318/500... Training loss: 0.0061\n",
      "Epoch: 318/500... Training loss: 0.0669\n",
      "Epoch: 318/500... Training loss: 0.0155\n",
      "Epoch: 318/500... Training loss: 0.0082\n",
      "Epoch: 318/500... Training loss: 0.0011\n",
      "Epoch: 318/500... Training loss: 0.0113\n",
      "Epoch: 318/500... Training loss: 0.0309\n",
      "Epoch: 318/500... Training loss: 0.0117\n",
      "Epoch: 318/500... Training loss: 0.0982\n",
      "Epoch: 318/500... Training loss: 0.0091\n",
      "Epoch: 318/500... Training loss: 0.0455\n",
      "Epoch: 318/500... Training loss: 0.0636\n",
      "Epoch: 318/500... Training loss: 0.0029\n",
      "Epoch: 318/500... Training loss: 0.0323\n",
      "Epoch: 318/500... Training loss: 0.0018\n",
      "Epoch: 318/500... Training loss: 0.0056\n",
      "Epoch: 318/500... Training loss: 0.0649\n",
      "Epoch: 318/500... Training loss: 0.0191\n",
      "Epoch: 318/500... Training loss: 0.0040\n",
      "Epoch: 318/500... Training loss: 0.0065\n",
      "Epoch: 318/500... Training loss: 0.0163\n",
      "Epoch: 319/500... Training loss: 0.0028\n",
      "Epoch: 319/500... Training loss: 0.0259\n",
      "Epoch: 319/500... Training loss: 0.0065\n",
      "Epoch: 319/500... Training loss: 0.0014\n",
      "Epoch: 319/500... Training loss: 0.0482\n",
      "Epoch: 319/500... Training loss: 0.0386\n",
      "Epoch: 319/500... Training loss: 0.0179\n",
      "Epoch: 319/500... Training loss: 0.0048\n",
      "Epoch: 319/500... Training loss: 0.0200\n",
      "Epoch: 319/500... Training loss: 0.0048\n",
      "Epoch: 319/500... Training loss: 0.0012\n",
      "Epoch: 319/500... Training loss: 0.0057\n",
      "Epoch: 319/500... Training loss: 0.0078\n",
      "Epoch: 319/500... Training loss: 0.0053\n",
      "Epoch: 319/500... Training loss: 0.0109\n",
      "Epoch: 319/500... Training loss: 0.0042\n",
      "Epoch: 319/500... Training loss: 0.0208\n",
      "Epoch: 319/500... Training loss: 0.0665\n",
      "Epoch: 319/500... Training loss: 0.0099\n",
      "Epoch: 319/500... Training loss: 0.0058\n",
      "Epoch: 319/500... Training loss: 0.0039\n",
      "Epoch: 319/500... Training loss: 0.0863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 319/500... Training loss: 0.0056\n",
      "Epoch: 319/500... Training loss: 0.0072\n",
      "Epoch: 319/500... Training loss: 0.0024\n",
      "Epoch: 319/500... Training loss: 0.0076\n",
      "Epoch: 319/500... Training loss: 0.0048\n",
      "Epoch: 319/500... Training loss: 0.0131\n",
      "Epoch: 319/500... Training loss: 0.0186\n",
      "Epoch: 319/500... Training loss: 0.0262\n",
      "Epoch: 319/500... Training loss: 0.0056\n",
      "Epoch: 320/500... Training loss: 0.0018\n",
      "Epoch: 320/500... Training loss: 0.0083\n",
      "Epoch: 320/500... Training loss: 0.0199\n",
      "Epoch: 320/500... Training loss: 0.0066\n",
      "Epoch: 320/500... Training loss: 0.0830\n",
      "Epoch: 320/500... Training loss: 0.0238\n",
      "Epoch: 320/500... Training loss: 0.0216\n",
      "Epoch: 320/500... Training loss: 0.0206\n",
      "Epoch: 320/500... Training loss: 0.0200\n",
      "Epoch: 320/500... Training loss: 0.0023\n",
      "Epoch: 320/500... Training loss: 0.0291\n",
      "Epoch: 320/500... Training loss: 0.0364\n",
      "Epoch: 320/500... Training loss: 0.0047\n",
      "Epoch: 320/500... Training loss: 0.0153\n",
      "Epoch: 320/500... Training loss: 0.0072\n",
      "Epoch: 320/500... Training loss: 0.0033\n",
      "Epoch: 320/500... Training loss: 0.0112\n",
      "Epoch: 320/500... Training loss: 0.0320\n",
      "Epoch: 320/500... Training loss: 0.0133\n",
      "Epoch: 320/500... Training loss: 0.0032\n",
      "Epoch: 320/500... Training loss: 0.0222\n",
      "Epoch: 320/500... Training loss: 0.0195\n",
      "Epoch: 320/500... Training loss: 0.0149\n",
      "Epoch: 320/500... Training loss: 0.0119\n",
      "Epoch: 320/500... Training loss: 0.0036\n",
      "Epoch: 320/500... Training loss: 0.0062\n",
      "Epoch: 320/500... Training loss: 0.0301\n",
      "Epoch: 320/500... Training loss: 0.0326\n",
      "Epoch: 320/500... Training loss: 0.0076\n",
      "Epoch: 320/500... Training loss: 0.0212\n",
      "Epoch: 320/500... Training loss: 0.0030\n",
      "Epoch: 321/500... Training loss: 0.0043\n",
      "Epoch: 321/500... Training loss: 0.0547\n",
      "Epoch: 321/500... Training loss: 0.0419\n",
      "Epoch: 321/500... Training loss: 0.0182\n",
      "Epoch: 321/500... Training loss: 0.0056\n",
      "Epoch: 321/500... Training loss: 0.0091\n",
      "Epoch: 321/500... Training loss: 0.0555\n",
      "Epoch: 321/500... Training loss: 0.0130\n",
      "Epoch: 321/500... Training loss: 0.0018\n",
      "Epoch: 321/500... Training loss: 0.0212\n",
      "Epoch: 321/500... Training loss: 0.0080\n",
      "Epoch: 321/500... Training loss: 0.0397\n",
      "Epoch: 321/500... Training loss: 0.0049\n",
      "Epoch: 321/500... Training loss: 0.0819\n",
      "Epoch: 321/500... Training loss: 0.0058\n",
      "Epoch: 321/500... Training loss: 0.0229\n",
      "Epoch: 321/500... Training loss: 0.0173\n",
      "Epoch: 321/500... Training loss: 0.0045\n",
      "Epoch: 321/500... Training loss: 0.0139\n",
      "Epoch: 321/500... Training loss: 0.0305\n",
      "Epoch: 321/500... Training loss: 0.0023\n",
      "Epoch: 321/500... Training loss: 0.0822\n",
      "Epoch: 321/500... Training loss: 0.0031\n",
      "Epoch: 321/500... Training loss: 0.0015\n",
      "Epoch: 321/500... Training loss: 0.0016\n",
      "Epoch: 321/500... Training loss: 0.0242\n",
      "Epoch: 321/500... Training loss: 0.0668\n",
      "Epoch: 321/500... Training loss: 0.0018\n",
      "Epoch: 321/500... Training loss: 0.0878\n",
      "Epoch: 321/500... Training loss: 0.0840\n",
      "Epoch: 321/500... Training loss: 0.0074\n",
      "Epoch: 322/500... Training loss: 0.0021\n",
      "Epoch: 322/500... Training loss: 0.0243\n",
      "Epoch: 322/500... Training loss: 0.0040\n",
      "Epoch: 322/500... Training loss: 0.0095\n",
      "Epoch: 322/500... Training loss: 0.0175\n",
      "Epoch: 322/500... Training loss: 0.0398\n",
      "Epoch: 322/500... Training loss: 0.0195\n",
      "Epoch: 322/500... Training loss: 0.0154\n",
      "Epoch: 322/500... Training loss: 0.0295\n",
      "Epoch: 322/500... Training loss: 0.0069\n",
      "Epoch: 322/500... Training loss: 0.1189\n",
      "Epoch: 322/500... Training loss: 0.0148\n",
      "Epoch: 322/500... Training loss: 0.0085\n",
      "Epoch: 322/500... Training loss: 0.0044\n",
      "Epoch: 322/500... Training loss: 0.0054\n",
      "Epoch: 322/500... Training loss: 0.0346\n",
      "Epoch: 322/500... Training loss: 0.0606\n",
      "Epoch: 322/500... Training loss: 0.0038\n",
      "Epoch: 322/500... Training loss: 0.0052\n",
      "Epoch: 322/500... Training loss: 0.0102\n",
      "Epoch: 322/500... Training loss: 0.0145\n",
      "Epoch: 322/500... Training loss: 0.0028\n",
      "Epoch: 322/500... Training loss: 0.0223\n",
      "Epoch: 322/500... Training loss: 0.0082\n",
      "Epoch: 322/500... Training loss: 0.0385\n",
      "Epoch: 322/500... Training loss: 0.0687\n",
      "Epoch: 322/500... Training loss: 0.0071\n",
      "Epoch: 322/500... Training loss: 0.0109\n",
      "Epoch: 322/500... Training loss: 0.0086\n",
      "Epoch: 322/500... Training loss: 0.0120\n",
      "Epoch: 322/500... Training loss: 0.0049\n",
      "Epoch: 323/500... Training loss: 0.0021\n",
      "Epoch: 323/500... Training loss: 0.0028\n",
      "Epoch: 323/500... Training loss: 0.0558\n",
      "Epoch: 323/500... Training loss: 0.0053\n",
      "Epoch: 323/500... Training loss: 0.0834\n",
      "Epoch: 323/500... Training loss: 0.0092\n",
      "Epoch: 323/500... Training loss: 0.0304\n",
      "Epoch: 323/500... Training loss: 0.0193\n",
      "Epoch: 323/500... Training loss: 0.0132\n",
      "Epoch: 323/500... Training loss: 0.0493\n",
      "Epoch: 323/500... Training loss: 0.0479\n",
      "Epoch: 323/500... Training loss: 0.0331\n",
      "Epoch: 323/500... Training loss: 0.0035\n",
      "Epoch: 323/500... Training loss: 0.0118\n",
      "Epoch: 323/500... Training loss: 0.0083\n",
      "Epoch: 323/500... Training loss: 0.0059\n",
      "Epoch: 323/500... Training loss: 0.0146\n",
      "Epoch: 323/500... Training loss: 0.0033\n",
      "Epoch: 323/500... Training loss: 0.0069\n",
      "Epoch: 323/500... Training loss: 0.0557\n",
      "Epoch: 323/500... Training loss: 0.0022\n",
      "Epoch: 323/500... Training loss: 0.0624\n",
      "Epoch: 323/500... Training loss: 0.0163\n",
      "Epoch: 323/500... Training loss: 0.0038\n",
      "Epoch: 323/500... Training loss: 0.0041\n",
      "Epoch: 323/500... Training loss: 0.0378\n",
      "Epoch: 323/500... Training loss: 0.0141\n",
      "Epoch: 323/500... Training loss: 0.0238\n",
      "Epoch: 323/500... Training loss: 0.0853\n",
      "Epoch: 323/500... Training loss: 0.0437\n",
      "Epoch: 323/500... Training loss: 0.0071\n",
      "Epoch: 324/500... Training loss: 0.0141\n",
      "Epoch: 324/500... Training loss: 0.1831\n",
      "Epoch: 324/500... Training loss: 0.0447\n",
      "Epoch: 324/500... Training loss: 0.0251\n",
      "Epoch: 324/500... Training loss: 0.0019\n",
      "Epoch: 324/500... Training loss: 0.0455\n",
      "Epoch: 324/500... Training loss: 0.0372\n",
      "Epoch: 324/500... Training loss: 0.0079\n",
      "Epoch: 324/500... Training loss: 0.0075\n",
      "Epoch: 324/500... Training loss: 0.0312\n",
      "Epoch: 324/500... Training loss: 0.0252\n",
      "Epoch: 324/500... Training loss: 0.0165\n",
      "Epoch: 324/500... Training loss: 0.0057\n",
      "Epoch: 324/500... Training loss: 0.0097\n",
      "Epoch: 324/500... Training loss: 0.0109\n",
      "Epoch: 324/500... Training loss: 0.0310\n",
      "Epoch: 324/500... Training loss: 0.0591\n",
      "Epoch: 324/500... Training loss: 0.0117\n",
      "Epoch: 324/500... Training loss: 0.0606\n",
      "Epoch: 324/500... Training loss: 0.0191\n",
      "Epoch: 324/500... Training loss: 0.0174\n",
      "Epoch: 324/500... Training loss: 0.0075\n",
      "Epoch: 324/500... Training loss: 0.0500\n",
      "Epoch: 324/500... Training loss: 0.0153\n",
      "Epoch: 324/500... Training loss: 0.0299\n",
      "Epoch: 324/500... Training loss: 0.0435\n",
      "Epoch: 324/500... Training loss: 0.0654\n",
      "Epoch: 324/500... Training loss: 0.0107\n",
      "Epoch: 324/500... Training loss: 0.0031\n",
      "Epoch: 324/500... Training loss: 0.0036\n",
      "Epoch: 324/500... Training loss: 0.0319\n",
      "Epoch: 325/500... Training loss: 0.0481\n",
      "Epoch: 325/500... Training loss: 0.0214\n",
      "Epoch: 325/500... Training loss: 0.0029\n",
      "Epoch: 325/500... Training loss: 0.0809\n",
      "Epoch: 325/500... Training loss: 0.0220\n",
      "Epoch: 325/500... Training loss: 0.0138\n",
      "Epoch: 325/500... Training loss: 0.0872\n",
      "Epoch: 325/500... Training loss: 0.0263\n",
      "Epoch: 325/500... Training loss: 0.0170\n",
      "Epoch: 325/500... Training loss: 0.0040\n",
      "Epoch: 325/500... Training loss: 0.0584\n",
      "Epoch: 325/500... Training loss: 0.0516\n",
      "Epoch: 325/500... Training loss: 0.0049\n",
      "Epoch: 325/500... Training loss: 0.0737\n",
      "Epoch: 325/500... Training loss: 0.0404\n",
      "Epoch: 325/500... Training loss: 0.0113\n",
      "Epoch: 325/500... Training loss: 0.0029\n",
      "Epoch: 325/500... Training loss: 0.0027\n",
      "Epoch: 325/500... Training loss: 0.0327\n",
      "Epoch: 325/500... Training loss: 0.0022\n",
      "Epoch: 325/500... Training loss: 0.0168\n",
      "Epoch: 325/500... Training loss: 0.0213\n",
      "Epoch: 325/500... Training loss: 0.0243\n",
      "Epoch: 325/500... Training loss: 0.0065\n",
      "Epoch: 325/500... Training loss: 0.0037\n",
      "Epoch: 325/500... Training loss: 0.0959\n",
      "Epoch: 325/500... Training loss: 0.0578\n",
      "Epoch: 325/500... Training loss: 0.0389\n",
      "Epoch: 325/500... Training loss: 0.0211\n",
      "Epoch: 325/500... Training loss: 0.0041\n",
      "Epoch: 325/500... Training loss: 0.0663\n",
      "Epoch: 326/500... Training loss: 0.0023\n",
      "Epoch: 326/500... Training loss: 0.0204\n",
      "Epoch: 326/500... Training loss: 0.1105\n",
      "Epoch: 326/500... Training loss: 0.0117\n",
      "Epoch: 326/500... Training loss: 0.0010\n",
      "Epoch: 326/500... Training loss: 0.0031\n",
      "Epoch: 326/500... Training loss: 0.0053\n",
      "Epoch: 326/500... Training loss: 0.0037\n",
      "Epoch: 326/500... Training loss: 0.0474\n",
      "Epoch: 326/500... Training loss: 0.0127\n",
      "Epoch: 326/500... Training loss: 0.0251\n",
      "Epoch: 326/500... Training loss: 0.0426\n",
      "Epoch: 326/500... Training loss: 0.0076\n",
      "Epoch: 326/500... Training loss: 0.0054\n",
      "Epoch: 326/500... Training loss: 0.0028\n",
      "Epoch: 326/500... Training loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 326/500... Training loss: 0.0027\n",
      "Epoch: 326/500... Training loss: 0.0916\n",
      "Epoch: 326/500... Training loss: 0.0598\n",
      "Epoch: 326/500... Training loss: 0.0195\n",
      "Epoch: 326/500... Training loss: 0.0068\n",
      "Epoch: 326/500... Training loss: 0.0309\n",
      "Epoch: 326/500... Training loss: 0.0040\n",
      "Epoch: 326/500... Training loss: 0.0043\n",
      "Epoch: 326/500... Training loss: 0.0372\n",
      "Epoch: 326/500... Training loss: 0.0273\n",
      "Epoch: 326/500... Training loss: 0.0072\n",
      "Epoch: 326/500... Training loss: 0.0237\n",
      "Epoch: 326/500... Training loss: 0.0032\n",
      "Epoch: 326/500... Training loss: 0.0081\n",
      "Epoch: 326/500... Training loss: 0.0065\n",
      "Epoch: 327/500... Training loss: 0.0088\n",
      "Epoch: 327/500... Training loss: 0.1162\n",
      "Epoch: 327/500... Training loss: 0.0075\n",
      "Epoch: 327/500... Training loss: 0.0767\n",
      "Epoch: 327/500... Training loss: 0.0036\n",
      "Epoch: 327/500... Training loss: 0.0078\n",
      "Epoch: 327/500... Training loss: 0.0168\n",
      "Epoch: 327/500... Training loss: 0.0389\n",
      "Epoch: 327/500... Training loss: 0.0019\n",
      "Epoch: 327/500... Training loss: 0.0097\n",
      "Epoch: 327/500... Training loss: 0.0120\n",
      "Epoch: 327/500... Training loss: 0.0484\n",
      "Epoch: 327/500... Training loss: 0.0154\n",
      "Epoch: 327/500... Training loss: 0.0045\n",
      "Epoch: 327/500... Training loss: 0.0168\n",
      "Epoch: 327/500... Training loss: 0.0022\n",
      "Epoch: 327/500... Training loss: 0.0209\n",
      "Epoch: 327/500... Training loss: 0.0021\n",
      "Epoch: 327/500... Training loss: 0.0378\n",
      "Epoch: 327/500... Training loss: 0.0049\n",
      "Epoch: 327/500... Training loss: 0.0077\n",
      "Epoch: 327/500... Training loss: 0.0012\n",
      "Epoch: 327/500... Training loss: 0.0177\n",
      "Epoch: 327/500... Training loss: 0.0132\n",
      "Epoch: 327/500... Training loss: 0.0081\n",
      "Epoch: 327/500... Training loss: 0.0025\n",
      "Epoch: 327/500... Training loss: 0.0089\n",
      "Epoch: 327/500... Training loss: 0.0092\n",
      "Epoch: 327/500... Training loss: 0.0042\n",
      "Epoch: 327/500... Training loss: 0.0154\n",
      "Epoch: 327/500... Training loss: 0.0077\n",
      "Epoch: 328/500... Training loss: 0.0062\n",
      "Epoch: 328/500... Training loss: 0.0185\n",
      "Epoch: 328/500... Training loss: 0.0632\n",
      "Epoch: 328/500... Training loss: 0.0197\n",
      "Epoch: 328/500... Training loss: 0.0172\n",
      "Epoch: 328/500... Training loss: 0.0061\n",
      "Epoch: 328/500... Training loss: 0.0133\n",
      "Epoch: 328/500... Training loss: 0.0275\n",
      "Epoch: 328/500... Training loss: 0.0212\n",
      "Epoch: 328/500... Training loss: 0.0044\n",
      "Epoch: 328/500... Training loss: 0.0234\n",
      "Epoch: 328/500... Training loss: 0.0055\n",
      "Epoch: 328/500... Training loss: 0.0259\n",
      "Epoch: 328/500... Training loss: 0.0037\n",
      "Epoch: 328/500... Training loss: 0.0057\n",
      "Epoch: 328/500... Training loss: 0.0016\n",
      "Epoch: 328/500... Training loss: 0.0031\n",
      "Epoch: 328/500... Training loss: 0.0020\n",
      "Epoch: 328/500... Training loss: 0.0445\n",
      "Epoch: 328/500... Training loss: 0.0025\n",
      "Epoch: 328/500... Training loss: 0.0018\n",
      "Epoch: 328/500... Training loss: 0.0193\n",
      "Epoch: 328/500... Training loss: 0.0062\n",
      "Epoch: 328/500... Training loss: 0.0121\n",
      "Epoch: 328/500... Training loss: 0.0545\n",
      "Epoch: 328/500... Training loss: 0.0057\n",
      "Epoch: 328/500... Training loss: 0.0039\n",
      "Epoch: 328/500... Training loss: 0.0399\n",
      "Epoch: 328/500... Training loss: 0.1094\n",
      "Epoch: 328/500... Training loss: 0.0118\n",
      "Epoch: 328/500... Training loss: 0.0211\n",
      "Epoch: 329/500... Training loss: 0.0040\n",
      "Epoch: 329/500... Training loss: 0.0020\n",
      "Epoch: 329/500... Training loss: 0.0173\n",
      "Epoch: 329/500... Training loss: 0.0035\n",
      "Epoch: 329/500... Training loss: 0.0016\n",
      "Epoch: 329/500... Training loss: 0.0725\n",
      "Epoch: 329/500... Training loss: 0.0390\n",
      "Epoch: 329/500... Training loss: 0.1105\n",
      "Epoch: 329/500... Training loss: 0.0625\n",
      "Epoch: 329/500... Training loss: 0.0225\n",
      "Epoch: 329/500... Training loss: 0.0056\n",
      "Epoch: 329/500... Training loss: 0.0144\n",
      "Epoch: 329/500... Training loss: 0.0899\n",
      "Epoch: 329/500... Training loss: 0.0558\n",
      "Epoch: 329/500... Training loss: 0.0404\n",
      "Epoch: 329/500... Training loss: 0.0033\n",
      "Epoch: 329/500... Training loss: 0.0169\n",
      "Epoch: 329/500... Training loss: 0.0295\n",
      "Epoch: 329/500... Training loss: 0.0249\n",
      "Epoch: 329/500... Training loss: 0.0029\n",
      "Epoch: 329/500... Training loss: 0.0103\n",
      "Epoch: 329/500... Training loss: 0.0148\n",
      "Epoch: 329/500... Training loss: 0.0169\n",
      "Epoch: 329/500... Training loss: 0.0028\n",
      "Epoch: 329/500... Training loss: 0.0476\n",
      "Epoch: 329/500... Training loss: 0.0167\n",
      "Epoch: 329/500... Training loss: 0.0034\n",
      "Epoch: 329/500... Training loss: 0.0044\n",
      "Epoch: 329/500... Training loss: 0.0136\n",
      "Epoch: 329/500... Training loss: 0.0030\n",
      "Epoch: 329/500... Training loss: 0.0014\n",
      "Epoch: 330/500... Training loss: 0.0569\n",
      "Epoch: 330/500... Training loss: 0.0032\n",
      "Epoch: 330/500... Training loss: 0.0809\n",
      "Epoch: 330/500... Training loss: 0.0036\n",
      "Epoch: 330/500... Training loss: 0.0560\n",
      "Epoch: 330/500... Training loss: 0.0082\n",
      "Epoch: 330/500... Training loss: 0.0080\n",
      "Epoch: 330/500... Training loss: 0.0288\n",
      "Epoch: 330/500... Training loss: 0.0037\n",
      "Epoch: 330/500... Training loss: 0.0153\n",
      "Epoch: 330/500... Training loss: 0.0268\n",
      "Epoch: 330/500... Training loss: 0.0070\n",
      "Epoch: 330/500... Training loss: 0.0962\n",
      "Epoch: 330/500... Training loss: 0.0181\n",
      "Epoch: 330/500... Training loss: 0.0107\n",
      "Epoch: 330/500... Training loss: 0.0021\n",
      "Epoch: 330/500... Training loss: 0.0124\n",
      "Epoch: 330/500... Training loss: 0.0241\n",
      "Epoch: 330/500... Training loss: 0.0208\n",
      "Epoch: 330/500... Training loss: 0.0209\n",
      "Epoch: 330/500... Training loss: 0.0051\n",
      "Epoch: 330/500... Training loss: 0.0110\n",
      "Epoch: 330/500... Training loss: 0.0534\n",
      "Epoch: 330/500... Training loss: 0.0126\n",
      "Epoch: 330/500... Training loss: 0.0358\n",
      "Epoch: 330/500... Training loss: 0.0256\n",
      "Epoch: 330/500... Training loss: 0.0085\n",
      "Epoch: 330/500... Training loss: 0.0215\n",
      "Epoch: 330/500... Training loss: 0.0025\n",
      "Epoch: 330/500... Training loss: 0.0042\n",
      "Epoch: 330/500... Training loss: 0.0075\n",
      "Epoch: 331/500... Training loss: 0.0143\n",
      "Epoch: 331/500... Training loss: 0.0385\n",
      "Epoch: 331/500... Training loss: 0.0079\n",
      "Epoch: 331/500... Training loss: 0.0352\n",
      "Epoch: 331/500... Training loss: 0.0173\n",
      "Epoch: 331/500... Training loss: 0.0310\n",
      "Epoch: 331/500... Training loss: 0.0053\n",
      "Epoch: 331/500... Training loss: 0.0130\n",
      "Epoch: 331/500... Training loss: 0.0075\n",
      "Epoch: 331/500... Training loss: 0.1183\n",
      "Epoch: 331/500... Training loss: 0.0239\n",
      "Epoch: 331/500... Training loss: 0.0116\n",
      "Epoch: 331/500... Training loss: 0.0739\n",
      "Epoch: 331/500... Training loss: 0.0045\n",
      "Epoch: 331/500... Training loss: 0.0060\n",
      "Epoch: 331/500... Training loss: 0.0197\n",
      "Epoch: 331/500... Training loss: 0.0018\n",
      "Epoch: 331/500... Training loss: 0.0020\n",
      "Epoch: 331/500... Training loss: 0.0299\n",
      "Epoch: 331/500... Training loss: 0.0244\n",
      "Epoch: 331/500... Training loss: 0.0187\n",
      "Epoch: 331/500... Training loss: 0.0109\n",
      "Epoch: 331/500... Training loss: 0.0608\n",
      "Epoch: 331/500... Training loss: 0.0121\n",
      "Epoch: 331/500... Training loss: 0.0203\n",
      "Epoch: 331/500... Training loss: 0.0164\n",
      "Epoch: 331/500... Training loss: 0.0048\n",
      "Epoch: 331/500... Training loss: 0.0092\n",
      "Epoch: 331/500... Training loss: 0.0062\n",
      "Epoch: 331/500... Training loss: 0.0097\n",
      "Epoch: 331/500... Training loss: 0.0031\n",
      "Epoch: 332/500... Training loss: 0.0354\n",
      "Epoch: 332/500... Training loss: 0.0009\n",
      "Epoch: 332/500... Training loss: 0.0047\n",
      "Epoch: 332/500... Training loss: 0.0020\n",
      "Epoch: 332/500... Training loss: 0.0079\n",
      "Epoch: 332/500... Training loss: 0.0027\n",
      "Epoch: 332/500... Training loss: 0.0044\n",
      "Epoch: 332/500... Training loss: 0.0790\n",
      "Epoch: 332/500... Training loss: 0.0195\n",
      "Epoch: 332/500... Training loss: 0.0053\n",
      "Epoch: 332/500... Training loss: 0.0132\n",
      "Epoch: 332/500... Training loss: 0.0172\n",
      "Epoch: 332/500... Training loss: 0.0074\n",
      "Epoch: 332/500... Training loss: 0.0230\n",
      "Epoch: 332/500... Training loss: 0.0092\n",
      "Epoch: 332/500... Training loss: 0.0038\n",
      "Epoch: 332/500... Training loss: 0.0030\n",
      "Epoch: 332/500... Training loss: 0.0355\n",
      "Epoch: 332/500... Training loss: 0.0070\n",
      "Epoch: 332/500... Training loss: 0.0046\n",
      "Epoch: 332/500... Training loss: 0.0111\n",
      "Epoch: 332/500... Training loss: 0.0107\n",
      "Epoch: 332/500... Training loss: 0.0057\n",
      "Epoch: 332/500... Training loss: 0.0029\n",
      "Epoch: 332/500... Training loss: 0.0270\n",
      "Epoch: 332/500... Training loss: 0.0547\n",
      "Epoch: 332/500... Training loss: 0.0083\n",
      "Epoch: 332/500... Training loss: 0.0023\n",
      "Epoch: 332/500... Training loss: 0.0129\n",
      "Epoch: 332/500... Training loss: 0.0256\n",
      "Epoch: 332/500... Training loss: 0.0091\n",
      "Epoch: 333/500... Training loss: 0.0087\n",
      "Epoch: 333/500... Training loss: 0.0093\n",
      "Epoch: 333/500... Training loss: 0.0162\n",
      "Epoch: 333/500... Training loss: 0.0100\n",
      "Epoch: 333/500... Training loss: 0.0099\n",
      "Epoch: 333/500... Training loss: 0.0131\n",
      "Epoch: 333/500... Training loss: 0.0019\n",
      "Epoch: 333/500... Training loss: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 333/500... Training loss: 0.0098\n",
      "Epoch: 333/500... Training loss: 0.0067\n",
      "Epoch: 333/500... Training loss: 0.0375\n",
      "Epoch: 333/500... Training loss: 0.0043\n",
      "Epoch: 333/500... Training loss: 0.0268\n",
      "Epoch: 333/500... Training loss: 0.0106\n",
      "Epoch: 333/500... Training loss: 0.1324\n",
      "Epoch: 333/500... Training loss: 0.0144\n",
      "Epoch: 333/500... Training loss: 0.0228\n",
      "Epoch: 333/500... Training loss: 0.0080\n",
      "Epoch: 333/500... Training loss: 0.1039\n",
      "Epoch: 333/500... Training loss: 0.0011\n",
      "Epoch: 333/500... Training loss: 0.0379\n",
      "Epoch: 333/500... Training loss: 0.0068\n",
      "Epoch: 333/500... Training loss: 0.0076\n",
      "Epoch: 333/500... Training loss: 0.0034\n",
      "Epoch: 333/500... Training loss: 0.0197\n",
      "Epoch: 333/500... Training loss: 0.0024\n",
      "Epoch: 333/500... Training loss: 0.0150\n",
      "Epoch: 333/500... Training loss: 0.0442\n",
      "Epoch: 333/500... Training loss: 0.0027\n",
      "Epoch: 333/500... Training loss: 0.0037\n",
      "Epoch: 333/500... Training loss: 0.0109\n",
      "Epoch: 334/500... Training loss: 0.1145\n",
      "Epoch: 334/500... Training loss: 0.0032\n",
      "Epoch: 334/500... Training loss: 0.0990\n",
      "Epoch: 334/500... Training loss: 0.0180\n",
      "Epoch: 334/500... Training loss: 0.0341\n",
      "Epoch: 334/500... Training loss: 0.0033\n",
      "Epoch: 334/500... Training loss: 0.0363\n",
      "Epoch: 334/500... Training loss: 0.0919\n",
      "Epoch: 334/500... Training loss: 0.0038\n",
      "Epoch: 334/500... Training loss: 0.0055\n",
      "Epoch: 334/500... Training loss: 0.0190\n",
      "Epoch: 334/500... Training loss: 0.0061\n",
      "Epoch: 334/500... Training loss: 0.0124\n",
      "Epoch: 334/500... Training loss: 0.0056\n",
      "Epoch: 334/500... Training loss: 0.0222\n",
      "Epoch: 334/500... Training loss: 0.0054\n",
      "Epoch: 334/500... Training loss: 0.0013\n",
      "Epoch: 334/500... Training loss: 0.0071\n",
      "Epoch: 334/500... Training loss: 0.0513\n",
      "Epoch: 334/500... Training loss: 0.0041\n",
      "Epoch: 334/500... Training loss: 0.0587\n",
      "Epoch: 334/500... Training loss: 0.0436\n",
      "Epoch: 334/500... Training loss: 0.0099\n",
      "Epoch: 334/500... Training loss: 0.0090\n",
      "Epoch: 334/500... Training loss: 0.0174\n",
      "Epoch: 334/500... Training loss: 0.0017\n",
      "Epoch: 334/500... Training loss: 0.0306\n",
      "Epoch: 334/500... Training loss: 0.0214\n",
      "Epoch: 334/500... Training loss: 0.0090\n",
      "Epoch: 334/500... Training loss: 0.0034\n",
      "Epoch: 334/500... Training loss: 0.0070\n",
      "Epoch: 335/500... Training loss: 0.0018\n",
      "Epoch: 335/500... Training loss: 0.0098\n",
      "Epoch: 335/500... Training loss: 0.1369\n",
      "Epoch: 335/500... Training loss: 0.0090\n",
      "Epoch: 335/500... Training loss: 0.0025\n",
      "Epoch: 335/500... Training loss: 0.0070\n",
      "Epoch: 335/500... Training loss: 0.0300\n",
      "Epoch: 335/500... Training loss: 0.0094\n",
      "Epoch: 335/500... Training loss: 0.0179\n",
      "Epoch: 335/500... Training loss: 0.0053\n",
      "Epoch: 335/500... Training loss: 0.0171\n",
      "Epoch: 335/500... Training loss: 0.0052\n",
      "Epoch: 335/500... Training loss: 0.0036\n",
      "Epoch: 335/500... Training loss: 0.0218\n",
      "Epoch: 335/500... Training loss: 0.0030\n",
      "Epoch: 335/500... Training loss: 0.0171\n",
      "Epoch: 335/500... Training loss: 0.0010\n",
      "Epoch: 335/500... Training loss: 0.0438\n",
      "Epoch: 335/500... Training loss: 0.0074\n",
      "Epoch: 335/500... Training loss: 0.0125\n",
      "Epoch: 335/500... Training loss: 0.0078\n",
      "Epoch: 335/500... Training loss: 0.0602\n",
      "Epoch: 335/500... Training loss: 0.0076\n",
      "Epoch: 335/500... Training loss: 0.0797\n",
      "Epoch: 335/500... Training loss: 0.0305\n",
      "Epoch: 335/500... Training loss: 0.0140\n",
      "Epoch: 335/500... Training loss: 0.0187\n",
      "Epoch: 335/500... Training loss: 0.0465\n",
      "Epoch: 335/500... Training loss: 0.0011\n",
      "Epoch: 335/500... Training loss: 0.0053\n",
      "Epoch: 335/500... Training loss: 0.0027\n",
      "Epoch: 336/500... Training loss: 0.0074\n",
      "Epoch: 336/500... Training loss: 0.0099\n",
      "Epoch: 336/500... Training loss: 0.0070\n",
      "Epoch: 336/500... Training loss: 0.0585\n",
      "Epoch: 336/500... Training loss: 0.0223\n",
      "Epoch: 336/500... Training loss: 0.0019\n",
      "Epoch: 336/500... Training loss: 0.0313\n",
      "Epoch: 336/500... Training loss: 0.0041\n",
      "Epoch: 336/500... Training loss: 0.0014\n",
      "Epoch: 336/500... Training loss: 0.0182\n",
      "Epoch: 336/500... Training loss: 0.3674\n",
      "Epoch: 336/500... Training loss: 0.0269\n",
      "Epoch: 336/500... Training loss: 0.0036\n",
      "Epoch: 336/500... Training loss: 0.0288\n",
      "Epoch: 336/500... Training loss: 0.0161\n",
      "Epoch: 336/500... Training loss: 0.0016\n",
      "Epoch: 336/500... Training loss: 0.0254\n",
      "Epoch: 336/500... Training loss: 0.0021\n",
      "Epoch: 336/500... Training loss: 0.0602\n",
      "Epoch: 336/500... Training loss: 0.0207\n",
      "Epoch: 336/500... Training loss: 0.0184\n",
      "Epoch: 336/500... Training loss: 0.0236\n",
      "Epoch: 336/500... Training loss: 0.0448\n",
      "Epoch: 336/500... Training loss: 0.0088\n",
      "Epoch: 336/500... Training loss: 0.0181\n",
      "Epoch: 336/500... Training loss: 0.0284\n",
      "Epoch: 336/500... Training loss: 0.0569\n",
      "Epoch: 336/500... Training loss: 0.0113\n",
      "Epoch: 336/500... Training loss: 0.0768\n",
      "Epoch: 336/500... Training loss: 0.0575\n",
      "Epoch: 336/500... Training loss: 0.0098\n",
      "Epoch: 337/500... Training loss: 0.1197\n",
      "Epoch: 337/500... Training loss: 0.0132\n",
      "Epoch: 337/500... Training loss: 0.0198\n",
      "Epoch: 337/500... Training loss: 0.0081\n",
      "Epoch: 337/500... Training loss: 0.0049\n",
      "Epoch: 337/500... Training loss: 0.0111\n",
      "Epoch: 337/500... Training loss: 0.0241\n",
      "Epoch: 337/500... Training loss: 0.0098\n",
      "Epoch: 337/500... Training loss: 0.0057\n",
      "Epoch: 337/500... Training loss: 0.0151\n",
      "Epoch: 337/500... Training loss: 0.1858\n",
      "Epoch: 337/500... Training loss: 0.0648\n",
      "Epoch: 337/500... Training loss: 0.0072\n",
      "Epoch: 337/500... Training loss: 0.0081\n",
      "Epoch: 337/500... Training loss: 0.0898\n",
      "Epoch: 337/500... Training loss: 0.0065\n",
      "Epoch: 337/500... Training loss: 0.0025\n",
      "Epoch: 337/500... Training loss: 0.0807\n",
      "Epoch: 337/500... Training loss: 0.0020\n",
      "Epoch: 337/500... Training loss: 0.0074\n",
      "Epoch: 337/500... Training loss: 0.0143\n",
      "Epoch: 337/500... Training loss: 0.0106\n",
      "Epoch: 337/500... Training loss: 0.0020\n",
      "Epoch: 337/500... Training loss: 0.0127\n",
      "Epoch: 337/500... Training loss: 0.0048\n",
      "Epoch: 337/500... Training loss: 0.0458\n",
      "Epoch: 337/500... Training loss: 0.0152\n",
      "Epoch: 337/500... Training loss: 0.0551\n",
      "Epoch: 337/500... Training loss: 0.0023\n",
      "Epoch: 337/500... Training loss: 0.0037\n",
      "Epoch: 337/500... Training loss: 0.0182\n",
      "Epoch: 338/500... Training loss: 0.0036\n",
      "Epoch: 338/500... Training loss: 0.0378\n",
      "Epoch: 338/500... Training loss: 0.1179\n",
      "Epoch: 338/500... Training loss: 0.0060\n",
      "Epoch: 338/500... Training loss: 0.0634\n",
      "Epoch: 338/500... Training loss: 0.0046\n",
      "Epoch: 338/500... Training loss: 0.1984\n",
      "Epoch: 338/500... Training loss: 0.0055\n",
      "Epoch: 338/500... Training loss: 0.0072\n",
      "Epoch: 338/500... Training loss: 0.0092\n",
      "Epoch: 338/500... Training loss: 0.0488\n",
      "Epoch: 338/500... Training loss: 0.0013\n",
      "Epoch: 338/500... Training loss: 0.0111\n",
      "Epoch: 338/500... Training loss: 0.0785\n",
      "Epoch: 338/500... Training loss: 0.0599\n",
      "Epoch: 338/500... Training loss: 0.0178\n",
      "Epoch: 338/500... Training loss: 0.0025\n",
      "Epoch: 338/500... Training loss: 0.0060\n",
      "Epoch: 338/500... Training loss: 0.0073\n",
      "Epoch: 338/500... Training loss: 0.0020\n",
      "Epoch: 338/500... Training loss: 0.0024\n",
      "Epoch: 338/500... Training loss: 0.0459\n",
      "Epoch: 338/500... Training loss: 0.0059\n",
      "Epoch: 338/500... Training loss: 0.0223\n",
      "Epoch: 338/500... Training loss: 0.0077\n",
      "Epoch: 338/500... Training loss: 0.0045\n",
      "Epoch: 338/500... Training loss: 0.0031\n",
      "Epoch: 338/500... Training loss: 0.0051\n",
      "Epoch: 338/500... Training loss: 0.0200\n",
      "Epoch: 338/500... Training loss: 0.0569\n",
      "Epoch: 338/500... Training loss: 0.0262\n",
      "Epoch: 339/500... Training loss: 0.0388\n",
      "Epoch: 339/500... Training loss: 0.0375\n",
      "Epoch: 339/500... Training loss: 0.0094\n",
      "Epoch: 339/500... Training loss: 0.0083\n",
      "Epoch: 339/500... Training loss: 0.0160\n",
      "Epoch: 339/500... Training loss: 0.0478\n",
      "Epoch: 339/500... Training loss: 0.0028\n",
      "Epoch: 339/500... Training loss: 0.0117\n",
      "Epoch: 339/500... Training loss: 0.0177\n",
      "Epoch: 339/500... Training loss: 0.0067\n",
      "Epoch: 339/500... Training loss: 0.0238\n",
      "Epoch: 339/500... Training loss: 0.0018\n",
      "Epoch: 339/500... Training loss: 0.0441\n",
      "Epoch: 339/500... Training loss: 0.0375\n",
      "Epoch: 339/500... Training loss: 0.0053\n",
      "Epoch: 339/500... Training loss: 0.0089\n",
      "Epoch: 339/500... Training loss: 0.0142\n",
      "Epoch: 339/500... Training loss: 0.0075\n",
      "Epoch: 339/500... Training loss: 0.0014\n",
      "Epoch: 339/500... Training loss: 0.0630\n",
      "Epoch: 339/500... Training loss: 0.0069\n",
      "Epoch: 339/500... Training loss: 0.0176\n",
      "Epoch: 339/500... Training loss: 0.0118\n",
      "Epoch: 339/500... Training loss: 0.0216\n",
      "Epoch: 339/500... Training loss: 0.0022\n",
      "Epoch: 339/500... Training loss: 0.0073\n",
      "Epoch: 339/500... Training loss: 0.0626\n",
      "Epoch: 339/500... Training loss: 0.0060\n",
      "Epoch: 339/500... Training loss: 0.0457\n",
      "Epoch: 339/500... Training loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 339/500... Training loss: 0.0034\n",
      "Epoch: 340/500... Training loss: 0.0073\n",
      "Epoch: 340/500... Training loss: 0.0014\n",
      "Epoch: 340/500... Training loss: 0.0264\n",
      "Epoch: 340/500... Training loss: 0.0061\n",
      "Epoch: 340/500... Training loss: 0.0108\n",
      "Epoch: 340/500... Training loss: 0.0032\n",
      "Epoch: 340/500... Training loss: 0.0214\n",
      "Epoch: 340/500... Training loss: 0.0713\n",
      "Epoch: 340/500... Training loss: 0.0047\n",
      "Epoch: 340/500... Training loss: 0.0173\n",
      "Epoch: 340/500... Training loss: 0.0118\n",
      "Epoch: 340/500... Training loss: 0.0281\n",
      "Epoch: 340/500... Training loss: 0.0072\n",
      "Epoch: 340/500... Training loss: 0.0223\n",
      "Epoch: 340/500... Training loss: 0.0140\n",
      "Epoch: 340/500... Training loss: 0.0025\n",
      "Epoch: 340/500... Training loss: 0.0029\n",
      "Epoch: 340/500... Training loss: 0.0037\n",
      "Epoch: 340/500... Training loss: 0.0718\n",
      "Epoch: 340/500... Training loss: 0.0708\n",
      "Epoch: 340/500... Training loss: 0.0072\n",
      "Epoch: 340/500... Training loss: 0.0051\n",
      "Epoch: 340/500... Training loss: 0.0019\n",
      "Epoch: 340/500... Training loss: 0.0112\n",
      "Epoch: 340/500... Training loss: 0.0034\n",
      "Epoch: 340/500... Training loss: 0.0023\n",
      "Epoch: 340/500... Training loss: 0.0017\n",
      "Epoch: 340/500... Training loss: 0.0274\n",
      "Epoch: 340/500... Training loss: 0.0371\n",
      "Epoch: 340/500... Training loss: 0.0070\n",
      "Epoch: 340/500... Training loss: 0.0162\n",
      "Epoch: 341/500... Training loss: 0.0079\n",
      "Epoch: 341/500... Training loss: 0.0110\n",
      "Epoch: 341/500... Training loss: 0.0089\n",
      "Epoch: 341/500... Training loss: 0.0012\n",
      "Epoch: 341/500... Training loss: 0.0369\n",
      "Epoch: 341/500... Training loss: 0.0061\n",
      "Epoch: 341/500... Training loss: 0.0028\n",
      "Epoch: 341/500... Training loss: 0.0139\n",
      "Epoch: 341/500... Training loss: 0.0055\n",
      "Epoch: 341/500... Training loss: 0.0029\n",
      "Epoch: 341/500... Training loss: 0.0132\n",
      "Epoch: 341/500... Training loss: 0.0085\n",
      "Epoch: 341/500... Training loss: 0.0123\n",
      "Epoch: 341/500... Training loss: 0.0090\n",
      "Epoch: 341/500... Training loss: 0.1515\n",
      "Epoch: 341/500... Training loss: 0.0075\n",
      "Epoch: 341/500... Training loss: 0.0074\n",
      "Epoch: 341/500... Training loss: 0.0019\n",
      "Epoch: 341/500... Training loss: 0.0074\n",
      "Epoch: 341/500... Training loss: 0.0244\n",
      "Epoch: 341/500... Training loss: 0.0177\n",
      "Epoch: 341/500... Training loss: 0.0058\n",
      "Epoch: 341/500... Training loss: 0.0052\n",
      "Epoch: 341/500... Training loss: 0.0190\n",
      "Epoch: 341/500... Training loss: 0.0298\n",
      "Epoch: 341/500... Training loss: 0.0050\n",
      "Epoch: 341/500... Training loss: 0.0014\n",
      "Epoch: 341/500... Training loss: 0.0097\n",
      "Epoch: 341/500... Training loss: 0.0413\n",
      "Epoch: 341/500... Training loss: 0.0011\n",
      "Epoch: 341/500... Training loss: 0.0646\n",
      "Epoch: 342/500... Training loss: 0.0576\n",
      "Epoch: 342/500... Training loss: 0.1349\n",
      "Epoch: 342/500... Training loss: 0.0748\n",
      "Epoch: 342/500... Training loss: 0.0181\n",
      "Epoch: 342/500... Training loss: 0.0014\n",
      "Epoch: 342/500... Training loss: 0.0054\n",
      "Epoch: 342/500... Training loss: 0.0100\n",
      "Epoch: 342/500... Training loss: 0.0073\n",
      "Epoch: 342/500... Training loss: 0.0177\n",
      "Epoch: 342/500... Training loss: 0.0148\n",
      "Epoch: 342/500... Training loss: 0.0289\n",
      "Epoch: 342/500... Training loss: 0.0038\n",
      "Epoch: 342/500... Training loss: 0.0089\n",
      "Epoch: 342/500... Training loss: 0.0052\n",
      "Epoch: 342/500... Training loss: 0.0889\n",
      "Epoch: 342/500... Training loss: 0.0698\n",
      "Epoch: 342/500... Training loss: 0.0273\n",
      "Epoch: 342/500... Training loss: 0.0653\n",
      "Epoch: 342/500... Training loss: 0.0090\n",
      "Epoch: 342/500... Training loss: 0.0296\n",
      "Epoch: 342/500... Training loss: 0.0081\n",
      "Epoch: 342/500... Training loss: 0.0020\n",
      "Epoch: 342/500... Training loss: 0.0044\n",
      "Epoch: 342/500... Training loss: 0.0020\n",
      "Epoch: 342/500... Training loss: 0.0019\n",
      "Epoch: 342/500... Training loss: 0.0223\n",
      "Epoch: 342/500... Training loss: 0.0062\n",
      "Epoch: 342/500... Training loss: 0.0067\n",
      "Epoch: 342/500... Training loss: 0.0054\n",
      "Epoch: 342/500... Training loss: 0.0026\n",
      "Epoch: 342/500... Training loss: 0.0191\n",
      "Epoch: 343/500... Training loss: 0.0054\n",
      "Epoch: 343/500... Training loss: 0.0515\n",
      "Epoch: 343/500... Training loss: 0.0111\n",
      "Epoch: 343/500... Training loss: 0.0153\n",
      "Epoch: 343/500... Training loss: 0.0719\n",
      "Epoch: 343/500... Training loss: 0.0082\n",
      "Epoch: 343/500... Training loss: 0.0174\n",
      "Epoch: 343/500... Training loss: 0.0473\n",
      "Epoch: 343/500... Training loss: 0.0114\n",
      "Epoch: 343/500... Training loss: 0.0031\n",
      "Epoch: 343/500... Training loss: 0.0507\n",
      "Epoch: 343/500... Training loss: 0.0042\n",
      "Epoch: 343/500... Training loss: 0.0311\n",
      "Epoch: 343/500... Training loss: 0.0015\n",
      "Epoch: 343/500... Training loss: 0.0188\n",
      "Epoch: 343/500... Training loss: 0.0262\n",
      "Epoch: 343/500... Training loss: 0.0128\n",
      "Epoch: 343/500... Training loss: 0.0404\n",
      "Epoch: 343/500... Training loss: 0.0649\n",
      "Epoch: 343/500... Training loss: 0.1054\n",
      "Epoch: 343/500... Training loss: 0.0040\n",
      "Epoch: 343/500... Training loss: 0.0017\n",
      "Epoch: 343/500... Training loss: 0.0134\n",
      "Epoch: 343/500... Training loss: 0.0344\n",
      "Epoch: 343/500... Training loss: 0.0191\n",
      "Epoch: 343/500... Training loss: 0.0035\n",
      "Epoch: 343/500... Training loss: 0.0044\n",
      "Epoch: 343/500... Training loss: 0.0184\n",
      "Epoch: 343/500... Training loss: 0.0044\n",
      "Epoch: 343/500... Training loss: 0.0168\n",
      "Epoch: 343/500... Training loss: 0.0079\n",
      "Epoch: 344/500... Training loss: 0.0438\n",
      "Epoch: 344/500... Training loss: 0.0103\n",
      "Epoch: 344/500... Training loss: 0.0074\n",
      "Epoch: 344/500... Training loss: 0.0104\n",
      "Epoch: 344/500... Training loss: 0.0059\n",
      "Epoch: 344/500... Training loss: 0.0038\n",
      "Epoch: 344/500... Training loss: 0.0205\n",
      "Epoch: 344/500... Training loss: 0.0038\n",
      "Epoch: 344/500... Training loss: 0.0320\n",
      "Epoch: 344/500... Training loss: 0.0192\n",
      "Epoch: 344/500... Training loss: 0.0520\n",
      "Epoch: 344/500... Training loss: 0.0056\n",
      "Epoch: 344/500... Training loss: 0.0022\n",
      "Epoch: 344/500... Training loss: 0.1729\n",
      "Epoch: 344/500... Training loss: 0.0507\n",
      "Epoch: 344/500... Training loss: 0.0035\n",
      "Epoch: 344/500... Training loss: 0.0054\n",
      "Epoch: 344/500... Training loss: 0.0059\n",
      "Epoch: 344/500... Training loss: 0.0083\n",
      "Epoch: 344/500... Training loss: 0.0029\n",
      "Epoch: 344/500... Training loss: 0.0076\n",
      "Epoch: 344/500... Training loss: 0.0064\n",
      "Epoch: 344/500... Training loss: 0.0331\n",
      "Epoch: 344/500... Training loss: 0.0367\n",
      "Epoch: 344/500... Training loss: 0.0049\n",
      "Epoch: 344/500... Training loss: 0.0036\n",
      "Epoch: 344/500... Training loss: 0.0025\n",
      "Epoch: 344/500... Training loss: 0.0395\n",
      "Epoch: 344/500... Training loss: 0.0659\n",
      "Epoch: 344/500... Training loss: 0.0092\n",
      "Epoch: 344/500... Training loss: 0.0011\n",
      "Epoch: 345/500... Training loss: 0.0106\n",
      "Epoch: 345/500... Training loss: 0.0031\n",
      "Epoch: 345/500... Training loss: 0.0035\n",
      "Epoch: 345/500... Training loss: 0.0890\n",
      "Epoch: 345/500... Training loss: 0.0031\n",
      "Epoch: 345/500... Training loss: 0.1227\n",
      "Epoch: 345/500... Training loss: 0.0027\n",
      "Epoch: 345/500... Training loss: 0.0169\n",
      "Epoch: 345/500... Training loss: 0.0057\n",
      "Epoch: 345/500... Training loss: 0.0039\n",
      "Epoch: 345/500... Training loss: 0.0560\n",
      "Epoch: 345/500... Training loss: 0.1144\n",
      "Epoch: 345/500... Training loss: 0.0019\n",
      "Epoch: 345/500... Training loss: 0.0184\n",
      "Epoch: 345/500... Training loss: 0.1281\n",
      "Epoch: 345/500... Training loss: 0.0067\n",
      "Epoch: 345/500... Training loss: 0.0172\n",
      "Epoch: 345/500... Training loss: 0.0032\n",
      "Epoch: 345/500... Training loss: 0.0020\n",
      "Epoch: 345/500... Training loss: 0.0020\n",
      "Epoch: 345/500... Training loss: 0.0484\n",
      "Epoch: 345/500... Training loss: 0.0116\n",
      "Epoch: 345/500... Training loss: 0.0301\n",
      "Epoch: 345/500... Training loss: 0.0050\n",
      "Epoch: 345/500... Training loss: 0.0056\n",
      "Epoch: 345/500... Training loss: 0.0170\n",
      "Epoch: 345/500... Training loss: 0.0212\n",
      "Epoch: 345/500... Training loss: 0.0066\n",
      "Epoch: 345/500... Training loss: 0.0008\n",
      "Epoch: 345/500... Training loss: 0.0067\n",
      "Epoch: 345/500... Training loss: 0.0593\n",
      "Epoch: 346/500... Training loss: 0.0069\n",
      "Epoch: 346/500... Training loss: 0.0145\n",
      "Epoch: 346/500... Training loss: 0.0018\n",
      "Epoch: 346/500... Training loss: 0.0064\n",
      "Epoch: 346/500... Training loss: 0.1705\n",
      "Epoch: 346/500... Training loss: 0.0093\n",
      "Epoch: 346/500... Training loss: 0.0227\n",
      "Epoch: 346/500... Training loss: 0.0170\n",
      "Epoch: 346/500... Training loss: 0.0067\n",
      "Epoch: 346/500... Training loss: 0.0022\n",
      "Epoch: 346/500... Training loss: 0.0074\n",
      "Epoch: 346/500... Training loss: 0.0059\n",
      "Epoch: 346/500... Training loss: 0.0057\n",
      "Epoch: 346/500... Training loss: 0.0055\n",
      "Epoch: 346/500... Training loss: 0.0255\n",
      "Epoch: 346/500... Training loss: 0.0059\n",
      "Epoch: 346/500... Training loss: 0.0030\n",
      "Epoch: 346/500... Training loss: 0.0038\n",
      "Epoch: 346/500... Training loss: 0.0225\n",
      "Epoch: 346/500... Training loss: 0.0040\n",
      "Epoch: 346/500... Training loss: 0.0064\n",
      "Epoch: 346/500... Training loss: 0.0041\n",
      "Epoch: 346/500... Training loss: 0.0558\n",
      "Epoch: 346/500... Training loss: 0.0714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 346/500... Training loss: 0.0118\n",
      "Epoch: 346/500... Training loss: 0.0148\n",
      "Epoch: 346/500... Training loss: 0.0348\n",
      "Epoch: 346/500... Training loss: 0.0241\n",
      "Epoch: 346/500... Training loss: 0.0012\n",
      "Epoch: 346/500... Training loss: 0.0058\n",
      "Epoch: 346/500... Training loss: 0.0074\n",
      "Epoch: 347/500... Training loss: 0.0031\n",
      "Epoch: 347/500... Training loss: 0.0127\n",
      "Epoch: 347/500... Training loss: 0.0269\n",
      "Epoch: 347/500... Training loss: 0.0169\n",
      "Epoch: 347/500... Training loss: 0.1113\n",
      "Epoch: 347/500... Training loss: 0.0038\n",
      "Epoch: 347/500... Training loss: 0.0220\n",
      "Epoch: 347/500... Training loss: 0.0491\n",
      "Epoch: 347/500... Training loss: 0.0044\n",
      "Epoch: 347/500... Training loss: 0.0165\n",
      "Epoch: 347/500... Training loss: 0.1187\n",
      "Epoch: 347/500... Training loss: 0.0189\n",
      "Epoch: 347/500... Training loss: 0.0040\n",
      "Epoch: 347/500... Training loss: 0.0139\n",
      "Epoch: 347/500... Training loss: 0.0033\n",
      "Epoch: 347/500... Training loss: 0.0031\n",
      "Epoch: 347/500... Training loss: 0.0091\n",
      "Epoch: 347/500... Training loss: 0.0100\n",
      "Epoch: 347/500... Training loss: 0.0059\n",
      "Epoch: 347/500... Training loss: 0.0133\n",
      "Epoch: 347/500... Training loss: 0.0118\n",
      "Epoch: 347/500... Training loss: 0.0022\n",
      "Epoch: 347/500... Training loss: 0.0641\n",
      "Epoch: 347/500... Training loss: 0.0094\n",
      "Epoch: 347/500... Training loss: 0.0056\n",
      "Epoch: 347/500... Training loss: 0.0026\n",
      "Epoch: 347/500... Training loss: 0.0111\n",
      "Epoch: 347/500... Training loss: 0.1375\n",
      "Epoch: 347/500... Training loss: 0.0035\n",
      "Epoch: 347/500... Training loss: 0.0018\n",
      "Epoch: 347/500... Training loss: 0.0089\n",
      "Epoch: 348/500... Training loss: 0.0033\n",
      "Epoch: 348/500... Training loss: 0.0032\n",
      "Epoch: 348/500... Training loss: 0.0324\n",
      "Epoch: 348/500... Training loss: 0.0055\n",
      "Epoch: 348/500... Training loss: 0.0065\n",
      "Epoch: 348/500... Training loss: 0.0081\n",
      "Epoch: 348/500... Training loss: 0.0052\n",
      "Epoch: 348/500... Training loss: 0.0208\n",
      "Epoch: 348/500... Training loss: 0.0259\n",
      "Epoch: 348/500... Training loss: 0.0206\n",
      "Epoch: 348/500... Training loss: 0.0061\n",
      "Epoch: 348/500... Training loss: 0.0063\n",
      "Epoch: 348/500... Training loss: 0.0065\n",
      "Epoch: 348/500... Training loss: 0.0031\n",
      "Epoch: 348/500... Training loss: 0.0030\n",
      "Epoch: 348/500... Training loss: 0.0266\n",
      "Epoch: 348/500... Training loss: 0.0052\n",
      "Epoch: 348/500... Training loss: 0.0351\n",
      "Epoch: 348/500... Training loss: 0.0494\n",
      "Epoch: 348/500... Training loss: 0.0310\n",
      "Epoch: 348/500... Training loss: 0.0037\n",
      "Epoch: 348/500... Training loss: 0.0136\n",
      "Epoch: 348/500... Training loss: 0.0114\n",
      "Epoch: 348/500... Training loss: 0.0028\n",
      "Epoch: 348/500... Training loss: 0.0123\n",
      "Epoch: 348/500... Training loss: 0.0014\n",
      "Epoch: 348/500... Training loss: 0.0179\n",
      "Epoch: 348/500... Training loss: 0.0620\n",
      "Epoch: 348/500... Training loss: 0.0064\n",
      "Epoch: 348/500... Training loss: 0.0063\n",
      "Epoch: 348/500... Training loss: 0.0043\n",
      "Epoch: 349/500... Training loss: 0.0109\n",
      "Epoch: 349/500... Training loss: 0.0284\n",
      "Epoch: 349/500... Training loss: 0.0067\n",
      "Epoch: 349/500... Training loss: 0.0140\n",
      "Epoch: 349/500... Training loss: 0.0264\n",
      "Epoch: 349/500... Training loss: 0.0096\n",
      "Epoch: 349/500... Training loss: 0.0023\n",
      "Epoch: 349/500... Training loss: 0.0184\n",
      "Epoch: 349/500... Training loss: 0.0081\n",
      "Epoch: 349/500... Training loss: 0.0268\n",
      "Epoch: 349/500... Training loss: 0.0099\n",
      "Epoch: 349/500... Training loss: 0.0145\n",
      "Epoch: 349/500... Training loss: 0.0007\n",
      "Epoch: 349/500... Training loss: 0.0019\n",
      "Epoch: 349/500... Training loss: 0.0014\n",
      "Epoch: 349/500... Training loss: 0.0127\n",
      "Epoch: 349/500... Training loss: 0.0121\n",
      "Epoch: 349/500... Training loss: 0.0102\n",
      "Epoch: 349/500... Training loss: 0.0202\n",
      "Epoch: 349/500... Training loss: 0.0202\n",
      "Epoch: 349/500... Training loss: 0.0063\n",
      "Epoch: 349/500... Training loss: 0.0051\n",
      "Epoch: 349/500... Training loss: 0.0035\n",
      "Epoch: 349/500... Training loss: 0.0109\n",
      "Epoch: 349/500... Training loss: 0.0025\n",
      "Epoch: 349/500... Training loss: 0.0525\n",
      "Epoch: 349/500... Training loss: 0.0345\n",
      "Epoch: 349/500... Training loss: 0.0177\n",
      "Epoch: 349/500... Training loss: 0.0195\n",
      "Epoch: 349/500... Training loss: 0.0132\n",
      "Epoch: 349/500... Training loss: 0.0037\n",
      "Epoch: 350/500... Training loss: 0.0040\n",
      "Epoch: 350/500... Training loss: 0.0050\n",
      "Epoch: 350/500... Training loss: 0.0305\n",
      "Epoch: 350/500... Training loss: 0.1609\n",
      "Epoch: 350/500... Training loss: 0.0298\n",
      "Epoch: 350/500... Training loss: 0.0055\n",
      "Epoch: 350/500... Training loss: 0.0055\n",
      "Epoch: 350/500... Training loss: 0.0054\n",
      "Epoch: 350/500... Training loss: 0.0092\n",
      "Epoch: 350/500... Training loss: 0.0059\n",
      "Epoch: 350/500... Training loss: 0.0137\n",
      "Epoch: 350/500... Training loss: 0.0343\n",
      "Epoch: 350/500... Training loss: 0.0043\n",
      "Epoch: 350/500... Training loss: 0.0277\n",
      "Epoch: 350/500... Training loss: 0.0259\n",
      "Epoch: 350/500... Training loss: 0.0061\n",
      "Epoch: 350/500... Training loss: 0.1557\n",
      "Epoch: 350/500... Training loss: 0.0052\n",
      "Epoch: 350/500... Training loss: 0.0291\n",
      "Epoch: 350/500... Training loss: 0.0360\n",
      "Epoch: 350/500... Training loss: 0.0143\n",
      "Epoch: 350/500... Training loss: 0.0155\n",
      "Epoch: 350/500... Training loss: 0.0471\n",
      "Epoch: 350/500... Training loss: 0.0067\n",
      "Epoch: 350/500... Training loss: 0.0062\n",
      "Epoch: 350/500... Training loss: 0.0153\n",
      "Epoch: 350/500... Training loss: 0.0440\n",
      "Epoch: 350/500... Training loss: 0.0366\n",
      "Epoch: 350/500... Training loss: 0.0013\n",
      "Epoch: 350/500... Training loss: 0.0072\n",
      "Epoch: 350/500... Training loss: 0.0157\n",
      "Epoch: 351/500... Training loss: 0.0531\n",
      "Epoch: 351/500... Training loss: 0.0113\n",
      "Epoch: 351/500... Training loss: 0.0069\n",
      "Epoch: 351/500... Training loss: 0.0109\n",
      "Epoch: 351/500... Training loss: 0.0089\n",
      "Epoch: 351/500... Training loss: 0.0109\n",
      "Epoch: 351/500... Training loss: 0.0139\n",
      "Epoch: 351/500... Training loss: 0.0070\n",
      "Epoch: 351/500... Training loss: 0.0241\n",
      "Epoch: 351/500... Training loss: 0.0029\n",
      "Epoch: 351/500... Training loss: 0.0278\n",
      "Epoch: 351/500... Training loss: 0.0133\n",
      "Epoch: 351/500... Training loss: 0.0094\n",
      "Epoch: 351/500... Training loss: 0.0063\n",
      "Epoch: 351/500... Training loss: 0.0123\n",
      "Epoch: 351/500... Training loss: 0.0195\n",
      "Epoch: 351/500... Training loss: 0.0019\n",
      "Epoch: 351/500... Training loss: 0.0015\n",
      "Epoch: 351/500... Training loss: 0.0036\n",
      "Epoch: 351/500... Training loss: 0.0061\n",
      "Epoch: 351/500... Training loss: 0.0777\n",
      "Epoch: 351/500... Training loss: 0.0126\n",
      "Epoch: 351/500... Training loss: 0.0051\n",
      "Epoch: 351/500... Training loss: 0.0008\n",
      "Epoch: 351/500... Training loss: 0.0719\n",
      "Epoch: 351/500... Training loss: 0.0090\n",
      "Epoch: 351/500... Training loss: 0.0180\n",
      "Epoch: 351/500... Training loss: 0.0421\n",
      "Epoch: 351/500... Training loss: 0.0074\n",
      "Epoch: 351/500... Training loss: 0.0441\n",
      "Epoch: 351/500... Training loss: 0.0120\n",
      "Epoch: 352/500... Training loss: 0.0596\n",
      "Epoch: 352/500... Training loss: 0.0048\n",
      "Epoch: 352/500... Training loss: 0.0025\n",
      "Epoch: 352/500... Training loss: 0.0062\n",
      "Epoch: 352/500... Training loss: 0.0069\n",
      "Epoch: 352/500... Training loss: 0.0151\n",
      "Epoch: 352/500... Training loss: 0.0240\n",
      "Epoch: 352/500... Training loss: 0.1162\n",
      "Epoch: 352/500... Training loss: 0.0147\n",
      "Epoch: 352/500... Training loss: 0.0413\n",
      "Epoch: 352/500... Training loss: 0.0064\n",
      "Epoch: 352/500... Training loss: 0.0937\n",
      "Epoch: 352/500... Training loss: 0.0115\n",
      "Epoch: 352/500... Training loss: 0.0021\n",
      "Epoch: 352/500... Training loss: 0.0018\n",
      "Epoch: 352/500... Training loss: 0.0044\n",
      "Epoch: 352/500... Training loss: 0.0681\n",
      "Epoch: 352/500... Training loss: 0.0065\n",
      "Epoch: 352/500... Training loss: 0.0117\n",
      "Epoch: 352/500... Training loss: 0.0022\n",
      "Epoch: 352/500... Training loss: 0.0032\n",
      "Epoch: 352/500... Training loss: 0.0094\n",
      "Epoch: 352/500... Training loss: 0.0440\n",
      "Epoch: 352/500... Training loss: 0.0047\n",
      "Epoch: 352/500... Training loss: 0.0036\n",
      "Epoch: 352/500... Training loss: 0.0057\n",
      "Epoch: 352/500... Training loss: 0.0146\n",
      "Epoch: 352/500... Training loss: 0.0008\n",
      "Epoch: 352/500... Training loss: 0.0714\n",
      "Epoch: 352/500... Training loss: 0.0195\n",
      "Epoch: 352/500... Training loss: 0.0331\n",
      "Epoch: 353/500... Training loss: 0.0034\n",
      "Epoch: 353/500... Training loss: 0.0508\n",
      "Epoch: 353/500... Training loss: 0.0049\n",
      "Epoch: 353/500... Training loss: 0.0380\n",
      "Epoch: 353/500... Training loss: 0.0040\n",
      "Epoch: 353/500... Training loss: 0.0076\n",
      "Epoch: 353/500... Training loss: 0.0473\n",
      "Epoch: 353/500... Training loss: 0.0397\n",
      "Epoch: 353/500... Training loss: 0.0328\n",
      "Epoch: 353/500... Training loss: 0.0125\n",
      "Epoch: 353/500... Training loss: 0.0156\n",
      "Epoch: 353/500... Training loss: 0.0186\n",
      "Epoch: 353/500... Training loss: 0.0536\n",
      "Epoch: 353/500... Training loss: 0.0365\n",
      "Epoch: 353/500... Training loss: 0.0035\n",
      "Epoch: 353/500... Training loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 353/500... Training loss: 0.0050\n",
      "Epoch: 353/500... Training loss: 0.0465\n",
      "Epoch: 353/500... Training loss: 0.0027\n",
      "Epoch: 353/500... Training loss: 0.0057\n",
      "Epoch: 353/500... Training loss: 0.0045\n",
      "Epoch: 353/500... Training loss: 0.0051\n",
      "Epoch: 353/500... Training loss: 0.0043\n",
      "Epoch: 353/500... Training loss: 0.0024\n",
      "Epoch: 353/500... Training loss: 0.0524\n",
      "Epoch: 353/500... Training loss: 0.0057\n",
      "Epoch: 353/500... Training loss: 0.0116\n",
      "Epoch: 353/500... Training loss: 0.0398\n",
      "Epoch: 353/500... Training loss: 0.0424\n",
      "Epoch: 353/500... Training loss: 0.0057\n",
      "Epoch: 353/500... Training loss: 0.0269\n",
      "Epoch: 354/500... Training loss: 0.0252\n",
      "Epoch: 354/500... Training loss: 0.0183\n",
      "Epoch: 354/500... Training loss: 0.0080\n",
      "Epoch: 354/500... Training loss: 0.0302\n",
      "Epoch: 354/500... Training loss: 0.0516\n",
      "Epoch: 354/500... Training loss: 0.0203\n",
      "Epoch: 354/500... Training loss: 0.0023\n",
      "Epoch: 354/500... Training loss: 0.0084\n",
      "Epoch: 354/500... Training loss: 0.0125\n",
      "Epoch: 354/500... Training loss: 0.0181\n",
      "Epoch: 354/500... Training loss: 0.0246\n",
      "Epoch: 354/500... Training loss: 0.0151\n",
      "Epoch: 354/500... Training loss: 0.0156\n",
      "Epoch: 354/500... Training loss: 0.0464\n",
      "Epoch: 354/500... Training loss: 0.0083\n",
      "Epoch: 354/500... Training loss: 0.0167\n",
      "Epoch: 354/500... Training loss: 0.0038\n",
      "Epoch: 354/500... Training loss: 0.0150\n",
      "Epoch: 354/500... Training loss: 0.0107\n",
      "Epoch: 354/500... Training loss: 0.0079\n",
      "Epoch: 354/500... Training loss: 0.0820\n",
      "Epoch: 354/500... Training loss: 0.0050\n",
      "Epoch: 354/500... Training loss: 0.0112\n",
      "Epoch: 354/500... Training loss: 0.0011\n",
      "Epoch: 354/500... Training loss: 0.0238\n",
      "Epoch: 354/500... Training loss: 0.0455\n",
      "Epoch: 354/500... Training loss: 0.0069\n",
      "Epoch: 354/500... Training loss: 0.0157\n",
      "Epoch: 354/500... Training loss: 0.0450\n",
      "Epoch: 354/500... Training loss: 0.0423\n",
      "Epoch: 354/500... Training loss: 0.0090\n",
      "Epoch: 355/500... Training loss: 0.0114\n",
      "Epoch: 355/500... Training loss: 0.0168\n",
      "Epoch: 355/500... Training loss: 0.0191\n",
      "Epoch: 355/500... Training loss: 0.0198\n",
      "Epoch: 355/500... Training loss: 0.0027\n",
      "Epoch: 355/500... Training loss: 0.0104\n",
      "Epoch: 355/500... Training loss: 0.0056\n",
      "Epoch: 355/500... Training loss: 0.0913\n",
      "Epoch: 355/500... Training loss: 0.0074\n",
      "Epoch: 355/500... Training loss: 0.0485\n",
      "Epoch: 355/500... Training loss: 0.2091\n",
      "Epoch: 355/500... Training loss: 0.0050\n",
      "Epoch: 355/500... Training loss: 0.0330\n",
      "Epoch: 355/500... Training loss: 0.0223\n",
      "Epoch: 355/500... Training loss: 0.0202\n",
      "Epoch: 355/500... Training loss: 0.0088\n",
      "Epoch: 355/500... Training loss: 0.0045\n",
      "Epoch: 355/500... Training loss: 0.0083\n",
      "Epoch: 355/500... Training loss: 0.0133\n",
      "Epoch: 355/500... Training loss: 0.0023\n",
      "Epoch: 355/500... Training loss: 0.0056\n",
      "Epoch: 355/500... Training loss: 0.0071\n",
      "Epoch: 355/500... Training loss: 0.0053\n",
      "Epoch: 355/500... Training loss: 0.0271\n",
      "Epoch: 355/500... Training loss: 0.0024\n",
      "Epoch: 355/500... Training loss: 0.0118\n",
      "Epoch: 355/500... Training loss: 0.0715\n",
      "Epoch: 355/500... Training loss: 0.0040\n",
      "Epoch: 355/500... Training loss: 0.0058\n",
      "Epoch: 355/500... Training loss: 0.0513\n",
      "Epoch: 355/500... Training loss: 0.0945\n",
      "Epoch: 356/500... Training loss: 0.0222\n",
      "Epoch: 356/500... Training loss: 0.0101\n",
      "Epoch: 356/500... Training loss: 0.0103\n",
      "Epoch: 356/500... Training loss: 0.0237\n",
      "Epoch: 356/500... Training loss: 0.0203\n",
      "Epoch: 356/500... Training loss: 0.0035\n",
      "Epoch: 356/500... Training loss: 0.0138\n",
      "Epoch: 356/500... Training loss: 0.0017\n",
      "Epoch: 356/500... Training loss: 0.0036\n",
      "Epoch: 356/500... Training loss: 0.0378\n",
      "Epoch: 356/500... Training loss: 0.0291\n",
      "Epoch: 356/500... Training loss: 0.0531\n",
      "Epoch: 356/500... Training loss: 0.0038\n",
      "Epoch: 356/500... Training loss: 0.0602\n",
      "Epoch: 356/500... Training loss: 0.0049\n",
      "Epoch: 356/500... Training loss: 0.0182\n",
      "Epoch: 356/500... Training loss: 0.0741\n",
      "Epoch: 356/500... Training loss: 0.0436\n",
      "Epoch: 356/500... Training loss: 0.0039\n",
      "Epoch: 356/500... Training loss: 0.0034\n",
      "Epoch: 356/500... Training loss: 0.0297\n",
      "Epoch: 356/500... Training loss: 0.0031\n",
      "Epoch: 356/500... Training loss: 0.1439\n",
      "Epoch: 356/500... Training loss: 0.0266\n",
      "Epoch: 356/500... Training loss: 0.0395\n",
      "Epoch: 356/500... Training loss: 0.0081\n",
      "Epoch: 356/500... Training loss: 0.0164\n",
      "Epoch: 356/500... Training loss: 0.0341\n",
      "Epoch: 356/500... Training loss: 0.0020\n",
      "Epoch: 356/500... Training loss: 0.0166\n",
      "Epoch: 356/500... Training loss: 0.0045\n",
      "Epoch: 357/500... Training loss: 0.0250\n",
      "Epoch: 357/500... Training loss: 0.0097\n",
      "Epoch: 357/500... Training loss: 0.0187\n",
      "Epoch: 357/500... Training loss: 0.0047\n",
      "Epoch: 357/500... Training loss: 0.0409\n",
      "Epoch: 357/500... Training loss: 0.0023\n",
      "Epoch: 357/500... Training loss: 0.0103\n",
      "Epoch: 357/500... Training loss: 0.0023\n",
      "Epoch: 357/500... Training loss: 0.0062\n",
      "Epoch: 357/500... Training loss: 0.0171\n",
      "Epoch: 357/500... Training loss: 0.0124\n",
      "Epoch: 357/500... Training loss: 0.0118\n",
      "Epoch: 357/500... Training loss: 0.3081\n",
      "Epoch: 357/500... Training loss: 0.0049\n",
      "Epoch: 357/500... Training loss: 0.0069\n",
      "Epoch: 357/500... Training loss: 0.0061\n",
      "Epoch: 357/500... Training loss: 0.0157\n",
      "Epoch: 357/500... Training loss: 0.0253\n",
      "Epoch: 357/500... Training loss: 0.0082\n",
      "Epoch: 357/500... Training loss: 0.0004\n",
      "Epoch: 357/500... Training loss: 0.0035\n",
      "Epoch: 357/500... Training loss: 0.0050\n",
      "Epoch: 357/500... Training loss: 0.0241\n",
      "Epoch: 357/500... Training loss: 0.0055\n",
      "Epoch: 357/500... Training loss: 0.0061\n",
      "Epoch: 357/500... Training loss: 0.0176\n",
      "Epoch: 357/500... Training loss: 0.0069\n",
      "Epoch: 357/500... Training loss: 0.0210\n",
      "Epoch: 357/500... Training loss: 0.0615\n",
      "Epoch: 357/500... Training loss: 0.0700\n",
      "Epoch: 357/500... Training loss: 0.1243\n",
      "Epoch: 358/500... Training loss: 0.0098\n",
      "Epoch: 358/500... Training loss: 0.0039\n",
      "Epoch: 358/500... Training loss: 0.0114\n",
      "Epoch: 358/500... Training loss: 0.0266\n",
      "Epoch: 358/500... Training loss: 0.0238\n",
      "Epoch: 358/500... Training loss: 0.0212\n",
      "Epoch: 358/500... Training loss: 0.0229\n",
      "Epoch: 358/500... Training loss: 0.0018\n",
      "Epoch: 358/500... Training loss: 0.0056\n",
      "Epoch: 358/500... Training loss: 0.0213\n",
      "Epoch: 358/500... Training loss: 0.0397\n",
      "Epoch: 358/500... Training loss: 0.0111\n",
      "Epoch: 358/500... Training loss: 0.0031\n",
      "Epoch: 358/500... Training loss: 0.0063\n",
      "Epoch: 358/500... Training loss: 0.0055\n",
      "Epoch: 358/500... Training loss: 0.0089\n",
      "Epoch: 358/500... Training loss: 0.0278\n",
      "Epoch: 358/500... Training loss: 0.0059\n",
      "Epoch: 358/500... Training loss: 0.0448\n",
      "Epoch: 358/500... Training loss: 0.0196\n",
      "Epoch: 358/500... Training loss: 0.0055\n",
      "Epoch: 358/500... Training loss: 0.0027\n",
      "Epoch: 358/500... Training loss: 0.0037\n",
      "Epoch: 358/500... Training loss: 0.0014\n",
      "Epoch: 358/500... Training loss: 0.0062\n",
      "Epoch: 358/500... Training loss: 0.0028\n",
      "Epoch: 358/500... Training loss: 0.0019\n",
      "Epoch: 358/500... Training loss: 0.0082\n",
      "Epoch: 358/500... Training loss: 0.0026\n",
      "Epoch: 358/500... Training loss: 0.0176\n",
      "Epoch: 358/500... Training loss: 0.0252\n",
      "Epoch: 359/500... Training loss: 0.0195\n",
      "Epoch: 359/500... Training loss: 0.0208\n",
      "Epoch: 359/500... Training loss: 0.0161\n",
      "Epoch: 359/500... Training loss: 0.0118\n",
      "Epoch: 359/500... Training loss: 0.0636\n",
      "Epoch: 359/500... Training loss: 0.0044\n",
      "Epoch: 359/500... Training loss: 0.0287\n",
      "Epoch: 359/500... Training loss: 0.0059\n",
      "Epoch: 359/500... Training loss: 0.0096\n",
      "Epoch: 359/500... Training loss: 0.0682\n",
      "Epoch: 359/500... Training loss: 0.0070\n",
      "Epoch: 359/500... Training loss: 0.0232\n",
      "Epoch: 359/500... Training loss: 0.0060\n",
      "Epoch: 359/500... Training loss: 0.0112\n",
      "Epoch: 359/500... Training loss: 0.0025\n",
      "Epoch: 359/500... Training loss: 0.0014\n",
      "Epoch: 359/500... Training loss: 0.0136\n",
      "Epoch: 359/500... Training loss: 0.0886\n",
      "Epoch: 359/500... Training loss: 0.0085\n",
      "Epoch: 359/500... Training loss: 0.0118\n",
      "Epoch: 359/500... Training loss: 0.0397\n",
      "Epoch: 359/500... Training loss: 0.0027\n",
      "Epoch: 359/500... Training loss: 0.0046\n",
      "Epoch: 359/500... Training loss: 0.0734\n",
      "Epoch: 359/500... Training loss: 0.0048\n",
      "Epoch: 359/500... Training loss: 0.0066\n",
      "Epoch: 359/500... Training loss: 0.0299\n",
      "Epoch: 359/500... Training loss: 0.0368\n",
      "Epoch: 359/500... Training loss: 0.0106\n",
      "Epoch: 359/500... Training loss: 0.0415\n",
      "Epoch: 359/500... Training loss: 0.0025\n",
      "Epoch: 360/500... Training loss: 0.0123\n",
      "Epoch: 360/500... Training loss: 0.0079\n",
      "Epoch: 360/500... Training loss: 0.0092\n",
      "Epoch: 360/500... Training loss: 0.0061\n",
      "Epoch: 360/500... Training loss: 0.0024\n",
      "Epoch: 360/500... Training loss: 0.0130\n",
      "Epoch: 360/500... Training loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/500... Training loss: 0.0255\n",
      "Epoch: 360/500... Training loss: 0.0068\n",
      "Epoch: 360/500... Training loss: 0.0042\n",
      "Epoch: 360/500... Training loss: 0.0020\n",
      "Epoch: 360/500... Training loss: 0.0056\n",
      "Epoch: 360/500... Training loss: 0.0215\n",
      "Epoch: 360/500... Training loss: 0.0289\n",
      "Epoch: 360/500... Training loss: 0.0058\n",
      "Epoch: 360/500... Training loss: 0.0045\n",
      "Epoch: 360/500... Training loss: 0.0018\n",
      "Epoch: 360/500... Training loss: 0.0349\n",
      "Epoch: 360/500... Training loss: 0.0044\n",
      "Epoch: 360/500... Training loss: 0.0035\n",
      "Epoch: 360/500... Training loss: 0.0335\n",
      "Epoch: 360/500... Training loss: 0.0058\n",
      "Epoch: 360/500... Training loss: 0.0184\n",
      "Epoch: 360/500... Training loss: 0.0028\n",
      "Epoch: 360/500... Training loss: 0.0059\n",
      "Epoch: 360/500... Training loss: 0.0024\n",
      "Epoch: 360/500... Training loss: 0.0020\n",
      "Epoch: 360/500... Training loss: 0.0368\n",
      "Epoch: 360/500... Training loss: 0.0166\n",
      "Epoch: 360/500... Training loss: 0.0343\n",
      "Epoch: 360/500... Training loss: 0.0091\n",
      "Epoch: 361/500... Training loss: 0.0428\n",
      "Epoch: 361/500... Training loss: 0.0454\n",
      "Epoch: 361/500... Training loss: 0.0026\n",
      "Epoch: 361/500... Training loss: 0.0018\n",
      "Epoch: 361/500... Training loss: 0.0214\n",
      "Epoch: 361/500... Training loss: 0.0344\n",
      "Epoch: 361/500... Training loss: 0.0145\n",
      "Epoch: 361/500... Training loss: 0.0298\n",
      "Epoch: 361/500... Training loss: 0.0019\n",
      "Epoch: 361/500... Training loss: 0.0021\n",
      "Epoch: 361/500... Training loss: 0.0036\n",
      "Epoch: 361/500... Training loss: 0.0023\n",
      "Epoch: 361/500... Training loss: 0.0248\n",
      "Epoch: 361/500... Training loss: 0.0024\n",
      "Epoch: 361/500... Training loss: 0.0199\n",
      "Epoch: 361/500... Training loss: 0.0452\n",
      "Epoch: 361/500... Training loss: 0.0017\n",
      "Epoch: 361/500... Training loss: 0.0125\n",
      "Epoch: 361/500... Training loss: 0.0047\n",
      "Epoch: 361/500... Training loss: 0.0563\n",
      "Epoch: 361/500... Training loss: 0.0036\n",
      "Epoch: 361/500... Training loss: 0.0021\n",
      "Epoch: 361/500... Training loss: 0.1023\n",
      "Epoch: 361/500... Training loss: 0.0046\n",
      "Epoch: 361/500... Training loss: 0.0199\n",
      "Epoch: 361/500... Training loss: 0.0116\n",
      "Epoch: 361/500... Training loss: 0.0444\n",
      "Epoch: 361/500... Training loss: 0.0662\n",
      "Epoch: 361/500... Training loss: 0.0209\n",
      "Epoch: 361/500... Training loss: 0.0165\n",
      "Epoch: 361/500... Training loss: 0.0027\n",
      "Epoch: 362/500... Training loss: 0.0142\n",
      "Epoch: 362/500... Training loss: 0.0015\n",
      "Epoch: 362/500... Training loss: 0.0018\n",
      "Epoch: 362/500... Training loss: 0.0235\n",
      "Epoch: 362/500... Training loss: 0.0056\n",
      "Epoch: 362/500... Training loss: 0.0103\n",
      "Epoch: 362/500... Training loss: 0.0030\n",
      "Epoch: 362/500... Training loss: 0.0088\n",
      "Epoch: 362/500... Training loss: 0.0058\n",
      "Epoch: 362/500... Training loss: 0.0075\n",
      "Epoch: 362/500... Training loss: 0.0076\n",
      "Epoch: 362/500... Training loss: 0.0159\n",
      "Epoch: 362/500... Training loss: 0.0411\n",
      "Epoch: 362/500... Training loss: 0.0385\n",
      "Epoch: 362/500... Training loss: 0.0210\n",
      "Epoch: 362/500... Training loss: 0.0020\n",
      "Epoch: 362/500... Training loss: 0.0385\n",
      "Epoch: 362/500... Training loss: 0.0158\n",
      "Epoch: 362/500... Training loss: 0.0112\n",
      "Epoch: 362/500... Training loss: 0.0143\n",
      "Epoch: 362/500... Training loss: 0.0026\n",
      "Epoch: 362/500... Training loss: 0.0093\n",
      "Epoch: 362/500... Training loss: 0.0200\n",
      "Epoch: 362/500... Training loss: 0.0022\n",
      "Epoch: 362/500... Training loss: 0.0072\n",
      "Epoch: 362/500... Training loss: 0.0160\n",
      "Epoch: 362/500... Training loss: 0.0027\n",
      "Epoch: 362/500... Training loss: 0.0943\n",
      "Epoch: 362/500... Training loss: 0.0053\n",
      "Epoch: 362/500... Training loss: 0.0182\n",
      "Epoch: 362/500... Training loss: 0.0015\n",
      "Epoch: 363/500... Training loss: 0.0008\n",
      "Epoch: 363/500... Training loss: 0.0016\n",
      "Epoch: 363/500... Training loss: 0.0051\n",
      "Epoch: 363/500... Training loss: 0.0128\n",
      "Epoch: 363/500... Training loss: 0.0041\n",
      "Epoch: 363/500... Training loss: 0.0129\n",
      "Epoch: 363/500... Training loss: 0.0063\n",
      "Epoch: 363/500... Training loss: 0.0022\n",
      "Epoch: 363/500... Training loss: 0.0014\n",
      "Epoch: 363/500... Training loss: 0.0054\n",
      "Epoch: 363/500... Training loss: 0.0074\n",
      "Epoch: 363/500... Training loss: 0.0511\n",
      "Epoch: 363/500... Training loss: 0.1384\n",
      "Epoch: 363/500... Training loss: 0.0037\n",
      "Epoch: 363/500... Training loss: 0.1097\n",
      "Epoch: 363/500... Training loss: 0.0389\n",
      "Epoch: 363/500... Training loss: 0.0401\n",
      "Epoch: 363/500... Training loss: 0.0099\n",
      "Epoch: 363/500... Training loss: 0.0041\n",
      "Epoch: 363/500... Training loss: 0.0055\n",
      "Epoch: 363/500... Training loss: 0.0762\n",
      "Epoch: 363/500... Training loss: 0.0494\n",
      "Epoch: 363/500... Training loss: 0.0357\n",
      "Epoch: 363/500... Training loss: 0.0054\n",
      "Epoch: 363/500... Training loss: 0.1087\n",
      "Epoch: 363/500... Training loss: 0.0131\n",
      "Epoch: 363/500... Training loss: 0.0029\n",
      "Epoch: 363/500... Training loss: 0.0178\n",
      "Epoch: 363/500... Training loss: 0.0179\n",
      "Epoch: 363/500... Training loss: 0.0133\n",
      "Epoch: 363/500... Training loss: 0.0146\n",
      "Epoch: 364/500... Training loss: 0.0056\n",
      "Epoch: 364/500... Training loss: 0.0919\n",
      "Epoch: 364/500... Training loss: 0.0297\n",
      "Epoch: 364/500... Training loss: 0.0084\n",
      "Epoch: 364/500... Training loss: 0.0047\n",
      "Epoch: 364/500... Training loss: 0.0070\n",
      "Epoch: 364/500... Training loss: 0.0104\n",
      "Epoch: 364/500... Training loss: 0.0246\n",
      "Epoch: 364/500... Training loss: 0.0158\n",
      "Epoch: 364/500... Training loss: 0.0120\n",
      "Epoch: 364/500... Training loss: 0.0083\n",
      "Epoch: 364/500... Training loss: 0.0250\n",
      "Epoch: 364/500... Training loss: 0.0596\n",
      "Epoch: 364/500... Training loss: 0.0021\n",
      "Epoch: 364/500... Training loss: 0.0506\n",
      "Epoch: 364/500... Training loss: 0.0660\n",
      "Epoch: 364/500... Training loss: 0.0029\n",
      "Epoch: 364/500... Training loss: 0.0206\n",
      "Epoch: 364/500... Training loss: 0.0410\n",
      "Epoch: 364/500... Training loss: 0.0163\n",
      "Epoch: 364/500... Training loss: 0.0240\n",
      "Epoch: 364/500... Training loss: 0.0042\n",
      "Epoch: 364/500... Training loss: 0.0053\n",
      "Epoch: 364/500... Training loss: 0.0041\n",
      "Epoch: 364/500... Training loss: 0.0026\n",
      "Epoch: 364/500... Training loss: 0.0202\n",
      "Epoch: 364/500... Training loss: 0.0452\n",
      "Epoch: 364/500... Training loss: 0.0661\n",
      "Epoch: 364/500... Training loss: 0.0050\n",
      "Epoch: 364/500... Training loss: 0.0314\n",
      "Epoch: 364/500... Training loss: 0.0044\n",
      "Epoch: 365/500... Training loss: 0.0147\n",
      "Epoch: 365/500... Training loss: 0.0635\n",
      "Epoch: 365/500... Training loss: 0.0030\n",
      "Epoch: 365/500... Training loss: 0.0033\n",
      "Epoch: 365/500... Training loss: 0.0040\n",
      "Epoch: 365/500... Training loss: 0.0324\n",
      "Epoch: 365/500... Training loss: 0.0026\n",
      "Epoch: 365/500... Training loss: 0.0118\n",
      "Epoch: 365/500... Training loss: 0.0058\n",
      "Epoch: 365/500... Training loss: 0.0101\n",
      "Epoch: 365/500... Training loss: 0.0266\n",
      "Epoch: 365/500... Training loss: 0.0203\n",
      "Epoch: 365/500... Training loss: 0.0318\n",
      "Epoch: 365/500... Training loss: 0.0058\n",
      "Epoch: 365/500... Training loss: 0.0050\n",
      "Epoch: 365/500... Training loss: 0.0166\n",
      "Epoch: 365/500... Training loss: 0.0071\n",
      "Epoch: 365/500... Training loss: 0.0051\n",
      "Epoch: 365/500... Training loss: 0.0015\n",
      "Epoch: 365/500... Training loss: 0.0051\n",
      "Epoch: 365/500... Training loss: 0.0036\n",
      "Epoch: 365/500... Training loss: 0.0326\n",
      "Epoch: 365/500... Training loss: 0.0274\n",
      "Epoch: 365/500... Training loss: 0.0082\n",
      "Epoch: 365/500... Training loss: 0.0039\n",
      "Epoch: 365/500... Training loss: 0.0143\n",
      "Epoch: 365/500... Training loss: 0.0028\n",
      "Epoch: 365/500... Training loss: 0.0677\n",
      "Epoch: 365/500... Training loss: 0.0727\n",
      "Epoch: 365/500... Training loss: 0.0088\n",
      "Epoch: 365/500... Training loss: 0.0087\n",
      "Epoch: 366/500... Training loss: 0.0627\n",
      "Epoch: 366/500... Training loss: 0.0881\n",
      "Epoch: 366/500... Training loss: 0.0223\n",
      "Epoch: 366/500... Training loss: 0.0350\n",
      "Epoch: 366/500... Training loss: 0.0020\n",
      "Epoch: 366/500... Training loss: 0.0325\n",
      "Epoch: 366/500... Training loss: 0.0930\n",
      "Epoch: 366/500... Training loss: 0.0104\n",
      "Epoch: 366/500... Training loss: 0.0034\n",
      "Epoch: 366/500... Training loss: 0.0121\n",
      "Epoch: 366/500... Training loss: 0.0305\n",
      "Epoch: 366/500... Training loss: 0.0876\n",
      "Epoch: 366/500... Training loss: 0.0648\n",
      "Epoch: 366/500... Training loss: 0.0078\n",
      "Epoch: 366/500... Training loss: 0.0941\n",
      "Epoch: 366/500... Training loss: 0.0297\n",
      "Epoch: 366/500... Training loss: 0.0084\n",
      "Epoch: 366/500... Training loss: 0.0018\n",
      "Epoch: 366/500... Training loss: 0.0382\n",
      "Epoch: 366/500... Training loss: 0.0158\n",
      "Epoch: 366/500... Training loss: 0.0083\n",
      "Epoch: 366/500... Training loss: 0.0482\n",
      "Epoch: 366/500... Training loss: 0.0012\n",
      "Epoch: 366/500... Training loss: 0.0207\n",
      "Epoch: 366/500... Training loss: 0.0165\n",
      "Epoch: 366/500... Training loss: 0.0071\n",
      "Epoch: 366/500... Training loss: 0.0034\n",
      "Epoch: 366/500... Training loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 366/500... Training loss: 0.0051\n",
      "Epoch: 366/500... Training loss: 0.0044\n",
      "Epoch: 366/500... Training loss: 0.0204\n",
      "Epoch: 367/500... Training loss: 0.0101\n",
      "Epoch: 367/500... Training loss: 0.0121\n",
      "Epoch: 367/500... Training loss: 0.0034\n",
      "Epoch: 367/500... Training loss: 0.0043\n",
      "Epoch: 367/500... Training loss: 0.0105\n",
      "Epoch: 367/500... Training loss: 0.0435\n",
      "Epoch: 367/500... Training loss: 0.0035\n",
      "Epoch: 367/500... Training loss: 0.0033\n",
      "Epoch: 367/500... Training loss: 0.0034\n",
      "Epoch: 367/500... Training loss: 0.0059\n",
      "Epoch: 367/500... Training loss: 0.0093\n",
      "Epoch: 367/500... Training loss: 0.0540\n",
      "Epoch: 367/500... Training loss: 0.0046\n",
      "Epoch: 367/500... Training loss: 0.0245\n",
      "Epoch: 367/500... Training loss: 0.0020\n",
      "Epoch: 367/500... Training loss: 0.0082\n",
      "Epoch: 367/500... Training loss: 0.0052\n",
      "Epoch: 367/500... Training loss: 0.0039\n",
      "Epoch: 367/500... Training loss: 0.0114\n",
      "Epoch: 367/500... Training loss: 0.0555\n",
      "Epoch: 367/500... Training loss: 0.0074\n",
      "Epoch: 367/500... Training loss: 0.0019\n",
      "Epoch: 367/500... Training loss: 0.0281\n",
      "Epoch: 367/500... Training loss: 0.0160\n",
      "Epoch: 367/500... Training loss: 0.0060\n",
      "Epoch: 367/500... Training loss: 0.0138\n",
      "Epoch: 367/500... Training loss: 0.0462\n",
      "Epoch: 367/500... Training loss: 0.0273\n",
      "Epoch: 367/500... Training loss: 0.0348\n",
      "Epoch: 367/500... Training loss: 0.0046\n",
      "Epoch: 367/500... Training loss: 0.0059\n",
      "Epoch: 368/500... Training loss: 0.0057\n",
      "Epoch: 368/500... Training loss: 0.0016\n",
      "Epoch: 368/500... Training loss: 0.0051\n",
      "Epoch: 368/500... Training loss: 0.0101\n",
      "Epoch: 368/500... Training loss: 0.0154\n",
      "Epoch: 368/500... Training loss: 0.0217\n",
      "Epoch: 368/500... Training loss: 0.0038\n",
      "Epoch: 368/500... Training loss: 0.0061\n",
      "Epoch: 368/500... Training loss: 0.0182\n",
      "Epoch: 368/500... Training loss: 0.0142\n",
      "Epoch: 368/500... Training loss: 0.0209\n",
      "Epoch: 368/500... Training loss: 0.0281\n",
      "Epoch: 368/500... Training loss: 0.0063\n",
      "Epoch: 368/500... Training loss: 0.0890\n",
      "Epoch: 368/500... Training loss: 0.0064\n",
      "Epoch: 368/500... Training loss: 0.0083\n",
      "Epoch: 368/500... Training loss: 0.0515\n",
      "Epoch: 368/500... Training loss: 0.0019\n",
      "Epoch: 368/500... Training loss: 0.0040\n",
      "Epoch: 368/500... Training loss: 0.0375\n",
      "Epoch: 368/500... Training loss: 0.0246\n",
      "Epoch: 368/500... Training loss: 0.0036\n",
      "Epoch: 368/500... Training loss: 0.0589\n",
      "Epoch: 368/500... Training loss: 0.0195\n",
      "Epoch: 368/500... Training loss: 0.0013\n",
      "Epoch: 368/500... Training loss: 0.0186\n",
      "Epoch: 368/500... Training loss: 0.0106\n",
      "Epoch: 368/500... Training loss: 0.0169\n",
      "Epoch: 368/500... Training loss: 0.0207\n",
      "Epoch: 368/500... Training loss: 0.0034\n",
      "Epoch: 368/500... Training loss: 0.0065\n",
      "Epoch: 369/500... Training loss: 0.0066\n",
      "Epoch: 369/500... Training loss: 0.0036\n",
      "Epoch: 369/500... Training loss: 0.0654\n",
      "Epoch: 369/500... Training loss: 0.0049\n",
      "Epoch: 369/500... Training loss: 0.0108\n",
      "Epoch: 369/500... Training loss: 0.0051\n",
      "Epoch: 369/500... Training loss: 0.0041\n",
      "Epoch: 369/500... Training loss: 0.0241\n",
      "Epoch: 369/500... Training loss: 0.0080\n",
      "Epoch: 369/500... Training loss: 0.0056\n",
      "Epoch: 369/500... Training loss: 0.0161\n",
      "Epoch: 369/500... Training loss: 0.0477\n",
      "Epoch: 369/500... Training loss: 0.0076\n",
      "Epoch: 369/500... Training loss: 0.0043\n",
      "Epoch: 369/500... Training loss: 0.0056\n",
      "Epoch: 369/500... Training loss: 0.0154\n",
      "Epoch: 369/500... Training loss: 0.0036\n",
      "Epoch: 369/500... Training loss: 0.0031\n",
      "Epoch: 369/500... Training loss: 0.0382\n",
      "Epoch: 369/500... Training loss: 0.0372\n",
      "Epoch: 369/500... Training loss: 0.0211\n",
      "Epoch: 369/500... Training loss: 0.0258\n",
      "Epoch: 369/500... Training loss: 0.0141\n",
      "Epoch: 369/500... Training loss: 0.0046\n",
      "Epoch: 369/500... Training loss: 0.0083\n",
      "Epoch: 369/500... Training loss: 0.0024\n",
      "Epoch: 369/500... Training loss: 0.0108\n",
      "Epoch: 369/500... Training loss: 0.0132\n",
      "Epoch: 369/500... Training loss: 0.0019\n",
      "Epoch: 369/500... Training loss: 0.0028\n",
      "Epoch: 369/500... Training loss: 0.0609\n",
      "Epoch: 370/500... Training loss: 0.0215\n",
      "Epoch: 370/500... Training loss: 0.0042\n",
      "Epoch: 370/500... Training loss: 0.0065\n",
      "Epoch: 370/500... Training loss: 0.0029\n",
      "Epoch: 370/500... Training loss: 0.0092\n",
      "Epoch: 370/500... Training loss: 0.0519\n",
      "Epoch: 370/500... Training loss: 0.0032\n",
      "Epoch: 370/500... Training loss: 0.0631\n",
      "Epoch: 370/500... Training loss: 0.0060\n",
      "Epoch: 370/500... Training loss: 0.0024\n",
      "Epoch: 370/500... Training loss: 0.0062\n",
      "Epoch: 370/500... Training loss: 0.0020\n",
      "Epoch: 370/500... Training loss: 0.0506\n",
      "Epoch: 370/500... Training loss: 0.0292\n",
      "Epoch: 370/500... Training loss: 0.0078\n",
      "Epoch: 370/500... Training loss: 0.0458\n",
      "Epoch: 370/500... Training loss: 0.0912\n",
      "Epoch: 370/500... Training loss: 0.0065\n",
      "Epoch: 370/500... Training loss: 0.0099\n",
      "Epoch: 370/500... Training loss: 0.0134\n",
      "Epoch: 370/500... Training loss: 0.0035\n",
      "Epoch: 370/500... Training loss: 0.0559\n",
      "Epoch: 370/500... Training loss: 0.0104\n",
      "Epoch: 370/500... Training loss: 0.0145\n",
      "Epoch: 370/500... Training loss: 0.0096\n",
      "Epoch: 370/500... Training loss: 0.0036\n",
      "Epoch: 370/500... Training loss: 0.0051\n",
      "Epoch: 370/500... Training loss: 0.0031\n",
      "Epoch: 370/500... Training loss: 0.0046\n",
      "Epoch: 370/500... Training loss: 0.0405\n",
      "Epoch: 370/500... Training loss: 0.0106\n",
      "Epoch: 371/500... Training loss: 0.0684\n",
      "Epoch: 371/500... Training loss: 0.0065\n",
      "Epoch: 371/500... Training loss: 0.0175\n",
      "Epoch: 371/500... Training loss: 0.0059\n",
      "Epoch: 371/500... Training loss: 0.0075\n",
      "Epoch: 371/500... Training loss: 0.0232\n",
      "Epoch: 371/500... Training loss: 0.0020\n",
      "Epoch: 371/500... Training loss: 0.0146\n",
      "Epoch: 371/500... Training loss: 0.0047\n",
      "Epoch: 371/500... Training loss: 0.0156\n",
      "Epoch: 371/500... Training loss: 0.0573\n",
      "Epoch: 371/500... Training loss: 0.0054\n",
      "Epoch: 371/500... Training loss: 0.0010\n",
      "Epoch: 371/500... Training loss: 0.0061\n",
      "Epoch: 371/500... Training loss: 0.0178\n",
      "Epoch: 371/500... Training loss: 0.0022\n",
      "Epoch: 371/500... Training loss: 0.0026\n",
      "Epoch: 371/500... Training loss: 0.0034\n",
      "Epoch: 371/500... Training loss: 0.0183\n",
      "Epoch: 371/500... Training loss: 0.0024\n",
      "Epoch: 371/500... Training loss: 0.0060\n",
      "Epoch: 371/500... Training loss: 0.0241\n",
      "Epoch: 371/500... Training loss: 0.0018\n",
      "Epoch: 371/500... Training loss: 0.0173\n",
      "Epoch: 371/500... Training loss: 0.0070\n",
      "Epoch: 371/500... Training loss: 0.0052\n",
      "Epoch: 371/500... Training loss: 0.0070\n",
      "Epoch: 371/500... Training loss: 0.0092\n",
      "Epoch: 371/500... Training loss: 0.0012\n",
      "Epoch: 371/500... Training loss: 0.0061\n",
      "Epoch: 371/500... Training loss: 0.0703\n",
      "Epoch: 372/500... Training loss: 0.0152\n",
      "Epoch: 372/500... Training loss: 0.0166\n",
      "Epoch: 372/500... Training loss: 0.0025\n",
      "Epoch: 372/500... Training loss: 0.0028\n",
      "Epoch: 372/500... Training loss: 0.0563\n",
      "Epoch: 372/500... Training loss: 0.0034\n",
      "Epoch: 372/500... Training loss: 0.0010\n",
      "Epoch: 372/500... Training loss: 0.0358\n",
      "Epoch: 372/500... Training loss: 0.0282\n",
      "Epoch: 372/500... Training loss: 0.0029\n",
      "Epoch: 372/500... Training loss: 0.0212\n",
      "Epoch: 372/500... Training loss: 0.0372\n",
      "Epoch: 372/500... Training loss: 0.0035\n",
      "Epoch: 372/500... Training loss: 0.0164\n",
      "Epoch: 372/500... Training loss: 0.0352\n",
      "Epoch: 372/500... Training loss: 0.0197\n",
      "Epoch: 372/500... Training loss: 0.0319\n",
      "Epoch: 372/500... Training loss: 0.0083\n",
      "Epoch: 372/500... Training loss: 0.0164\n",
      "Epoch: 372/500... Training loss: 0.0219\n",
      "Epoch: 372/500... Training loss: 0.0348\n",
      "Epoch: 372/500... Training loss: 0.0044\n",
      "Epoch: 372/500... Training loss: 0.0018\n",
      "Epoch: 372/500... Training loss: 0.0010\n",
      "Epoch: 372/500... Training loss: 0.0254\n",
      "Epoch: 372/500... Training loss: 0.0029\n",
      "Epoch: 372/500... Training loss: 0.0008\n",
      "Epoch: 372/500... Training loss: 0.0136\n",
      "Epoch: 372/500... Training loss: 0.0101\n",
      "Epoch: 372/500... Training loss: 0.0720\n",
      "Epoch: 372/500... Training loss: 0.0051\n",
      "Epoch: 373/500... Training loss: 0.0104\n",
      "Epoch: 373/500... Training loss: 0.0643\n",
      "Epoch: 373/500... Training loss: 0.0043\n",
      "Epoch: 373/500... Training loss: 0.1500\n",
      "Epoch: 373/500... Training loss: 0.0147\n",
      "Epoch: 373/500... Training loss: 0.0105\n",
      "Epoch: 373/500... Training loss: 0.0124\n",
      "Epoch: 373/500... Training loss: 0.0094\n",
      "Epoch: 373/500... Training loss: 0.0090\n",
      "Epoch: 373/500... Training loss: 0.0018\n",
      "Epoch: 373/500... Training loss: 0.0029\n",
      "Epoch: 373/500... Training loss: 0.0022\n",
      "Epoch: 373/500... Training loss: 0.0317\n",
      "Epoch: 373/500... Training loss: 0.0027\n",
      "Epoch: 373/500... Training loss: 0.0275\n",
      "Epoch: 373/500... Training loss: 0.0017\n",
      "Epoch: 373/500... Training loss: 0.0019\n",
      "Epoch: 373/500... Training loss: 0.0014\n",
      "Epoch: 373/500... Training loss: 0.0484\n",
      "Epoch: 373/500... Training loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 373/500... Training loss: 0.0077\n",
      "Epoch: 373/500... Training loss: 0.0283\n",
      "Epoch: 373/500... Training loss: 0.0030\n",
      "Epoch: 373/500... Training loss: 0.0151\n",
      "Epoch: 373/500... Training loss: 0.0178\n",
      "Epoch: 373/500... Training loss: 0.0189\n",
      "Epoch: 373/500... Training loss: 0.0491\n",
      "Epoch: 373/500... Training loss: 0.0046\n",
      "Epoch: 373/500... Training loss: 0.0025\n",
      "Epoch: 373/500... Training loss: 0.0017\n",
      "Epoch: 373/500... Training loss: 0.0067\n",
      "Epoch: 374/500... Training loss: 0.0011\n",
      "Epoch: 374/500... Training loss: 0.0328\n",
      "Epoch: 374/500... Training loss: 0.0204\n",
      "Epoch: 374/500... Training loss: 0.0657\n",
      "Epoch: 374/500... Training loss: 0.0021\n",
      "Epoch: 374/500... Training loss: 0.0364\n",
      "Epoch: 374/500... Training loss: 0.0009\n",
      "Epoch: 374/500... Training loss: 0.0070\n",
      "Epoch: 374/500... Training loss: 0.0028\n",
      "Epoch: 374/500... Training loss: 0.0218\n",
      "Epoch: 374/500... Training loss: 0.0166\n",
      "Epoch: 374/500... Training loss: 0.0324\n",
      "Epoch: 374/500... Training loss: 0.0531\n",
      "Epoch: 374/500... Training loss: 0.0083\n",
      "Epoch: 374/500... Training loss: 0.0040\n",
      "Epoch: 374/500... Training loss: 0.0097\n",
      "Epoch: 374/500... Training loss: 0.0055\n",
      "Epoch: 374/500... Training loss: 0.0035\n",
      "Epoch: 374/500... Training loss: 0.0032\n",
      "Epoch: 374/500... Training loss: 0.0071\n",
      "Epoch: 374/500... Training loss: 0.0171\n",
      "Epoch: 374/500... Training loss: 0.0237\n",
      "Epoch: 374/500... Training loss: 0.0008\n",
      "Epoch: 374/500... Training loss: 0.0017\n",
      "Epoch: 374/500... Training loss: 0.0031\n",
      "Epoch: 374/500... Training loss: 0.0015\n",
      "Epoch: 374/500... Training loss: 0.0127\n",
      "Epoch: 374/500... Training loss: 0.0030\n",
      "Epoch: 374/500... Training loss: 0.0104\n",
      "Epoch: 374/500... Training loss: 0.0036\n",
      "Epoch: 374/500... Training loss: 0.0006\n",
      "Epoch: 375/500... Training loss: 0.0018\n",
      "Epoch: 375/500... Training loss: 0.0315\n",
      "Epoch: 375/500... Training loss: 0.0209\n",
      "Epoch: 375/500... Training loss: 0.0038\n",
      "Epoch: 375/500... Training loss: 0.0089\n",
      "Epoch: 375/500... Training loss: 0.0071\n",
      "Epoch: 375/500... Training loss: 0.0008\n",
      "Epoch: 375/500... Training loss: 0.0030\n",
      "Epoch: 375/500... Training loss: 0.0198\n",
      "Epoch: 375/500... Training loss: 0.0087\n",
      "Epoch: 375/500... Training loss: 0.0036\n",
      "Epoch: 375/500... Training loss: 0.0164\n",
      "Epoch: 375/500... Training loss: 0.0934\n",
      "Epoch: 375/500... Training loss: 0.0056\n",
      "Epoch: 375/500... Training loss: 0.0288\n",
      "Epoch: 375/500... Training loss: 0.0023\n",
      "Epoch: 375/500... Training loss: 0.0061\n",
      "Epoch: 375/500... Training loss: 0.0008\n",
      "Epoch: 375/500... Training loss: 0.0022\n",
      "Epoch: 375/500... Training loss: 0.0030\n",
      "Epoch: 375/500... Training loss: 0.0047\n",
      "Epoch: 375/500... Training loss: 0.0019\n",
      "Epoch: 375/500... Training loss: 0.0038\n",
      "Epoch: 375/500... Training loss: 0.1112\n",
      "Epoch: 375/500... Training loss: 0.0046\n",
      "Epoch: 375/500... Training loss: 0.0407\n",
      "Epoch: 375/500... Training loss: 0.0011\n",
      "Epoch: 375/500... Training loss: 0.0041\n",
      "Epoch: 375/500... Training loss: 0.0147\n",
      "Epoch: 375/500... Training loss: 0.0020\n",
      "Epoch: 375/500... Training loss: 0.0016\n",
      "Epoch: 376/500... Training loss: 0.0074\n",
      "Epoch: 376/500... Training loss: 0.0032\n",
      "Epoch: 376/500... Training loss: 0.0018\n",
      "Epoch: 376/500... Training loss: 0.0144\n",
      "Epoch: 376/500... Training loss: 0.0043\n",
      "Epoch: 376/500... Training loss: 0.0028\n",
      "Epoch: 376/500... Training loss: 0.0047\n",
      "Epoch: 376/500... Training loss: 0.0084\n",
      "Epoch: 376/500... Training loss: 0.0224\n",
      "Epoch: 376/500... Training loss: 0.0295\n",
      "Epoch: 376/500... Training loss: 0.0053\n",
      "Epoch: 376/500... Training loss: 0.0032\n",
      "Epoch: 376/500... Training loss: 0.0018\n",
      "Epoch: 376/500... Training loss: 0.0053\n",
      "Epoch: 376/500... Training loss: 0.1264\n",
      "Epoch: 376/500... Training loss: 0.0020\n",
      "Epoch: 376/500... Training loss: 0.0085\n",
      "Epoch: 376/500... Training loss: 0.0505\n",
      "Epoch: 376/500... Training loss: 0.0008\n",
      "Epoch: 376/500... Training loss: 0.0008\n",
      "Epoch: 376/500... Training loss: 0.0015\n",
      "Epoch: 376/500... Training loss: 0.0029\n",
      "Epoch: 376/500... Training loss: 0.0141\n",
      "Epoch: 376/500... Training loss: 0.0026\n",
      "Epoch: 376/500... Training loss: 0.0134\n",
      "Epoch: 376/500... Training loss: 0.0012\n",
      "Epoch: 376/500... Training loss: 0.0179\n",
      "Epoch: 376/500... Training loss: 0.0043\n",
      "Epoch: 376/500... Training loss: 0.0231\n",
      "Epoch: 376/500... Training loss: 0.0027\n",
      "Epoch: 376/500... Training loss: 0.0051\n",
      "Epoch: 377/500... Training loss: 0.0016\n",
      "Epoch: 377/500... Training loss: 0.0020\n",
      "Epoch: 377/500... Training loss: 0.0309\n",
      "Epoch: 377/500... Training loss: 0.0346\n",
      "Epoch: 377/500... Training loss: 0.0052\n",
      "Epoch: 377/500... Training loss: 0.0180\n",
      "Epoch: 377/500... Training loss: 0.0020\n",
      "Epoch: 377/500... Training loss: 0.0459\n",
      "Epoch: 377/500... Training loss: 0.0179\n",
      "Epoch: 377/500... Training loss: 0.0361\n",
      "Epoch: 377/500... Training loss: 0.0021\n",
      "Epoch: 377/500... Training loss: 0.0289\n",
      "Epoch: 377/500... Training loss: 0.0025\n",
      "Epoch: 377/500... Training loss: 0.0114\n",
      "Epoch: 377/500... Training loss: 0.0140\n",
      "Epoch: 377/500... Training loss: 0.0028\n",
      "Epoch: 377/500... Training loss: 0.0075\n",
      "Epoch: 377/500... Training loss: 0.0004\n",
      "Epoch: 377/500... Training loss: 0.0032\n",
      "Epoch: 377/500... Training loss: 0.0220\n",
      "Epoch: 377/500... Training loss: 0.0098\n",
      "Epoch: 377/500... Training loss: 0.0081\n",
      "Epoch: 377/500... Training loss: 0.0008\n",
      "Epoch: 377/500... Training loss: 0.0011\n",
      "Epoch: 377/500... Training loss: 0.0149\n",
      "Epoch: 377/500... Training loss: 0.0074\n",
      "Epoch: 377/500... Training loss: 0.1020\n",
      "Epoch: 377/500... Training loss: 0.0261\n",
      "Epoch: 377/500... Training loss: 0.0010\n",
      "Epoch: 377/500... Training loss: 0.0131\n",
      "Epoch: 377/500... Training loss: 0.0072\n",
      "Epoch: 378/500... Training loss: 0.0016\n",
      "Epoch: 378/500... Training loss: 0.0133\n",
      "Epoch: 378/500... Training loss: 0.0008\n",
      "Epoch: 378/500... Training loss: 0.0039\n",
      "Epoch: 378/500... Training loss: 0.0699\n",
      "Epoch: 378/500... Training loss: 0.0317\n",
      "Epoch: 378/500... Training loss: 0.0116\n",
      "Epoch: 378/500... Training loss: 0.0038\n",
      "Epoch: 378/500... Training loss: 0.0034\n",
      "Epoch: 378/500... Training loss: 0.0020\n",
      "Epoch: 378/500... Training loss: 0.0238\n",
      "Epoch: 378/500... Training loss: 0.0462\n",
      "Epoch: 378/500... Training loss: 0.0123\n",
      "Epoch: 378/500... Training loss: 0.0092\n",
      "Epoch: 378/500... Training loss: 0.0146\n",
      "Epoch: 378/500... Training loss: 0.0524\n",
      "Epoch: 378/500... Training loss: 0.0043\n",
      "Epoch: 378/500... Training loss: 0.0016\n",
      "Epoch: 378/500... Training loss: 0.1832\n",
      "Epoch: 378/500... Training loss: 0.0556\n",
      "Epoch: 378/500... Training loss: 0.0015\n",
      "Epoch: 378/500... Training loss: 0.0055\n",
      "Epoch: 378/500... Training loss: 0.0012\n",
      "Epoch: 378/500... Training loss: 0.0018\n",
      "Epoch: 378/500... Training loss: 0.0104\n",
      "Epoch: 378/500... Training loss: 0.0036\n",
      "Epoch: 378/500... Training loss: 0.0049\n",
      "Epoch: 378/500... Training loss: 0.0050\n",
      "Epoch: 378/500... Training loss: 0.0070\n",
      "Epoch: 378/500... Training loss: 0.0032\n",
      "Epoch: 378/500... Training loss: 0.0013\n",
      "Epoch: 379/500... Training loss: 0.0015\n",
      "Epoch: 379/500... Training loss: 0.0162\n",
      "Epoch: 379/500... Training loss: 0.0037\n",
      "Epoch: 379/500... Training loss: 0.0017\n",
      "Epoch: 379/500... Training loss: 0.0063\n",
      "Epoch: 379/500... Training loss: 0.0252\n",
      "Epoch: 379/500... Training loss: 0.0012\n",
      "Epoch: 379/500... Training loss: 0.0077\n",
      "Epoch: 379/500... Training loss: 0.0077\n",
      "Epoch: 379/500... Training loss: 0.0300\n",
      "Epoch: 379/500... Training loss: 0.0046\n",
      "Epoch: 379/500... Training loss: 0.0368\n",
      "Epoch: 379/500... Training loss: 0.0149\n",
      "Epoch: 379/500... Training loss: 0.0443\n",
      "Epoch: 379/500... Training loss: 0.0027\n",
      "Epoch: 379/500... Training loss: 0.0148\n",
      "Epoch: 379/500... Training loss: 0.0014\n",
      "Epoch: 379/500... Training loss: 0.0010\n",
      "Epoch: 379/500... Training loss: 0.0220\n",
      "Epoch: 379/500... Training loss: 0.0170\n",
      "Epoch: 379/500... Training loss: 0.0041\n",
      "Epoch: 379/500... Training loss: 0.0157\n",
      "Epoch: 379/500... Training loss: 0.0011\n",
      "Epoch: 379/500... Training loss: 0.0166\n",
      "Epoch: 379/500... Training loss: 0.0322\n",
      "Epoch: 379/500... Training loss: 0.0104\n",
      "Epoch: 379/500... Training loss: 0.0020\n",
      "Epoch: 379/500... Training loss: 0.0274\n",
      "Epoch: 379/500... Training loss: 0.0225\n",
      "Epoch: 379/500... Training loss: 0.0015\n",
      "Epoch: 379/500... Training loss: 0.0024\n",
      "Epoch: 380/500... Training loss: 0.0033\n",
      "Epoch: 380/500... Training loss: 0.0015\n",
      "Epoch: 380/500... Training loss: 0.0082\n",
      "Epoch: 380/500... Training loss: 0.0020\n",
      "Epoch: 380/500... Training loss: 0.0023\n",
      "Epoch: 380/500... Training loss: 0.0014\n",
      "Epoch: 380/500... Training loss: 0.0264\n",
      "Epoch: 380/500... Training loss: 0.0095\n",
      "Epoch: 380/500... Training loss: 0.0218\n",
      "Epoch: 380/500... Training loss: 0.0022\n",
      "Epoch: 380/500... Training loss: 0.0077\n",
      "Epoch: 380/500... Training loss: 0.0104\n",
      "Epoch: 380/500... Training loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380/500... Training loss: 0.0028\n",
      "Epoch: 380/500... Training loss: 0.0053\n",
      "Epoch: 380/500... Training loss: 0.0213\n",
      "Epoch: 380/500... Training loss: 0.0802\n",
      "Epoch: 380/500... Training loss: 0.0381\n",
      "Epoch: 380/500... Training loss: 0.0142\n",
      "Epoch: 380/500... Training loss: 0.0023\n",
      "Epoch: 380/500... Training loss: 0.0036\n",
      "Epoch: 380/500... Training loss: 0.0425\n",
      "Epoch: 380/500... Training loss: 0.0023\n",
      "Epoch: 380/500... Training loss: 0.0023\n",
      "Epoch: 380/500... Training loss: 0.0020\n",
      "Epoch: 380/500... Training loss: 0.0115\n",
      "Epoch: 380/500... Training loss: 0.0084\n",
      "Epoch: 380/500... Training loss: 0.0185\n",
      "Epoch: 380/500... Training loss: 0.0051\n",
      "Epoch: 380/500... Training loss: 0.0080\n",
      "Epoch: 380/500... Training loss: 0.0017\n",
      "Epoch: 381/500... Training loss: 0.0029\n",
      "Epoch: 381/500... Training loss: 0.0142\n",
      "Epoch: 381/500... Training loss: 0.0069\n",
      "Epoch: 381/500... Training loss: 0.0291\n",
      "Epoch: 381/500... Training loss: 0.0009\n",
      "Epoch: 381/500... Training loss: 0.0264\n",
      "Epoch: 381/500... Training loss: 0.0038\n",
      "Epoch: 381/500... Training loss: 0.0077\n",
      "Epoch: 381/500... Training loss: 0.0251\n",
      "Epoch: 381/500... Training loss: 0.0014\n",
      "Epoch: 381/500... Training loss: 0.0223\n",
      "Epoch: 381/500... Training loss: 0.0182\n",
      "Epoch: 381/500... Training loss: 0.0375\n",
      "Epoch: 381/500... Training loss: 0.0068\n",
      "Epoch: 381/500... Training loss: 0.0122\n",
      "Epoch: 381/500... Training loss: 0.0023\n",
      "Epoch: 381/500... Training loss: 0.0595\n",
      "Epoch: 381/500... Training loss: 0.0051\n",
      "Epoch: 381/500... Training loss: 0.0582\n",
      "Epoch: 381/500... Training loss: 0.0626\n",
      "Epoch: 381/500... Training loss: 0.0023\n",
      "Epoch: 381/500... Training loss: 0.0799\n",
      "Epoch: 381/500... Training loss: 0.0021\n",
      "Epoch: 381/500... Training loss: 0.0235\n",
      "Epoch: 381/500... Training loss: 0.0036\n",
      "Epoch: 381/500... Training loss: 0.0345\n",
      "Epoch: 381/500... Training loss: 0.0031\n",
      "Epoch: 381/500... Training loss: 0.0020\n",
      "Epoch: 381/500... Training loss: 0.0759\n",
      "Epoch: 381/500... Training loss: 0.0024\n",
      "Epoch: 381/500... Training loss: 0.0027\n",
      "Epoch: 382/500... Training loss: 0.0027\n",
      "Epoch: 382/500... Training loss: 0.0022\n",
      "Epoch: 382/500... Training loss: 0.0159\n",
      "Epoch: 382/500... Training loss: 0.0103\n",
      "Epoch: 382/500... Training loss: 0.0047\n",
      "Epoch: 382/500... Training loss: 0.0033\n",
      "Epoch: 382/500... Training loss: 0.0013\n",
      "Epoch: 382/500... Training loss: 0.0173\n",
      "Epoch: 382/500... Training loss: 0.0248\n",
      "Epoch: 382/500... Training loss: 0.0085\n",
      "Epoch: 382/500... Training loss: 0.0017\n",
      "Epoch: 382/500... Training loss: 0.0776\n",
      "Epoch: 382/500... Training loss: 0.0159\n",
      "Epoch: 382/500... Training loss: 0.0180\n",
      "Epoch: 382/500... Training loss: 0.0041\n",
      "Epoch: 382/500... Training loss: 0.0016\n",
      "Epoch: 382/500... Training loss: 0.0045\n",
      "Epoch: 382/500... Training loss: 0.0119\n",
      "Epoch: 382/500... Training loss: 0.0146\n",
      "Epoch: 382/500... Training loss: 0.0606\n",
      "Epoch: 382/500... Training loss: 0.0146\n",
      "Epoch: 382/500... Training loss: 0.0312\n",
      "Epoch: 382/500... Training loss: 0.0024\n",
      "Epoch: 382/500... Training loss: 0.0186\n",
      "Epoch: 382/500... Training loss: 0.0888\n",
      "Epoch: 382/500... Training loss: 0.0030\n",
      "Epoch: 382/500... Training loss: 0.0336\n",
      "Epoch: 382/500... Training loss: 0.0113\n",
      "Epoch: 382/500... Training loss: 0.0019\n",
      "Epoch: 382/500... Training loss: 0.0056\n",
      "Epoch: 382/500... Training loss: 0.0211\n",
      "Epoch: 383/500... Training loss: 0.0081\n",
      "Epoch: 383/500... Training loss: 0.0474\n",
      "Epoch: 383/500... Training loss: 0.0011\n",
      "Epoch: 383/500... Training loss: 0.0106\n",
      "Epoch: 383/500... Training loss: 0.0114\n",
      "Epoch: 383/500... Training loss: 0.0073\n",
      "Epoch: 383/500... Training loss: 0.0018\n",
      "Epoch: 383/500... Training loss: 0.0211\n",
      "Epoch: 383/500... Training loss: 0.0049\n",
      "Epoch: 383/500... Training loss: 0.1683\n",
      "Epoch: 383/500... Training loss: 0.0043\n",
      "Epoch: 383/500... Training loss: 0.0010\n",
      "Epoch: 383/500... Training loss: 0.0241\n",
      "Epoch: 383/500... Training loss: 0.0180\n",
      "Epoch: 383/500... Training loss: 0.0007\n",
      "Epoch: 383/500... Training loss: 0.0076\n",
      "Epoch: 383/500... Training loss: 0.0054\n",
      "Epoch: 383/500... Training loss: 0.0007\n",
      "Epoch: 383/500... Training loss: 0.0138\n",
      "Epoch: 383/500... Training loss: 0.0058\n",
      "Epoch: 383/500... Training loss: 0.0059\n",
      "Epoch: 383/500... Training loss: 0.0162\n",
      "Epoch: 383/500... Training loss: 0.0009\n",
      "Epoch: 383/500... Training loss: 0.0268\n",
      "Epoch: 383/500... Training loss: 0.0038\n",
      "Epoch: 383/500... Training loss: 0.0293\n",
      "Epoch: 383/500... Training loss: 0.0278\n",
      "Epoch: 383/500... Training loss: 0.0032\n",
      "Epoch: 383/500... Training loss: 0.0029\n",
      "Epoch: 383/500... Training loss: 0.0516\n",
      "Epoch: 383/500... Training loss: 0.0512\n",
      "Epoch: 384/500... Training loss: 0.0031\n",
      "Epoch: 384/500... Training loss: 0.0025\n",
      "Epoch: 384/500... Training loss: 0.0410\n",
      "Epoch: 384/500... Training loss: 0.0071\n",
      "Epoch: 384/500... Training loss: 0.0062\n",
      "Epoch: 384/500... Training loss: 0.0039\n",
      "Epoch: 384/500... Training loss: 0.0016\n",
      "Epoch: 384/500... Training loss: 0.0461\n",
      "Epoch: 384/500... Training loss: 0.0077\n",
      "Epoch: 384/500... Training loss: 0.0024\n",
      "Epoch: 384/500... Training loss: 0.0024\n",
      "Epoch: 384/500... Training loss: 0.0410\n",
      "Epoch: 384/500... Training loss: 0.0126\n",
      "Epoch: 384/500... Training loss: 0.0190\n",
      "Epoch: 384/500... Training loss: 0.0379\n",
      "Epoch: 384/500... Training loss: 0.0111\n",
      "Epoch: 384/500... Training loss: 0.0049\n",
      "Epoch: 384/500... Training loss: 0.0110\n",
      "Epoch: 384/500... Training loss: 0.0677\n",
      "Epoch: 384/500... Training loss: 0.0052\n",
      "Epoch: 384/500... Training loss: 0.0741\n",
      "Epoch: 384/500... Training loss: 0.0137\n",
      "Epoch: 384/500... Training loss: 0.0389\n",
      "Epoch: 384/500... Training loss: 0.0155\n",
      "Epoch: 384/500... Training loss: 0.0038\n",
      "Epoch: 384/500... Training loss: 0.0474\n",
      "Epoch: 384/500... Training loss: 0.0011\n",
      "Epoch: 384/500... Training loss: 0.0006\n",
      "Epoch: 384/500... Training loss: 0.0143\n",
      "Epoch: 384/500... Training loss: 0.0111\n",
      "Epoch: 384/500... Training loss: 0.0443\n",
      "Epoch: 385/500... Training loss: 0.0024\n",
      "Epoch: 385/500... Training loss: 0.0037\n",
      "Epoch: 385/500... Training loss: 0.0045\n",
      "Epoch: 385/500... Training loss: 0.0012\n",
      "Epoch: 385/500... Training loss: 0.0055\n",
      "Epoch: 385/500... Training loss: 0.0076\n",
      "Epoch: 385/500... Training loss: 0.0152\n",
      "Epoch: 385/500... Training loss: 0.0126\n",
      "Epoch: 385/500... Training loss: 0.0318\n",
      "Epoch: 385/500... Training loss: 0.0218\n",
      "Epoch: 385/500... Training loss: 0.0045\n",
      "Epoch: 385/500... Training loss: 0.0014\n",
      "Epoch: 385/500... Training loss: 0.0015\n",
      "Epoch: 385/500... Training loss: 0.0024\n",
      "Epoch: 385/500... Training loss: 0.0152\n",
      "Epoch: 385/500... Training loss: 0.0034\n",
      "Epoch: 385/500... Training loss: 0.0096\n",
      "Epoch: 385/500... Training loss: 0.0044\n",
      "Epoch: 385/500... Training loss: 0.0162\n",
      "Epoch: 385/500... Training loss: 0.0325\n",
      "Epoch: 385/500... Training loss: 0.0014\n",
      "Epoch: 385/500... Training loss: 0.0010\n",
      "Epoch: 385/500... Training loss: 0.0079\n",
      "Epoch: 385/500... Training loss: 0.0079\n",
      "Epoch: 385/500... Training loss: 0.0007\n",
      "Epoch: 385/500... Training loss: 0.0042\n",
      "Epoch: 385/500... Training loss: 0.0082\n",
      "Epoch: 385/500... Training loss: 0.0009\n",
      "Epoch: 385/500... Training loss: 0.0018\n",
      "Epoch: 385/500... Training loss: 0.0010\n",
      "Epoch: 385/500... Training loss: 0.0043\n",
      "Epoch: 386/500... Training loss: 0.0024\n",
      "Epoch: 386/500... Training loss: 0.0499\n",
      "Epoch: 386/500... Training loss: 0.0107\n",
      "Epoch: 386/500... Training loss: 0.0038\n",
      "Epoch: 386/500... Training loss: 0.0046\n",
      "Epoch: 386/500... Training loss: 0.0181\n",
      "Epoch: 386/500... Training loss: 0.0260\n",
      "Epoch: 386/500... Training loss: 0.0138\n",
      "Epoch: 386/500... Training loss: 0.0022\n",
      "Epoch: 386/500... Training loss: 0.0064\n",
      "Epoch: 386/500... Training loss: 0.0254\n",
      "Epoch: 386/500... Training loss: 0.0039\n",
      "Epoch: 386/500... Training loss: 0.0097\n",
      "Epoch: 386/500... Training loss: 0.0086\n",
      "Epoch: 386/500... Training loss: 0.0021\n",
      "Epoch: 386/500... Training loss: 0.0051\n",
      "Epoch: 386/500... Training loss: 0.0051\n",
      "Epoch: 386/500... Training loss: 0.0374\n",
      "Epoch: 386/500... Training loss: 0.1367\n",
      "Epoch: 386/500... Training loss: 0.0043\n",
      "Epoch: 386/500... Training loss: 0.0024\n",
      "Epoch: 386/500... Training loss: 0.0315\n",
      "Epoch: 386/500... Training loss: 0.0276\n",
      "Epoch: 386/500... Training loss: 0.0073\n",
      "Epoch: 386/500... Training loss: 0.0063\n",
      "Epoch: 386/500... Training loss: 0.0065\n",
      "Epoch: 386/500... Training loss: 0.0018\n",
      "Epoch: 386/500... Training loss: 0.0104\n",
      "Epoch: 386/500... Training loss: 0.0201\n",
      "Epoch: 386/500... Training loss: 0.0181\n",
      "Epoch: 386/500... Training loss: 0.0015\n",
      "Epoch: 387/500... Training loss: 0.0021\n",
      "Epoch: 387/500... Training loss: 0.0560\n",
      "Epoch: 387/500... Training loss: 0.0012\n",
      "Epoch: 387/500... Training loss: 0.0052\n",
      "Epoch: 387/500... Training loss: 0.1043\n",
      "Epoch: 387/500... Training loss: 0.0109\n",
      "Epoch: 387/500... Training loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387/500... Training loss: 0.0338\n",
      "Epoch: 387/500... Training loss: 0.0447\n",
      "Epoch: 387/500... Training loss: 0.0034\n",
      "Epoch: 387/500... Training loss: 0.0028\n",
      "Epoch: 387/500... Training loss: 0.0025\n",
      "Epoch: 387/500... Training loss: 0.0021\n",
      "Epoch: 387/500... Training loss: 0.0022\n",
      "Epoch: 387/500... Training loss: 0.0008\n",
      "Epoch: 387/500... Training loss: 0.0102\n",
      "Epoch: 387/500... Training loss: 0.0541\n",
      "Epoch: 387/500... Training loss: 0.0063\n",
      "Epoch: 387/500... Training loss: 0.0145\n",
      "Epoch: 387/500... Training loss: 0.0045\n",
      "Epoch: 387/500... Training loss: 0.0089\n",
      "Epoch: 387/500... Training loss: 0.0121\n",
      "Epoch: 387/500... Training loss: 0.0119\n",
      "Epoch: 387/500... Training loss: 0.0041\n",
      "Epoch: 387/500... Training loss: 0.0354\n",
      "Epoch: 387/500... Training loss: 0.0025\n",
      "Epoch: 387/500... Training loss: 0.0807\n",
      "Epoch: 387/500... Training loss: 0.0296\n",
      "Epoch: 387/500... Training loss: 0.0508\n",
      "Epoch: 387/500... Training loss: 0.0777\n",
      "Epoch: 387/500... Training loss: 0.0037\n",
      "Epoch: 388/500... Training loss: 0.0012\n",
      "Epoch: 388/500... Training loss: 0.0022\n",
      "Epoch: 388/500... Training loss: 0.0016\n",
      "Epoch: 388/500... Training loss: 0.0319\n",
      "Epoch: 388/500... Training loss: 0.0125\n",
      "Epoch: 388/500... Training loss: 0.0029\n",
      "Epoch: 388/500... Training loss: 0.0076\n",
      "Epoch: 388/500... Training loss: 0.0186\n",
      "Epoch: 388/500... Training loss: 0.0030\n",
      "Epoch: 388/500... Training loss: 0.0456\n",
      "Epoch: 388/500... Training loss: 0.0024\n",
      "Epoch: 388/500... Training loss: 0.0037\n",
      "Epoch: 388/500... Training loss: 0.0152\n",
      "Epoch: 388/500... Training loss: 0.0066\n",
      "Epoch: 388/500... Training loss: 0.0044\n",
      "Epoch: 388/500... Training loss: 0.0020\n",
      "Epoch: 388/500... Training loss: 0.0016\n",
      "Epoch: 388/500... Training loss: 0.0040\n",
      "Epoch: 388/500... Training loss: 0.0134\n",
      "Epoch: 388/500... Training loss: 0.0029\n",
      "Epoch: 388/500... Training loss: 0.0595\n",
      "Epoch: 388/500... Training loss: 0.0017\n",
      "Epoch: 388/500... Training loss: 0.0617\n",
      "Epoch: 388/500... Training loss: 0.0027\n",
      "Epoch: 388/500... Training loss: 0.0177\n",
      "Epoch: 388/500... Training loss: 0.0236\n",
      "Epoch: 388/500... Training loss: 0.0040\n",
      "Epoch: 388/500... Training loss: 0.0271\n",
      "Epoch: 388/500... Training loss: 0.0171\n",
      "Epoch: 388/500... Training loss: 0.0122\n",
      "Epoch: 388/500... Training loss: 0.0014\n",
      "Epoch: 389/500... Training loss: 0.0025\n",
      "Epoch: 389/500... Training loss: 0.0074\n",
      "Epoch: 389/500... Training loss: 0.0021\n",
      "Epoch: 389/500... Training loss: 0.0019\n",
      "Epoch: 389/500... Training loss: 0.0088\n",
      "Epoch: 389/500... Training loss: 0.0072\n",
      "Epoch: 389/500... Training loss: 0.0048\n",
      "Epoch: 389/500... Training loss: 0.0174\n",
      "Epoch: 389/500... Training loss: 0.0027\n",
      "Epoch: 389/500... Training loss: 0.0285\n",
      "Epoch: 389/500... Training loss: 0.0099\n",
      "Epoch: 389/500... Training loss: 0.0054\n",
      "Epoch: 389/500... Training loss: 0.0121\n",
      "Epoch: 389/500... Training loss: 0.0022\n",
      "Epoch: 389/500... Training loss: 0.0050\n",
      "Epoch: 389/500... Training loss: 0.0088\n",
      "Epoch: 389/500... Training loss: 0.0264\n",
      "Epoch: 389/500... Training loss: 0.0090\n",
      "Epoch: 389/500... Training loss: 0.0020\n",
      "Epoch: 389/500... Training loss: 0.0024\n",
      "Epoch: 389/500... Training loss: 0.0031\n",
      "Epoch: 389/500... Training loss: 0.0284\n",
      "Epoch: 389/500... Training loss: 0.0197\n",
      "Epoch: 389/500... Training loss: 0.0205\n",
      "Epoch: 389/500... Training loss: 0.0030\n",
      "Epoch: 389/500... Training loss: 0.0008\n",
      "Epoch: 389/500... Training loss: 0.0307\n",
      "Epoch: 389/500... Training loss: 0.0022\n",
      "Epoch: 389/500... Training loss: 0.0052\n",
      "Epoch: 389/500... Training loss: 0.0105\n",
      "Epoch: 389/500... Training loss: 0.0040\n",
      "Epoch: 390/500... Training loss: 0.0083\n",
      "Epoch: 390/500... Training loss: 0.0048\n",
      "Epoch: 390/500... Training loss: 0.0043\n",
      "Epoch: 390/500... Training loss: 0.0024\n",
      "Epoch: 390/500... Training loss: 0.0026\n",
      "Epoch: 390/500... Training loss: 0.0309\n",
      "Epoch: 390/500... Training loss: 0.0012\n",
      "Epoch: 390/500... Training loss: 0.0031\n",
      "Epoch: 390/500... Training loss: 0.0202\n",
      "Epoch: 390/500... Training loss: 0.0105\n",
      "Epoch: 390/500... Training loss: 0.0143\n",
      "Epoch: 390/500... Training loss: 0.0307\n",
      "Epoch: 390/500... Training loss: 0.0043\n",
      "Epoch: 390/500... Training loss: 0.0024\n",
      "Epoch: 390/500... Training loss: 0.0031\n",
      "Epoch: 390/500... Training loss: 0.0075\n",
      "Epoch: 390/500... Training loss: 0.0031\n",
      "Epoch: 390/500... Training loss: 0.0051\n",
      "Epoch: 390/500... Training loss: 0.0062\n",
      "Epoch: 390/500... Training loss: 0.0028\n",
      "Epoch: 390/500... Training loss: 0.0025\n",
      "Epoch: 390/500... Training loss: 0.0575\n",
      "Epoch: 390/500... Training loss: 0.0744\n",
      "Epoch: 390/500... Training loss: 0.0018\n",
      "Epoch: 390/500... Training loss: 0.0021\n",
      "Epoch: 390/500... Training loss: 0.0137\n",
      "Epoch: 390/500... Training loss: 0.0035\n",
      "Epoch: 390/500... Training loss: 0.0051\n",
      "Epoch: 390/500... Training loss: 0.0050\n",
      "Epoch: 390/500... Training loss: 0.0986\n",
      "Epoch: 390/500... Training loss: 0.0773\n",
      "Epoch: 391/500... Training loss: 0.0028\n",
      "Epoch: 391/500... Training loss: 0.0054\n",
      "Epoch: 391/500... Training loss: 0.0052\n",
      "Epoch: 391/500... Training loss: 0.0068\n",
      "Epoch: 391/500... Training loss: 0.0074\n",
      "Epoch: 391/500... Training loss: 0.0073\n",
      "Epoch: 391/500... Training loss: 0.0229\n",
      "Epoch: 391/500... Training loss: 0.0124\n",
      "Epoch: 391/500... Training loss: 0.0012\n",
      "Epoch: 391/500... Training loss: 0.0087\n",
      "Epoch: 391/500... Training loss: 0.0054\n",
      "Epoch: 391/500... Training loss: 0.0028\n",
      "Epoch: 391/500... Training loss: 0.0093\n",
      "Epoch: 391/500... Training loss: 0.0017\n",
      "Epoch: 391/500... Training loss: 0.0015\n",
      "Epoch: 391/500... Training loss: 0.0043\n",
      "Epoch: 391/500... Training loss: 0.0127\n",
      "Epoch: 391/500... Training loss: 0.0018\n",
      "Epoch: 391/500... Training loss: 0.0020\n",
      "Epoch: 391/500... Training loss: 0.0017\n",
      "Epoch: 391/500... Training loss: 0.0016\n",
      "Epoch: 391/500... Training loss: 0.0173\n",
      "Epoch: 391/500... Training loss: 0.0863\n",
      "Epoch: 391/500... Training loss: 0.0009\n",
      "Epoch: 391/500... Training loss: 0.0014\n",
      "Epoch: 391/500... Training loss: 0.0029\n",
      "Epoch: 391/500... Training loss: 0.0104\n",
      "Epoch: 391/500... Training loss: 0.0021\n",
      "Epoch: 391/500... Training loss: 0.0149\n",
      "Epoch: 391/500... Training loss: 0.0149\n",
      "Epoch: 391/500... Training loss: 0.0019\n",
      "Epoch: 392/500... Training loss: 0.0092\n",
      "Epoch: 392/500... Training loss: 0.0524\n",
      "Epoch: 392/500... Training loss: 0.0051\n",
      "Epoch: 392/500... Training loss: 0.0138\n",
      "Epoch: 392/500... Training loss: 0.0023\n",
      "Epoch: 392/500... Training loss: 0.0024\n",
      "Epoch: 392/500... Training loss: 0.0130\n",
      "Epoch: 392/500... Training loss: 0.0310\n",
      "Epoch: 392/500... Training loss: 0.0016\n",
      "Epoch: 392/500... Training loss: 0.0020\n",
      "Epoch: 392/500... Training loss: 0.0233\n",
      "Epoch: 392/500... Training loss: 0.0005\n",
      "Epoch: 392/500... Training loss: 0.0330\n",
      "Epoch: 392/500... Training loss: 0.0082\n",
      "Epoch: 392/500... Training loss: 0.0191\n",
      "Epoch: 392/500... Training loss: 0.0257\n",
      "Epoch: 392/500... Training loss: 0.0042\n",
      "Epoch: 392/500... Training loss: 0.0082\n",
      "Epoch: 392/500... Training loss: 0.0076\n",
      "Epoch: 392/500... Training loss: 0.0027\n",
      "Epoch: 392/500... Training loss: 0.0014\n",
      "Epoch: 392/500... Training loss: 0.0035\n",
      "Epoch: 392/500... Training loss: 0.0071\n",
      "Epoch: 392/500... Training loss: 0.0009\n",
      "Epoch: 392/500... Training loss: 0.0011\n",
      "Epoch: 392/500... Training loss: 0.0010\n",
      "Epoch: 392/500... Training loss: 0.0007\n",
      "Epoch: 392/500... Training loss: 0.0190\n",
      "Epoch: 392/500... Training loss: 0.0026\n",
      "Epoch: 392/500... Training loss: 0.0018\n",
      "Epoch: 392/500... Training loss: 0.0024\n",
      "Epoch: 393/500... Training loss: 0.0008\n",
      "Epoch: 393/500... Training loss: 0.0012\n",
      "Epoch: 393/500... Training loss: 0.0235\n",
      "Epoch: 393/500... Training loss: 0.0062\n",
      "Epoch: 393/500... Training loss: 0.0011\n",
      "Epoch: 393/500... Training loss: 0.0160\n",
      "Epoch: 393/500... Training loss: 0.0121\n",
      "Epoch: 393/500... Training loss: 0.0113\n",
      "Epoch: 393/500... Training loss: 0.0030\n",
      "Epoch: 393/500... Training loss: 0.0026\n",
      "Epoch: 393/500... Training loss: 0.0179\n",
      "Epoch: 393/500... Training loss: 0.0090\n",
      "Epoch: 393/500... Training loss: 0.0101\n",
      "Epoch: 393/500... Training loss: 0.0049\n",
      "Epoch: 393/500... Training loss: 0.0079\n",
      "Epoch: 393/500... Training loss: 0.0604\n",
      "Epoch: 393/500... Training loss: 0.0452\n",
      "Epoch: 393/500... Training loss: 0.0020\n",
      "Epoch: 393/500... Training loss: 0.0040\n",
      "Epoch: 393/500... Training loss: 0.0035\n",
      "Epoch: 393/500... Training loss: 0.0118\n",
      "Epoch: 393/500... Training loss: 0.0010\n",
      "Epoch: 393/500... Training loss: 0.0012\n",
      "Epoch: 393/500... Training loss: 0.0043\n",
      "Epoch: 393/500... Training loss: 0.0034\n",
      "Epoch: 393/500... Training loss: 0.0045\n",
      "Epoch: 393/500... Training loss: 0.0086\n",
      "Epoch: 393/500... Training loss: 0.0037\n",
      "Epoch: 393/500... Training loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 393/500... Training loss: 0.0023\n",
      "Epoch: 393/500... Training loss: 0.0141\n",
      "Epoch: 394/500... Training loss: 0.0004\n",
      "Epoch: 394/500... Training loss: 0.0880\n",
      "Epoch: 394/500... Training loss: 0.0012\n",
      "Epoch: 394/500... Training loss: 0.0029\n",
      "Epoch: 394/500... Training loss: 0.0052\n",
      "Epoch: 394/500... Training loss: 0.0152\n",
      "Epoch: 394/500... Training loss: 0.0299\n",
      "Epoch: 394/500... Training loss: 0.0021\n",
      "Epoch: 394/500... Training loss: 0.0063\n",
      "Epoch: 394/500... Training loss: 0.0050\n",
      "Epoch: 394/500... Training loss: 0.0051\n",
      "Epoch: 394/500... Training loss: 0.0013\n",
      "Epoch: 394/500... Training loss: 0.0031\n",
      "Epoch: 394/500... Training loss: 0.0014\n",
      "Epoch: 394/500... Training loss: 0.0198\n",
      "Epoch: 394/500... Training loss: 0.1178\n",
      "Epoch: 394/500... Training loss: 0.0062\n",
      "Epoch: 394/500... Training loss: 0.0441\n",
      "Epoch: 394/500... Training loss: 0.0043\n",
      "Epoch: 394/500... Training loss: 0.0013\n",
      "Epoch: 394/500... Training loss: 0.0004\n",
      "Epoch: 394/500... Training loss: 0.0115\n",
      "Epoch: 394/500... Training loss: 0.0017\n",
      "Epoch: 394/500... Training loss: 0.0023\n",
      "Epoch: 394/500... Training loss: 0.0021\n",
      "Epoch: 394/500... Training loss: 0.0029\n",
      "Epoch: 394/500... Training loss: 0.0118\n",
      "Epoch: 394/500... Training loss: 0.0015\n",
      "Epoch: 394/500... Training loss: 0.0020\n",
      "Epoch: 394/500... Training loss: 0.0569\n",
      "Epoch: 394/500... Training loss: 0.0051\n",
      "Epoch: 395/500... Training loss: 0.0166\n",
      "Epoch: 395/500... Training loss: 0.0191\n",
      "Epoch: 395/500... Training loss: 0.0050\n",
      "Epoch: 395/500... Training loss: 0.0220\n",
      "Epoch: 395/500... Training loss: 0.0515\n",
      "Epoch: 395/500... Training loss: 0.0021\n",
      "Epoch: 395/500... Training loss: 0.0008\n",
      "Epoch: 395/500... Training loss: 0.0026\n",
      "Epoch: 395/500... Training loss: 0.0059\n",
      "Epoch: 395/500... Training loss: 0.0041\n",
      "Epoch: 395/500... Training loss: 0.0080\n",
      "Epoch: 395/500... Training loss: 0.0012\n",
      "Epoch: 395/500... Training loss: 0.0264\n",
      "Epoch: 395/500... Training loss: 0.0064\n",
      "Epoch: 395/500... Training loss: 0.0030\n",
      "Epoch: 395/500... Training loss: 0.0179\n",
      "Epoch: 395/500... Training loss: 0.0061\n",
      "Epoch: 395/500... Training loss: 0.0059\n",
      "Epoch: 395/500... Training loss: 0.0218\n",
      "Epoch: 395/500... Training loss: 0.0330\n",
      "Epoch: 395/500... Training loss: 0.0015\n",
      "Epoch: 395/500... Training loss: 0.0038\n",
      "Epoch: 395/500... Training loss: 0.0105\n",
      "Epoch: 395/500... Training loss: 0.0030\n",
      "Epoch: 395/500... Training loss: 0.0008\n",
      "Epoch: 395/500... Training loss: 0.0035\n",
      "Epoch: 395/500... Training loss: 0.0089\n",
      "Epoch: 395/500... Training loss: 0.0067\n",
      "Epoch: 395/500... Training loss: 0.0177\n",
      "Epoch: 395/500... Training loss: 0.0017\n",
      "Epoch: 395/500... Training loss: 0.0126\n",
      "Epoch: 396/500... Training loss: 0.0147\n",
      "Epoch: 396/500... Training loss: 0.0801\n",
      "Epoch: 396/500... Training loss: 0.1090\n",
      "Epoch: 396/500... Training loss: 0.0190\n",
      "Epoch: 396/500... Training loss: 0.0691\n",
      "Epoch: 396/500... Training loss: 0.0040\n",
      "Epoch: 396/500... Training loss: 0.0278\n",
      "Epoch: 396/500... Training loss: 0.0502\n",
      "Epoch: 396/500... Training loss: 0.0348\n",
      "Epoch: 396/500... Training loss: 0.0009\n",
      "Epoch: 396/500... Training loss: 0.0752\n",
      "Epoch: 396/500... Training loss: 0.0029\n",
      "Epoch: 396/500... Training loss: 0.0020\n",
      "Epoch: 396/500... Training loss: 0.0065\n",
      "Epoch: 396/500... Training loss: 0.0028\n",
      "Epoch: 396/500... Training loss: 0.0007\n",
      "Epoch: 396/500... Training loss: 0.0745\n",
      "Epoch: 396/500... Training loss: 0.0008\n",
      "Epoch: 396/500... Training loss: 0.0263\n",
      "Epoch: 396/500... Training loss: 0.0209\n",
      "Epoch: 396/500... Training loss: 0.0021\n",
      "Epoch: 396/500... Training loss: 0.0007\n",
      "Epoch: 396/500... Training loss: 0.0028\n",
      "Epoch: 396/500... Training loss: 0.0013\n",
      "Epoch: 396/500... Training loss: 0.0087\n",
      "Epoch: 396/500... Training loss: 0.0039\n",
      "Epoch: 396/500... Training loss: 0.0023\n",
      "Epoch: 396/500... Training loss: 0.0590\n",
      "Epoch: 396/500... Training loss: 0.0607\n",
      "Epoch: 396/500... Training loss: 0.0446\n",
      "Epoch: 396/500... Training loss: 0.0128\n",
      "Epoch: 397/500... Training loss: 0.0863\n",
      "Epoch: 397/500... Training loss: 0.0019\n",
      "Epoch: 397/500... Training loss: 0.0037\n",
      "Epoch: 397/500... Training loss: 0.0021\n",
      "Epoch: 397/500... Training loss: 0.0005\n",
      "Epoch: 397/500... Training loss: 0.0031\n",
      "Epoch: 397/500... Training loss: 0.0036\n",
      "Epoch: 397/500... Training loss: 0.0838\n",
      "Epoch: 397/500... Training loss: 0.0039\n",
      "Epoch: 397/500... Training loss: 0.0208\n",
      "Epoch: 397/500... Training loss: 0.0196\n",
      "Epoch: 397/500... Training loss: 0.0319\n",
      "Epoch: 397/500... Training loss: 0.0749\n",
      "Epoch: 397/500... Training loss: 0.0117\n",
      "Epoch: 397/500... Training loss: 0.0184\n",
      "Epoch: 397/500... Training loss: 0.1515\n",
      "Epoch: 397/500... Training loss: 0.0092\n",
      "Epoch: 397/500... Training loss: 0.0442\n",
      "Epoch: 397/500... Training loss: 0.0011\n",
      "Epoch: 397/500... Training loss: 0.0125\n",
      "Epoch: 397/500... Training loss: 0.0041\n",
      "Epoch: 397/500... Training loss: 0.0122\n",
      "Epoch: 397/500... Training loss: 0.0486\n",
      "Epoch: 397/500... Training loss: 0.0031\n",
      "Epoch: 397/500... Training loss: 0.0303\n",
      "Epoch: 397/500... Training loss: 0.0010\n",
      "Epoch: 397/500... Training loss: 0.0042\n",
      "Epoch: 397/500... Training loss: 0.0023\n",
      "Epoch: 397/500... Training loss: 0.0078\n",
      "Epoch: 397/500... Training loss: 0.0020\n",
      "Epoch: 397/500... Training loss: 0.0006\n",
      "Epoch: 398/500... Training loss: 0.0026\n",
      "Epoch: 398/500... Training loss: 0.0028\n",
      "Epoch: 398/500... Training loss: 0.0034\n",
      "Epoch: 398/500... Training loss: 0.0048\n",
      "Epoch: 398/500... Training loss: 0.0096\n",
      "Epoch: 398/500... Training loss: 0.0313\n",
      "Epoch: 398/500... Training loss: 0.0154\n",
      "Epoch: 398/500... Training loss: 0.0045\n",
      "Epoch: 398/500... Training loss: 0.0345\n",
      "Epoch: 398/500... Training loss: 0.0082\n",
      "Epoch: 398/500... Training loss: 0.0020\n",
      "Epoch: 398/500... Training loss: 0.0027\n",
      "Epoch: 398/500... Training loss: 0.0013\n",
      "Epoch: 398/500... Training loss: 0.0279\n",
      "Epoch: 398/500... Training loss: 0.0762\n",
      "Epoch: 398/500... Training loss: 0.0395\n",
      "Epoch: 398/500... Training loss: 0.0967\n",
      "Epoch: 398/500... Training loss: 0.0033\n",
      "Epoch: 398/500... Training loss: 0.0219\n",
      "Epoch: 398/500... Training loss: 0.0181\n",
      "Epoch: 398/500... Training loss: 0.0172\n",
      "Epoch: 398/500... Training loss: 0.0018\n",
      "Epoch: 398/500... Training loss: 0.0325\n",
      "Epoch: 398/500... Training loss: 0.0463\n",
      "Epoch: 398/500... Training loss: 0.0009\n",
      "Epoch: 398/500... Training loss: 0.0025\n",
      "Epoch: 398/500... Training loss: 0.0015\n",
      "Epoch: 398/500... Training loss: 0.0020\n",
      "Epoch: 398/500... Training loss: 0.0028\n",
      "Epoch: 398/500... Training loss: 0.0046\n",
      "Epoch: 398/500... Training loss: 0.0104\n",
      "Epoch: 399/500... Training loss: 0.0016\n",
      "Epoch: 399/500... Training loss: 0.0044\n",
      "Epoch: 399/500... Training loss: 0.1603\n",
      "Epoch: 399/500... Training loss: 0.0300\n",
      "Epoch: 399/500... Training loss: 0.0399\n",
      "Epoch: 399/500... Training loss: 0.0018\n",
      "Epoch: 399/500... Training loss: 0.0091\n",
      "Epoch: 399/500... Training loss: 0.0343\n",
      "Epoch: 399/500... Training loss: 0.0151\n",
      "Epoch: 399/500... Training loss: 0.0162\n",
      "Epoch: 399/500... Training loss: 0.0043\n",
      "Epoch: 399/500... Training loss: 0.0198\n",
      "Epoch: 399/500... Training loss: 0.0421\n",
      "Epoch: 399/500... Training loss: 0.0762\n",
      "Epoch: 399/500... Training loss: 0.0027\n",
      "Epoch: 399/500... Training loss: 0.0115\n",
      "Epoch: 399/500... Training loss: 0.0058\n",
      "Epoch: 399/500... Training loss: 0.0056\n",
      "Epoch: 399/500... Training loss: 0.0073\n",
      "Epoch: 399/500... Training loss: 0.0012\n",
      "Epoch: 399/500... Training loss: 0.0183\n",
      "Epoch: 399/500... Training loss: 0.0342\n",
      "Epoch: 399/500... Training loss: 0.0019\n",
      "Epoch: 399/500... Training loss: 0.0478\n",
      "Epoch: 399/500... Training loss: 0.0376\n",
      "Epoch: 399/500... Training loss: 0.0039\n",
      "Epoch: 399/500... Training loss: 0.0056\n",
      "Epoch: 399/500... Training loss: 0.0066\n",
      "Epoch: 399/500... Training loss: 0.0212\n",
      "Epoch: 399/500... Training loss: 0.0042\n",
      "Epoch: 399/500... Training loss: 0.0751\n",
      "Epoch: 400/500... Training loss: 0.0304\n",
      "Epoch: 400/500... Training loss: 0.0052\n",
      "Epoch: 400/500... Training loss: 0.0096\n",
      "Epoch: 400/500... Training loss: 0.0597\n",
      "Epoch: 400/500... Training loss: 0.0688\n",
      "Epoch: 400/500... Training loss: 0.0049\n",
      "Epoch: 400/500... Training loss: 0.0027\n",
      "Epoch: 400/500... Training loss: 0.0031\n",
      "Epoch: 400/500... Training loss: 0.0070\n",
      "Epoch: 400/500... Training loss: 0.0052\n",
      "Epoch: 400/500... Training loss: 0.0175\n",
      "Epoch: 400/500... Training loss: 0.0143\n",
      "Epoch: 400/500... Training loss: 0.0192\n",
      "Epoch: 400/500... Training loss: 0.0286\n",
      "Epoch: 400/500... Training loss: 0.0031\n",
      "Epoch: 400/500... Training loss: 0.0121\n",
      "Epoch: 400/500... Training loss: 0.0214\n",
      "Epoch: 400/500... Training loss: 0.0237\n",
      "Epoch: 400/500... Training loss: 0.0751\n",
      "Epoch: 400/500... Training loss: 0.0099\n",
      "Epoch: 400/500... Training loss: 0.0047\n",
      "Epoch: 400/500... Training loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400/500... Training loss: 0.0296\n",
      "Epoch: 400/500... Training loss: 0.0052\n",
      "Epoch: 400/500... Training loss: 0.0056\n",
      "Epoch: 400/500... Training loss: 0.0031\n",
      "Epoch: 400/500... Training loss: 0.0832\n",
      "Epoch: 400/500... Training loss: 0.0010\n",
      "Epoch: 400/500... Training loss: 0.0051\n",
      "Epoch: 400/500... Training loss: 0.0026\n",
      "Epoch: 400/500... Training loss: 0.0032\n",
      "Epoch: 401/500... Training loss: 0.0190\n",
      "Epoch: 401/500... Training loss: 0.0026\n",
      "Epoch: 401/500... Training loss: 0.0041\n",
      "Epoch: 401/500... Training loss: 0.0311\n",
      "Epoch: 401/500... Training loss: 0.0179\n",
      "Epoch: 401/500... Training loss: 0.0014\n",
      "Epoch: 401/500... Training loss: 0.0193\n",
      "Epoch: 401/500... Training loss: 0.0091\n",
      "Epoch: 401/500... Training loss: 0.0082\n",
      "Epoch: 401/500... Training loss: 0.0015\n",
      "Epoch: 401/500... Training loss: 0.0068\n",
      "Epoch: 401/500... Training loss: 0.0015\n",
      "Epoch: 401/500... Training loss: 0.0589\n",
      "Epoch: 401/500... Training loss: 0.0078\n",
      "Epoch: 401/500... Training loss: 0.0131\n",
      "Epoch: 401/500... Training loss: 0.0048\n",
      "Epoch: 401/500... Training loss: 0.0018\n",
      "Epoch: 401/500... Training loss: 0.0029\n",
      "Epoch: 401/500... Training loss: 0.0297\n",
      "Epoch: 401/500... Training loss: 0.0053\n",
      "Epoch: 401/500... Training loss: 0.0159\n",
      "Epoch: 401/500... Training loss: 0.0052\n",
      "Epoch: 401/500... Training loss: 0.0030\n",
      "Epoch: 401/500... Training loss: 0.0021\n",
      "Epoch: 401/500... Training loss: 0.0009\n",
      "Epoch: 401/500... Training loss: 0.0107\n",
      "Epoch: 401/500... Training loss: 0.0214\n",
      "Epoch: 401/500... Training loss: 0.0040\n",
      "Epoch: 401/500... Training loss: 0.0070\n",
      "Epoch: 401/500... Training loss: 0.0019\n",
      "Epoch: 401/500... Training loss: 0.0017\n",
      "Epoch: 402/500... Training loss: 0.0057\n",
      "Epoch: 402/500... Training loss: 0.0071\n",
      "Epoch: 402/500... Training loss: 0.0021\n",
      "Epoch: 402/500... Training loss: 0.0020\n",
      "Epoch: 402/500... Training loss: 0.0025\n",
      "Epoch: 402/500... Training loss: 0.0029\n",
      "Epoch: 402/500... Training loss: 0.0122\n",
      "Epoch: 402/500... Training loss: 0.0282\n",
      "Epoch: 402/500... Training loss: 0.0045\n",
      "Epoch: 402/500... Training loss: 0.0019\n",
      "Epoch: 402/500... Training loss: 0.0104\n",
      "Epoch: 402/500... Training loss: 0.0017\n",
      "Epoch: 402/500... Training loss: 0.0650\n",
      "Epoch: 402/500... Training loss: 0.0008\n",
      "Epoch: 402/500... Training loss: 0.0013\n",
      "Epoch: 402/500... Training loss: 0.1188\n",
      "Epoch: 402/500... Training loss: 0.0040\n",
      "Epoch: 402/500... Training loss: 0.0499\n",
      "Epoch: 402/500... Training loss: 0.0115\n",
      "Epoch: 402/500... Training loss: 0.0077\n",
      "Epoch: 402/500... Training loss: 0.0018\n",
      "Epoch: 402/500... Training loss: 0.0168\n",
      "Epoch: 402/500... Training loss: 0.0534\n",
      "Epoch: 402/500... Training loss: 0.0041\n",
      "Epoch: 402/500... Training loss: 0.0330\n",
      "Epoch: 402/500... Training loss: 0.0016\n",
      "Epoch: 402/500... Training loss: 0.0599\n",
      "Epoch: 402/500... Training loss: 0.0019\n",
      "Epoch: 402/500... Training loss: 0.0006\n",
      "Epoch: 402/500... Training loss: 0.0046\n",
      "Epoch: 402/500... Training loss: 0.0043\n",
      "Epoch: 403/500... Training loss: 0.0017\n",
      "Epoch: 403/500... Training loss: 0.0031\n",
      "Epoch: 403/500... Training loss: 0.0067\n",
      "Epoch: 403/500... Training loss: 0.0091\n",
      "Epoch: 403/500... Training loss: 0.0022\n",
      "Epoch: 403/500... Training loss: 0.0145\n",
      "Epoch: 403/500... Training loss: 0.0043\n",
      "Epoch: 403/500... Training loss: 0.0029\n",
      "Epoch: 403/500... Training loss: 0.0003\n",
      "Epoch: 403/500... Training loss: 0.0012\n",
      "Epoch: 403/500... Training loss: 0.0361\n",
      "Epoch: 403/500... Training loss: 0.0057\n",
      "Epoch: 403/500... Training loss: 0.0133\n",
      "Epoch: 403/500... Training loss: 0.0079\n",
      "Epoch: 403/500... Training loss: 0.0228\n",
      "Epoch: 403/500... Training loss: 0.0345\n",
      "Epoch: 403/500... Training loss: 0.0699\n",
      "Epoch: 403/500... Training loss: 0.0309\n",
      "Epoch: 403/500... Training loss: 0.0058\n",
      "Epoch: 403/500... Training loss: 0.0010\n",
      "Epoch: 403/500... Training loss: 0.0133\n",
      "Epoch: 403/500... Training loss: 0.0039\n",
      "Epoch: 403/500... Training loss: 0.0598\n",
      "Epoch: 403/500... Training loss: 0.0068\n",
      "Epoch: 403/500... Training loss: 0.0015\n",
      "Epoch: 403/500... Training loss: 0.0032\n",
      "Epoch: 403/500... Training loss: 0.0129\n",
      "Epoch: 403/500... Training loss: 0.0010\n",
      "Epoch: 403/500... Training loss: 0.0204\n",
      "Epoch: 403/500... Training loss: 0.0535\n",
      "Epoch: 403/500... Training loss: 0.0017\n",
      "Epoch: 404/500... Training loss: 0.0010\n",
      "Epoch: 404/500... Training loss: 0.0011\n",
      "Epoch: 404/500... Training loss: 0.0569\n",
      "Epoch: 404/500... Training loss: 0.0040\n",
      "Epoch: 404/500... Training loss: 0.0046\n",
      "Epoch: 404/500... Training loss: 0.0041\n",
      "Epoch: 404/500... Training loss: 0.0444\n",
      "Epoch: 404/500... Training loss: 0.0031\n",
      "Epoch: 404/500... Training loss: 0.0050\n",
      "Epoch: 404/500... Training loss: 0.0159\n",
      "Epoch: 404/500... Training loss: 0.0046\n",
      "Epoch: 404/500... Training loss: 0.2136\n",
      "Epoch: 404/500... Training loss: 0.0019\n",
      "Epoch: 404/500... Training loss: 0.0087\n",
      "Epoch: 404/500... Training loss: 0.0051\n",
      "Epoch: 404/500... Training loss: 0.0046\n",
      "Epoch: 404/500... Training loss: 0.0010\n",
      "Epoch: 404/500... Training loss: 0.0226\n",
      "Epoch: 404/500... Training loss: 0.0031\n",
      "Epoch: 404/500... Training loss: 0.0462\n",
      "Epoch: 404/500... Training loss: 0.0041\n",
      "Epoch: 404/500... Training loss: 0.0441\n",
      "Epoch: 404/500... Training loss: 0.0023\n",
      "Epoch: 404/500... Training loss: 0.0008\n",
      "Epoch: 404/500... Training loss: 0.0008\n",
      "Epoch: 404/500... Training loss: 0.0568\n",
      "Epoch: 404/500... Training loss: 0.0019\n",
      "Epoch: 404/500... Training loss: 0.0012\n",
      "Epoch: 404/500... Training loss: 0.0035\n",
      "Epoch: 404/500... Training loss: 0.0029\n",
      "Epoch: 404/500... Training loss: 0.0338\n",
      "Epoch: 405/500... Training loss: 0.0375\n",
      "Epoch: 405/500... Training loss: 0.0032\n",
      "Epoch: 405/500... Training loss: 0.0356\n",
      "Epoch: 405/500... Training loss: 0.0009\n",
      "Epoch: 405/500... Training loss: 0.0011\n",
      "Epoch: 405/500... Training loss: 0.0723\n",
      "Epoch: 405/500... Training loss: 0.0055\n",
      "Epoch: 405/500... Training loss: 0.0025\n",
      "Epoch: 405/500... Training loss: 0.0014\n",
      "Epoch: 405/500... Training loss: 0.0272\n",
      "Epoch: 405/500... Training loss: 0.0026\n",
      "Epoch: 405/500... Training loss: 0.0336\n",
      "Epoch: 405/500... Training loss: 0.0117\n",
      "Epoch: 405/500... Training loss: 0.0020\n",
      "Epoch: 405/500... Training loss: 0.0215\n",
      "Epoch: 405/500... Training loss: 0.0175\n",
      "Epoch: 405/500... Training loss: 0.0049\n",
      "Epoch: 405/500... Training loss: 0.0105\n",
      "Epoch: 405/500... Training loss: 0.0349\n",
      "Epoch: 405/500... Training loss: 0.0033\n",
      "Epoch: 405/500... Training loss: 0.0018\n",
      "Epoch: 405/500... Training loss: 0.0102\n",
      "Epoch: 405/500... Training loss: 0.0031\n",
      "Epoch: 405/500... Training loss: 0.0005\n",
      "Epoch: 405/500... Training loss: 0.0085\n",
      "Epoch: 405/500... Training loss: 0.0075\n",
      "Epoch: 405/500... Training loss: 0.0084\n",
      "Epoch: 405/500... Training loss: 0.0039\n",
      "Epoch: 405/500... Training loss: 0.0396\n",
      "Epoch: 405/500... Training loss: 0.0017\n",
      "Epoch: 405/500... Training loss: 0.0716\n",
      "Epoch: 406/500... Training loss: 0.0015\n",
      "Epoch: 406/500... Training loss: 0.0057\n",
      "Epoch: 406/500... Training loss: 0.0068\n",
      "Epoch: 406/500... Training loss: 0.0344\n",
      "Epoch: 406/500... Training loss: 0.0006\n",
      "Epoch: 406/500... Training loss: 0.0589\n",
      "Epoch: 406/500... Training loss: 0.0047\n",
      "Epoch: 406/500... Training loss: 0.0197\n",
      "Epoch: 406/500... Training loss: 0.0178\n",
      "Epoch: 406/500... Training loss: 0.0025\n",
      "Epoch: 406/500... Training loss: 0.0124\n",
      "Epoch: 406/500... Training loss: 0.0025\n",
      "Epoch: 406/500... Training loss: 0.0178\n",
      "Epoch: 406/500... Training loss: 0.0022\n",
      "Epoch: 406/500... Training loss: 0.0284\n",
      "Epoch: 406/500... Training loss: 0.0011\n",
      "Epoch: 406/500... Training loss: 0.0017\n",
      "Epoch: 406/500... Training loss: 0.0196\n",
      "Epoch: 406/500... Training loss: 0.0453\n",
      "Epoch: 406/500... Training loss: 0.0012\n",
      "Epoch: 406/500... Training loss: 0.0032\n",
      "Epoch: 406/500... Training loss: 0.0105\n",
      "Epoch: 406/500... Training loss: 0.0244\n",
      "Epoch: 406/500... Training loss: 0.0048\n",
      "Epoch: 406/500... Training loss: 0.0510\n",
      "Epoch: 406/500... Training loss: 0.0300\n",
      "Epoch: 406/500... Training loss: 0.0032\n",
      "Epoch: 406/500... Training loss: 0.0190\n",
      "Epoch: 406/500... Training loss: 0.0046\n",
      "Epoch: 406/500... Training loss: 0.0427\n",
      "Epoch: 406/500... Training loss: 0.0102\n",
      "Epoch: 407/500... Training loss: 0.0109\n",
      "Epoch: 407/500... Training loss: 0.0517\n",
      "Epoch: 407/500... Training loss: 0.0013\n",
      "Epoch: 407/500... Training loss: 0.0316\n",
      "Epoch: 407/500... Training loss: 0.0469\n",
      "Epoch: 407/500... Training loss: 0.0149\n",
      "Epoch: 407/500... Training loss: 0.0221\n",
      "Epoch: 407/500... Training loss: 0.0366\n",
      "Epoch: 407/500... Training loss: 0.0023\n",
      "Epoch: 407/500... Training loss: 0.0297\n",
      "Epoch: 407/500... Training loss: 0.0052\n",
      "Epoch: 407/500... Training loss: 0.0167\n",
      "Epoch: 407/500... Training loss: 0.0042\n",
      "Epoch: 407/500... Training loss: 0.0074\n",
      "Epoch: 407/500... Training loss: 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407/500... Training loss: 0.0248\n",
      "Epoch: 407/500... Training loss: 0.0264\n",
      "Epoch: 407/500... Training loss: 0.0018\n",
      "Epoch: 407/500... Training loss: 0.0084\n",
      "Epoch: 407/500... Training loss: 0.0046\n",
      "Epoch: 407/500... Training loss: 0.0023\n",
      "Epoch: 407/500... Training loss: 0.0148\n",
      "Epoch: 407/500... Training loss: 0.0137\n",
      "Epoch: 407/500... Training loss: 0.0113\n",
      "Epoch: 407/500... Training loss: 0.0096\n",
      "Epoch: 407/500... Training loss: 0.0277\n",
      "Epoch: 407/500... Training loss: 0.0679\n",
      "Epoch: 407/500... Training loss: 0.0014\n",
      "Epoch: 407/500... Training loss: 0.0033\n",
      "Epoch: 407/500... Training loss: 0.0112\n",
      "Epoch: 407/500... Training loss: 0.0028\n",
      "Epoch: 408/500... Training loss: 0.0449\n",
      "Epoch: 408/500... Training loss: 0.0332\n",
      "Epoch: 408/500... Training loss: 0.0040\n",
      "Epoch: 408/500... Training loss: 0.0561\n",
      "Epoch: 408/500... Training loss: 0.0672\n",
      "Epoch: 408/500... Training loss: 0.0512\n",
      "Epoch: 408/500... Training loss: 0.1590\n",
      "Epoch: 408/500... Training loss: 0.0164\n",
      "Epoch: 408/500... Training loss: 0.0067\n",
      "Epoch: 408/500... Training loss: 0.0060\n",
      "Epoch: 408/500... Training loss: 0.0419\n",
      "Epoch: 408/500... Training loss: 0.0164\n",
      "Epoch: 408/500... Training loss: 0.0230\n",
      "Epoch: 408/500... Training loss: 0.0047\n",
      "Epoch: 408/500... Training loss: 0.0024\n",
      "Epoch: 408/500... Training loss: 0.0094\n",
      "Epoch: 408/500... Training loss: 0.0012\n",
      "Epoch: 408/500... Training loss: 0.0080\n",
      "Epoch: 408/500... Training loss: 0.0276\n",
      "Epoch: 408/500... Training loss: 0.0020\n",
      "Epoch: 408/500... Training loss: 0.0056\n",
      "Epoch: 408/500... Training loss: 0.0217\n",
      "Epoch: 408/500... Training loss: 0.0214\n",
      "Epoch: 408/500... Training loss: 0.0017\n",
      "Epoch: 408/500... Training loss: 0.0031\n",
      "Epoch: 408/500... Training loss: 0.0108\n",
      "Epoch: 408/500... Training loss: 0.0211\n",
      "Epoch: 408/500... Training loss: 0.0209\n",
      "Epoch: 408/500... Training loss: 0.0058\n",
      "Epoch: 408/500... Training loss: 0.0165\n",
      "Epoch: 408/500... Training loss: 0.0063\n",
      "Epoch: 409/500... Training loss: 0.0034\n",
      "Epoch: 409/500... Training loss: 0.0139\n",
      "Epoch: 409/500... Training loss: 0.0193\n",
      "Epoch: 409/500... Training loss: 0.0028\n",
      "Epoch: 409/500... Training loss: 0.0744\n",
      "Epoch: 409/500... Training loss: 0.0581\n",
      "Epoch: 409/500... Training loss: 0.0058\n",
      "Epoch: 409/500... Training loss: 0.0040\n",
      "Epoch: 409/500... Training loss: 0.0079\n",
      "Epoch: 409/500... Training loss: 0.0006\n",
      "Epoch: 409/500... Training loss: 0.0108\n",
      "Epoch: 409/500... Training loss: 0.0199\n",
      "Epoch: 409/500... Training loss: 0.0613\n",
      "Epoch: 409/500... Training loss: 0.0143\n",
      "Epoch: 409/500... Training loss: 0.0041\n",
      "Epoch: 409/500... Training loss: 0.0042\n",
      "Epoch: 409/500... Training loss: 0.0051\n",
      "Epoch: 409/500... Training loss: 0.0808\n",
      "Epoch: 409/500... Training loss: 0.0258\n",
      "Epoch: 409/500... Training loss: 0.0106\n",
      "Epoch: 409/500... Training loss: 0.0059\n",
      "Epoch: 409/500... Training loss: 0.0033\n",
      "Epoch: 409/500... Training loss: 0.0020\n",
      "Epoch: 409/500... Training loss: 0.0861\n",
      "Epoch: 409/500... Training loss: 0.0009\n",
      "Epoch: 409/500... Training loss: 0.0034\n",
      "Epoch: 409/500... Training loss: 0.0122\n",
      "Epoch: 409/500... Training loss: 0.0101\n",
      "Epoch: 409/500... Training loss: 0.0420\n",
      "Epoch: 409/500... Training loss: 0.0057\n",
      "Epoch: 409/500... Training loss: 0.0042\n",
      "Epoch: 410/500... Training loss: 0.0503\n",
      "Epoch: 410/500... Training loss: 0.0018\n",
      "Epoch: 410/500... Training loss: 0.0102\n",
      "Epoch: 410/500... Training loss: 0.0147\n",
      "Epoch: 410/500... Training loss: 0.0070\n",
      "Epoch: 410/500... Training loss: 0.1050\n",
      "Epoch: 410/500... Training loss: 0.0982\n",
      "Epoch: 410/500... Training loss: 0.0021\n",
      "Epoch: 410/500... Training loss: 0.0370\n",
      "Epoch: 410/500... Training loss: 0.0061\n",
      "Epoch: 410/500... Training loss: 0.0113\n",
      "Epoch: 410/500... Training loss: 0.0409\n",
      "Epoch: 410/500... Training loss: 0.0574\n",
      "Epoch: 410/500... Training loss: 0.0011\n",
      "Epoch: 410/500... Training loss: 0.0125\n",
      "Epoch: 410/500... Training loss: 0.0072\n",
      "Epoch: 410/500... Training loss: 0.0284\n",
      "Epoch: 410/500... Training loss: 0.0115\n",
      "Epoch: 410/500... Training loss: 0.0250\n",
      "Epoch: 410/500... Training loss: 0.0073\n",
      "Epoch: 410/500... Training loss: 0.0123\n",
      "Epoch: 410/500... Training loss: 0.0013\n",
      "Epoch: 410/500... Training loss: 0.0048\n",
      "Epoch: 410/500... Training loss: 0.1139\n",
      "Epoch: 410/500... Training loss: 0.0389\n",
      "Epoch: 410/500... Training loss: 0.0019\n",
      "Epoch: 410/500... Training loss: 0.0056\n",
      "Epoch: 410/500... Training loss: 0.0008\n",
      "Epoch: 410/500... Training loss: 0.0222\n",
      "Epoch: 410/500... Training loss: 0.0185\n",
      "Epoch: 410/500... Training loss: 0.0054\n",
      "Epoch: 411/500... Training loss: 0.0158\n",
      "Epoch: 411/500... Training loss: 0.0885\n",
      "Epoch: 411/500... Training loss: 0.0013\n",
      "Epoch: 411/500... Training loss: 0.0035\n",
      "Epoch: 411/500... Training loss: 0.0045\n",
      "Epoch: 411/500... Training loss: 0.0152\n",
      "Epoch: 411/500... Training loss: 0.0788\n",
      "Epoch: 411/500... Training loss: 0.0128\n",
      "Epoch: 411/500... Training loss: 0.0322\n",
      "Epoch: 411/500... Training loss: 0.0025\n",
      "Epoch: 411/500... Training loss: 0.0392\n",
      "Epoch: 411/500... Training loss: 0.0239\n",
      "Epoch: 411/500... Training loss: 0.0597\n",
      "Epoch: 411/500... Training loss: 0.0204\n",
      "Epoch: 411/500... Training loss: 0.0205\n",
      "Epoch: 411/500... Training loss: 0.0077\n",
      "Epoch: 411/500... Training loss: 0.0225\n",
      "Epoch: 411/500... Training loss: 0.0063\n",
      "Epoch: 411/500... Training loss: 0.0158\n",
      "Epoch: 411/500... Training loss: 0.0028\n",
      "Epoch: 411/500... Training loss: 0.0136\n",
      "Epoch: 411/500... Training loss: 0.0014\n",
      "Epoch: 411/500... Training loss: 0.0349\n",
      "Epoch: 411/500... Training loss: 0.0460\n",
      "Epoch: 411/500... Training loss: 0.0556\n",
      "Epoch: 411/500... Training loss: 0.0035\n",
      "Epoch: 411/500... Training loss: 0.0034\n",
      "Epoch: 411/500... Training loss: 0.0154\n",
      "Epoch: 411/500... Training loss: 0.0416\n",
      "Epoch: 411/500... Training loss: 0.0021\n",
      "Epoch: 411/500... Training loss: 0.0069\n",
      "Epoch: 412/500... Training loss: 0.0092\n",
      "Epoch: 412/500... Training loss: 0.0267\n",
      "Epoch: 412/500... Training loss: 0.0025\n",
      "Epoch: 412/500... Training loss: 0.0551\n",
      "Epoch: 412/500... Training loss: 0.0016\n",
      "Epoch: 412/500... Training loss: 0.0200\n",
      "Epoch: 412/500... Training loss: 0.0138\n",
      "Epoch: 412/500... Training loss: 0.1571\n",
      "Epoch: 412/500... Training loss: 0.0007\n",
      "Epoch: 412/500... Training loss: 0.0007\n",
      "Epoch: 412/500... Training loss: 0.1079\n",
      "Epoch: 412/500... Training loss: 0.0013\n",
      "Epoch: 412/500... Training loss: 0.0046\n",
      "Epoch: 412/500... Training loss: 0.0205\n",
      "Epoch: 412/500... Training loss: 0.0153\n",
      "Epoch: 412/500... Training loss: 0.0100\n",
      "Epoch: 412/500... Training loss: 0.0009\n",
      "Epoch: 412/500... Training loss: 0.0281\n",
      "Epoch: 412/500... Training loss: 0.0042\n",
      "Epoch: 412/500... Training loss: 0.0056\n",
      "Epoch: 412/500... Training loss: 0.0050\n",
      "Epoch: 412/500... Training loss: 0.0023\n",
      "Epoch: 412/500... Training loss: 0.0080\n",
      "Epoch: 412/500... Training loss: 0.0065\n",
      "Epoch: 412/500... Training loss: 0.0022\n",
      "Epoch: 412/500... Training loss: 0.0041\n",
      "Epoch: 412/500... Training loss: 0.0171\n",
      "Epoch: 412/500... Training loss: 0.0462\n",
      "Epoch: 412/500... Training loss: 0.0080\n",
      "Epoch: 412/500... Training loss: 0.0151\n",
      "Epoch: 412/500... Training loss: 0.0031\n",
      "Epoch: 413/500... Training loss: 0.0082\n",
      "Epoch: 413/500... Training loss: 0.0189\n",
      "Epoch: 413/500... Training loss: 0.0078\n",
      "Epoch: 413/500... Training loss: 0.0168\n",
      "Epoch: 413/500... Training loss: 0.0066\n",
      "Epoch: 413/500... Training loss: 0.0026\n",
      "Epoch: 413/500... Training loss: 0.0185\n",
      "Epoch: 413/500... Training loss: 0.0195\n",
      "Epoch: 413/500... Training loss: 0.0031\n",
      "Epoch: 413/500... Training loss: 0.0099\n",
      "Epoch: 413/500... Training loss: 0.0365\n",
      "Epoch: 413/500... Training loss: 0.0304\n",
      "Epoch: 413/500... Training loss: 0.0034\n",
      "Epoch: 413/500... Training loss: 0.0056\n",
      "Epoch: 413/500... Training loss: 0.0096\n",
      "Epoch: 413/500... Training loss: 0.0203\n",
      "Epoch: 413/500... Training loss: 0.0105\n",
      "Epoch: 413/500... Training loss: 0.0034\n",
      "Epoch: 413/500... Training loss: 0.0027\n",
      "Epoch: 413/500... Training loss: 0.0138\n",
      "Epoch: 413/500... Training loss: 0.0032\n",
      "Epoch: 413/500... Training loss: 0.0013\n",
      "Epoch: 413/500... Training loss: 0.0055\n",
      "Epoch: 413/500... Training loss: 0.0096\n",
      "Epoch: 413/500... Training loss: 0.0025\n",
      "Epoch: 413/500... Training loss: 0.0195\n",
      "Epoch: 413/500... Training loss: 0.0046\n",
      "Epoch: 413/500... Training loss: 0.0284\n",
      "Epoch: 413/500... Training loss: 0.0036\n",
      "Epoch: 413/500... Training loss: 0.1081\n",
      "Epoch: 413/500... Training loss: 0.0241\n",
      "Epoch: 414/500... Training loss: 0.0085\n",
      "Epoch: 414/500... Training loss: 0.0109\n",
      "Epoch: 414/500... Training loss: 0.0158\n",
      "Epoch: 414/500... Training loss: 0.0151\n",
      "Epoch: 414/500... Training loss: 0.0016\n",
      "Epoch: 414/500... Training loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 414/500... Training loss: 0.0008\n",
      "Epoch: 414/500... Training loss: 0.0028\n",
      "Epoch: 414/500... Training loss: 0.0011\n",
      "Epoch: 414/500... Training loss: 0.0276\n",
      "Epoch: 414/500... Training loss: 0.0179\n",
      "Epoch: 414/500... Training loss: 0.0107\n",
      "Epoch: 414/500... Training loss: 0.0558\n",
      "Epoch: 414/500... Training loss: 0.0187\n",
      "Epoch: 414/500... Training loss: 0.0018\n",
      "Epoch: 414/500... Training loss: 0.0438\n",
      "Epoch: 414/500... Training loss: 0.0124\n",
      "Epoch: 414/500... Training loss: 0.0045\n",
      "Epoch: 414/500... Training loss: 0.0198\n",
      "Epoch: 414/500... Training loss: 0.0017\n",
      "Epoch: 414/500... Training loss: 0.0890\n",
      "Epoch: 414/500... Training loss: 0.0031\n",
      "Epoch: 414/500... Training loss: 0.0173\n",
      "Epoch: 414/500... Training loss: 0.0071\n",
      "Epoch: 414/500... Training loss: 0.0041\n",
      "Epoch: 414/500... Training loss: 0.0019\n",
      "Epoch: 414/500... Training loss: 0.0104\n",
      "Epoch: 414/500... Training loss: 0.0019\n",
      "Epoch: 414/500... Training loss: 0.0083\n",
      "Epoch: 414/500... Training loss: 0.0069\n",
      "Epoch: 414/500... Training loss: 0.0076\n",
      "Epoch: 415/500... Training loss: 0.0090\n",
      "Epoch: 415/500... Training loss: 0.0023\n",
      "Epoch: 415/500... Training loss: 0.0016\n",
      "Epoch: 415/500... Training loss: 0.0269\n",
      "Epoch: 415/500... Training loss: 0.0007\n",
      "Epoch: 415/500... Training loss: 0.0066\n",
      "Epoch: 415/500... Training loss: 0.0203\n",
      "Epoch: 415/500... Training loss: 0.0526\n",
      "Epoch: 415/500... Training loss: 0.0063\n",
      "Epoch: 415/500... Training loss: 0.0092\n",
      "Epoch: 415/500... Training loss: 0.0036\n",
      "Epoch: 415/500... Training loss: 0.0061\n",
      "Epoch: 415/500... Training loss: 0.0293\n",
      "Epoch: 415/500... Training loss: 0.0482\n",
      "Epoch: 415/500... Training loss: 0.0142\n",
      "Epoch: 415/500... Training loss: 0.0058\n",
      "Epoch: 415/500... Training loss: 0.0033\n",
      "Epoch: 415/500... Training loss: 0.0023\n",
      "Epoch: 415/500... Training loss: 0.0142\n",
      "Epoch: 415/500... Training loss: 0.0015\n",
      "Epoch: 415/500... Training loss: 0.0044\n",
      "Epoch: 415/500... Training loss: 0.0046\n",
      "Epoch: 415/500... Training loss: 0.0031\n",
      "Epoch: 415/500... Training loss: 0.0463\n",
      "Epoch: 415/500... Training loss: 0.0025\n",
      "Epoch: 415/500... Training loss: 0.0036\n",
      "Epoch: 415/500... Training loss: 0.0066\n",
      "Epoch: 415/500... Training loss: 0.0030\n",
      "Epoch: 415/500... Training loss: 0.0432\n",
      "Epoch: 415/500... Training loss: 0.0027\n",
      "Epoch: 415/500... Training loss: 0.0062\n",
      "Epoch: 416/500... Training loss: 0.0038\n",
      "Epoch: 416/500... Training loss: 0.0091\n",
      "Epoch: 416/500... Training loss: 0.0040\n",
      "Epoch: 416/500... Training loss: 0.0089\n",
      "Epoch: 416/500... Training loss: 0.0091\n",
      "Epoch: 416/500... Training loss: 0.0397\n",
      "Epoch: 416/500... Training loss: 0.0006\n",
      "Epoch: 416/500... Training loss: 0.0114\n",
      "Epoch: 416/500... Training loss: 0.0054\n",
      "Epoch: 416/500... Training loss: 0.0054\n",
      "Epoch: 416/500... Training loss: 0.0009\n",
      "Epoch: 416/500... Training loss: 0.0155\n",
      "Epoch: 416/500... Training loss: 0.0167\n",
      "Epoch: 416/500... Training loss: 0.0115\n",
      "Epoch: 416/500... Training loss: 0.0403\n",
      "Epoch: 416/500... Training loss: 0.0038\n",
      "Epoch: 416/500... Training loss: 0.0009\n",
      "Epoch: 416/500... Training loss: 0.0018\n",
      "Epoch: 416/500... Training loss: 0.0167\n",
      "Epoch: 416/500... Training loss: 0.0547\n",
      "Epoch: 416/500... Training loss: 0.0033\n",
      "Epoch: 416/500... Training loss: 0.0029\n",
      "Epoch: 416/500... Training loss: 0.0039\n",
      "Epoch: 416/500... Training loss: 0.0048\n",
      "Epoch: 416/500... Training loss: 0.0119\n",
      "Epoch: 416/500... Training loss: 0.0101\n",
      "Epoch: 416/500... Training loss: 0.0083\n",
      "Epoch: 416/500... Training loss: 0.0384\n",
      "Epoch: 416/500... Training loss: 0.0043\n",
      "Epoch: 416/500... Training loss: 0.0185\n",
      "Epoch: 416/500... Training loss: 0.0082\n",
      "Epoch: 417/500... Training loss: 0.0024\n",
      "Epoch: 417/500... Training loss: 0.0003\n",
      "Epoch: 417/500... Training loss: 0.0041\n",
      "Epoch: 417/500... Training loss: 0.0016\n",
      "Epoch: 417/500... Training loss: 0.0100\n",
      "Epoch: 417/500... Training loss: 0.0049\n",
      "Epoch: 417/500... Training loss: 0.0068\n",
      "Epoch: 417/500... Training loss: 0.0138\n",
      "Epoch: 417/500... Training loss: 0.0109\n",
      "Epoch: 417/500... Training loss: 0.0598\n",
      "Epoch: 417/500... Training loss: 0.0072\n",
      "Epoch: 417/500... Training loss: 0.0055\n",
      "Epoch: 417/500... Training loss: 0.0258\n",
      "Epoch: 417/500... Training loss: 0.0312\n",
      "Epoch: 417/500... Training loss: 0.0115\n",
      "Epoch: 417/500... Training loss: 0.0154\n",
      "Epoch: 417/500... Training loss: 0.0034\n",
      "Epoch: 417/500... Training loss: 0.0007\n",
      "Epoch: 417/500... Training loss: 0.0547\n",
      "Epoch: 417/500... Training loss: 0.0088\n",
      "Epoch: 417/500... Training loss: 0.0186\n",
      "Epoch: 417/500... Training loss: 0.0037\n",
      "Epoch: 417/500... Training loss: 0.0015\n",
      "Epoch: 417/500... Training loss: 0.0027\n",
      "Epoch: 417/500... Training loss: 0.0023\n",
      "Epoch: 417/500... Training loss: 0.0087\n",
      "Epoch: 417/500... Training loss: 0.0271\n",
      "Epoch: 417/500... Training loss: 0.0007\n",
      "Epoch: 417/500... Training loss: 0.0115\n",
      "Epoch: 417/500... Training loss: 0.0029\n",
      "Epoch: 417/500... Training loss: 0.0088\n",
      "Epoch: 418/500... Training loss: 0.0015\n",
      "Epoch: 418/500... Training loss: 0.0020\n",
      "Epoch: 418/500... Training loss: 0.0247\n",
      "Epoch: 418/500... Training loss: 0.0409\n",
      "Epoch: 418/500... Training loss: 0.0177\n",
      "Epoch: 418/500... Training loss: 0.0824\n",
      "Epoch: 418/500... Training loss: 0.0049\n",
      "Epoch: 418/500... Training loss: 0.0023\n",
      "Epoch: 418/500... Training loss: 0.0012\n",
      "Epoch: 418/500... Training loss: 0.0100\n",
      "Epoch: 418/500... Training loss: 0.0035\n",
      "Epoch: 418/500... Training loss: 0.0350\n",
      "Epoch: 418/500... Training loss: 0.0046\n",
      "Epoch: 418/500... Training loss: 0.0022\n",
      "Epoch: 418/500... Training loss: 0.0074\n",
      "Epoch: 418/500... Training loss: 0.0047\n",
      "Epoch: 418/500... Training loss: 0.0099\n",
      "Epoch: 418/500... Training loss: 0.0110\n",
      "Epoch: 418/500... Training loss: 0.0090\n",
      "Epoch: 418/500... Training loss: 0.0019\n",
      "Epoch: 418/500... Training loss: 0.0040\n",
      "Epoch: 418/500... Training loss: 0.0656\n",
      "Epoch: 418/500... Training loss: 0.0013\n",
      "Epoch: 418/500... Training loss: 0.0016\n",
      "Epoch: 418/500... Training loss: 0.0021\n",
      "Epoch: 418/500... Training loss: 0.0422\n",
      "Epoch: 418/500... Training loss: 0.0088\n",
      "Epoch: 418/500... Training loss: 0.0066\n",
      "Epoch: 418/500... Training loss: 0.0151\n",
      "Epoch: 418/500... Training loss: 0.0244\n",
      "Epoch: 418/500... Training loss: 0.0012\n",
      "Epoch: 419/500... Training loss: 0.0044\n",
      "Epoch: 419/500... Training loss: 0.1075\n",
      "Epoch: 419/500... Training loss: 0.0041\n",
      "Epoch: 419/500... Training loss: 0.0835\n",
      "Epoch: 419/500... Training loss: 0.0017\n",
      "Epoch: 419/500... Training loss: 0.0266\n",
      "Epoch: 419/500... Training loss: 0.0055\n",
      "Epoch: 419/500... Training loss: 0.0009\n",
      "Epoch: 419/500... Training loss: 0.0121\n",
      "Epoch: 419/500... Training loss: 0.0052\n",
      "Epoch: 419/500... Training loss: 0.0683\n",
      "Epoch: 419/500... Training loss: 0.0061\n",
      "Epoch: 419/500... Training loss: 0.0345\n",
      "Epoch: 419/500... Training loss: 0.0011\n",
      "Epoch: 419/500... Training loss: 0.0111\n",
      "Epoch: 419/500... Training loss: 0.0023\n",
      "Epoch: 419/500... Training loss: 0.0543\n",
      "Epoch: 419/500... Training loss: 0.0014\n",
      "Epoch: 419/500... Training loss: 0.0034\n",
      "Epoch: 419/500... Training loss: 0.0041\n",
      "Epoch: 419/500... Training loss: 0.0034\n",
      "Epoch: 419/500... Training loss: 0.0176\n",
      "Epoch: 419/500... Training loss: 0.0039\n",
      "Epoch: 419/500... Training loss: 0.0012\n",
      "Epoch: 419/500... Training loss: 0.0232\n",
      "Epoch: 419/500... Training loss: 0.0309\n",
      "Epoch: 419/500... Training loss: 0.0016\n",
      "Epoch: 419/500... Training loss: 0.0019\n",
      "Epoch: 419/500... Training loss: 0.0545\n",
      "Epoch: 419/500... Training loss: 0.0037\n",
      "Epoch: 419/500... Training loss: 0.0618\n",
      "Epoch: 420/500... Training loss: 0.0081\n",
      "Epoch: 420/500... Training loss: 0.0381\n",
      "Epoch: 420/500... Training loss: 0.0059\n",
      "Epoch: 420/500... Training loss: 0.0071\n",
      "Epoch: 420/500... Training loss: 0.0028\n",
      "Epoch: 420/500... Training loss: 0.0024\n",
      "Epoch: 420/500... Training loss: 0.0015\n",
      "Epoch: 420/500... Training loss: 0.0136\n",
      "Epoch: 420/500... Training loss: 0.0463\n",
      "Epoch: 420/500... Training loss: 0.0028\n",
      "Epoch: 420/500... Training loss: 0.0050\n",
      "Epoch: 420/500... Training loss: 0.0071\n",
      "Epoch: 420/500... Training loss: 0.0041\n",
      "Epoch: 420/500... Training loss: 0.0052\n",
      "Epoch: 420/500... Training loss: 0.0149\n",
      "Epoch: 420/500... Training loss: 0.0011\n",
      "Epoch: 420/500... Training loss: 0.0962\n",
      "Epoch: 420/500... Training loss: 0.0020\n",
      "Epoch: 420/500... Training loss: 0.0020\n",
      "Epoch: 420/500... Training loss: 0.0008\n",
      "Epoch: 420/500... Training loss: 0.0033\n",
      "Epoch: 420/500... Training loss: 0.0017\n",
      "Epoch: 420/500... Training loss: 0.0055\n",
      "Epoch: 420/500... Training loss: 0.0045\n",
      "Epoch: 420/500... Training loss: 0.0062\n",
      "Epoch: 420/500... Training loss: 0.0027\n",
      "Epoch: 420/500... Training loss: 0.0055\n",
      "Epoch: 420/500... Training loss: 0.0033\n",
      "Epoch: 420/500... Training loss: 0.0086\n",
      "Epoch: 420/500... Training loss: 0.0032\n",
      "Epoch: 420/500... Training loss: 0.0084\n",
      "Epoch: 421/500... Training loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 421/500... Training loss: 0.0175\n",
      "Epoch: 421/500... Training loss: 0.0061\n",
      "Epoch: 421/500... Training loss: 0.0032\n",
      "Epoch: 421/500... Training loss: 0.0061\n",
      "Epoch: 421/500... Training loss: 0.0137\n",
      "Epoch: 421/500... Training loss: 0.0022\n",
      "Epoch: 421/500... Training loss: 0.0392\n",
      "Epoch: 421/500... Training loss: 0.0022\n",
      "Epoch: 421/500... Training loss: 0.0012\n",
      "Epoch: 421/500... Training loss: 0.0024\n",
      "Epoch: 421/500... Training loss: 0.0049\n",
      "Epoch: 421/500... Training loss: 0.0011\n",
      "Epoch: 421/500... Training loss: 0.0274\n",
      "Epoch: 421/500... Training loss: 0.0028\n",
      "Epoch: 421/500... Training loss: 0.0165\n",
      "Epoch: 421/500... Training loss: 0.0015\n",
      "Epoch: 421/500... Training loss: 0.0650\n",
      "Epoch: 421/500... Training loss: 0.0019\n",
      "Epoch: 421/500... Training loss: 0.0019\n",
      "Epoch: 421/500... Training loss: 0.0030\n",
      "Epoch: 421/500... Training loss: 0.0006\n",
      "Epoch: 421/500... Training loss: 0.0016\n",
      "Epoch: 421/500... Training loss: 0.0066\n",
      "Epoch: 421/500... Training loss: 0.0017\n",
      "Epoch: 421/500... Training loss: 0.0030\n",
      "Epoch: 421/500... Training loss: 0.0281\n",
      "Epoch: 421/500... Training loss: 0.0093\n",
      "Epoch: 421/500... Training loss: 0.0009\n",
      "Epoch: 421/500... Training loss: 0.0110\n",
      "Epoch: 421/500... Training loss: 0.0066\n",
      "Epoch: 422/500... Training loss: 0.0069\n",
      "Epoch: 422/500... Training loss: 0.0672\n",
      "Epoch: 422/500... Training loss: 0.0022\n",
      "Epoch: 422/500... Training loss: 0.0162\n",
      "Epoch: 422/500... Training loss: 0.0063\n",
      "Epoch: 422/500... Training loss: 0.0049\n",
      "Epoch: 422/500... Training loss: 0.0048\n",
      "Epoch: 422/500... Training loss: 0.0231\n",
      "Epoch: 422/500... Training loss: 0.0009\n",
      "Epoch: 422/500... Training loss: 0.0034\n",
      "Epoch: 422/500... Training loss: 0.0191\n",
      "Epoch: 422/500... Training loss: 0.0016\n",
      "Epoch: 422/500... Training loss: 0.0033\n",
      "Epoch: 422/500... Training loss: 0.0035\n",
      "Epoch: 422/500... Training loss: 0.0051\n",
      "Epoch: 422/500... Training loss: 0.0021\n",
      "Epoch: 422/500... Training loss: 0.0029\n",
      "Epoch: 422/500... Training loss: 0.0007\n",
      "Epoch: 422/500... Training loss: 0.0311\n",
      "Epoch: 422/500... Training loss: 0.0023\n",
      "Epoch: 422/500... Training loss: 0.0019\n",
      "Epoch: 422/500... Training loss: 0.0037\n",
      "Epoch: 422/500... Training loss: 0.0357\n",
      "Epoch: 422/500... Training loss: 0.0011\n",
      "Epoch: 422/500... Training loss: 0.0332\n",
      "Epoch: 422/500... Training loss: 0.0020\n",
      "Epoch: 422/500... Training loss: 0.0168\n",
      "Epoch: 422/500... Training loss: 0.0013\n",
      "Epoch: 422/500... Training loss: 0.0004\n",
      "Epoch: 422/500... Training loss: 0.0430\n",
      "Epoch: 422/500... Training loss: 0.0069\n",
      "Epoch: 423/500... Training loss: 0.0453\n",
      "Epoch: 423/500... Training loss: 0.0634\n",
      "Epoch: 423/500... Training loss: 0.0052\n",
      "Epoch: 423/500... Training loss: 0.0019\n",
      "Epoch: 423/500... Training loss: 0.0096\n",
      "Epoch: 423/500... Training loss: 0.0013\n",
      "Epoch: 423/500... Training loss: 0.0022\n",
      "Epoch: 423/500... Training loss: 0.0006\n",
      "Epoch: 423/500... Training loss: 0.0004\n",
      "Epoch: 423/500... Training loss: 0.0023\n",
      "Epoch: 423/500... Training loss: 0.0277\n",
      "Epoch: 423/500... Training loss: 0.0137\n",
      "Epoch: 423/500... Training loss: 0.0015\n",
      "Epoch: 423/500... Training loss: 0.0722\n",
      "Epoch: 423/500... Training loss: 0.0046\n",
      "Epoch: 423/500... Training loss: 0.0340\n",
      "Epoch: 423/500... Training loss: 0.0340\n",
      "Epoch: 423/500... Training loss: 0.0161\n",
      "Epoch: 423/500... Training loss: 0.0018\n",
      "Epoch: 423/500... Training loss: 0.0045\n",
      "Epoch: 423/500... Training loss: 0.0023\n",
      "Epoch: 423/500... Training loss: 0.0072\n",
      "Epoch: 423/500... Training loss: 0.0014\n",
      "Epoch: 423/500... Training loss: 0.0049\n",
      "Epoch: 423/500... Training loss: 0.0506\n",
      "Epoch: 423/500... Training loss: 0.0034\n",
      "Epoch: 423/500... Training loss: 0.0014\n",
      "Epoch: 423/500... Training loss: 0.0122\n",
      "Epoch: 423/500... Training loss: 0.0025\n",
      "Epoch: 423/500... Training loss: 0.0022\n",
      "Epoch: 423/500... Training loss: 0.0013\n",
      "Epoch: 424/500... Training loss: 0.0016\n",
      "Epoch: 424/500... Training loss: 0.0089\n",
      "Epoch: 424/500... Training loss: 0.0017\n",
      "Epoch: 424/500... Training loss: 0.0321\n",
      "Epoch: 424/500... Training loss: 0.0256\n",
      "Epoch: 424/500... Training loss: 0.0129\n",
      "Epoch: 424/500... Training loss: 0.0018\n",
      "Epoch: 424/500... Training loss: 0.0519\n",
      "Epoch: 424/500... Training loss: 0.0336\n",
      "Epoch: 424/500... Training loss: 0.0256\n",
      "Epoch: 424/500... Training loss: 0.0043\n",
      "Epoch: 424/500... Training loss: 0.0070\n",
      "Epoch: 424/500... Training loss: 0.0019\n",
      "Epoch: 424/500... Training loss: 0.0041\n",
      "Epoch: 424/500... Training loss: 0.0338\n",
      "Epoch: 424/500... Training loss: 0.0069\n",
      "Epoch: 424/500... Training loss: 0.0008\n",
      "Epoch: 424/500... Training loss: 0.0027\n",
      "Epoch: 424/500... Training loss: 0.0443\n",
      "Epoch: 424/500... Training loss: 0.0108\n",
      "Epoch: 424/500... Training loss: 0.0021\n",
      "Epoch: 424/500... Training loss: 0.0080\n",
      "Epoch: 424/500... Training loss: 0.0050\n",
      "Epoch: 424/500... Training loss: 0.0102\n",
      "Epoch: 424/500... Training loss: 0.0033\n",
      "Epoch: 424/500... Training loss: 0.0014\n",
      "Epoch: 424/500... Training loss: 0.0040\n",
      "Epoch: 424/500... Training loss: 0.0019\n",
      "Epoch: 424/500... Training loss: 0.0018\n",
      "Epoch: 424/500... Training loss: 0.0727\n",
      "Epoch: 424/500... Training loss: 0.0014\n",
      "Epoch: 425/500... Training loss: 0.0207\n",
      "Epoch: 425/500... Training loss: 0.0015\n",
      "Epoch: 425/500... Training loss: 0.0345\n",
      "Epoch: 425/500... Training loss: 0.0030\n",
      "Epoch: 425/500... Training loss: 0.0132\n",
      "Epoch: 425/500... Training loss: 0.0277\n",
      "Epoch: 425/500... Training loss: 0.0061\n",
      "Epoch: 425/500... Training loss: 0.0597\n",
      "Epoch: 425/500... Training loss: 0.0025\n",
      "Epoch: 425/500... Training loss: 0.0015\n",
      "Epoch: 425/500... Training loss: 0.0043\n",
      "Epoch: 425/500... Training loss: 0.0030\n",
      "Epoch: 425/500... Training loss: 0.0093\n",
      "Epoch: 425/500... Training loss: 0.0576\n",
      "Epoch: 425/500... Training loss: 0.0012\n",
      "Epoch: 425/500... Training loss: 0.0017\n",
      "Epoch: 425/500... Training loss: 0.0015\n",
      "Epoch: 425/500... Training loss: 0.0038\n",
      "Epoch: 425/500... Training loss: 0.0045\n",
      "Epoch: 425/500... Training loss: 0.0023\n",
      "Epoch: 425/500... Training loss: 0.0821\n",
      "Epoch: 425/500... Training loss: 0.0016\n",
      "Epoch: 425/500... Training loss: 0.0013\n",
      "Epoch: 425/500... Training loss: 0.0018\n",
      "Epoch: 425/500... Training loss: 0.0391\n",
      "Epoch: 425/500... Training loss: 0.0140\n",
      "Epoch: 425/500... Training loss: 0.0784\n",
      "Epoch: 425/500... Training loss: 0.0053\n",
      "Epoch: 425/500... Training loss: 0.0063\n",
      "Epoch: 425/500... Training loss: 0.0450\n",
      "Epoch: 425/500... Training loss: 0.0259\n",
      "Epoch: 426/500... Training loss: 0.0016\n",
      "Epoch: 426/500... Training loss: 0.0009\n",
      "Epoch: 426/500... Training loss: 0.0099\n",
      "Epoch: 426/500... Training loss: 0.0018\n",
      "Epoch: 426/500... Training loss: 0.0075\n",
      "Epoch: 426/500... Training loss: 0.0792\n",
      "Epoch: 426/500... Training loss: 0.0207\n",
      "Epoch: 426/500... Training loss: 0.0476\n",
      "Epoch: 426/500... Training loss: 0.0006\n",
      "Epoch: 426/500... Training loss: 0.0010\n",
      "Epoch: 426/500... Training loss: 0.0044\n",
      "Epoch: 426/500... Training loss: 0.0036\n",
      "Epoch: 426/500... Training loss: 0.0172\n",
      "Epoch: 426/500... Training loss: 0.0041\n",
      "Epoch: 426/500... Training loss: 0.0230\n",
      "Epoch: 426/500... Training loss: 0.0017\n",
      "Epoch: 426/500... Training loss: 0.0134\n",
      "Epoch: 426/500... Training loss: 0.0023\n",
      "Epoch: 426/500... Training loss: 0.0048\n",
      "Epoch: 426/500... Training loss: 0.0007\n",
      "Epoch: 426/500... Training loss: 0.0039\n",
      "Epoch: 426/500... Training loss: 0.0019\n",
      "Epoch: 426/500... Training loss: 0.0012\n",
      "Epoch: 426/500... Training loss: 0.0187\n",
      "Epoch: 426/500... Training loss: 0.0041\n",
      "Epoch: 426/500... Training loss: 0.0058\n",
      "Epoch: 426/500... Training loss: 0.0021\n",
      "Epoch: 426/500... Training loss: 0.0259\n",
      "Epoch: 426/500... Training loss: 0.0029\n",
      "Epoch: 426/500... Training loss: 0.0335\n",
      "Epoch: 426/500... Training loss: 0.0016\n",
      "Epoch: 427/500... Training loss: 0.0632\n",
      "Epoch: 427/500... Training loss: 0.0022\n",
      "Epoch: 427/500... Training loss: 0.0088\n",
      "Epoch: 427/500... Training loss: 0.0103\n",
      "Epoch: 427/500... Training loss: 0.0054\n",
      "Epoch: 427/500... Training loss: 0.0009\n",
      "Epoch: 427/500... Training loss: 0.0134\n",
      "Epoch: 427/500... Training loss: 0.0168\n",
      "Epoch: 427/500... Training loss: 0.0020\n",
      "Epoch: 427/500... Training loss: 0.0052\n",
      "Epoch: 427/500... Training loss: 0.0590\n",
      "Epoch: 427/500... Training loss: 0.0147\n",
      "Epoch: 427/500... Training loss: 0.0687\n",
      "Epoch: 427/500... Training loss: 0.0016\n",
      "Epoch: 427/500... Training loss: 0.0028\n",
      "Epoch: 427/500... Training loss: 0.0040\n",
      "Epoch: 427/500... Training loss: 0.0018\n",
      "Epoch: 427/500... Training loss: 0.0086\n",
      "Epoch: 427/500... Training loss: 0.0043\n",
      "Epoch: 427/500... Training loss: 0.0619\n",
      "Epoch: 427/500... Training loss: 0.0089\n",
      "Epoch: 427/500... Training loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 427/500... Training loss: 0.0056\n",
      "Epoch: 427/500... Training loss: 0.0014\n",
      "Epoch: 427/500... Training loss: 0.0291\n",
      "Epoch: 427/500... Training loss: 0.0014\n",
      "Epoch: 427/500... Training loss: 0.0641\n",
      "Epoch: 427/500... Training loss: 0.0134\n",
      "Epoch: 427/500... Training loss: 0.0191\n",
      "Epoch: 427/500... Training loss: 0.0033\n",
      "Epoch: 427/500... Training loss: 0.0043\n",
      "Epoch: 428/500... Training loss: 0.0006\n",
      "Epoch: 428/500... Training loss: 0.0020\n",
      "Epoch: 428/500... Training loss: 0.0029\n",
      "Epoch: 428/500... Training loss: 0.0051\n",
      "Epoch: 428/500... Training loss: 0.0072\n",
      "Epoch: 428/500... Training loss: 0.0127\n",
      "Epoch: 428/500... Training loss: 0.0047\n",
      "Epoch: 428/500... Training loss: 0.0090\n",
      "Epoch: 428/500... Training loss: 0.0018\n",
      "Epoch: 428/500... Training loss: 0.0019\n",
      "Epoch: 428/500... Training loss: 0.0328\n",
      "Epoch: 428/500... Training loss: 0.0096\n",
      "Epoch: 428/500... Training loss: 0.0415\n",
      "Epoch: 428/500... Training loss: 0.0038\n",
      "Epoch: 428/500... Training loss: 0.0062\n",
      "Epoch: 428/500... Training loss: 0.0039\n",
      "Epoch: 428/500... Training loss: 0.0023\n",
      "Epoch: 428/500... Training loss: 0.0211\n",
      "Epoch: 428/500... Training loss: 0.0574\n",
      "Epoch: 428/500... Training loss: 0.0062\n",
      "Epoch: 428/500... Training loss: 0.0009\n",
      "Epoch: 428/500... Training loss: 0.0191\n",
      "Epoch: 428/500... Training loss: 0.0055\n",
      "Epoch: 428/500... Training loss: 0.0813\n",
      "Epoch: 428/500... Training loss: 0.0254\n",
      "Epoch: 428/500... Training loss: 0.0031\n",
      "Epoch: 428/500... Training loss: 0.0009\n",
      "Epoch: 428/500... Training loss: 0.0100\n",
      "Epoch: 428/500... Training loss: 0.0033\n",
      "Epoch: 428/500... Training loss: 0.0013\n",
      "Epoch: 428/500... Training loss: 0.0035\n",
      "Epoch: 429/500... Training loss: 0.0081\n",
      "Epoch: 429/500... Training loss: 0.0069\n",
      "Epoch: 429/500... Training loss: 0.0058\n",
      "Epoch: 429/500... Training loss: 0.0125\n",
      "Epoch: 429/500... Training loss: 0.0011\n",
      "Epoch: 429/500... Training loss: 0.0020\n",
      "Epoch: 429/500... Training loss: 0.0006\n",
      "Epoch: 429/500... Training loss: 0.0012\n",
      "Epoch: 429/500... Training loss: 0.0110\n",
      "Epoch: 429/500... Training loss: 0.0417\n",
      "Epoch: 429/500... Training loss: 0.0152\n",
      "Epoch: 429/500... Training loss: 0.0177\n",
      "Epoch: 429/500... Training loss: 0.0259\n",
      "Epoch: 429/500... Training loss: 0.0320\n",
      "Epoch: 429/500... Training loss: 0.0048\n",
      "Epoch: 429/500... Training loss: 0.0124\n",
      "Epoch: 429/500... Training loss: 0.0073\n",
      "Epoch: 429/500... Training loss: 0.0061\n",
      "Epoch: 429/500... Training loss: 0.0008\n",
      "Epoch: 429/500... Training loss: 0.0504\n",
      "Epoch: 429/500... Training loss: 0.0054\n",
      "Epoch: 429/500... Training loss: 0.0246\n",
      "Epoch: 429/500... Training loss: 0.0026\n",
      "Epoch: 429/500... Training loss: 0.0073\n",
      "Epoch: 429/500... Training loss: 0.0014\n",
      "Epoch: 429/500... Training loss: 0.0023\n",
      "Epoch: 429/500... Training loss: 0.0028\n",
      "Epoch: 429/500... Training loss: 0.0528\n",
      "Epoch: 429/500... Training loss: 0.0046\n",
      "Epoch: 429/500... Training loss: 0.0224\n",
      "Epoch: 429/500... Training loss: 0.0016\n",
      "Epoch: 430/500... Training loss: 0.0090\n",
      "Epoch: 430/500... Training loss: 0.0142\n",
      "Epoch: 430/500... Training loss: 0.0015\n",
      "Epoch: 430/500... Training loss: 0.0044\n",
      "Epoch: 430/500... Training loss: 0.0355\n",
      "Epoch: 430/500... Training loss: 0.0044\n",
      "Epoch: 430/500... Training loss: 0.0394\n",
      "Epoch: 430/500... Training loss: 0.0052\n",
      "Epoch: 430/500... Training loss: 0.0197\n",
      "Epoch: 430/500... Training loss: 0.0113\n",
      "Epoch: 430/500... Training loss: 0.0019\n",
      "Epoch: 430/500... Training loss: 0.0182\n",
      "Epoch: 430/500... Training loss: 0.0013\n",
      "Epoch: 430/500... Training loss: 0.0013\n",
      "Epoch: 430/500... Training loss: 0.0057\n",
      "Epoch: 430/500... Training loss: 0.0529\n",
      "Epoch: 430/500... Training loss: 0.0017\n",
      "Epoch: 430/500... Training loss: 0.0995\n",
      "Epoch: 430/500... Training loss: 0.0068\n",
      "Epoch: 430/500... Training loss: 0.0012\n",
      "Epoch: 430/500... Training loss: 0.0278\n",
      "Epoch: 430/500... Training loss: 0.0467\n",
      "Epoch: 430/500... Training loss: 0.0197\n",
      "Epoch: 430/500... Training loss: 0.0010\n",
      "Epoch: 430/500... Training loss: 0.0141\n",
      "Epoch: 430/500... Training loss: 0.0031\n",
      "Epoch: 430/500... Training loss: 0.0449\n",
      "Epoch: 430/500... Training loss: 0.0026\n",
      "Epoch: 430/500... Training loss: 0.0021\n",
      "Epoch: 430/500... Training loss: 0.0238\n",
      "Epoch: 430/500... Training loss: 0.0035\n",
      "Epoch: 431/500... Training loss: 0.0066\n",
      "Epoch: 431/500... Training loss: 0.0048\n",
      "Epoch: 431/500... Training loss: 0.0056\n",
      "Epoch: 431/500... Training loss: 0.0032\n",
      "Epoch: 431/500... Training loss: 0.0005\n",
      "Epoch: 431/500... Training loss: 0.0090\n",
      "Epoch: 431/500... Training loss: 0.0010\n",
      "Epoch: 431/500... Training loss: 0.0049\n",
      "Epoch: 431/500... Training loss: 0.0067\n",
      "Epoch: 431/500... Training loss: 0.0486\n",
      "Epoch: 431/500... Training loss: 0.0078\n",
      "Epoch: 431/500... Training loss: 0.0045\n",
      "Epoch: 431/500... Training loss: 0.0235\n",
      "Epoch: 431/500... Training loss: 0.0813\n",
      "Epoch: 431/500... Training loss: 0.0061\n",
      "Epoch: 431/500... Training loss: 0.0013\n",
      "Epoch: 431/500... Training loss: 0.0340\n",
      "Epoch: 431/500... Training loss: 0.0023\n",
      "Epoch: 431/500... Training loss: 0.0183\n",
      "Epoch: 431/500... Training loss: 0.0008\n",
      "Epoch: 431/500... Training loss: 0.0681\n",
      "Epoch: 431/500... Training loss: 0.0129\n",
      "Epoch: 431/500... Training loss: 0.0005\n",
      "Epoch: 431/500... Training loss: 0.0011\n",
      "Epoch: 431/500... Training loss: 0.0041\n",
      "Epoch: 431/500... Training loss: 0.1059\n",
      "Epoch: 431/500... Training loss: 0.0020\n",
      "Epoch: 431/500... Training loss: 0.0045\n",
      "Epoch: 431/500... Training loss: 0.0056\n",
      "Epoch: 431/500... Training loss: 0.0062\n",
      "Epoch: 431/500... Training loss: 0.0016\n",
      "Epoch: 432/500... Training loss: 0.0051\n",
      "Epoch: 432/500... Training loss: 0.0025\n",
      "Epoch: 432/500... Training loss: 0.0075\n",
      "Epoch: 432/500... Training loss: 0.0051\n",
      "Epoch: 432/500... Training loss: 0.1022\n",
      "Epoch: 432/500... Training loss: 0.0019\n",
      "Epoch: 432/500... Training loss: 0.0010\n",
      "Epoch: 432/500... Training loss: 0.0019\n",
      "Epoch: 432/500... Training loss: 0.0758\n",
      "Epoch: 432/500... Training loss: 0.0013\n",
      "Epoch: 432/500... Training loss: 0.0310\n",
      "Epoch: 432/500... Training loss: 0.0700\n",
      "Epoch: 432/500... Training loss: 0.0063\n",
      "Epoch: 432/500... Training loss: 0.0084\n",
      "Epoch: 432/500... Training loss: 0.0047\n",
      "Epoch: 432/500... Training loss: 0.0023\n",
      "Epoch: 432/500... Training loss: 0.0140\n",
      "Epoch: 432/500... Training loss: 0.0208\n",
      "Epoch: 432/500... Training loss: 0.0033\n",
      "Epoch: 432/500... Training loss: 0.0038\n",
      "Epoch: 432/500... Training loss: 0.0058\n",
      "Epoch: 432/500... Training loss: 0.0013\n",
      "Epoch: 432/500... Training loss: 0.0027\n",
      "Epoch: 432/500... Training loss: 0.0030\n",
      "Epoch: 432/500... Training loss: 0.0070\n",
      "Epoch: 432/500... Training loss: 0.0086\n",
      "Epoch: 432/500... Training loss: 0.0026\n",
      "Epoch: 432/500... Training loss: 0.0090\n",
      "Epoch: 432/500... Training loss: 0.0144\n",
      "Epoch: 432/500... Training loss: 0.0081\n",
      "Epoch: 432/500... Training loss: 0.0021\n",
      "Epoch: 433/500... Training loss: 0.0022\n",
      "Epoch: 433/500... Training loss: 0.0082\n",
      "Epoch: 433/500... Training loss: 0.0008\n",
      "Epoch: 433/500... Training loss: 0.0013\n",
      "Epoch: 433/500... Training loss: 0.0050\n",
      "Epoch: 433/500... Training loss: 0.0427\n",
      "Epoch: 433/500... Training loss: 0.1289\n",
      "Epoch: 433/500... Training loss: 0.0243\n",
      "Epoch: 433/500... Training loss: 0.0023\n",
      "Epoch: 433/500... Training loss: 0.0011\n",
      "Epoch: 433/500... Training loss: 0.0193\n",
      "Epoch: 433/500... Training loss: 0.1178\n",
      "Epoch: 433/500... Training loss: 0.0344\n",
      "Epoch: 433/500... Training loss: 0.0009\n",
      "Epoch: 433/500... Training loss: 0.0014\n",
      "Epoch: 433/500... Training loss: 0.0014\n",
      "Epoch: 433/500... Training loss: 0.0014\n",
      "Epoch: 433/500... Training loss: 0.0123\n",
      "Epoch: 433/500... Training loss: 0.0032\n",
      "Epoch: 433/500... Training loss: 0.0021\n",
      "Epoch: 433/500... Training loss: 0.0040\n",
      "Epoch: 433/500... Training loss: 0.0026\n",
      "Epoch: 433/500... Training loss: 0.0020\n",
      "Epoch: 433/500... Training loss: 0.0013\n",
      "Epoch: 433/500... Training loss: 0.0077\n",
      "Epoch: 433/500... Training loss: 0.0011\n",
      "Epoch: 433/500... Training loss: 0.0033\n",
      "Epoch: 433/500... Training loss: 0.0027\n",
      "Epoch: 433/500... Training loss: 0.0575\n",
      "Epoch: 433/500... Training loss: 0.0088\n",
      "Epoch: 433/500... Training loss: 0.0540\n",
      "Epoch: 434/500... Training loss: 0.0028\n",
      "Epoch: 434/500... Training loss: 0.0034\n",
      "Epoch: 434/500... Training loss: 0.0048\n",
      "Epoch: 434/500... Training loss: 0.0025\n",
      "Epoch: 434/500... Training loss: 0.0010\n",
      "Epoch: 434/500... Training loss: 0.0129\n",
      "Epoch: 434/500... Training loss: 0.0030\n",
      "Epoch: 434/500... Training loss: 0.0089\n",
      "Epoch: 434/500... Training loss: 0.0555\n",
      "Epoch: 434/500... Training loss: 0.0010\n",
      "Epoch: 434/500... Training loss: 0.0303\n",
      "Epoch: 434/500... Training loss: 0.0017\n",
      "Epoch: 434/500... Training loss: 0.0438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 434/500... Training loss: 0.0006\n",
      "Epoch: 434/500... Training loss: 0.0059\n",
      "Epoch: 434/500... Training loss: 0.0013\n",
      "Epoch: 434/500... Training loss: 0.0181\n",
      "Epoch: 434/500... Training loss: 0.0009\n",
      "Epoch: 434/500... Training loss: 0.0023\n",
      "Epoch: 434/500... Training loss: 0.0034\n",
      "Epoch: 434/500... Training loss: 0.0016\n",
      "Epoch: 434/500... Training loss: 0.0070\n",
      "Epoch: 434/500... Training loss: 0.0299\n",
      "Epoch: 434/500... Training loss: 0.0265\n",
      "Epoch: 434/500... Training loss: 0.0023\n",
      "Epoch: 434/500... Training loss: 0.0050\n",
      "Epoch: 434/500... Training loss: 0.0042\n",
      "Epoch: 434/500... Training loss: 0.0043\n",
      "Epoch: 434/500... Training loss: 0.0009\n",
      "Epoch: 434/500... Training loss: 0.0163\n",
      "Epoch: 434/500... Training loss: 0.0030\n",
      "Epoch: 435/500... Training loss: 0.0009\n",
      "Epoch: 435/500... Training loss: 0.0045\n",
      "Epoch: 435/500... Training loss: 0.0179\n",
      "Epoch: 435/500... Training loss: 0.0011\n",
      "Epoch: 435/500... Training loss: 0.0370\n",
      "Epoch: 435/500... Training loss: 0.0418\n",
      "Epoch: 435/500... Training loss: 0.0038\n",
      "Epoch: 435/500... Training loss: 0.0015\n",
      "Epoch: 435/500... Training loss: 0.0267\n",
      "Epoch: 435/500... Training loss: 0.0026\n",
      "Epoch: 435/500... Training loss: 0.0097\n",
      "Epoch: 435/500... Training loss: 0.0600\n",
      "Epoch: 435/500... Training loss: 0.0652\n",
      "Epoch: 435/500... Training loss: 0.0012\n",
      "Epoch: 435/500... Training loss: 0.0358\n",
      "Epoch: 435/500... Training loss: 0.0009\n",
      "Epoch: 435/500... Training loss: 0.0011\n",
      "Epoch: 435/500... Training loss: 0.0073\n",
      "Epoch: 435/500... Training loss: 0.0146\n",
      "Epoch: 435/500... Training loss: 0.0044\n",
      "Epoch: 435/500... Training loss: 0.0017\n",
      "Epoch: 435/500... Training loss: 0.0054\n",
      "Epoch: 435/500... Training loss: 0.0008\n",
      "Epoch: 435/500... Training loss: 0.0078\n",
      "Epoch: 435/500... Training loss: 0.0102\n",
      "Epoch: 435/500... Training loss: 0.0063\n",
      "Epoch: 435/500... Training loss: 0.0201\n",
      "Epoch: 435/500... Training loss: 0.0153\n",
      "Epoch: 435/500... Training loss: 0.0044\n",
      "Epoch: 435/500... Training loss: 0.0221\n",
      "Epoch: 435/500... Training loss: 0.0183\n",
      "Epoch: 436/500... Training loss: 0.0140\n",
      "Epoch: 436/500... Training loss: 0.0068\n",
      "Epoch: 436/500... Training loss: 0.0031\n",
      "Epoch: 436/500... Training loss: 0.0933\n",
      "Epoch: 436/500... Training loss: 0.0135\n",
      "Epoch: 436/500... Training loss: 0.0317\n",
      "Epoch: 436/500... Training loss: 0.0070\n",
      "Epoch: 436/500... Training loss: 0.0059\n",
      "Epoch: 436/500... Training loss: 0.0593\n",
      "Epoch: 436/500... Training loss: 0.0016\n",
      "Epoch: 436/500... Training loss: 0.0018\n",
      "Epoch: 436/500... Training loss: 0.0734\n",
      "Epoch: 436/500... Training loss: 0.0769\n",
      "Epoch: 436/500... Training loss: 0.0016\n",
      "Epoch: 436/500... Training loss: 0.0129\n",
      "Epoch: 436/500... Training loss: 0.0105\n",
      "Epoch: 436/500... Training loss: 0.0067\n",
      "Epoch: 436/500... Training loss: 0.0014\n",
      "Epoch: 436/500... Training loss: 0.0160\n",
      "Epoch: 436/500... Training loss: 0.0082\n",
      "Epoch: 436/500... Training loss: 0.0127\n",
      "Epoch: 436/500... Training loss: 0.0025\n",
      "Epoch: 436/500... Training loss: 0.0150\n",
      "Epoch: 436/500... Training loss: 0.0026\n",
      "Epoch: 436/500... Training loss: 0.0066\n",
      "Epoch: 436/500... Training loss: 0.0120\n",
      "Epoch: 436/500... Training loss: 0.0011\n",
      "Epoch: 436/500... Training loss: 0.0008\n",
      "Epoch: 436/500... Training loss: 0.0015\n",
      "Epoch: 436/500... Training loss: 0.0192\n",
      "Epoch: 436/500... Training loss: 0.0275\n",
      "Epoch: 437/500... Training loss: 0.0010\n",
      "Epoch: 437/500... Training loss: 0.0216\n",
      "Epoch: 437/500... Training loss: 0.0008\n",
      "Epoch: 437/500... Training loss: 0.0027\n",
      "Epoch: 437/500... Training loss: 0.0032\n",
      "Epoch: 437/500... Training loss: 0.0047\n",
      "Epoch: 437/500... Training loss: 0.0113\n",
      "Epoch: 437/500... Training loss: 0.0074\n",
      "Epoch: 437/500... Training loss: 0.0185\n",
      "Epoch: 437/500... Training loss: 0.0014\n",
      "Epoch: 437/500... Training loss: 0.0021\n",
      "Epoch: 437/500... Training loss: 0.0607\n",
      "Epoch: 437/500... Training loss: 0.0081\n",
      "Epoch: 437/500... Training loss: 0.0011\n",
      "Epoch: 437/500... Training loss: 0.0059\n",
      "Epoch: 437/500... Training loss: 0.0045\n",
      "Epoch: 437/500... Training loss: 0.0070\n",
      "Epoch: 437/500... Training loss: 0.0538\n",
      "Epoch: 437/500... Training loss: 0.0028\n",
      "Epoch: 437/500... Training loss: 0.0014\n",
      "Epoch: 437/500... Training loss: 0.0026\n",
      "Epoch: 437/500... Training loss: 0.0158\n",
      "Epoch: 437/500... Training loss: 0.0020\n",
      "Epoch: 437/500... Training loss: 0.0011\n",
      "Epoch: 437/500... Training loss: 0.0005\n",
      "Epoch: 437/500... Training loss: 0.0092\n",
      "Epoch: 437/500... Training loss: 0.0013\n",
      "Epoch: 437/500... Training loss: 0.0005\n",
      "Epoch: 437/500... Training loss: 0.0140\n",
      "Epoch: 437/500... Training loss: 0.0076\n",
      "Epoch: 437/500... Training loss: 0.0013\n",
      "Epoch: 438/500... Training loss: 0.0043\n",
      "Epoch: 438/500... Training loss: 0.0404\n",
      "Epoch: 438/500... Training loss: 0.0015\n",
      "Epoch: 438/500... Training loss: 0.0039\n",
      "Epoch: 438/500... Training loss: 0.0282\n",
      "Epoch: 438/500... Training loss: 0.0013\n",
      "Epoch: 438/500... Training loss: 0.0032\n",
      "Epoch: 438/500... Training loss: 0.0012\n",
      "Epoch: 438/500... Training loss: 0.0027\n",
      "Epoch: 438/500... Training loss: 0.0241\n",
      "Epoch: 438/500... Training loss: 0.0243\n",
      "Epoch: 438/500... Training loss: 0.0039\n",
      "Epoch: 438/500... Training loss: 0.0017\n",
      "Epoch: 438/500... Training loss: 0.0061\n",
      "Epoch: 438/500... Training loss: 0.0059\n",
      "Epoch: 438/500... Training loss: 0.0099\n",
      "Epoch: 438/500... Training loss: 0.0116\n",
      "Epoch: 438/500... Training loss: 0.0618\n",
      "Epoch: 438/500... Training loss: 0.0045\n",
      "Epoch: 438/500... Training loss: 0.0019\n",
      "Epoch: 438/500... Training loss: 0.0081\n",
      "Epoch: 438/500... Training loss: 0.0018\n",
      "Epoch: 438/500... Training loss: 0.0052\n",
      "Epoch: 438/500... Training loss: 0.0015\n",
      "Epoch: 438/500... Training loss: 0.0026\n",
      "Epoch: 438/500... Training loss: 0.0026\n",
      "Epoch: 438/500... Training loss: 0.0021\n",
      "Epoch: 438/500... Training loss: 0.0072\n",
      "Epoch: 438/500... Training loss: 0.0186\n",
      "Epoch: 438/500... Training loss: 0.0060\n",
      "Epoch: 438/500... Training loss: 0.0009\n",
      "Epoch: 439/500... Training loss: 0.0063\n",
      "Epoch: 439/500... Training loss: 0.0862\n",
      "Epoch: 439/500... Training loss: 0.0012\n",
      "Epoch: 439/500... Training loss: 0.0045\n",
      "Epoch: 439/500... Training loss: 0.0582\n",
      "Epoch: 439/500... Training loss: 0.0021\n",
      "Epoch: 439/500... Training loss: 0.0015\n",
      "Epoch: 439/500... Training loss: 0.0035\n",
      "Epoch: 439/500... Training loss: 0.0010\n",
      "Epoch: 439/500... Training loss: 0.0008\n",
      "Epoch: 439/500... Training loss: 0.0008\n",
      "Epoch: 439/500... Training loss: 0.0012\n",
      "Epoch: 439/500... Training loss: 0.0612\n",
      "Epoch: 439/500... Training loss: 0.0016\n",
      "Epoch: 439/500... Training loss: 0.0052\n",
      "Epoch: 439/500... Training loss: 0.0036\n",
      "Epoch: 439/500... Training loss: 0.0025\n",
      "Epoch: 439/500... Training loss: 0.0253\n",
      "Epoch: 439/500... Training loss: 0.0129\n",
      "Epoch: 439/500... Training loss: 0.0127\n",
      "Epoch: 439/500... Training loss: 0.0095\n",
      "Epoch: 439/500... Training loss: 0.0015\n",
      "Epoch: 439/500... Training loss: 0.0054\n",
      "Epoch: 439/500... Training loss: 0.0026\n",
      "Epoch: 439/500... Training loss: 0.0356\n",
      "Epoch: 439/500... Training loss: 0.0084\n",
      "Epoch: 439/500... Training loss: 0.0703\n",
      "Epoch: 439/500... Training loss: 0.0133\n",
      "Epoch: 439/500... Training loss: 0.0460\n",
      "Epoch: 439/500... Training loss: 0.0031\n",
      "Epoch: 439/500... Training loss: 0.0047\n",
      "Epoch: 440/500... Training loss: 0.0027\n",
      "Epoch: 440/500... Training loss: 0.0741\n",
      "Epoch: 440/500... Training loss: 0.0360\n",
      "Epoch: 440/500... Training loss: 0.0067\n",
      "Epoch: 440/500... Training loss: 0.0024\n",
      "Epoch: 440/500... Training loss: 0.0036\n",
      "Epoch: 440/500... Training loss: 0.0011\n",
      "Epoch: 440/500... Training loss: 0.0043\n",
      "Epoch: 440/500... Training loss: 0.0022\n",
      "Epoch: 440/500... Training loss: 0.0118\n",
      "Epoch: 440/500... Training loss: 0.0032\n",
      "Epoch: 440/500... Training loss: 0.0267\n",
      "Epoch: 440/500... Training loss: 0.0015\n",
      "Epoch: 440/500... Training loss: 0.0006\n",
      "Epoch: 440/500... Training loss: 0.0036\n",
      "Epoch: 440/500... Training loss: 0.0021\n",
      "Epoch: 440/500... Training loss: 0.0046\n",
      "Epoch: 440/500... Training loss: 0.0050\n",
      "Epoch: 440/500... Training loss: 0.0022\n",
      "Epoch: 440/500... Training loss: 0.0058\n",
      "Epoch: 440/500... Training loss: 0.0007\n",
      "Epoch: 440/500... Training loss: 0.0021\n",
      "Epoch: 440/500... Training loss: 0.1092\n",
      "Epoch: 440/500... Training loss: 0.0042\n",
      "Epoch: 440/500... Training loss: 0.0014\n",
      "Epoch: 440/500... Training loss: 0.0148\n",
      "Epoch: 440/500... Training loss: 0.0024\n",
      "Epoch: 440/500... Training loss: 0.0031\n",
      "Epoch: 440/500... Training loss: 0.0041\n",
      "Epoch: 440/500... Training loss: 0.0547\n",
      "Epoch: 440/500... Training loss: 0.0017\n",
      "Epoch: 441/500... Training loss: 0.0309\n",
      "Epoch: 441/500... Training loss: 0.0542\n",
      "Epoch: 441/500... Training loss: 0.0052\n",
      "Epoch: 441/500... Training loss: 0.0156\n",
      "Epoch: 441/500... Training loss: 0.0008\n",
      "Epoch: 441/500... Training loss: 0.0012\n",
      "Epoch: 441/500... Training loss: 0.0052\n",
      "Epoch: 441/500... Training loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 441/500... Training loss: 0.0321\n",
      "Epoch: 441/500... Training loss: 0.0547\n",
      "Epoch: 441/500... Training loss: 0.0931\n",
      "Epoch: 441/500... Training loss: 0.0083\n",
      "Epoch: 441/500... Training loss: 0.0007\n",
      "Epoch: 441/500... Training loss: 0.0079\n",
      "Epoch: 441/500... Training loss: 0.0015\n",
      "Epoch: 441/500... Training loss: 0.0377\n",
      "Epoch: 441/500... Training loss: 0.0037\n",
      "Epoch: 441/500... Training loss: 0.0096\n",
      "Epoch: 441/500... Training loss: 0.0061\n",
      "Epoch: 441/500... Training loss: 0.0047\n",
      "Epoch: 441/500... Training loss: 0.0215\n",
      "Epoch: 441/500... Training loss: 0.0010\n",
      "Epoch: 441/500... Training loss: 0.0006\n",
      "Epoch: 441/500... Training loss: 0.0026\n",
      "Epoch: 441/500... Training loss: 0.0017\n",
      "Epoch: 441/500... Training loss: 0.0025\n",
      "Epoch: 441/500... Training loss: 0.0013\n",
      "Epoch: 441/500... Training loss: 0.0220\n",
      "Epoch: 441/500... Training loss: 0.0009\n",
      "Epoch: 441/500... Training loss: 0.0017\n",
      "Epoch: 441/500... Training loss: 0.0029\n",
      "Epoch: 442/500... Training loss: 0.0107\n",
      "Epoch: 442/500... Training loss: 0.0130\n",
      "Epoch: 442/500... Training loss: 0.0188\n",
      "Epoch: 442/500... Training loss: 0.0158\n",
      "Epoch: 442/500... Training loss: 0.0003\n",
      "Epoch: 442/500... Training loss: 0.0011\n",
      "Epoch: 442/500... Training loss: 0.0037\n",
      "Epoch: 442/500... Training loss: 0.0262\n",
      "Epoch: 442/500... Training loss: 0.0005\n",
      "Epoch: 442/500... Training loss: 0.0027\n",
      "Epoch: 442/500... Training loss: 0.0328\n",
      "Epoch: 442/500... Training loss: 0.0061\n",
      "Epoch: 442/500... Training loss: 0.0724\n",
      "Epoch: 442/500... Training loss: 0.0741\n",
      "Epoch: 442/500... Training loss: 0.0031\n",
      "Epoch: 442/500... Training loss: 0.0026\n",
      "Epoch: 442/500... Training loss: 0.0066\n",
      "Epoch: 442/500... Training loss: 0.0178\n",
      "Epoch: 442/500... Training loss: 0.0033\n",
      "Epoch: 442/500... Training loss: 0.0036\n",
      "Epoch: 442/500... Training loss: 0.0007\n",
      "Epoch: 442/500... Training loss: 0.0074\n",
      "Epoch: 442/500... Training loss: 0.0053\n",
      "Epoch: 442/500... Training loss: 0.0049\n",
      "Epoch: 442/500... Training loss: 0.0154\n",
      "Epoch: 442/500... Training loss: 0.0513\n",
      "Epoch: 442/500... Training loss: 0.0181\n",
      "Epoch: 442/500... Training loss: 0.0017\n",
      "Epoch: 442/500... Training loss: 0.0038\n",
      "Epoch: 442/500... Training loss: 0.0137\n",
      "Epoch: 442/500... Training loss: 0.0068\n",
      "Epoch: 443/500... Training loss: 0.0018\n",
      "Epoch: 443/500... Training loss: 0.0153\n",
      "Epoch: 443/500... Training loss: 0.0230\n",
      "Epoch: 443/500... Training loss: 0.0008\n",
      "Epoch: 443/500... Training loss: 0.0113\n",
      "Epoch: 443/500... Training loss: 0.0066\n",
      "Epoch: 443/500... Training loss: 0.0019\n",
      "Epoch: 443/500... Training loss: 0.0104\n",
      "Epoch: 443/500... Training loss: 0.0007\n",
      "Epoch: 443/500... Training loss: 0.0021\n",
      "Epoch: 443/500... Training loss: 0.0114\n",
      "Epoch: 443/500... Training loss: 0.0702\n",
      "Epoch: 443/500... Training loss: 0.0058\n",
      "Epoch: 443/500... Training loss: 0.1719\n",
      "Epoch: 443/500... Training loss: 0.0046\n",
      "Epoch: 443/500... Training loss: 0.0019\n",
      "Epoch: 443/500... Training loss: 0.0009\n",
      "Epoch: 443/500... Training loss: 0.0011\n",
      "Epoch: 443/500... Training loss: 0.0109\n",
      "Epoch: 443/500... Training loss: 0.0139\n",
      "Epoch: 443/500... Training loss: 0.0032\n",
      "Epoch: 443/500... Training loss: 0.0069\n",
      "Epoch: 443/500... Training loss: 0.0041\n",
      "Epoch: 443/500... Training loss: 0.0323\n",
      "Epoch: 443/500... Training loss: 0.0011\n",
      "Epoch: 443/500... Training loss: 0.0062\n",
      "Epoch: 443/500... Training loss: 0.0021\n",
      "Epoch: 443/500... Training loss: 0.0018\n",
      "Epoch: 443/500... Training loss: 0.0014\n",
      "Epoch: 443/500... Training loss: 0.0070\n",
      "Epoch: 443/500... Training loss: 0.0592\n",
      "Epoch: 444/500... Training loss: 0.0058\n",
      "Epoch: 444/500... Training loss: 0.0102\n",
      "Epoch: 444/500... Training loss: 0.0277\n",
      "Epoch: 444/500... Training loss: 0.0005\n",
      "Epoch: 444/500... Training loss: 0.0030\n",
      "Epoch: 444/500... Training loss: 0.0038\n",
      "Epoch: 444/500... Training loss: 0.0011\n",
      "Epoch: 444/500... Training loss: 0.0005\n",
      "Epoch: 444/500... Training loss: 0.0012\n",
      "Epoch: 444/500... Training loss: 0.0139\n",
      "Epoch: 444/500... Training loss: 0.0124\n",
      "Epoch: 444/500... Training loss: 0.0034\n",
      "Epoch: 444/500... Training loss: 0.0015\n",
      "Epoch: 444/500... Training loss: 0.0219\n",
      "Epoch: 444/500... Training loss: 0.0371\n",
      "Epoch: 444/500... Training loss: 0.0388\n",
      "Epoch: 444/500... Training loss: 0.0021\n",
      "Epoch: 444/500... Training loss: 0.0024\n",
      "Epoch: 444/500... Training loss: 0.0012\n",
      "Epoch: 444/500... Training loss: 0.0015\n",
      "Epoch: 444/500... Training loss: 0.0058\n",
      "Epoch: 444/500... Training loss: 0.0012\n",
      "Epoch: 444/500... Training loss: 0.0002\n",
      "Epoch: 444/500... Training loss: 0.0004\n",
      "Epoch: 444/500... Training loss: 0.0026\n",
      "Epoch: 444/500... Training loss: 0.0467\n",
      "Epoch: 444/500... Training loss: 0.0259\n",
      "Epoch: 444/500... Training loss: 0.0014\n",
      "Epoch: 444/500... Training loss: 0.0575\n",
      "Epoch: 444/500... Training loss: 0.0178\n",
      "Epoch: 444/500... Training loss: 0.0031\n",
      "Epoch: 445/500... Training loss: 0.0097\n",
      "Epoch: 445/500... Training loss: 0.0446\n",
      "Epoch: 445/500... Training loss: 0.0266\n",
      "Epoch: 445/500... Training loss: 0.0065\n",
      "Epoch: 445/500... Training loss: 0.0041\n",
      "Epoch: 445/500... Training loss: 0.0157\n",
      "Epoch: 445/500... Training loss: 0.0011\n",
      "Epoch: 445/500... Training loss: 0.0221\n",
      "Epoch: 445/500... Training loss: 0.0111\n",
      "Epoch: 445/500... Training loss: 0.0191\n",
      "Epoch: 445/500... Training loss: 0.0020\n",
      "Epoch: 445/500... Training loss: 0.0013\n",
      "Epoch: 445/500... Training loss: 0.0137\n",
      "Epoch: 445/500... Training loss: 0.0129\n",
      "Epoch: 445/500... Training loss: 0.1096\n",
      "Epoch: 445/500... Training loss: 0.0008\n",
      "Epoch: 445/500... Training loss: 0.0021\n",
      "Epoch: 445/500... Training loss: 0.0072\n",
      "Epoch: 445/500... Training loss: 0.0173\n",
      "Epoch: 445/500... Training loss: 0.0085\n",
      "Epoch: 445/500... Training loss: 0.0152\n",
      "Epoch: 445/500... Training loss: 0.0084\n",
      "Epoch: 445/500... Training loss: 0.0036\n",
      "Epoch: 445/500... Training loss: 0.0008\n",
      "Epoch: 445/500... Training loss: 0.0024\n",
      "Epoch: 445/500... Training loss: 0.0008\n",
      "Epoch: 445/500... Training loss: 0.0045\n",
      "Epoch: 445/500... Training loss: 0.0348\n",
      "Epoch: 445/500... Training loss: 0.0019\n",
      "Epoch: 445/500... Training loss: 0.0332\n",
      "Epoch: 445/500... Training loss: 0.0013\n",
      "Epoch: 446/500... Training loss: 0.0208\n",
      "Epoch: 446/500... Training loss: 0.0145\n",
      "Epoch: 446/500... Training loss: 0.0070\n",
      "Epoch: 446/500... Training loss: 0.0003\n",
      "Epoch: 446/500... Training loss: 0.0030\n",
      "Epoch: 446/500... Training loss: 0.0031\n",
      "Epoch: 446/500... Training loss: 0.0286\n",
      "Epoch: 446/500... Training loss: 0.0025\n",
      "Epoch: 446/500... Training loss: 0.0016\n",
      "Epoch: 446/500... Training loss: 0.0469\n",
      "Epoch: 446/500... Training loss: 0.0154\n",
      "Epoch: 446/500... Training loss: 0.0010\n",
      "Epoch: 446/500... Training loss: 0.0257\n",
      "Epoch: 446/500... Training loss: 0.0098\n",
      "Epoch: 446/500... Training loss: 0.0029\n",
      "Epoch: 446/500... Training loss: 0.0225\n",
      "Epoch: 446/500... Training loss: 0.0538\n",
      "Epoch: 446/500... Training loss: 0.0041\n",
      "Epoch: 446/500... Training loss: 0.0044\n",
      "Epoch: 446/500... Training loss: 0.0777\n",
      "Epoch: 446/500... Training loss: 0.0204\n",
      "Epoch: 446/500... Training loss: 0.0721\n",
      "Epoch: 446/500... Training loss: 0.0015\n",
      "Epoch: 446/500... Training loss: 0.0233\n",
      "Epoch: 446/500... Training loss: 0.0007\n",
      "Epoch: 446/500... Training loss: 0.0014\n",
      "Epoch: 446/500... Training loss: 0.0590\n",
      "Epoch: 446/500... Training loss: 0.0257\n",
      "Epoch: 446/500... Training loss: 0.0115\n",
      "Epoch: 446/500... Training loss: 0.0020\n",
      "Epoch: 446/500... Training loss: 0.0337\n",
      "Epoch: 447/500... Training loss: 0.0341\n",
      "Epoch: 447/500... Training loss: 0.0128\n",
      "Epoch: 447/500... Training loss: 0.0038\n",
      "Epoch: 447/500... Training loss: 0.0064\n",
      "Epoch: 447/500... Training loss: 0.0312\n",
      "Epoch: 447/500... Training loss: 0.0504\n",
      "Epoch: 447/500... Training loss: 0.0251\n",
      "Epoch: 447/500... Training loss: 0.0039\n",
      "Epoch: 447/500... Training loss: 0.0021\n",
      "Epoch: 447/500... Training loss: 0.0737\n",
      "Epoch: 447/500... Training loss: 0.0024\n",
      "Epoch: 447/500... Training loss: 0.0030\n",
      "Epoch: 447/500... Training loss: 0.0342\n",
      "Epoch: 447/500... Training loss: 0.0516\n",
      "Epoch: 447/500... Training loss: 0.0014\n",
      "Epoch: 447/500... Training loss: 0.0075\n",
      "Epoch: 447/500... Training loss: 0.0087\n",
      "Epoch: 447/500... Training loss: 0.0008\n",
      "Epoch: 447/500... Training loss: 0.0011\n",
      "Epoch: 447/500... Training loss: 0.0007\n",
      "Epoch: 447/500... Training loss: 0.0033\n",
      "Epoch: 447/500... Training loss: 0.0090\n",
      "Epoch: 447/500... Training loss: 0.0057\n",
      "Epoch: 447/500... Training loss: 0.0017\n",
      "Epoch: 447/500... Training loss: 0.0295\n",
      "Epoch: 447/500... Training loss: 0.0017\n",
      "Epoch: 447/500... Training loss: 0.0009\n",
      "Epoch: 447/500... Training loss: 0.0015\n",
      "Epoch: 447/500... Training loss: 0.0307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 447/500... Training loss: 0.0212\n",
      "Epoch: 447/500... Training loss: 0.0037\n",
      "Epoch: 448/500... Training loss: 0.0082\n",
      "Epoch: 448/500... Training loss: 0.0099\n",
      "Epoch: 448/500... Training loss: 0.0069\n",
      "Epoch: 448/500... Training loss: 0.0118\n",
      "Epoch: 448/500... Training loss: 0.0058\n",
      "Epoch: 448/500... Training loss: 0.0393\n",
      "Epoch: 448/500... Training loss: 0.0038\n",
      "Epoch: 448/500... Training loss: 0.0007\n",
      "Epoch: 448/500... Training loss: 0.0035\n",
      "Epoch: 448/500... Training loss: 0.0137\n",
      "Epoch: 448/500... Training loss: 0.0065\n",
      "Epoch: 448/500... Training loss: 0.0056\n",
      "Epoch: 448/500... Training loss: 0.0092\n",
      "Epoch: 448/500... Training loss: 0.0021\n",
      "Epoch: 448/500... Training loss: 0.0013\n",
      "Epoch: 448/500... Training loss: 0.0197\n",
      "Epoch: 448/500... Training loss: 0.0126\n",
      "Epoch: 448/500... Training loss: 0.0023\n",
      "Epoch: 448/500... Training loss: 0.0124\n",
      "Epoch: 448/500... Training loss: 0.0021\n",
      "Epoch: 448/500... Training loss: 0.0372\n",
      "Epoch: 448/500... Training loss: 0.0009\n",
      "Epoch: 448/500... Training loss: 0.0205\n",
      "Epoch: 448/500... Training loss: 0.0012\n",
      "Epoch: 448/500... Training loss: 0.0047\n",
      "Epoch: 448/500... Training loss: 0.0696\n",
      "Epoch: 448/500... Training loss: 0.0135\n",
      "Epoch: 448/500... Training loss: 0.0008\n",
      "Epoch: 448/500... Training loss: 0.0012\n",
      "Epoch: 448/500... Training loss: 0.0010\n",
      "Epoch: 448/500... Training loss: 0.0011\n",
      "Epoch: 449/500... Training loss: 0.0497\n",
      "Epoch: 449/500... Training loss: 0.0071\n",
      "Epoch: 449/500... Training loss: 0.0199\n",
      "Epoch: 449/500... Training loss: 0.0476\n",
      "Epoch: 449/500... Training loss: 0.0062\n",
      "Epoch: 449/500... Training loss: 0.0052\n",
      "Epoch: 449/500... Training loss: 0.0008\n",
      "Epoch: 449/500... Training loss: 0.0044\n",
      "Epoch: 449/500... Training loss: 0.0024\n",
      "Epoch: 449/500... Training loss: 0.0021\n",
      "Epoch: 449/500... Training loss: 0.0775\n",
      "Epoch: 449/500... Training loss: 0.0208\n",
      "Epoch: 449/500... Training loss: 0.0026\n",
      "Epoch: 449/500... Training loss: 0.0015\n",
      "Epoch: 449/500... Training loss: 0.0035\n",
      "Epoch: 449/500... Training loss: 0.0011\n",
      "Epoch: 449/500... Training loss: 0.0012\n",
      "Epoch: 449/500... Training loss: 0.0008\n",
      "Epoch: 449/500... Training loss: 0.0072\n",
      "Epoch: 449/500... Training loss: 0.0045\n",
      "Epoch: 449/500... Training loss: 0.0020\n",
      "Epoch: 449/500... Training loss: 0.0044\n",
      "Epoch: 449/500... Training loss: 0.0160\n",
      "Epoch: 449/500... Training loss: 0.0012\n",
      "Epoch: 449/500... Training loss: 0.0018\n",
      "Epoch: 449/500... Training loss: 0.1159\n",
      "Epoch: 449/500... Training loss: 0.0011\n",
      "Epoch: 449/500... Training loss: 0.0061\n",
      "Epoch: 449/500... Training loss: 0.0024\n",
      "Epoch: 449/500... Training loss: 0.0067\n",
      "Epoch: 449/500... Training loss: 0.0013\n",
      "Epoch: 450/500... Training loss: 0.0168\n",
      "Epoch: 450/500... Training loss: 0.0071\n",
      "Epoch: 450/500... Training loss: 0.0016\n",
      "Epoch: 450/500... Training loss: 0.0075\n",
      "Epoch: 450/500... Training loss: 0.0474\n",
      "Epoch: 450/500... Training loss: 0.0043\n",
      "Epoch: 450/500... Training loss: 0.0005\n",
      "Epoch: 450/500... Training loss: 0.0047\n",
      "Epoch: 450/500... Training loss: 0.0007\n",
      "Epoch: 450/500... Training loss: 0.1122\n",
      "Epoch: 450/500... Training loss: 0.0190\n",
      "Epoch: 450/500... Training loss: 0.0026\n",
      "Epoch: 450/500... Training loss: 0.0041\n",
      "Epoch: 450/500... Training loss: 0.0125\n",
      "Epoch: 450/500... Training loss: 0.0103\n",
      "Epoch: 450/500... Training loss: 0.0037\n",
      "Epoch: 450/500... Training loss: 0.0045\n",
      "Epoch: 450/500... Training loss: 0.0048\n",
      "Epoch: 450/500... Training loss: 0.0396\n",
      "Epoch: 450/500... Training loss: 0.0018\n",
      "Epoch: 450/500... Training loss: 0.0076\n",
      "Epoch: 450/500... Training loss: 0.0014\n",
      "Epoch: 450/500... Training loss: 0.0059\n",
      "Epoch: 450/500... Training loss: 0.0104\n",
      "Epoch: 450/500... Training loss: 0.0019\n",
      "Epoch: 450/500... Training loss: 0.0010\n",
      "Epoch: 450/500... Training loss: 0.0045\n",
      "Epoch: 450/500... Training loss: 0.0242\n",
      "Epoch: 450/500... Training loss: 0.0019\n",
      "Epoch: 450/500... Training loss: 0.0303\n",
      "Epoch: 450/500... Training loss: 0.0009\n",
      "Epoch: 451/500... Training loss: 0.0011\n",
      "Epoch: 451/500... Training loss: 0.0169\n",
      "Epoch: 451/500... Training loss: 0.0384\n",
      "Epoch: 451/500... Training loss: 0.0394\n",
      "Epoch: 451/500... Training loss: 0.0014\n",
      "Epoch: 451/500... Training loss: 0.0756\n",
      "Epoch: 451/500... Training loss: 0.0047\n",
      "Epoch: 451/500... Training loss: 0.0235\n",
      "Epoch: 451/500... Training loss: 0.0366\n",
      "Epoch: 451/500... Training loss: 0.0024\n",
      "Epoch: 451/500... Training loss: 0.0407\n",
      "Epoch: 451/500... Training loss: 0.0056\n",
      "Epoch: 451/500... Training loss: 0.0021\n",
      "Epoch: 451/500... Training loss: 0.0314\n",
      "Epoch: 451/500... Training loss: 0.0027\n",
      "Epoch: 451/500... Training loss: 0.0043\n",
      "Epoch: 451/500... Training loss: 0.0048\n",
      "Epoch: 451/500... Training loss: 0.0018\n",
      "Epoch: 451/500... Training loss: 0.0018\n",
      "Epoch: 451/500... Training loss: 0.0022\n",
      "Epoch: 451/500... Training loss: 0.0086\n",
      "Epoch: 451/500... Training loss: 0.0430\n",
      "Epoch: 451/500... Training loss: 0.0839\n",
      "Epoch: 451/500... Training loss: 0.0036\n",
      "Epoch: 451/500... Training loss: 0.0297\n",
      "Epoch: 451/500... Training loss: 0.0159\n",
      "Epoch: 451/500... Training loss: 0.0009\n",
      "Epoch: 451/500... Training loss: 0.0128\n",
      "Epoch: 451/500... Training loss: 0.0061\n",
      "Epoch: 451/500... Training loss: 0.0008\n",
      "Epoch: 451/500... Training loss: 0.0225\n",
      "Epoch: 452/500... Training loss: 0.0016\n",
      "Epoch: 452/500... Training loss: 0.0207\n",
      "Epoch: 452/500... Training loss: 0.0014\n",
      "Epoch: 452/500... Training loss: 0.0052\n",
      "Epoch: 452/500... Training loss: 0.0082\n",
      "Epoch: 452/500... Training loss: 0.0007\n",
      "Epoch: 452/500... Training loss: 0.0031\n",
      "Epoch: 452/500... Training loss: 0.0061\n",
      "Epoch: 452/500... Training loss: 0.0011\n",
      "Epoch: 452/500... Training loss: 0.0240\n",
      "Epoch: 452/500... Training loss: 0.0244\n",
      "Epoch: 452/500... Training loss: 0.0289\n",
      "Epoch: 452/500... Training loss: 0.0115\n",
      "Epoch: 452/500... Training loss: 0.0856\n",
      "Epoch: 452/500... Training loss: 0.0037\n",
      "Epoch: 452/500... Training loss: 0.0034\n",
      "Epoch: 452/500... Training loss: 0.0130\n",
      "Epoch: 452/500... Training loss: 0.0418\n",
      "Epoch: 452/500... Training loss: 0.0023\n",
      "Epoch: 452/500... Training loss: 0.0014\n",
      "Epoch: 452/500... Training loss: 0.1578\n",
      "Epoch: 452/500... Training loss: 0.0182\n",
      "Epoch: 452/500... Training loss: 0.0013\n",
      "Epoch: 452/500... Training loss: 0.0021\n",
      "Epoch: 452/500... Training loss: 0.0019\n",
      "Epoch: 452/500... Training loss: 0.0230\n",
      "Epoch: 452/500... Training loss: 0.0164\n",
      "Epoch: 452/500... Training loss: 0.0694\n",
      "Epoch: 452/500... Training loss: 0.0012\n",
      "Epoch: 452/500... Training loss: 0.0102\n",
      "Epoch: 452/500... Training loss: 0.0006\n",
      "Epoch: 453/500... Training loss: 0.0134\n",
      "Epoch: 453/500... Training loss: 0.0014\n",
      "Epoch: 453/500... Training loss: 0.0010\n",
      "Epoch: 453/500... Training loss: 0.0047\n",
      "Epoch: 453/500... Training loss: 0.0010\n",
      "Epoch: 453/500... Training loss: 0.0641\n",
      "Epoch: 453/500... Training loss: 0.0012\n",
      "Epoch: 453/500... Training loss: 0.0005\n",
      "Epoch: 453/500... Training loss: 0.0011\n",
      "Epoch: 453/500... Training loss: 0.0031\n",
      "Epoch: 453/500... Training loss: 0.0353\n",
      "Epoch: 453/500... Training loss: 0.0059\n",
      "Epoch: 453/500... Training loss: 0.0062\n",
      "Epoch: 453/500... Training loss: 0.0058\n",
      "Epoch: 453/500... Training loss: 0.0040\n",
      "Epoch: 453/500... Training loss: 0.0019\n",
      "Epoch: 453/500... Training loss: 0.0094\n",
      "Epoch: 453/500... Training loss: 0.0006\n",
      "Epoch: 453/500... Training loss: 0.0031\n",
      "Epoch: 453/500... Training loss: 0.0053\n",
      "Epoch: 453/500... Training loss: 0.0085\n",
      "Epoch: 453/500... Training loss: 0.0082\n",
      "Epoch: 453/500... Training loss: 0.0023\n",
      "Epoch: 453/500... Training loss: 0.0283\n",
      "Epoch: 453/500... Training loss: 0.0278\n",
      "Epoch: 453/500... Training loss: 0.0054\n",
      "Epoch: 453/500... Training loss: 0.0023\n",
      "Epoch: 453/500... Training loss: 0.0007\n",
      "Epoch: 453/500... Training loss: 0.0025\n",
      "Epoch: 453/500... Training loss: 0.0052\n",
      "Epoch: 453/500... Training loss: 0.0088\n",
      "Epoch: 454/500... Training loss: 0.0006\n",
      "Epoch: 454/500... Training loss: 0.0392\n",
      "Epoch: 454/500... Training loss: 0.0031\n",
      "Epoch: 454/500... Training loss: 0.0140\n",
      "Epoch: 454/500... Training loss: 0.0005\n",
      "Epoch: 454/500... Training loss: 0.0009\n",
      "Epoch: 454/500... Training loss: 0.0227\n",
      "Epoch: 454/500... Training loss: 0.0151\n",
      "Epoch: 454/500... Training loss: 0.0006\n",
      "Epoch: 454/500... Training loss: 0.0289\n",
      "Epoch: 454/500... Training loss: 0.0035\n",
      "Epoch: 454/500... Training loss: 0.0340\n",
      "Epoch: 454/500... Training loss: 0.0548\n",
      "Epoch: 454/500... Training loss: 0.0011\n",
      "Epoch: 454/500... Training loss: 0.0063\n",
      "Epoch: 454/500... Training loss: 0.0043\n",
      "Epoch: 454/500... Training loss: 0.0070\n",
      "Epoch: 454/500... Training loss: 0.0885\n",
      "Epoch: 454/500... Training loss: 0.0015\n",
      "Epoch: 454/500... Training loss: 0.0156\n",
      "Epoch: 454/500... Training loss: 0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 454/500... Training loss: 0.0728\n",
      "Epoch: 454/500... Training loss: 0.0162\n",
      "Epoch: 454/500... Training loss: 0.0210\n",
      "Epoch: 454/500... Training loss: 0.0033\n",
      "Epoch: 454/500... Training loss: 0.0162\n",
      "Epoch: 454/500... Training loss: 0.0076\n",
      "Epoch: 454/500... Training loss: 0.0092\n",
      "Epoch: 454/500... Training loss: 0.0066\n",
      "Epoch: 454/500... Training loss: 0.0067\n",
      "Epoch: 454/500... Training loss: 0.0025\n",
      "Epoch: 455/500... Training loss: 0.0028\n",
      "Epoch: 455/500... Training loss: 0.0042\n",
      "Epoch: 455/500... Training loss: 0.0023\n",
      "Epoch: 455/500... Training loss: 0.0289\n",
      "Epoch: 455/500... Training loss: 0.0026\n",
      "Epoch: 455/500... Training loss: 0.0096\n",
      "Epoch: 455/500... Training loss: 0.0015\n",
      "Epoch: 455/500... Training loss: 0.0041\n",
      "Epoch: 455/500... Training loss: 0.0037\n",
      "Epoch: 455/500... Training loss: 0.0032\n",
      "Epoch: 455/500... Training loss: 0.0189\n",
      "Epoch: 455/500... Training loss: 0.0231\n",
      "Epoch: 455/500... Training loss: 0.0021\n",
      "Epoch: 455/500... Training loss: 0.0621\n",
      "Epoch: 455/500... Training loss: 0.0025\n",
      "Epoch: 455/500... Training loss: 0.0132\n",
      "Epoch: 455/500... Training loss: 0.0010\n",
      "Epoch: 455/500... Training loss: 0.0016\n",
      "Epoch: 455/500... Training loss: 0.0043\n",
      "Epoch: 455/500... Training loss: 0.0012\n",
      "Epoch: 455/500... Training loss: 0.0020\n",
      "Epoch: 455/500... Training loss: 0.0110\n",
      "Epoch: 455/500... Training loss: 0.0113\n",
      "Epoch: 455/500... Training loss: 0.0016\n",
      "Epoch: 455/500... Training loss: 0.0003\n",
      "Epoch: 455/500... Training loss: 0.0013\n",
      "Epoch: 455/500... Training loss: 0.0176\n",
      "Epoch: 455/500... Training loss: 0.0003\n",
      "Epoch: 455/500... Training loss: 0.0168\n",
      "Epoch: 455/500... Training loss: 0.0009\n",
      "Epoch: 455/500... Training loss: 0.0351\n",
      "Epoch: 456/500... Training loss: 0.0103\n",
      "Epoch: 456/500... Training loss: 0.0004\n",
      "Epoch: 456/500... Training loss: 0.0016\n",
      "Epoch: 456/500... Training loss: 0.0016\n",
      "Epoch: 456/500... Training loss: 0.0025\n",
      "Epoch: 456/500... Training loss: 0.0006\n",
      "Epoch: 456/500... Training loss: 0.0534\n",
      "Epoch: 456/500... Training loss: 0.0213\n",
      "Epoch: 456/500... Training loss: 0.0053\n",
      "Epoch: 456/500... Training loss: 0.0026\n",
      "Epoch: 456/500... Training loss: 0.0058\n",
      "Epoch: 456/500... Training loss: 0.0518\n",
      "Epoch: 456/500... Training loss: 0.0478\n",
      "Epoch: 456/500... Training loss: 0.0017\n",
      "Epoch: 456/500... Training loss: 0.0056\n",
      "Epoch: 456/500... Training loss: 0.0323\n",
      "Epoch: 456/500... Training loss: 0.0056\n",
      "Epoch: 456/500... Training loss: 0.0011\n",
      "Epoch: 456/500... Training loss: 0.0022\n",
      "Epoch: 456/500... Training loss: 0.1165\n",
      "Epoch: 456/500... Training loss: 0.0358\n",
      "Epoch: 456/500... Training loss: 0.0009\n",
      "Epoch: 456/500... Training loss: 0.0966\n",
      "Epoch: 456/500... Training loss: 0.0311\n",
      "Epoch: 456/500... Training loss: 0.0044\n",
      "Epoch: 456/500... Training loss: 0.0008\n",
      "Epoch: 456/500... Training loss: 0.0024\n",
      "Epoch: 456/500... Training loss: 0.0008\n",
      "Epoch: 456/500... Training loss: 0.0042\n",
      "Epoch: 456/500... Training loss: 0.0226\n",
      "Epoch: 456/500... Training loss: 0.0020\n",
      "Epoch: 457/500... Training loss: 0.0060\n",
      "Epoch: 457/500... Training loss: 0.0008\n",
      "Epoch: 457/500... Training loss: 0.0053\n",
      "Epoch: 457/500... Training loss: 0.0633\n",
      "Epoch: 457/500... Training loss: 0.0009\n",
      "Epoch: 457/500... Training loss: 0.0092\n",
      "Epoch: 457/500... Training loss: 0.0032\n",
      "Epoch: 457/500... Training loss: 0.0013\n",
      "Epoch: 457/500... Training loss: 0.0090\n",
      "Epoch: 457/500... Training loss: 0.0025\n",
      "Epoch: 457/500... Training loss: 0.0012\n",
      "Epoch: 457/500... Training loss: 0.0074\n",
      "Epoch: 457/500... Training loss: 0.0239\n",
      "Epoch: 457/500... Training loss: 0.0562\n",
      "Epoch: 457/500... Training loss: 0.0053\n",
      "Epoch: 457/500... Training loss: 0.0035\n",
      "Epoch: 457/500... Training loss: 0.0178\n",
      "Epoch: 457/500... Training loss: 0.0043\n",
      "Epoch: 457/500... Training loss: 0.0219\n",
      "Epoch: 457/500... Training loss: 0.0032\n",
      "Epoch: 457/500... Training loss: 0.0022\n",
      "Epoch: 457/500... Training loss: 0.0007\n",
      "Epoch: 457/500... Training loss: 0.0583\n",
      "Epoch: 457/500... Training loss: 0.0017\n",
      "Epoch: 457/500... Training loss: 0.0035\n",
      "Epoch: 457/500... Training loss: 0.0166\n",
      "Epoch: 457/500... Training loss: 0.0086\n",
      "Epoch: 457/500... Training loss: 0.0019\n",
      "Epoch: 457/500... Training loss: 0.0005\n",
      "Epoch: 457/500... Training loss: 0.0210\n",
      "Epoch: 457/500... Training loss: 0.0021\n",
      "Epoch: 458/500... Training loss: 0.0035\n",
      "Epoch: 458/500... Training loss: 0.0009\n",
      "Epoch: 458/500... Training loss: 0.0173\n",
      "Epoch: 458/500... Training loss: 0.0042\n",
      "Epoch: 458/500... Training loss: 0.0075\n",
      "Epoch: 458/500... Training loss: 0.0117\n",
      "Epoch: 458/500... Training loss: 0.0013\n",
      "Epoch: 458/500... Training loss: 0.0130\n",
      "Epoch: 458/500... Training loss: 0.0005\n",
      "Epoch: 458/500... Training loss: 0.0051\n",
      "Epoch: 458/500... Training loss: 0.0099\n",
      "Epoch: 458/500... Training loss: 0.0193\n",
      "Epoch: 458/500... Training loss: 0.0823\n",
      "Epoch: 458/500... Training loss: 0.0021\n",
      "Epoch: 458/500... Training loss: 0.0025\n",
      "Epoch: 458/500... Training loss: 0.0570\n",
      "Epoch: 458/500... Training loss: 0.0128\n",
      "Epoch: 458/500... Training loss: 0.0006\n",
      "Epoch: 458/500... Training loss: 0.0064\n",
      "Epoch: 458/500... Training loss: 0.0010\n",
      "Epoch: 458/500... Training loss: 0.0212\n",
      "Epoch: 458/500... Training loss: 0.0024\n",
      "Epoch: 458/500... Training loss: 0.0102\n",
      "Epoch: 458/500... Training loss: 0.0847\n",
      "Epoch: 458/500... Training loss: 0.0005\n",
      "Epoch: 458/500... Training loss: 0.0004\n",
      "Epoch: 458/500... Training loss: 0.0022\n",
      "Epoch: 458/500... Training loss: 0.0003\n",
      "Epoch: 458/500... Training loss: 0.0012\n",
      "Epoch: 458/500... Training loss: 0.0037\n",
      "Epoch: 458/500... Training loss: 0.0409\n",
      "Epoch: 459/500... Training loss: 0.0108\n",
      "Epoch: 459/500... Training loss: 0.0047\n",
      "Epoch: 459/500... Training loss: 0.0055\n",
      "Epoch: 459/500... Training loss: 0.0337\n",
      "Epoch: 459/500... Training loss: 0.0035\n",
      "Epoch: 459/500... Training loss: 0.0050\n",
      "Epoch: 459/500... Training loss: 0.0012\n",
      "Epoch: 459/500... Training loss: 0.0035\n",
      "Epoch: 459/500... Training loss: 0.0563\n",
      "Epoch: 459/500... Training loss: 0.0059\n",
      "Epoch: 459/500... Training loss: 0.0016\n",
      "Epoch: 459/500... Training loss: 0.0019\n",
      "Epoch: 459/500... Training loss: 0.0949\n",
      "Epoch: 459/500... Training loss: 0.0183\n",
      "Epoch: 459/500... Training loss: 0.0063\n",
      "Epoch: 459/500... Training loss: 0.0010\n",
      "Epoch: 459/500... Training loss: 0.0028\n",
      "Epoch: 459/500... Training loss: 0.0486\n",
      "Epoch: 459/500... Training loss: 0.0025\n",
      "Epoch: 459/500... Training loss: 0.0017\n",
      "Epoch: 459/500... Training loss: 0.0016\n",
      "Epoch: 459/500... Training loss: 0.0009\n",
      "Epoch: 459/500... Training loss: 0.0006\n",
      "Epoch: 459/500... Training loss: 0.0023\n",
      "Epoch: 459/500... Training loss: 0.0031\n",
      "Epoch: 459/500... Training loss: 0.0011\n",
      "Epoch: 459/500... Training loss: 0.0047\n",
      "Epoch: 459/500... Training loss: 0.0007\n",
      "Epoch: 459/500... Training loss: 0.0007\n",
      "Epoch: 459/500... Training loss: 0.0016\n",
      "Epoch: 459/500... Training loss: 0.0024\n",
      "Epoch: 460/500... Training loss: 0.0018\n",
      "Epoch: 460/500... Training loss: 0.0103\n",
      "Epoch: 460/500... Training loss: 0.0028\n",
      "Epoch: 460/500... Training loss: 0.0017\n",
      "Epoch: 460/500... Training loss: 0.0128\n",
      "Epoch: 460/500... Training loss: 0.0563\n",
      "Epoch: 460/500... Training loss: 0.0202\n",
      "Epoch: 460/500... Training loss: 0.0152\n",
      "Epoch: 460/500... Training loss: 0.0042\n",
      "Epoch: 460/500... Training loss: 0.0244\n",
      "Epoch: 460/500... Training loss: 0.0089\n",
      "Epoch: 460/500... Training loss: 0.0155\n",
      "Epoch: 460/500... Training loss: 0.0029\n",
      "Epoch: 460/500... Training loss: 0.0085\n",
      "Epoch: 460/500... Training loss: 0.0075\n",
      "Epoch: 460/500... Training loss: 0.0010\n",
      "Epoch: 460/500... Training loss: 0.0119\n",
      "Epoch: 460/500... Training loss: 0.0024\n",
      "Epoch: 460/500... Training loss: 0.0012\n",
      "Epoch: 460/500... Training loss: 0.0070\n",
      "Epoch: 460/500... Training loss: 0.0016\n",
      "Epoch: 460/500... Training loss: 0.0019\n",
      "Epoch: 460/500... Training loss: 0.0049\n",
      "Epoch: 460/500... Training loss: 0.0010\n",
      "Epoch: 460/500... Training loss: 0.0029\n",
      "Epoch: 460/500... Training loss: 0.0171\n",
      "Epoch: 460/500... Training loss: 0.0099\n",
      "Epoch: 460/500... Training loss: 0.0004\n",
      "Epoch: 460/500... Training loss: 0.0010\n",
      "Epoch: 460/500... Training loss: 0.0017\n",
      "Epoch: 460/500... Training loss: 0.0006\n",
      "Epoch: 461/500... Training loss: 0.0026\n",
      "Epoch: 461/500... Training loss: 0.0022\n",
      "Epoch: 461/500... Training loss: 0.0006\n",
      "Epoch: 461/500... Training loss: 0.0061\n",
      "Epoch: 461/500... Training loss: 0.0080\n",
      "Epoch: 461/500... Training loss: 0.0007\n",
      "Epoch: 461/500... Training loss: 0.0132\n",
      "Epoch: 461/500... Training loss: 0.0077\n",
      "Epoch: 461/500... Training loss: 0.0075\n",
      "Epoch: 461/500... Training loss: 0.0005\n",
      "Epoch: 461/500... Training loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 461/500... Training loss: 0.0035\n",
      "Epoch: 461/500... Training loss: 0.0059\n",
      "Epoch: 461/500... Training loss: 0.0070\n",
      "Epoch: 461/500... Training loss: 0.0013\n",
      "Epoch: 461/500... Training loss: 0.0644\n",
      "Epoch: 461/500... Training loss: 0.0017\n",
      "Epoch: 461/500... Training loss: 0.0040\n",
      "Epoch: 461/500... Training loss: 0.0474\n",
      "Epoch: 461/500... Training loss: 0.0005\n",
      "Epoch: 461/500... Training loss: 0.0004\n",
      "Epoch: 461/500... Training loss: 0.0013\n",
      "Epoch: 461/500... Training loss: 0.0274\n",
      "Epoch: 461/500... Training loss: 0.0057\n",
      "Epoch: 461/500... Training loss: 0.0004\n",
      "Epoch: 461/500... Training loss: 0.0064\n",
      "Epoch: 461/500... Training loss: 0.0026\n",
      "Epoch: 461/500... Training loss: 0.0021\n",
      "Epoch: 461/500... Training loss: 0.0010\n",
      "Epoch: 461/500... Training loss: 0.0131\n",
      "Epoch: 461/500... Training loss: 0.0010\n",
      "Epoch: 462/500... Training loss: 0.0121\n",
      "Epoch: 462/500... Training loss: 0.0007\n",
      "Epoch: 462/500... Training loss: 0.0025\n",
      "Epoch: 462/500... Training loss: 0.0006\n",
      "Epoch: 462/500... Training loss: 0.0008\n",
      "Epoch: 462/500... Training loss: 0.0024\n",
      "Epoch: 462/500... Training loss: 0.0011\n",
      "Epoch: 462/500... Training loss: 0.0017\n",
      "Epoch: 462/500... Training loss: 0.0022\n",
      "Epoch: 462/500... Training loss: 0.0018\n",
      "Epoch: 462/500... Training loss: 0.0024\n",
      "Epoch: 462/500... Training loss: 0.0566\n",
      "Epoch: 462/500... Training loss: 0.0022\n",
      "Epoch: 462/500... Training loss: 0.0003\n",
      "Epoch: 462/500... Training loss: 0.0161\n",
      "Epoch: 462/500... Training loss: 0.0049\n",
      "Epoch: 462/500... Training loss: 0.0009\n",
      "Epoch: 462/500... Training loss: 0.0004\n",
      "Epoch: 462/500... Training loss: 0.1056\n",
      "Epoch: 462/500... Training loss: 0.0033\n",
      "Epoch: 462/500... Training loss: 0.0012\n",
      "Epoch: 462/500... Training loss: 0.0104\n",
      "Epoch: 462/500... Training loss: 0.0010\n",
      "Epoch: 462/500... Training loss: 0.0008\n",
      "Epoch: 462/500... Training loss: 0.0020\n",
      "Epoch: 462/500... Training loss: 0.1292\n",
      "Epoch: 462/500... Training loss: 0.0195\n",
      "Epoch: 462/500... Training loss: 0.0014\n",
      "Epoch: 462/500... Training loss: 0.0005\n",
      "Epoch: 462/500... Training loss: 0.0021\n",
      "Epoch: 462/500... Training loss: 0.0142\n",
      "Epoch: 463/500... Training loss: 0.0019\n",
      "Epoch: 463/500... Training loss: 0.0041\n",
      "Epoch: 463/500... Training loss: 0.0123\n",
      "Epoch: 463/500... Training loss: 0.0017\n",
      "Epoch: 463/500... Training loss: 0.0016\n",
      "Epoch: 463/500... Training loss: 0.0059\n",
      "Epoch: 463/500... Training loss: 0.0025\n",
      "Epoch: 463/500... Training loss: 0.0004\n",
      "Epoch: 463/500... Training loss: 0.0014\n",
      "Epoch: 463/500... Training loss: 0.0075\n",
      "Epoch: 463/500... Training loss: 0.0004\n",
      "Epoch: 463/500... Training loss: 0.0091\n",
      "Epoch: 463/500... Training loss: 0.0027\n",
      "Epoch: 463/500... Training loss: 0.0021\n",
      "Epoch: 463/500... Training loss: 0.0029\n",
      "Epoch: 463/500... Training loss: 0.0007\n",
      "Epoch: 463/500... Training loss: 0.0114\n",
      "Epoch: 463/500... Training loss: 0.0013\n",
      "Epoch: 463/500... Training loss: 0.0196\n",
      "Epoch: 463/500... Training loss: 0.0328\n",
      "Epoch: 463/500... Training loss: 0.0016\n",
      "Epoch: 463/500... Training loss: 0.0013\n",
      "Epoch: 463/500... Training loss: 0.0020\n",
      "Epoch: 463/500... Training loss: 0.0026\n",
      "Epoch: 463/500... Training loss: 0.0072\n",
      "Epoch: 463/500... Training loss: 0.0021\n",
      "Epoch: 463/500... Training loss: 0.0433\n",
      "Epoch: 463/500... Training loss: 0.0012\n",
      "Epoch: 463/500... Training loss: 0.0059\n",
      "Epoch: 463/500... Training loss: 0.0016\n",
      "Epoch: 463/500... Training loss: 0.0052\n",
      "Epoch: 464/500... Training loss: 0.0124\n",
      "Epoch: 464/500... Training loss: 0.0006\n",
      "Epoch: 464/500... Training loss: 0.0928\n",
      "Epoch: 464/500... Training loss: 0.0010\n",
      "Epoch: 464/500... Training loss: 0.0052\n",
      "Epoch: 464/500... Training loss: 0.0020\n",
      "Epoch: 464/500... Training loss: 0.0049\n",
      "Epoch: 464/500... Training loss: 0.0091\n",
      "Epoch: 464/500... Training loss: 0.0098\n",
      "Epoch: 464/500... Training loss: 0.0015\n",
      "Epoch: 464/500... Training loss: 0.0010\n",
      "Epoch: 464/500... Training loss: 0.0005\n",
      "Epoch: 464/500... Training loss: 0.0014\n",
      "Epoch: 464/500... Training loss: 0.0079\n",
      "Epoch: 464/500... Training loss: 0.0058\n",
      "Epoch: 464/500... Training loss: 0.0674\n",
      "Epoch: 464/500... Training loss: 0.0038\n",
      "Epoch: 464/500... Training loss: 0.0018\n",
      "Epoch: 464/500... Training loss: 0.0005\n",
      "Epoch: 464/500... Training loss: 0.0078\n",
      "Epoch: 464/500... Training loss: 0.0243\n",
      "Epoch: 464/500... Training loss: 0.0327\n",
      "Epoch: 464/500... Training loss: 0.0017\n",
      "Epoch: 464/500... Training loss: 0.0439\n",
      "Epoch: 464/500... Training loss: 0.0020\n",
      "Epoch: 464/500... Training loss: 0.0028\n",
      "Epoch: 464/500... Training loss: 0.0169\n",
      "Epoch: 464/500... Training loss: 0.0020\n",
      "Epoch: 464/500... Training loss: 0.0016\n",
      "Epoch: 464/500... Training loss: 0.0129\n",
      "Epoch: 464/500... Training loss: 0.0024\n",
      "Epoch: 465/500... Training loss: 0.0024\n",
      "Epoch: 465/500... Training loss: 0.0064\n",
      "Epoch: 465/500... Training loss: 0.0060\n",
      "Epoch: 465/500... Training loss: 0.0060\n",
      "Epoch: 465/500... Training loss: 0.0003\n",
      "Epoch: 465/500... Training loss: 0.0043\n",
      "Epoch: 465/500... Training loss: 0.0004\n",
      "Epoch: 465/500... Training loss: 0.0007\n",
      "Epoch: 465/500... Training loss: 0.0016\n",
      "Epoch: 465/500... Training loss: 0.0020\n",
      "Epoch: 465/500... Training loss: 0.0023\n",
      "Epoch: 465/500... Training loss: 0.0016\n",
      "Epoch: 465/500... Training loss: 0.0045\n",
      "Epoch: 465/500... Training loss: 0.0007\n",
      "Epoch: 465/500... Training loss: 0.0034\n",
      "Epoch: 465/500... Training loss: 0.0034\n",
      "Epoch: 465/500... Training loss: 0.0024\n",
      "Epoch: 465/500... Training loss: 0.0026\n",
      "Epoch: 465/500... Training loss: 0.0004\n",
      "Epoch: 465/500... Training loss: 0.0013\n",
      "Epoch: 465/500... Training loss: 0.0162\n",
      "Epoch: 465/500... Training loss: 0.0008\n",
      "Epoch: 465/500... Training loss: 0.0004\n",
      "Epoch: 465/500... Training loss: 0.0003\n",
      "Epoch: 465/500... Training loss: 0.0023\n",
      "Epoch: 465/500... Training loss: 0.0950\n",
      "Epoch: 465/500... Training loss: 0.0049\n",
      "Epoch: 465/500... Training loss: 0.0018\n",
      "Epoch: 465/500... Training loss: 0.0013\n",
      "Epoch: 465/500... Training loss: 0.0033\n",
      "Epoch: 465/500... Training loss: 0.0017\n",
      "Epoch: 466/500... Training loss: 0.0213\n",
      "Epoch: 466/500... Training loss: 0.0046\n",
      "Epoch: 466/500... Training loss: 0.0029\n",
      "Epoch: 466/500... Training loss: 0.0111\n",
      "Epoch: 466/500... Training loss: 0.0098\n",
      "Epoch: 466/500... Training loss: 0.0026\n",
      "Epoch: 466/500... Training loss: 0.0007\n",
      "Epoch: 466/500... Training loss: 0.0020\n",
      "Epoch: 466/500... Training loss: 0.0234\n",
      "Epoch: 466/500... Training loss: 0.0060\n",
      "Epoch: 466/500... Training loss: 0.0062\n",
      "Epoch: 466/500... Training loss: 0.0034\n",
      "Epoch: 466/500... Training loss: 0.0115\n",
      "Epoch: 466/500... Training loss: 0.0121\n",
      "Epoch: 466/500... Training loss: 0.0007\n",
      "Epoch: 466/500... Training loss: 0.0011\n",
      "Epoch: 466/500... Training loss: 0.0033\n",
      "Epoch: 466/500... Training loss: 0.0015\n",
      "Epoch: 466/500... Training loss: 0.0037\n",
      "Epoch: 466/500... Training loss: 0.0019\n",
      "Epoch: 466/500... Training loss: 0.0010\n",
      "Epoch: 466/500... Training loss: 0.0011\n",
      "Epoch: 466/500... Training loss: 0.0003\n",
      "Epoch: 466/500... Training loss: 0.0157\n",
      "Epoch: 466/500... Training loss: 0.0006\n",
      "Epoch: 466/500... Training loss: 0.0085\n",
      "Epoch: 466/500... Training loss: 0.0157\n",
      "Epoch: 466/500... Training loss: 0.0047\n",
      "Epoch: 466/500... Training loss: 0.0245\n",
      "Epoch: 466/500... Training loss: 0.0015\n",
      "Epoch: 466/500... Training loss: 0.0014\n",
      "Epoch: 467/500... Training loss: 0.0128\n",
      "Epoch: 467/500... Training loss: 0.0029\n",
      "Epoch: 467/500... Training loss: 0.0037\n",
      "Epoch: 467/500... Training loss: 0.0011\n",
      "Epoch: 467/500... Training loss: 0.0013\n",
      "Epoch: 467/500... Training loss: 0.0245\n",
      "Epoch: 467/500... Training loss: 0.0037\n",
      "Epoch: 467/500... Training loss: 0.1641\n",
      "Epoch: 467/500... Training loss: 0.0002\n",
      "Epoch: 467/500... Training loss: 0.0036\n",
      "Epoch: 467/500... Training loss: 0.0179\n",
      "Epoch: 467/500... Training loss: 0.0057\n",
      "Epoch: 467/500... Training loss: 0.0050\n",
      "Epoch: 467/500... Training loss: 0.0009\n",
      "Epoch: 467/500... Training loss: 0.0050\n",
      "Epoch: 467/500... Training loss: 0.0030\n",
      "Epoch: 467/500... Training loss: 0.0173\n",
      "Epoch: 467/500... Training loss: 0.0094\n",
      "Epoch: 467/500... Training loss: 0.0006\n",
      "Epoch: 467/500... Training loss: 0.0457\n",
      "Epoch: 467/500... Training loss: 0.0018\n",
      "Epoch: 467/500... Training loss: 0.0006\n",
      "Epoch: 467/500... Training loss: 0.0075\n",
      "Epoch: 467/500... Training loss: 0.0006\n",
      "Epoch: 467/500... Training loss: 0.0794\n",
      "Epoch: 467/500... Training loss: 0.0019\n",
      "Epoch: 467/500... Training loss: 0.0050\n",
      "Epoch: 467/500... Training loss: 0.0023\n",
      "Epoch: 467/500... Training loss: 0.0106\n",
      "Epoch: 467/500... Training loss: 0.0016\n",
      "Epoch: 467/500... Training loss: 0.0110\n",
      "Epoch: 468/500... Training loss: 0.0577\n",
      "Epoch: 468/500... Training loss: 0.0152\n",
      "Epoch: 468/500... Training loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 468/500... Training loss: 0.0053\n",
      "Epoch: 468/500... Training loss: 0.0146\n",
      "Epoch: 468/500... Training loss: 0.0113\n",
      "Epoch: 468/500... Training loss: 0.0012\n",
      "Epoch: 468/500... Training loss: 0.0017\n",
      "Epoch: 468/500... Training loss: 0.0852\n",
      "Epoch: 468/500... Training loss: 0.0019\n",
      "Epoch: 468/500... Training loss: 0.0028\n",
      "Epoch: 468/500... Training loss: 0.0023\n",
      "Epoch: 468/500... Training loss: 0.0040\n",
      "Epoch: 468/500... Training loss: 0.0045\n",
      "Epoch: 468/500... Training loss: 0.0012\n",
      "Epoch: 468/500... Training loss: 0.0020\n",
      "Epoch: 468/500... Training loss: 0.0002\n",
      "Epoch: 468/500... Training loss: 0.0050\n",
      "Epoch: 468/500... Training loss: 0.0008\n",
      "Epoch: 468/500... Training loss: 0.0008\n",
      "Epoch: 468/500... Training loss: 0.0032\n",
      "Epoch: 468/500... Training loss: 0.0766\n",
      "Epoch: 468/500... Training loss: 0.0007\n",
      "Epoch: 468/500... Training loss: 0.0006\n",
      "Epoch: 468/500... Training loss: 0.0140\n",
      "Epoch: 468/500... Training loss: 0.0120\n",
      "Epoch: 468/500... Training loss: 0.0044\n",
      "Epoch: 468/500... Training loss: 0.0020\n",
      "Epoch: 468/500... Training loss: 0.0063\n",
      "Epoch: 468/500... Training loss: 0.0057\n",
      "Epoch: 468/500... Training loss: 0.0009\n",
      "Epoch: 469/500... Training loss: 0.0309\n",
      "Epoch: 469/500... Training loss: 0.0032\n",
      "Epoch: 469/500... Training loss: 0.0048\n",
      "Epoch: 469/500... Training loss: 0.0926\n",
      "Epoch: 469/500... Training loss: 0.0020\n",
      "Epoch: 469/500... Training loss: 0.0058\n",
      "Epoch: 469/500... Training loss: 0.0026\n",
      "Epoch: 469/500... Training loss: 0.0084\n",
      "Epoch: 469/500... Training loss: 0.0010\n",
      "Epoch: 469/500... Training loss: 0.0047\n",
      "Epoch: 469/500... Training loss: 0.0086\n",
      "Epoch: 469/500... Training loss: 0.0351\n",
      "Epoch: 469/500... Training loss: 0.0336\n",
      "Epoch: 469/500... Training loss: 0.0033\n",
      "Epoch: 469/500... Training loss: 0.0034\n",
      "Epoch: 469/500... Training loss: 0.0073\n",
      "Epoch: 469/500... Training loss: 0.0033\n",
      "Epoch: 469/500... Training loss: 0.0011\n",
      "Epoch: 469/500... Training loss: 0.0016\n",
      "Epoch: 469/500... Training loss: 0.0231\n",
      "Epoch: 469/500... Training loss: 0.0030\n",
      "Epoch: 469/500... Training loss: 0.0013\n",
      "Epoch: 469/500... Training loss: 0.0005\n",
      "Epoch: 469/500... Training loss: 0.0044\n",
      "Epoch: 469/500... Training loss: 0.0227\n",
      "Epoch: 469/500... Training loss: 0.0012\n",
      "Epoch: 469/500... Training loss: 0.0051\n",
      "Epoch: 469/500... Training loss: 0.0005\n",
      "Epoch: 469/500... Training loss: 0.0008\n",
      "Epoch: 469/500... Training loss: 0.0191\n",
      "Epoch: 469/500... Training loss: 0.0032\n",
      "Epoch: 470/500... Training loss: 0.0335\n",
      "Epoch: 470/500... Training loss: 0.0392\n",
      "Epoch: 470/500... Training loss: 0.0070\n",
      "Epoch: 470/500... Training loss: 0.0275\n",
      "Epoch: 470/500... Training loss: 0.0672\n",
      "Epoch: 470/500... Training loss: 0.0293\n",
      "Epoch: 470/500... Training loss: 0.0007\n",
      "Epoch: 470/500... Training loss: 0.0021\n",
      "Epoch: 470/500... Training loss: 0.0028\n",
      "Epoch: 470/500... Training loss: 0.0093\n",
      "Epoch: 470/500... Training loss: 0.0243\n",
      "Epoch: 470/500... Training loss: 0.0052\n",
      "Epoch: 470/500... Training loss: 0.0504\n",
      "Epoch: 470/500... Training loss: 0.0058\n",
      "Epoch: 470/500... Training loss: 0.0062\n",
      "Epoch: 470/500... Training loss: 0.0014\n",
      "Epoch: 470/500... Training loss: 0.0013\n",
      "Epoch: 470/500... Training loss: 0.0037\n",
      "Epoch: 470/500... Training loss: 0.0040\n",
      "Epoch: 470/500... Training loss: 0.0057\n",
      "Epoch: 470/500... Training loss: 0.0034\n",
      "Epoch: 470/500... Training loss: 0.0022\n",
      "Epoch: 470/500... Training loss: 0.0024\n",
      "Epoch: 470/500... Training loss: 0.0007\n",
      "Epoch: 470/500... Training loss: 0.0025\n",
      "Epoch: 470/500... Training loss: 0.0182\n",
      "Epoch: 470/500... Training loss: 0.0008\n",
      "Epoch: 470/500... Training loss: 0.0077\n",
      "Epoch: 470/500... Training loss: 0.0042\n",
      "Epoch: 470/500... Training loss: 0.0026\n",
      "Epoch: 470/500... Training loss: 0.0018\n",
      "Epoch: 471/500... Training loss: 0.0465\n",
      "Epoch: 471/500... Training loss: 0.0078\n",
      "Epoch: 471/500... Training loss: 0.0335\n",
      "Epoch: 471/500... Training loss: 0.0015\n",
      "Epoch: 471/500... Training loss: 0.0016\n",
      "Epoch: 471/500... Training loss: 0.0017\n",
      "Epoch: 471/500... Training loss: 0.0018\n",
      "Epoch: 471/500... Training loss: 0.0011\n",
      "Epoch: 471/500... Training loss: 0.0011\n",
      "Epoch: 471/500... Training loss: 0.0006\n",
      "Epoch: 471/500... Training loss: 0.0020\n",
      "Epoch: 471/500... Training loss: 0.1166\n",
      "Epoch: 471/500... Training loss: 0.0018\n",
      "Epoch: 471/500... Training loss: 0.0005\n",
      "Epoch: 471/500... Training loss: 0.0014\n",
      "Epoch: 471/500... Training loss: 0.0068\n",
      "Epoch: 471/500... Training loss: 0.0707\n",
      "Epoch: 471/500... Training loss: 0.0019\n",
      "Epoch: 471/500... Training loss: 0.0020\n",
      "Epoch: 471/500... Training loss: 0.0003\n",
      "Epoch: 471/500... Training loss: 0.0035\n",
      "Epoch: 471/500... Training loss: 0.0031\n",
      "Epoch: 471/500... Training loss: 0.0014\n",
      "Epoch: 471/500... Training loss: 0.0006\n",
      "Epoch: 471/500... Training loss: 0.0353\n",
      "Epoch: 471/500... Training loss: 0.0064\n",
      "Epoch: 471/500... Training loss: 0.0007\n",
      "Epoch: 471/500... Training loss: 0.0048\n",
      "Epoch: 471/500... Training loss: 0.0083\n",
      "Epoch: 471/500... Training loss: 0.0007\n",
      "Epoch: 471/500... Training loss: 0.0010\n",
      "Epoch: 472/500... Training loss: 0.0012\n",
      "Epoch: 472/500... Training loss: 0.0020\n",
      "Epoch: 472/500... Training loss: 0.0608\n",
      "Epoch: 472/500... Training loss: 0.0005\n",
      "Epoch: 472/500... Training loss: 0.0032\n",
      "Epoch: 472/500... Training loss: 0.0018\n",
      "Epoch: 472/500... Training loss: 0.0163\n",
      "Epoch: 472/500... Training loss: 0.0017\n",
      "Epoch: 472/500... Training loss: 0.0222\n",
      "Epoch: 472/500... Training loss: 0.0474\n",
      "Epoch: 472/500... Training loss: 0.0231\n",
      "Epoch: 472/500... Training loss: 0.0046\n",
      "Epoch: 472/500... Training loss: 0.0061\n",
      "Epoch: 472/500... Training loss: 0.0010\n",
      "Epoch: 472/500... Training loss: 0.0023\n",
      "Epoch: 472/500... Training loss: 0.0003\n",
      "Epoch: 472/500... Training loss: 0.0380\n",
      "Epoch: 472/500... Training loss: 0.0009\n",
      "Epoch: 472/500... Training loss: 0.0069\n",
      "Epoch: 472/500... Training loss: 0.0385\n",
      "Epoch: 472/500... Training loss: 0.0009\n",
      "Epoch: 472/500... Training loss: 0.0051\n",
      "Epoch: 472/500... Training loss: 0.0007\n",
      "Epoch: 472/500... Training loss: 0.0076\n",
      "Epoch: 472/500... Training loss: 0.0023\n",
      "Epoch: 472/500... Training loss: 0.0006\n",
      "Epoch: 472/500... Training loss: 0.0151\n",
      "Epoch: 472/500... Training loss: 0.0020\n",
      "Epoch: 472/500... Training loss: 0.0297\n",
      "Epoch: 472/500... Training loss: 0.0056\n",
      "Epoch: 472/500... Training loss: 0.0015\n",
      "Epoch: 473/500... Training loss: 0.0027\n",
      "Epoch: 473/500... Training loss: 0.0214\n",
      "Epoch: 473/500... Training loss: 0.0032\n",
      "Epoch: 473/500... Training loss: 0.0163\n",
      "Epoch: 473/500... Training loss: 0.0025\n",
      "Epoch: 473/500... Training loss: 0.0012\n",
      "Epoch: 473/500... Training loss: 0.0020\n",
      "Epoch: 473/500... Training loss: 0.0036\n",
      "Epoch: 473/500... Training loss: 0.0011\n",
      "Epoch: 473/500... Training loss: 0.0010\n",
      "Epoch: 473/500... Training loss: 0.0043\n",
      "Epoch: 473/500... Training loss: 0.1912\n",
      "Epoch: 473/500... Training loss: 0.0086\n",
      "Epoch: 473/500... Training loss: 0.0387\n",
      "Epoch: 473/500... Training loss: 0.0039\n",
      "Epoch: 473/500... Training loss: 0.0006\n",
      "Epoch: 473/500... Training loss: 0.0095\n",
      "Epoch: 473/500... Training loss: 0.0137\n",
      "Epoch: 473/500... Training loss: 0.0008\n",
      "Epoch: 473/500... Training loss: 0.0022\n",
      "Epoch: 473/500... Training loss: 0.0061\n",
      "Epoch: 473/500... Training loss: 0.0857\n",
      "Epoch: 473/500... Training loss: 0.0008\n",
      "Epoch: 473/500... Training loss: 0.0010\n",
      "Epoch: 473/500... Training loss: 0.0007\n",
      "Epoch: 473/500... Training loss: 0.0006\n",
      "Epoch: 473/500... Training loss: 0.0009\n",
      "Epoch: 473/500... Training loss: 0.0049\n",
      "Epoch: 473/500... Training loss: 0.0024\n",
      "Epoch: 473/500... Training loss: 0.0023\n",
      "Epoch: 473/500... Training loss: 0.0006\n",
      "Epoch: 474/500... Training loss: 0.0007\n",
      "Epoch: 474/500... Training loss: 0.0009\n",
      "Epoch: 474/500... Training loss: 0.0220\n",
      "Epoch: 474/500... Training loss: 0.0012\n",
      "Epoch: 474/500... Training loss: 0.0136\n",
      "Epoch: 474/500... Training loss: 0.0007\n",
      "Epoch: 474/500... Training loss: 0.0016\n",
      "Epoch: 474/500... Training loss: 0.0004\n",
      "Epoch: 474/500... Training loss: 0.0040\n",
      "Epoch: 474/500... Training loss: 0.0012\n",
      "Epoch: 474/500... Training loss: 0.0025\n",
      "Epoch: 474/500... Training loss: 0.0023\n",
      "Epoch: 474/500... Training loss: 0.0065\n",
      "Epoch: 474/500... Training loss: 0.0661\n",
      "Epoch: 474/500... Training loss: 0.0096\n",
      "Epoch: 474/500... Training loss: 0.0024\n",
      "Epoch: 474/500... Training loss: 0.0046\n",
      "Epoch: 474/500... Training loss: 0.0026\n",
      "Epoch: 474/500... Training loss: 0.0149\n",
      "Epoch: 474/500... Training loss: 0.0008\n",
      "Epoch: 474/500... Training loss: 0.0015\n",
      "Epoch: 474/500... Training loss: 0.0014\n",
      "Epoch: 474/500... Training loss: 0.0078\n",
      "Epoch: 474/500... Training loss: 0.0032\n",
      "Epoch: 474/500... Training loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 474/500... Training loss: 0.0019\n",
      "Epoch: 474/500... Training loss: 0.0023\n",
      "Epoch: 474/500... Training loss: 0.0051\n",
      "Epoch: 474/500... Training loss: 0.0021\n",
      "Epoch: 474/500... Training loss: 0.0010\n",
      "Epoch: 474/500... Training loss: 0.0089\n",
      "Epoch: 475/500... Training loss: 0.0018\n",
      "Epoch: 475/500... Training loss: 0.0470\n",
      "Epoch: 475/500... Training loss: 0.0019\n",
      "Epoch: 475/500... Training loss: 0.0014\n",
      "Epoch: 475/500... Training loss: 0.0051\n",
      "Epoch: 475/500... Training loss: 0.0011\n",
      "Epoch: 475/500... Training loss: 0.0061\n",
      "Epoch: 475/500... Training loss: 0.0474\n",
      "Epoch: 475/500... Training loss: 0.0018\n",
      "Epoch: 475/500... Training loss: 0.0029\n",
      "Epoch: 475/500... Training loss: 0.0075\n",
      "Epoch: 475/500... Training loss: 0.0015\n",
      "Epoch: 475/500... Training loss: 0.0093\n",
      "Epoch: 475/500... Training loss: 0.0079\n",
      "Epoch: 475/500... Training loss: 0.0099\n",
      "Epoch: 475/500... Training loss: 0.0110\n",
      "Epoch: 475/500... Training loss: 0.0131\n",
      "Epoch: 475/500... Training loss: 0.0244\n",
      "Epoch: 475/500... Training loss: 0.0058\n",
      "Epoch: 475/500... Training loss: 0.0274\n",
      "Epoch: 475/500... Training loss: 0.0018\n",
      "Epoch: 475/500... Training loss: 0.0016\n",
      "Epoch: 475/500... Training loss: 0.0016\n",
      "Epoch: 475/500... Training loss: 0.0007\n",
      "Epoch: 475/500... Training loss: 0.0181\n",
      "Epoch: 475/500... Training loss: 0.0007\n",
      "Epoch: 475/500... Training loss: 0.0008\n",
      "Epoch: 475/500... Training loss: 0.0017\n",
      "Epoch: 475/500... Training loss: 0.0274\n",
      "Epoch: 475/500... Training loss: 0.0003\n",
      "Epoch: 475/500... Training loss: 0.0163\n",
      "Epoch: 476/500... Training loss: 0.0033\n",
      "Epoch: 476/500... Training loss: 0.0151\n",
      "Epoch: 476/500... Training loss: 0.0014\n",
      "Epoch: 476/500... Training loss: 0.0007\n",
      "Epoch: 476/500... Training loss: 0.0291\n",
      "Epoch: 476/500... Training loss: 0.0090\n",
      "Epoch: 476/500... Training loss: 0.0027\n",
      "Epoch: 476/500... Training loss: 0.0032\n",
      "Epoch: 476/500... Training loss: 0.0049\n",
      "Epoch: 476/500... Training loss: 0.0035\n",
      "Epoch: 476/500... Training loss: 0.0024\n",
      "Epoch: 476/500... Training loss: 0.0127\n",
      "Epoch: 476/500... Training loss: 0.0099\n",
      "Epoch: 476/500... Training loss: 0.0784\n",
      "Epoch: 476/500... Training loss: 0.0149\n",
      "Epoch: 476/500... Training loss: 0.0130\n",
      "Epoch: 476/500... Training loss: 0.0019\n",
      "Epoch: 476/500... Training loss: 0.0007\n",
      "Epoch: 476/500... Training loss: 0.0015\n",
      "Epoch: 476/500... Training loss: 0.0021\n",
      "Epoch: 476/500... Training loss: 0.0085\n",
      "Epoch: 476/500... Training loss: 0.0004\n",
      "Epoch: 476/500... Training loss: 0.0197\n",
      "Epoch: 476/500... Training loss: 0.0003\n",
      "Epoch: 476/500... Training loss: 0.0005\n",
      "Epoch: 476/500... Training loss: 0.0021\n",
      "Epoch: 476/500... Training loss: 0.0008\n",
      "Epoch: 476/500... Training loss: 0.0110\n",
      "Epoch: 476/500... Training loss: 0.0042\n",
      "Epoch: 476/500... Training loss: 0.0042\n",
      "Epoch: 476/500... Training loss: 0.0511\n",
      "Epoch: 477/500... Training loss: 0.0157\n",
      "Epoch: 477/500... Training loss: 0.0015\n",
      "Epoch: 477/500... Training loss: 0.0003\n",
      "Epoch: 477/500... Training loss: 0.0008\n",
      "Epoch: 477/500... Training loss: 0.0006\n",
      "Epoch: 477/500... Training loss: 0.0011\n",
      "Epoch: 477/500... Training loss: 0.1244\n",
      "Epoch: 477/500... Training loss: 0.0019\n",
      "Epoch: 477/500... Training loss: 0.0005\n",
      "Epoch: 477/500... Training loss: 0.0030\n",
      "Epoch: 477/500... Training loss: 0.0029\n",
      "Epoch: 477/500... Training loss: 0.0019\n",
      "Epoch: 477/500... Training loss: 0.0305\n",
      "Epoch: 477/500... Training loss: 0.0161\n",
      "Epoch: 477/500... Training loss: 0.0015\n",
      "Epoch: 477/500... Training loss: 0.0792\n",
      "Epoch: 477/500... Training loss: 0.0021\n",
      "Epoch: 477/500... Training loss: 0.0021\n",
      "Epoch: 477/500... Training loss: 0.0014\n",
      "Epoch: 477/500... Training loss: 0.0015\n",
      "Epoch: 477/500... Training loss: 0.0104\n",
      "Epoch: 477/500... Training loss: 0.0008\n",
      "Epoch: 477/500... Training loss: 0.0015\n",
      "Epoch: 477/500... Training loss: 0.0003\n",
      "Epoch: 477/500... Training loss: 0.0010\n",
      "Epoch: 477/500... Training loss: 0.0006\n",
      "Epoch: 477/500... Training loss: 0.0010\n",
      "Epoch: 477/500... Training loss: 0.0039\n",
      "Epoch: 477/500... Training loss: 0.0014\n",
      "Epoch: 477/500... Training loss: 0.0088\n",
      "Epoch: 477/500... Training loss: 0.0012\n",
      "Epoch: 478/500... Training loss: 0.0072\n",
      "Epoch: 478/500... Training loss: 0.0018\n",
      "Epoch: 478/500... Training loss: 0.0013\n",
      "Epoch: 478/500... Training loss: 0.0048\n",
      "Epoch: 478/500... Training loss: 0.0088\n",
      "Epoch: 478/500... Training loss: 0.0121\n",
      "Epoch: 478/500... Training loss: 0.0005\n",
      "Epoch: 478/500... Training loss: 0.0009\n",
      "Epoch: 478/500... Training loss: 0.0011\n",
      "Epoch: 478/500... Training loss: 0.0003\n",
      "Epoch: 478/500... Training loss: 0.0272\n",
      "Epoch: 478/500... Training loss: 0.0686\n",
      "Epoch: 478/500... Training loss: 0.0047\n",
      "Epoch: 478/500... Training loss: 0.0008\n",
      "Epoch: 478/500... Training loss: 0.0006\n",
      "Epoch: 478/500... Training loss: 0.0001\n",
      "Epoch: 478/500... Training loss: 0.0006\n",
      "Epoch: 478/500... Training loss: 0.0006\n",
      "Epoch: 478/500... Training loss: 0.0017\n",
      "Epoch: 478/500... Training loss: 0.0103\n",
      "Epoch: 478/500... Training loss: 0.0131\n",
      "Epoch: 478/500... Training loss: 0.0015\n",
      "Epoch: 478/500... Training loss: 0.0010\n",
      "Epoch: 478/500... Training loss: 0.0040\n",
      "Epoch: 478/500... Training loss: 0.0057\n",
      "Epoch: 478/500... Training loss: 0.0005\n",
      "Epoch: 478/500... Training loss: 0.0126\n",
      "Epoch: 478/500... Training loss: 0.0009\n",
      "Epoch: 478/500... Training loss: 0.0110\n",
      "Epoch: 478/500... Training loss: 0.0005\n",
      "Epoch: 478/500... Training loss: 0.0016\n",
      "Epoch: 479/500... Training loss: 0.0391\n",
      "Epoch: 479/500... Training loss: 0.0006\n",
      "Epoch: 479/500... Training loss: 0.0041\n",
      "Epoch: 479/500... Training loss: 0.0049\n",
      "Epoch: 479/500... Training loss: 0.0578\n",
      "Epoch: 479/500... Training loss: 0.0054\n",
      "Epoch: 479/500... Training loss: 0.0711\n",
      "Epoch: 479/500... Training loss: 0.0021\n",
      "Epoch: 479/500... Training loss: 0.0022\n",
      "Epoch: 479/500... Training loss: 0.0019\n",
      "Epoch: 479/500... Training loss: 0.0118\n",
      "Epoch: 479/500... Training loss: 0.0024\n",
      "Epoch: 479/500... Training loss: 0.0105\n",
      "Epoch: 479/500... Training loss: 0.0106\n",
      "Epoch: 479/500... Training loss: 0.0273\n",
      "Epoch: 479/500... Training loss: 0.0148\n",
      "Epoch: 479/500... Training loss: 0.0343\n",
      "Epoch: 479/500... Training loss: 0.0241\n",
      "Epoch: 479/500... Training loss: 0.0303\n",
      "Epoch: 479/500... Training loss: 0.0057\n",
      "Epoch: 479/500... Training loss: 0.0007\n",
      "Epoch: 479/500... Training loss: 0.0028\n",
      "Epoch: 479/500... Training loss: 0.0006\n",
      "Epoch: 479/500... Training loss: 0.0020\n",
      "Epoch: 479/500... Training loss: 0.0004\n",
      "Epoch: 479/500... Training loss: 0.0044\n",
      "Epoch: 479/500... Training loss: 0.0076\n",
      "Epoch: 479/500... Training loss: 0.0017\n",
      "Epoch: 479/500... Training loss: 0.0302\n",
      "Epoch: 479/500... Training loss: 0.0021\n",
      "Epoch: 479/500... Training loss: 0.0139\n",
      "Epoch: 480/500... Training loss: 0.0017\n",
      "Epoch: 480/500... Training loss: 0.0012\n",
      "Epoch: 480/500... Training loss: 0.0107\n",
      "Epoch: 480/500... Training loss: 0.0026\n",
      "Epoch: 480/500... Training loss: 0.0018\n",
      "Epoch: 480/500... Training loss: 0.0137\n",
      "Epoch: 480/500... Training loss: 0.1047\n",
      "Epoch: 480/500... Training loss: 0.0025\n",
      "Epoch: 480/500... Training loss: 0.0377\n",
      "Epoch: 480/500... Training loss: 0.0070\n",
      "Epoch: 480/500... Training loss: 0.0163\n",
      "Epoch: 480/500... Training loss: 0.0003\n",
      "Epoch: 480/500... Training loss: 0.0096\n",
      "Epoch: 480/500... Training loss: 0.0054\n",
      "Epoch: 480/500... Training loss: 0.0015\n",
      "Epoch: 480/500... Training loss: 0.0009\n",
      "Epoch: 480/500... Training loss: 0.0034\n",
      "Epoch: 480/500... Training loss: 0.0269\n",
      "Epoch: 480/500... Training loss: 0.0055\n",
      "Epoch: 480/500... Training loss: 0.0432\n",
      "Epoch: 480/500... Training loss: 0.0561\n",
      "Epoch: 480/500... Training loss: 0.0007\n",
      "Epoch: 480/500... Training loss: 0.0010\n",
      "Epoch: 480/500... Training loss: 0.0198\n",
      "Epoch: 480/500... Training loss: 0.0007\n",
      "Epoch: 480/500... Training loss: 0.0008\n",
      "Epoch: 480/500... Training loss: 0.0005\n",
      "Epoch: 480/500... Training loss: 0.0038\n",
      "Epoch: 480/500... Training loss: 0.0521\n",
      "Epoch: 480/500... Training loss: 0.0034\n",
      "Epoch: 480/500... Training loss: 0.0016\n",
      "Epoch: 481/500... Training loss: 0.0032\n",
      "Epoch: 481/500... Training loss: 0.0756\n",
      "Epoch: 481/500... Training loss: 0.0266\n",
      "Epoch: 481/500... Training loss: 0.0109\n",
      "Epoch: 481/500... Training loss: 0.0018\n",
      "Epoch: 481/500... Training loss: 0.0119\n",
      "Epoch: 481/500... Training loss: 0.0005\n",
      "Epoch: 481/500... Training loss: 0.0029\n",
      "Epoch: 481/500... Training loss: 0.0041\n",
      "Epoch: 481/500... Training loss: 0.0007\n",
      "Epoch: 481/500... Training loss: 0.0161\n",
      "Epoch: 481/500... Training loss: 0.0069\n",
      "Epoch: 481/500... Training loss: 0.0004\n",
      "Epoch: 481/500... Training loss: 0.0158\n",
      "Epoch: 481/500... Training loss: 0.0039\n",
      "Epoch: 481/500... Training loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 481/500... Training loss: 0.0027\n",
      "Epoch: 481/500... Training loss: 0.0005\n",
      "Epoch: 481/500... Training loss: 0.0016\n",
      "Epoch: 481/500... Training loss: 0.0186\n",
      "Epoch: 481/500... Training loss: 0.0430\n",
      "Epoch: 481/500... Training loss: 0.0082\n",
      "Epoch: 481/500... Training loss: 0.0062\n",
      "Epoch: 481/500... Training loss: 0.0054\n",
      "Epoch: 481/500... Training loss: 0.0077\n",
      "Epoch: 481/500... Training loss: 0.0062\n",
      "Epoch: 481/500... Training loss: 0.0003\n",
      "Epoch: 481/500... Training loss: 0.0007\n",
      "Epoch: 481/500... Training loss: 0.0124\n",
      "Epoch: 481/500... Training loss: 0.0051\n",
      "Epoch: 481/500... Training loss: 0.0060\n",
      "Epoch: 482/500... Training loss: 0.0017\n",
      "Epoch: 482/500... Training loss: 0.0075\n",
      "Epoch: 482/500... Training loss: 0.0009\n",
      "Epoch: 482/500... Training loss: 0.0019\n",
      "Epoch: 482/500... Training loss: 0.0044\n",
      "Epoch: 482/500... Training loss: 0.0030\n",
      "Epoch: 482/500... Training loss: 0.0109\n",
      "Epoch: 482/500... Training loss: 0.0005\n",
      "Epoch: 482/500... Training loss: 0.0103\n",
      "Epoch: 482/500... Training loss: 0.0032\n",
      "Epoch: 482/500... Training loss: 0.0239\n",
      "Epoch: 482/500... Training loss: 0.0649\n",
      "Epoch: 482/500... Training loss: 0.0136\n",
      "Epoch: 482/500... Training loss: 0.0005\n",
      "Epoch: 482/500... Training loss: 0.0020\n",
      "Epoch: 482/500... Training loss: 0.0008\n",
      "Epoch: 482/500... Training loss: 0.0031\n",
      "Epoch: 482/500... Training loss: 0.0008\n",
      "Epoch: 482/500... Training loss: 0.0189\n",
      "Epoch: 482/500... Training loss: 0.0011\n",
      "Epoch: 482/500... Training loss: 0.0038\n",
      "Epoch: 482/500... Training loss: 0.0027\n",
      "Epoch: 482/500... Training loss: 0.0035\n",
      "Epoch: 482/500... Training loss: 0.0580\n",
      "Epoch: 482/500... Training loss: 0.0005\n",
      "Epoch: 482/500... Training loss: 0.0121\n",
      "Epoch: 482/500... Training loss: 0.0048\n",
      "Epoch: 482/500... Training loss: 0.0044\n",
      "Epoch: 482/500... Training loss: 0.0064\n",
      "Epoch: 482/500... Training loss: 0.0111\n",
      "Epoch: 482/500... Training loss: 0.0286\n",
      "Epoch: 483/500... Training loss: 0.0013\n",
      "Epoch: 483/500... Training loss: 0.0218\n",
      "Epoch: 483/500... Training loss: 0.0474\n",
      "Epoch: 483/500... Training loss: 0.0016\n",
      "Epoch: 483/500... Training loss: 0.0081\n",
      "Epoch: 483/500... Training loss: 0.0061\n",
      "Epoch: 483/500... Training loss: 0.0026\n",
      "Epoch: 483/500... Training loss: 0.0007\n",
      "Epoch: 483/500... Training loss: 0.0009\n",
      "Epoch: 483/500... Training loss: 0.0080\n",
      "Epoch: 483/500... Training loss: 0.0016\n",
      "Epoch: 483/500... Training loss: 0.0005\n",
      "Epoch: 483/500... Training loss: 0.0100\n",
      "Epoch: 483/500... Training loss: 0.0036\n",
      "Epoch: 483/500... Training loss: 0.0027\n",
      "Epoch: 483/500... Training loss: 0.0009\n",
      "Epoch: 483/500... Training loss: 0.0008\n",
      "Epoch: 483/500... Training loss: 0.0016\n",
      "Epoch: 483/500... Training loss: 0.0955\n",
      "Epoch: 483/500... Training loss: 0.0079\n",
      "Epoch: 483/500... Training loss: 0.0096\n",
      "Epoch: 483/500... Training loss: 0.0011\n",
      "Epoch: 483/500... Training loss: 0.0083\n",
      "Epoch: 483/500... Training loss: 0.0016\n",
      "Epoch: 483/500... Training loss: 0.0004\n",
      "Epoch: 483/500... Training loss: 0.0008\n",
      "Epoch: 483/500... Training loss: 0.0021\n",
      "Epoch: 483/500... Training loss: 0.0062\n",
      "Epoch: 483/500... Training loss: 0.0181\n",
      "Epoch: 483/500... Training loss: 0.0004\n",
      "Epoch: 483/500... Training loss: 0.0053\n",
      "Epoch: 484/500... Training loss: 0.0738\n",
      "Epoch: 484/500... Training loss: 0.0554\n",
      "Epoch: 484/500... Training loss: 0.0152\n",
      "Epoch: 484/500... Training loss: 0.0022\n",
      "Epoch: 484/500... Training loss: 0.0166\n",
      "Epoch: 484/500... Training loss: 0.0360\n",
      "Epoch: 484/500... Training loss: 0.0014\n",
      "Epoch: 484/500... Training loss: 0.0037\n",
      "Epoch: 484/500... Training loss: 0.0004\n",
      "Epoch: 484/500... Training loss: 0.0014\n",
      "Epoch: 484/500... Training loss: 0.0062\n",
      "Epoch: 484/500... Training loss: 0.0013\n",
      "Epoch: 484/500... Training loss: 0.0155\n",
      "Epoch: 484/500... Training loss: 0.0009\n",
      "Epoch: 484/500... Training loss: 0.0019\n",
      "Epoch: 484/500... Training loss: 0.0009\n",
      "Epoch: 484/500... Training loss: 0.0200\n",
      "Epoch: 484/500... Training loss: 0.0047\n",
      "Epoch: 484/500... Training loss: 0.0132\n",
      "Epoch: 484/500... Training loss: 0.0135\n",
      "Epoch: 484/500... Training loss: 0.0021\n",
      "Epoch: 484/500... Training loss: 0.0014\n",
      "Epoch: 484/500... Training loss: 0.0004\n",
      "Epoch: 484/500... Training loss: 0.0269\n",
      "Epoch: 484/500... Training loss: 0.0015\n",
      "Epoch: 484/500... Training loss: 0.0079\n",
      "Epoch: 484/500... Training loss: 0.0041\n",
      "Epoch: 484/500... Training loss: 0.0006\n",
      "Epoch: 484/500... Training loss: 0.0004\n",
      "Epoch: 484/500... Training loss: 0.0020\n",
      "Epoch: 484/500... Training loss: 0.0390\n",
      "Epoch: 485/500... Training loss: 0.0015\n",
      "Epoch: 485/500... Training loss: 0.0005\n",
      "Epoch: 485/500... Training loss: 0.0419\n",
      "Epoch: 485/500... Training loss: 0.0032\n",
      "Epoch: 485/500... Training loss: 0.0007\n",
      "Epoch: 485/500... Training loss: 0.0232\n",
      "Epoch: 485/500... Training loss: 0.0012\n",
      "Epoch: 485/500... Training loss: 0.0048\n",
      "Epoch: 485/500... Training loss: 0.0523\n",
      "Epoch: 485/500... Training loss: 0.0019\n",
      "Epoch: 485/500... Training loss: 0.1818\n",
      "Epoch: 485/500... Training loss: 0.0015\n",
      "Epoch: 485/500... Training loss: 0.0028\n",
      "Epoch: 485/500... Training loss: 0.0014\n",
      "Epoch: 485/500... Training loss: 0.0013\n",
      "Epoch: 485/500... Training loss: 0.0015\n",
      "Epoch: 485/500... Training loss: 0.0095\n",
      "Epoch: 485/500... Training loss: 0.0051\n",
      "Epoch: 485/500... Training loss: 0.0015\n",
      "Epoch: 485/500... Training loss: 0.0515\n",
      "Epoch: 485/500... Training loss: 0.0109\n",
      "Epoch: 485/500... Training loss: 0.0294\n",
      "Epoch: 485/500... Training loss: 0.0069\n",
      "Epoch: 485/500... Training loss: 0.0030\n",
      "Epoch: 485/500... Training loss: 0.0051\n",
      "Epoch: 485/500... Training loss: 0.0049\n",
      "Epoch: 485/500... Training loss: 0.0020\n",
      "Epoch: 485/500... Training loss: 0.0018\n",
      "Epoch: 485/500... Training loss: 0.0007\n",
      "Epoch: 485/500... Training loss: 0.0013\n",
      "Epoch: 485/500... Training loss: 0.0044\n",
      "Epoch: 486/500... Training loss: 0.0009\n",
      "Epoch: 486/500... Training loss: 0.0005\n",
      "Epoch: 486/500... Training loss: 0.0020\n",
      "Epoch: 486/500... Training loss: 0.0008\n",
      "Epoch: 486/500... Training loss: 0.0002\n",
      "Epoch: 486/500... Training loss: 0.0009\n",
      "Epoch: 486/500... Training loss: 0.0062\n",
      "Epoch: 486/500... Training loss: 0.0009\n",
      "Epoch: 486/500... Training loss: 0.0242\n",
      "Epoch: 486/500... Training loss: 0.0012\n",
      "Epoch: 486/500... Training loss: 0.0942\n",
      "Epoch: 486/500... Training loss: 0.0015\n",
      "Epoch: 486/500... Training loss: 0.0028\n",
      "Epoch: 486/500... Training loss: 0.0101\n",
      "Epoch: 486/500... Training loss: 0.0010\n",
      "Epoch: 486/500... Training loss: 0.0035\n",
      "Epoch: 486/500... Training loss: 0.0034\n",
      "Epoch: 486/500... Training loss: 0.0012\n",
      "Epoch: 486/500... Training loss: 0.0030\n",
      "Epoch: 486/500... Training loss: 0.0016\n",
      "Epoch: 486/500... Training loss: 0.0009\n",
      "Epoch: 486/500... Training loss: 0.0061\n",
      "Epoch: 486/500... Training loss: 0.0029\n",
      "Epoch: 486/500... Training loss: 0.0012\n",
      "Epoch: 486/500... Training loss: 0.0034\n",
      "Epoch: 486/500... Training loss: 0.0262\n",
      "Epoch: 486/500... Training loss: 0.0006\n",
      "Epoch: 486/500... Training loss: 0.0138\n",
      "Epoch: 486/500... Training loss: 0.0030\n",
      "Epoch: 486/500... Training loss: 0.0027\n",
      "Epoch: 486/500... Training loss: 0.0004\n",
      "Epoch: 487/500... Training loss: 0.0041\n",
      "Epoch: 487/500... Training loss: 0.0008\n",
      "Epoch: 487/500... Training loss: 0.0019\n",
      "Epoch: 487/500... Training loss: 0.0005\n",
      "Epoch: 487/500... Training loss: 0.0089\n",
      "Epoch: 487/500... Training loss: 0.0129\n",
      "Epoch: 487/500... Training loss: 0.0070\n",
      "Epoch: 487/500... Training loss: 0.0010\n",
      "Epoch: 487/500... Training loss: 0.0085\n",
      "Epoch: 487/500... Training loss: 0.0042\n",
      "Epoch: 487/500... Training loss: 0.0916\n",
      "Epoch: 487/500... Training loss: 0.0006\n",
      "Epoch: 487/500... Training loss: 0.0044\n",
      "Epoch: 487/500... Training loss: 0.0118\n",
      "Epoch: 487/500... Training loss: 0.0022\n",
      "Epoch: 487/500... Training loss: 0.0006\n",
      "Epoch: 487/500... Training loss: 0.0317\n",
      "Epoch: 487/500... Training loss: 0.0003\n",
      "Epoch: 487/500... Training loss: 0.0026\n",
      "Epoch: 487/500... Training loss: 0.1205\n",
      "Epoch: 487/500... Training loss: 0.0010\n",
      "Epoch: 487/500... Training loss: 0.0028\n",
      "Epoch: 487/500... Training loss: 0.0005\n",
      "Epoch: 487/500... Training loss: 0.0531\n",
      "Epoch: 487/500... Training loss: 0.0134\n",
      "Epoch: 487/500... Training loss: 0.0036\n",
      "Epoch: 487/500... Training loss: 0.0012\n",
      "Epoch: 487/500... Training loss: 0.0273\n",
      "Epoch: 487/500... Training loss: 0.0022\n",
      "Epoch: 487/500... Training loss: 0.0128\n",
      "Epoch: 487/500... Training loss: 0.1081\n",
      "Epoch: 488/500... Training loss: 0.0017\n",
      "Epoch: 488/500... Training loss: 0.0125\n",
      "Epoch: 488/500... Training loss: 0.0683\n",
      "Epoch: 488/500... Training loss: 0.0013\n",
      "Epoch: 488/500... Training loss: 0.0042\n",
      "Epoch: 488/500... Training loss: 0.0064\n",
      "Epoch: 488/500... Training loss: 0.0065\n",
      "Epoch: 488/500... Training loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488/500... Training loss: 0.0007\n",
      "Epoch: 488/500... Training loss: 0.0005\n",
      "Epoch: 488/500... Training loss: 0.0019\n",
      "Epoch: 488/500... Training loss: 0.0012\n",
      "Epoch: 488/500... Training loss: 0.0066\n",
      "Epoch: 488/500... Training loss: 0.0006\n",
      "Epoch: 488/500... Training loss: 0.0007\n",
      "Epoch: 488/500... Training loss: 0.0035\n",
      "Epoch: 488/500... Training loss: 0.0029\n",
      "Epoch: 488/500... Training loss: 0.0004\n",
      "Epoch: 488/500... Training loss: 0.0041\n",
      "Epoch: 488/500... Training loss: 0.0013\n",
      "Epoch: 488/500... Training loss: 0.0011\n",
      "Epoch: 488/500... Training loss: 0.0213\n",
      "Epoch: 488/500... Training loss: 0.0037\n",
      "Epoch: 488/500... Training loss: 0.0014\n",
      "Epoch: 488/500... Training loss: 0.0035\n",
      "Epoch: 488/500... Training loss: 0.0144\n",
      "Epoch: 488/500... Training loss: 0.0014\n",
      "Epoch: 488/500... Training loss: 0.0424\n",
      "Epoch: 488/500... Training loss: 0.0315\n",
      "Epoch: 488/500... Training loss: 0.0046\n",
      "Epoch: 488/500... Training loss: 0.0016\n",
      "Epoch: 489/500... Training loss: 0.0017\n",
      "Epoch: 489/500... Training loss: 0.0018\n",
      "Epoch: 489/500... Training loss: 0.0017\n",
      "Epoch: 489/500... Training loss: 0.0019\n",
      "Epoch: 489/500... Training loss: 0.0009\n",
      "Epoch: 489/500... Training loss: 0.0024\n",
      "Epoch: 489/500... Training loss: 0.0089\n",
      "Epoch: 489/500... Training loss: 0.0017\n",
      "Epoch: 489/500... Training loss: 0.0093\n",
      "Epoch: 489/500... Training loss: 0.0007\n",
      "Epoch: 489/500... Training loss: 0.0064\n",
      "Epoch: 489/500... Training loss: 0.0626\n",
      "Epoch: 489/500... Training loss: 0.0026\n",
      "Epoch: 489/500... Training loss: 0.0158\n",
      "Epoch: 489/500... Training loss: 0.0233\n",
      "Epoch: 489/500... Training loss: 0.0063\n",
      "Epoch: 489/500... Training loss: 0.0003\n",
      "Epoch: 489/500... Training loss: 0.0111\n",
      "Epoch: 489/500... Training loss: 0.0010\n",
      "Epoch: 489/500... Training loss: 0.0010\n",
      "Epoch: 489/500... Training loss: 0.0525\n",
      "Epoch: 489/500... Training loss: 0.0027\n",
      "Epoch: 489/500... Training loss: 0.0023\n",
      "Epoch: 489/500... Training loss: 0.0005\n",
      "Epoch: 489/500... Training loss: 0.0022\n",
      "Epoch: 489/500... Training loss: 0.0009\n",
      "Epoch: 489/500... Training loss: 0.0210\n",
      "Epoch: 489/500... Training loss: 0.0022\n",
      "Epoch: 489/500... Training loss: 0.0008\n",
      "Epoch: 489/500... Training loss: 0.0074\n",
      "Epoch: 489/500... Training loss: 0.0007\n",
      "Epoch: 490/500... Training loss: 0.0132\n",
      "Epoch: 490/500... Training loss: 0.0165\n",
      "Epoch: 490/500... Training loss: 0.0053\n",
      "Epoch: 490/500... Training loss: 0.0033\n",
      "Epoch: 490/500... Training loss: 0.0011\n",
      "Epoch: 490/500... Training loss: 0.0028\n",
      "Epoch: 490/500... Training loss: 0.0004\n",
      "Epoch: 490/500... Training loss: 0.0003\n",
      "Epoch: 490/500... Training loss: 0.0017\n",
      "Epoch: 490/500... Training loss: 0.0007\n",
      "Epoch: 490/500... Training loss: 0.0021\n",
      "Epoch: 490/500... Training loss: 0.0471\n",
      "Epoch: 490/500... Training loss: 0.0925\n",
      "Epoch: 490/500... Training loss: 0.0065\n",
      "Epoch: 490/500... Training loss: 0.0494\n",
      "Epoch: 490/500... Training loss: 0.0009\n",
      "Epoch: 490/500... Training loss: 0.0009\n",
      "Epoch: 490/500... Training loss: 0.0007\n",
      "Epoch: 490/500... Training loss: 0.0066\n",
      "Epoch: 490/500... Training loss: 0.0027\n",
      "Epoch: 490/500... Training loss: 0.0014\n",
      "Epoch: 490/500... Training loss: 0.0762\n",
      "Epoch: 490/500... Training loss: 0.0012\n",
      "Epoch: 490/500... Training loss: 0.0175\n",
      "Epoch: 490/500... Training loss: 0.0015\n",
      "Epoch: 490/500... Training loss: 0.0019\n",
      "Epoch: 490/500... Training loss: 0.0055\n",
      "Epoch: 490/500... Training loss: 0.0034\n",
      "Epoch: 490/500... Training loss: 0.0030\n",
      "Epoch: 490/500... Training loss: 0.0039\n",
      "Epoch: 490/500... Training loss: 0.0034\n",
      "Epoch: 491/500... Training loss: 0.0004\n",
      "Epoch: 491/500... Training loss: 0.0008\n",
      "Epoch: 491/500... Training loss: 0.0138\n",
      "Epoch: 491/500... Training loss: 0.0017\n",
      "Epoch: 491/500... Training loss: 0.0031\n",
      "Epoch: 491/500... Training loss: 0.0031\n",
      "Epoch: 491/500... Training loss: 0.0027\n",
      "Epoch: 491/500... Training loss: 0.0128\n",
      "Epoch: 491/500... Training loss: 0.0020\n",
      "Epoch: 491/500... Training loss: 0.0012\n",
      "Epoch: 491/500... Training loss: 0.0013\n",
      "Epoch: 491/500... Training loss: 0.0085\n",
      "Epoch: 491/500... Training loss: 0.0011\n",
      "Epoch: 491/500... Training loss: 0.0008\n",
      "Epoch: 491/500... Training loss: 0.0132\n",
      "Epoch: 491/500... Training loss: 0.0006\n",
      "Epoch: 491/500... Training loss: 0.0631\n",
      "Epoch: 491/500... Training loss: 0.0006\n",
      "Epoch: 491/500... Training loss: 0.0034\n",
      "Epoch: 491/500... Training loss: 0.0043\n",
      "Epoch: 491/500... Training loss: 0.0082\n",
      "Epoch: 491/500... Training loss: 0.0170\n",
      "Epoch: 491/500... Training loss: 0.0009\n",
      "Epoch: 491/500... Training loss: 0.0004\n",
      "Epoch: 491/500... Training loss: 0.0004\n",
      "Epoch: 491/500... Training loss: 0.0015\n",
      "Epoch: 491/500... Training loss: 0.0082\n",
      "Epoch: 491/500... Training loss: 0.0305\n",
      "Epoch: 491/500... Training loss: 0.0242\n",
      "Epoch: 491/500... Training loss: 0.0363\n",
      "Epoch: 491/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0016\n",
      "Epoch: 492/500... Training loss: 0.0054\n",
      "Epoch: 492/500... Training loss: 0.0050\n",
      "Epoch: 492/500... Training loss: 0.0023\n",
      "Epoch: 492/500... Training loss: 0.0002\n",
      "Epoch: 492/500... Training loss: 0.0204\n",
      "Epoch: 492/500... Training loss: 0.0037\n",
      "Epoch: 492/500... Training loss: 0.0218\n",
      "Epoch: 492/500... Training loss: 0.0022\n",
      "Epoch: 492/500... Training loss: 0.0007\n",
      "Epoch: 492/500... Training loss: 0.0012\n",
      "Epoch: 492/500... Training loss: 0.0017\n",
      "Epoch: 492/500... Training loss: 0.0014\n",
      "Epoch: 492/500... Training loss: 0.0011\n",
      "Epoch: 492/500... Training loss: 0.0948\n",
      "Epoch: 492/500... Training loss: 0.0029\n",
      "Epoch: 492/500... Training loss: 0.0008\n",
      "Epoch: 492/500... Training loss: 0.0309\n",
      "Epoch: 492/500... Training loss: 0.0068\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0014\n",
      "Epoch: 492/500... Training loss: 0.0006\n",
      "Epoch: 492/500... Training loss: 0.0109\n",
      "Epoch: 492/500... Training loss: 0.0070\n",
      "Epoch: 492/500... Training loss: 0.0014\n",
      "Epoch: 492/500... Training loss: 0.0059\n",
      "Epoch: 492/500... Training loss: 0.0171\n",
      "Epoch: 492/500... Training loss: 0.1117\n",
      "Epoch: 492/500... Training loss: 0.0017\n",
      "Epoch: 492/500... Training loss: 0.0007\n",
      "Epoch: 492/500... Training loss: 0.0250\n",
      "Epoch: 493/500... Training loss: 0.0100\n",
      "Epoch: 493/500... Training loss: 0.0012\n",
      "Epoch: 493/500... Training loss: 0.0431\n",
      "Epoch: 493/500... Training loss: 0.0091\n",
      "Epoch: 493/500... Training loss: 0.0356\n",
      "Epoch: 493/500... Training loss: 0.0145\n",
      "Epoch: 493/500... Training loss: 0.0013\n",
      "Epoch: 493/500... Training loss: 0.0018\n",
      "Epoch: 493/500... Training loss: 0.0051\n",
      "Epoch: 493/500... Training loss: 0.0008\n",
      "Epoch: 493/500... Training loss: 0.0344\n",
      "Epoch: 493/500... Training loss: 0.0036\n",
      "Epoch: 493/500... Training loss: 0.0006\n",
      "Epoch: 493/500... Training loss: 0.0011\n",
      "Epoch: 493/500... Training loss: 0.0472\n",
      "Epoch: 493/500... Training loss: 0.0027\n",
      "Epoch: 493/500... Training loss: 0.0045\n",
      "Epoch: 493/500... Training loss: 0.0015\n",
      "Epoch: 493/500... Training loss: 0.0466\n",
      "Epoch: 493/500... Training loss: 0.0006\n",
      "Epoch: 493/500... Training loss: 0.0057\n",
      "Epoch: 493/500... Training loss: 0.0271\n",
      "Epoch: 493/500... Training loss: 0.0493\n",
      "Epoch: 493/500... Training loss: 0.0015\n",
      "Epoch: 493/500... Training loss: 0.0006\n",
      "Epoch: 493/500... Training loss: 0.0450\n",
      "Epoch: 493/500... Training loss: 0.0243\n",
      "Epoch: 493/500... Training loss: 0.0016\n",
      "Epoch: 493/500... Training loss: 0.0162\n",
      "Epoch: 493/500... Training loss: 0.0088\n",
      "Epoch: 493/500... Training loss: 0.0067\n",
      "Epoch: 494/500... Training loss: 0.0015\n",
      "Epoch: 494/500... Training loss: 0.0004\n",
      "Epoch: 494/500... Training loss: 0.0044\n",
      "Epoch: 494/500... Training loss: 0.0010\n",
      "Epoch: 494/500... Training loss: 0.0042\n",
      "Epoch: 494/500... Training loss: 0.0011\n",
      "Epoch: 494/500... Training loss: 0.0680\n",
      "Epoch: 494/500... Training loss: 0.0009\n",
      "Epoch: 494/500... Training loss: 0.0034\n",
      "Epoch: 494/500... Training loss: 0.0017\n",
      "Epoch: 494/500... Training loss: 0.0124\n",
      "Epoch: 494/500... Training loss: 0.0213\n",
      "Epoch: 494/500... Training loss: 0.0048\n",
      "Epoch: 494/500... Training loss: 0.0021\n",
      "Epoch: 494/500... Training loss: 0.0052\n",
      "Epoch: 494/500... Training loss: 0.0040\n",
      "Epoch: 494/500... Training loss: 0.0192\n",
      "Epoch: 494/500... Training loss: 0.0010\n",
      "Epoch: 494/500... Training loss: 0.0012\n",
      "Epoch: 494/500... Training loss: 0.0017\n",
      "Epoch: 494/500... Training loss: 0.0144\n",
      "Epoch: 494/500... Training loss: 0.0228\n",
      "Epoch: 494/500... Training loss: 0.0037\n",
      "Epoch: 494/500... Training loss: 0.0045\n",
      "Epoch: 494/500... Training loss: 0.0526\n",
      "Epoch: 494/500... Training loss: 0.0015\n",
      "Epoch: 494/500... Training loss: 0.0018\n",
      "Epoch: 494/500... Training loss: 0.0023\n",
      "Epoch: 494/500... Training loss: 0.0036\n",
      "Epoch: 494/500... Training loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 494/500... Training loss: 0.0018\n",
      "Epoch: 495/500... Training loss: 0.0410\n",
      "Epoch: 495/500... Training loss: 0.0043\n",
      "Epoch: 495/500... Training loss: 0.0046\n",
      "Epoch: 495/500... Training loss: 0.0056\n",
      "Epoch: 495/500... Training loss: 0.0017\n",
      "Epoch: 495/500... Training loss: 0.0505\n",
      "Epoch: 495/500... Training loss: 0.1107\n",
      "Epoch: 495/500... Training loss: 0.0661\n",
      "Epoch: 495/500... Training loss: 0.0041\n",
      "Epoch: 495/500... Training loss: 0.0014\n",
      "Epoch: 495/500... Training loss: 0.1481\n",
      "Epoch: 495/500... Training loss: 0.0083\n",
      "Epoch: 495/500... Training loss: 0.0325\n",
      "Epoch: 495/500... Training loss: 0.0052\n",
      "Epoch: 495/500... Training loss: 0.1095\n",
      "Epoch: 495/500... Training loss: 0.0006\n",
      "Epoch: 495/500... Training loss: 0.0011\n",
      "Epoch: 495/500... Training loss: 0.0009\n",
      "Epoch: 495/500... Training loss: 0.0306\n",
      "Epoch: 495/500... Training loss: 0.0021\n",
      "Epoch: 495/500... Training loss: 0.0020\n",
      "Epoch: 495/500... Training loss: 0.0019\n",
      "Epoch: 495/500... Training loss: 0.0069\n",
      "Epoch: 495/500... Training loss: 0.0007\n",
      "Epoch: 495/500... Training loss: 0.0010\n",
      "Epoch: 495/500... Training loss: 0.0572\n",
      "Epoch: 495/500... Training loss: 0.0030\n",
      "Epoch: 495/500... Training loss: 0.0152\n",
      "Epoch: 495/500... Training loss: 0.0046\n",
      "Epoch: 495/500... Training loss: 0.0347\n",
      "Epoch: 495/500... Training loss: 0.0162\n",
      "Epoch: 496/500... Training loss: 0.0021\n",
      "Epoch: 496/500... Training loss: 0.0064\n",
      "Epoch: 496/500... Training loss: 0.0217\n",
      "Epoch: 496/500... Training loss: 0.0470\n",
      "Epoch: 496/500... Training loss: 0.0157\n",
      "Epoch: 496/500... Training loss: 0.0129\n",
      "Epoch: 496/500... Training loss: 0.0011\n",
      "Epoch: 496/500... Training loss: 0.0009\n",
      "Epoch: 496/500... Training loss: 0.0285\n",
      "Epoch: 496/500... Training loss: 0.0104\n",
      "Epoch: 496/500... Training loss: 0.0048\n",
      "Epoch: 496/500... Training loss: 0.0026\n",
      "Epoch: 496/500... Training loss: 0.0044\n",
      "Epoch: 496/500... Training loss: 0.0017\n",
      "Epoch: 496/500... Training loss: 0.0535\n",
      "Epoch: 496/500... Training loss: 0.0030\n",
      "Epoch: 496/500... Training loss: 0.0335\n",
      "Epoch: 496/500... Training loss: 0.0015\n",
      "Epoch: 496/500... Training loss: 0.0045\n",
      "Epoch: 496/500... Training loss: 0.0010\n",
      "Epoch: 496/500... Training loss: 0.0064\n",
      "Epoch: 496/500... Training loss: 0.0011\n",
      "Epoch: 496/500... Training loss: 0.0079\n",
      "Epoch: 496/500... Training loss: 0.0005\n",
      "Epoch: 496/500... Training loss: 0.0059\n",
      "Epoch: 496/500... Training loss: 0.0035\n",
      "Epoch: 496/500... Training loss: 0.0009\n",
      "Epoch: 496/500... Training loss: 0.0020\n",
      "Epoch: 496/500... Training loss: 0.0062\n",
      "Epoch: 496/500... Training loss: 0.0181\n",
      "Epoch: 496/500... Training loss: 0.0569\n",
      "Epoch: 497/500... Training loss: 0.0025\n",
      "Epoch: 497/500... Training loss: 0.0127\n",
      "Epoch: 497/500... Training loss: 0.0023\n",
      "Epoch: 497/500... Training loss: 0.0013\n",
      "Epoch: 497/500... Training loss: 0.0204\n",
      "Epoch: 497/500... Training loss: 0.0022\n",
      "Epoch: 497/500... Training loss: 0.0446\n",
      "Epoch: 497/500... Training loss: 0.0185\n",
      "Epoch: 497/500... Training loss: 0.0027\n",
      "Epoch: 497/500... Training loss: 0.0220\n",
      "Epoch: 497/500... Training loss: 0.0105\n",
      "Epoch: 497/500... Training loss: 0.0099\n",
      "Epoch: 497/500... Training loss: 0.0016\n",
      "Epoch: 497/500... Training loss: 0.0016\n",
      "Epoch: 497/500... Training loss: 0.0137\n",
      "Epoch: 497/500... Training loss: 0.0068\n",
      "Epoch: 497/500... Training loss: 0.0734\n",
      "Epoch: 497/500... Training loss: 0.0087\n",
      "Epoch: 497/500... Training loss: 0.0082\n",
      "Epoch: 497/500... Training loss: 0.0003\n",
      "Epoch: 497/500... Training loss: 0.0080\n",
      "Epoch: 497/500... Training loss: 0.0138\n",
      "Epoch: 497/500... Training loss: 0.0049\n",
      "Epoch: 497/500... Training loss: 0.0101\n",
      "Epoch: 497/500... Training loss: 0.1679\n",
      "Epoch: 497/500... Training loss: 0.0150\n",
      "Epoch: 497/500... Training loss: 0.0037\n",
      "Epoch: 497/500... Training loss: 0.0013\n",
      "Epoch: 497/500... Training loss: 0.0144\n",
      "Epoch: 497/500... Training loss: 0.0030\n",
      "Epoch: 497/500... Training loss: 0.0764\n",
      "Epoch: 498/500... Training loss: 0.0025\n",
      "Epoch: 498/500... Training loss: 0.0016\n",
      "Epoch: 498/500... Training loss: 0.0122\n",
      "Epoch: 498/500... Training loss: 0.0062\n",
      "Epoch: 498/500... Training loss: 0.0008\n",
      "Epoch: 498/500... Training loss: 0.0276\n",
      "Epoch: 498/500... Training loss: 0.0623\n",
      "Epoch: 498/500... Training loss: 0.0084\n",
      "Epoch: 498/500... Training loss: 0.0028\n",
      "Epoch: 498/500... Training loss: 0.0106\n",
      "Epoch: 498/500... Training loss: 0.0110\n",
      "Epoch: 498/500... Training loss: 0.0022\n",
      "Epoch: 498/500... Training loss: 0.0006\n",
      "Epoch: 498/500... Training loss: 0.0059\n",
      "Epoch: 498/500... Training loss: 0.0150\n",
      "Epoch: 498/500... Training loss: 0.0409\n",
      "Epoch: 498/500... Training loss: 0.0048\n",
      "Epoch: 498/500... Training loss: 0.0027\n",
      "Epoch: 498/500... Training loss: 0.0252\n",
      "Epoch: 498/500... Training loss: 0.0007\n",
      "Epoch: 498/500... Training loss: 0.0085\n",
      "Epoch: 498/500... Training loss: 0.0030\n",
      "Epoch: 498/500... Training loss: 0.0058\n",
      "Epoch: 498/500... Training loss: 0.0017\n",
      "Epoch: 498/500... Training loss: 0.0040\n",
      "Epoch: 498/500... Training loss: 0.0007\n",
      "Epoch: 498/500... Training loss: 0.0015\n",
      "Epoch: 498/500... Training loss: 0.0289\n",
      "Epoch: 498/500... Training loss: 0.0028\n",
      "Epoch: 498/500... Training loss: 0.0368\n",
      "Epoch: 498/500... Training loss: 0.0245\n",
      "Epoch: 499/500... Training loss: 0.0033\n",
      "Epoch: 499/500... Training loss: 0.0268\n",
      "Epoch: 499/500... Training loss: 0.0068\n",
      "Epoch: 499/500... Training loss: 0.0440\n",
      "Epoch: 499/500... Training loss: 0.0025\n",
      "Epoch: 499/500... Training loss: 0.0340\n",
      "Epoch: 499/500... Training loss: 0.0011\n",
      "Epoch: 499/500... Training loss: 0.0035\n",
      "Epoch: 499/500... Training loss: 0.0019\n",
      "Epoch: 499/500... Training loss: 0.0012\n",
      "Epoch: 499/500... Training loss: 0.0010\n",
      "Epoch: 499/500... Training loss: 0.0236\n",
      "Epoch: 499/500... Training loss: 0.0164\n",
      "Epoch: 499/500... Training loss: 0.0016\n",
      "Epoch: 499/500... Training loss: 0.0008\n",
      "Epoch: 499/500... Training loss: 0.0573\n",
      "Epoch: 499/500... Training loss: 0.0012\n",
      "Epoch: 499/500... Training loss: 0.0006\n",
      "Epoch: 499/500... Training loss: 0.0550\n",
      "Epoch: 499/500... Training loss: 0.0290\n",
      "Epoch: 499/500... Training loss: 0.0223\n",
      "Epoch: 499/500... Training loss: 0.0042\n",
      "Epoch: 499/500... Training loss: 0.0012\n",
      "Epoch: 499/500... Training loss: 0.0008\n",
      "Epoch: 499/500... Training loss: 0.0023\n",
      "Epoch: 499/500... Training loss: 0.0020\n",
      "Epoch: 499/500... Training loss: 0.0466\n",
      "Epoch: 499/500... Training loss: 0.0021\n",
      "Epoch: 499/500... Training loss: 0.0208\n",
      "Epoch: 499/500... Training loss: 0.0228\n",
      "Epoch: 499/500... Training loss: 0.0165\n",
      "Epoch: 500/500... Training loss: 0.0227\n",
      "Epoch: 500/500... Training loss: 0.0006\n",
      "Epoch: 500/500... Training loss: 0.0013\n",
      "Epoch: 500/500... Training loss: 0.0010\n",
      "Epoch: 500/500... Training loss: 0.0139\n",
      "Epoch: 500/500... Training loss: 0.0031\n",
      "Epoch: 500/500... Training loss: 0.0014\n",
      "Epoch: 500/500... Training loss: 0.0793\n",
      "Epoch: 500/500... Training loss: 0.0483\n",
      "Epoch: 500/500... Training loss: 0.0011\n",
      "Epoch: 500/500... Training loss: 0.0251\n",
      "Epoch: 500/500... Training loss: 0.0083\n",
      "Epoch: 500/500... Training loss: 0.0048\n",
      "Epoch: 500/500... Training loss: 0.0019\n",
      "Epoch: 500/500... Training loss: 0.0099\n",
      "Epoch: 500/500... Training loss: 0.0143\n",
      "Epoch: 500/500... Training loss: 0.0172\n",
      "Epoch: 500/500... Training loss: 0.0030\n",
      "Epoch: 500/500... Training loss: 0.0061\n",
      "Epoch: 500/500... Training loss: 0.0021\n",
      "Epoch: 500/500... Training loss: 0.0008\n",
      "Epoch: 500/500... Training loss: 0.0013\n",
      "Epoch: 500/500... Training loss: 0.0785\n",
      "Epoch: 500/500... Training loss: 0.0138\n",
      "Epoch: 500/500... Training loss: 0.0029\n",
      "Epoch: 500/500... Training loss: 0.0271\n",
      "Epoch: 500/500... Training loss: 0.0037\n",
      "Epoch: 500/500... Training loss: 0.0643\n",
      "Epoch: 500/500... Training loss: 0.0042\n",
      "Epoch: 500/500... Training loss: 0.0022\n",
      "Epoch: 500/500... Training loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Adam optimizer\n",
    "opt = tf.train.AdamOptimizer(0.0005).minimize(cost)\n",
    "\n",
    "# Create the session\n",
    "sess = tf.Session()\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range((len(features)//batch_size) - 1):\n",
    "        batch = features[ii*batch_size:(ii + 1)*batch_size]\n",
    "        \n",
    "        # add random noise\n",
    "        for jj in batch:\n",
    "            jj[np.random.randint(vocab_size)] += 0.02\n",
    "            jj[np.random.randint(vocab_size)] -= 0.02\n",
    "        \n",
    "        targ = np.array(labels[ii*batch_size:(ii + 1)*batch_size])\n",
    "\n",
    "        feed = {inputs_: batch, targets_: targ}\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tampa', 'adam tp', 'adams twp')\n",
      "('cranberry twp', 'cranbrry twp', 'cranberry twp')\n",
      "('colley twp', 'middlesx twp', 'middlesex twp')\n",
      "('cresson', 'mars bro', 'mars boro')\n",
      "('whately', 'alleghey twp', 'allegheny twp')\n",
      "('blossburg boro', 'buin boro', 'bruin boro')\n",
      "('brady twp', 'brady twp', 'brady twp')\n",
      "('slippery rock twp', 'slippery rock twp', 'slippery rock twp')\n",
      "('west buffalo twp', 'buffalo twp', 'buffalo twp')\n",
      "('winfield twp', 'winfield twp', 'winfield twp')\n",
      "('butler city', 'butler city', 'butler city')\n",
      "('butler twp', 'butler twp', 'butler twp')\n",
      "('penn twp', 'pen twp', 'penn twp')\n",
      "('cairo', 'callry boro', 'callery boro')\n",
      "('center twp', 'center twp', 'center twp')\n",
      "('clay twp', 'clay twp', 'clay twp')\n",
      "('cherry twp', 'cherry twp', 'cherry twp')\n",
      "('cherry valley', 'cherry valley boro', 'cherry valley boro')\n",
      "('starrucca borough', 'chicora buro', 'chicora boro')\n",
      "('ripley', 'clearyield tp', 'clearfield twp')\n",
      "('ogle twp', 'dolegal twp', 'donegal twp')\n",
      "('summittwp', 'sumit twp', 'summit twp')\n",
      "('portland', 'clnon twp', 'clinton twp')\n",
      "('new oxford boro', 'connoq boro', 'connoq boro')\n",
      "('crawford twp', 'forard twp', 'forward twp')\n",
      "('connoq twp', 'connoq twp', 'connoq twp')\n",
      "('mt carmel twp', 'lanpaster twp', 'lancaster twp')\n",
      "('jefferson valley', 'sevez fiels boro', 'seven fields boro')\n",
      "('fairview twp', 'fairview twp', 'fairview twp')\n",
      "('east butler boro', 'east buter boro', 'east butler boro')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "originals = ['adams twp', 'cranberry twp', 'middlesex twp', 'mars boro', 'allegheny twp', \n",
    "    'bruin boro', 'brady twp', 'slippery rock twp', 'buffalo twp', 'winfield twp', 'butler city', \n",
    "    'butler twp', 'penn twp', 'callery boro', 'center twp', 'clay twp', 'cherry twp', 'cherry valley boro', \n",
    "    'chicora boro', 'clearfield twp', 'donegal twp', 'summit twp', 'clinton twp', 'connoq boro', 'forward twp', \n",
    "    'connoq twp', 'lancaster twp', 'seven fields boro', 'fairview twp', 'east butler boro']\n",
    "\n",
    "\n",
    "test_words = ['adam tp', 'cranbrry twp', 'middlesx twp', 'mars bro', 'alleghey twp', \n",
    "   'buin boro', 'brady twp', 'slippery rock twp', 'buffalo twp', 'winfield twp', 'butler city', \n",
    "   'butler twp', 'pen twp', 'callry boro', 'center twp', 'clay twp', 'cherry twp', 'cherry valley boro', \n",
    "   'chicora buro', 'clearyield tp', 'dolegal twp', 'sumit twp', 'clnon twp', 'connoq boro', 'forard twp', \n",
    "   'connoq twp', 'lanpaster twp', 'sevez fiels boro', 'fairview twp', 'east buter boro']\n",
    "\n",
    "in_words = []\n",
    "for word in test_words:\n",
    "    X = np.zeros(vocab_size)\n",
    "    for j in range(len(word)):\n",
    "        if word[j] in vocab_to_id:\n",
    "            X[vocab_to_id[word[j]]] += 1\n",
    "            \n",
    "    # normalize input sizes \n",
    "    X = ((X - X.min()) / (X.max() - X.min())) + 0.001\n",
    "    in_words.append(X)\n",
    "    \n",
    "in_words = np.array(in_words)\n",
    "\n",
    "reconstructed, compressed = sess.run([logits, encoded], feed_dict={inputs_: in_words})\n",
    "\n",
    "out_words = []\n",
    "for out, inp, org in zip(reconstructed, test_words, originals):\n",
    "    best_match = np.argmax(out)\n",
    "    \n",
    "    out_words.append((id_to_address[labels_to_id[best_match]], inp, org))\n",
    "    \n",
    "        \n",
    "for i in out_words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
